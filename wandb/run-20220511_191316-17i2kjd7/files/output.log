___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | -0.00742 |
| fps                | 29       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 165      |
---------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BDF478D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BDF478D0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BDEDFA20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BDEDFA20>>: AttributeError: module 'gast' has no attribute 'Index'
---------------------------------
| explained_variance | -0.00471 |
| fps                | 373      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 229      |
---------------------------------
886.0
886.0
886.0
886.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 886       |
| ep_reward_mean     | -2.96e+03 |
| explained_variance | -0.0326   |
| fps                | 403       |
| nupdates           | 200       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1000      |
| value_loss         | 143       |
----------------------------------
----------------------------------
| ep_len_mean        | 554       |
| ep_reward_mean     | -1.84e+03 |
| explained_variance | 0.0107    |
| fps                | 414       |
| nupdates           | 300       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1500      |
| value_loss         | 87.6      |
----------------------------------
62.0
62.0
437.0
400.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 437       |
| ep_reward_mean     | -1.36e+03 |
| explained_variance | 0.00564   |
| fps                | 409       |
| nupdates           | 400       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2000      |
| value_loss         | 460       |
----------------------------------
----------------------------------
| ep_len_mean        | 346       |
| ep_reward_mean     | -1.01e+03 |
| explained_variance | 0.00991   |
| fps                | 413       |
| nupdates           | 500       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2500      |
| value_loss         | 502       |
----------------------------------
113.0
113.0
320.22222222222223
258.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 320      |
| ep_reward_mean     | -910     |
| explained_variance | -0.0808  |
| fps                | 415      |
| nupdates           | 600      |
| policy_entropy     | 1.1      |
| total_timesteps    | 3000     |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 321      |
| ep_reward_mean     | -953     |
| explained_variance | -0.00422 |
| fps                | 415      |
| nupdates           | 700      |
| policy_entropy     | 1.09     |
| total_timesteps    | 3500     |
| value_loss         | 576      |
---------------------------------
342.0
342.0
322.6363636363636
284.0
---------------------------------
| ep_len_mean        | 323      |
| ep_reward_mean     | -986     |
| explained_variance | -0.00878 |
| fps                | 399      |
| nupdates           | 800      |
| policy_entropy     | 1.1      |
| total_timesteps    | 4000     |
| value_loss         | 159      |
---------------------------------
----------------------------------
| ep_len_mean        | 358       |
| ep_reward_mean     | -1.1e+03  |
| explained_variance | -0.000284 |
| fps                | 403       |
| nupdates           | 900       |
| policy_entropy     | 1.08      |
| total_timesteps    | 4500      |
| value_loss         | 154       |
----------------------------------
421.0
421.0
363.2307692307692
317.5
---------------------------------
| ep_len_mean        | 363      |
| ep_reward_mean     | -1.1e+03 |
| explained_variance | -0.0187  |
| fps                | 398      |
| nupdates           | 1000     |
| policy_entropy     | 1.05     |
| total_timesteps    | 5000     |
| value_loss         | 174      |
---------------------------------
----------------------------------
| ep_len_mean        | 380       |
| ep_reward_mean     | -1.2e+03  |
| explained_variance | -7.71e-05 |
| fps                | 396       |
| nupdates           | 1100      |
| policy_entropy     | 1.08      |
| total_timesteps    | 5500      |
| value_loss         | 355       |
----------------------------------
107.0
107.0
351.8235294117647
333.5
----------------------------------
| ep_len_mean        | 352       |
| ep_reward_mean     | -1.09e+03 |
| explained_variance | -6.82e-05 |
| fps                | 399       |
| nupdates           | 1200      |
| policy_entropy     | 1.09      |
| total_timesteps    | 6000      |
| value_loss         | 112       |
----------------------------------
----------------------------------
| ep_len_mean        | 337       |
| ep_reward_mean     | -1.02e+03 |
| explained_variance | 0.000296  |
| fps                | 401       |
| nupdates           | 1300      |
| policy_entropy     | 1.07      |
| total_timesteps    | 6500      |
| value_loss         | 168       |
----------------------------------
332.0
332.0
327.9047619047619
320.0
----------------------------------
| ep_len_mean        | 328       |
| ep_reward_mean     | -984      |
| explained_variance | -5.45e-05 |
| fps                | 403       |
| nupdates           | 1400      |
| policy_entropy     | 1.06      |
| total_timesteps    | 7000      |
| value_loss         | 109       |
----------------------------------
---------------------------------
| ep_len_mean        | 325      |
| ep_reward_mean     | -963     |
| explained_variance | 3.18e-05 |
| fps                | 406      |
| nupdates           | 1500     |
| policy_entropy     | 1.04     |
| total_timesteps    | 7500     |
| value_loss         | 9.08     |
---------------------------------
72.0
72.0
265.4
79.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 265      |
| ep_reward_mean     | -742     |
| explained_variance | 6.79e-05 |
| fps                | 408      |
| nupdates           | 1600     |
| policy_entropy     | 0.883    |
| total_timesteps    | 8000     |
| value_loss         | 217      |
---------------------------------
---------------------------------
| ep_len_mean        | 242      |
| ep_reward_mean     | -660     |
| explained_variance | 0.000149 |
| fps                | 408      |
| nupdates           | 1700     |
| policy_entropy     | 0.867    |
| total_timesteps    | 8500     |
| value_loss         | 122      |
---------------------------------
17.0
17.0
220.85
72.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 221       |
| ep_reward_mean     | -576      |
| explained_variance | -8.34e-06 |
| fps                | 409       |
| nupdates           | 1800      |
| policy_entropy     | 0.765     |
| total_timesteps    | 9000      |
| value_loss         | 126       |
----------------------------------
---------------------------------
| ep_len_mean        | 220      |
| ep_reward_mean     | -575     |
| explained_variance | 6.52e-05 |
| fps                | 411      |
| nupdates           | 1900     |
| policy_entropy     | 0.853    |
| total_timesteps    | 9500     |
| value_loss         | 123      |
---------------------------------
61.0
61.0
185.0
40.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 185      |
| ep_reward_mean     | -442     |
| explained_variance | -0.0078  |
| fps                | 412      |
| nupdates           | 2000     |
| policy_entropy     | 0.745    |
| total_timesteps    | 10000    |
| value_loss         | 32.5     |
---------------------------------
----------------------------------
| ep_len_mean        | 154       |
| ep_reward_mean     | -327      |
| explained_variance | -0.000714 |
| fps                | 413       |
| nupdates           | 2100      |
| policy_entropy     | 0.6       |
| total_timesteps    | 10500     |
| value_loss         | 95.8      |
----------------------------------
16.0
16.0
146.64
55.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 147       |
| ep_reward_mean     | -296      |
| explained_variance | -1.41e-05 |
| fps                | 414       |
| nupdates           | 2200      |
| policy_entropy     | 0.558     |
| total_timesteps    | 11000     |
| value_loss         | 4.09e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 133      |
| ep_reward_mean     | -244     |
| explained_variance | 0.000282 |
| fps                | 415      |
| nupdates           | 2300     |
| policy_entropy     | 0.786    |
| total_timesteps    | 11500    |
| value_loss         | 197      |
---------------------------------
157.0
157.0
120.97979797979798
19.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 121      |
| ep_reward_mean     | -196     |
| explained_variance | -0.00112 |
| fps                | 416      |
| nupdates           | 2400     |
| policy_entropy     | 0.631    |
| total_timesteps    | 12000    |
| value_loss         | 47.1     |
---------------------------------
----------------------------------
| ep_len_mean        | 66.3      |
| ep_reward_mean     | 15.2      |
| explained_variance | -3.28e-05 |
| fps                | 416       |
| nupdates           | 2500      |
| policy_entropy     | 0.336     |
| total_timesteps    | 12500     |
| value_loss         | 6.78e+04  |
----------------------------------
26.0
26.0
46.12
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 46.1     |
| ep_reward_mean     | 90.4     |
| explained_variance | 0.00427  |
| fps                | 417      |
| nupdates           | 2600     |
| policy_entropy     | 0.307    |
| total_timesteps    | 13000    |
| value_loss         | 617      |
---------------------------------
----------------------------------
| ep_len_mean        | 39.3      |
| ep_reward_mean     | 115       |
| explained_variance | -0.000435 |
| fps                | 418       |
| nupdates           | 2700      |
| policy_entropy     | 0.522     |
| total_timesteps    | 13500     |
| value_loss         | 1.6e+04   |
----------------------------------
10.0
10.0
38.37
20.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 38.4     |
| ep_reward_mean     | 122      |
| explained_variance | 1.58e-05 |
| fps                | 418      |
| nupdates           | 2800     |
| policy_entropy     | 0.606    |
| total_timesteps    | 14000    |
| value_loss         | 3.03e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 34.2     |
| ep_reward_mean     | 141      |
| explained_variance | 0.135    |
| fps                | 419      |
| nupdates           | 2900     |
| policy_entropy     | 0.19     |
| total_timesteps    | 14500    |
| value_loss         | 371      |
---------------------------------
17.0
17.0
34.43
17.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 34.4     |
| ep_reward_mean     | 144      |
| explained_variance | 0.133    |
| fps                | 417      |
| nupdates           | 3000     |
| policy_entropy     | 0.482    |
| total_timesteps    | 15000    |
| value_loss         | 356      |
---------------------------------
---------------------------------
| ep_len_mean        | 30.3     |
| ep_reward_mean     | 157      |
| explained_variance | 0        |
| fps                | 417      |
| nupdates           | 3100     |
| policy_entropy     | 0.361    |
| total_timesteps    | 15500    |
| value_loss         | 14.4     |
---------------------------------
20.0
20.0
31.29
18.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 31.3     |
| ep_reward_mean     | 156      |
| explained_variance | -0.32    |
| fps                | 417      |
| nupdates           | 3200     |
| policy_entropy     | 0.301    |
| total_timesteps    | 16000    |
| value_loss         | 41.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 34.1     |
| ep_reward_mean     | 150      |
| explained_variance | -0.247   |
| fps                | 417      |
| nupdates           | 3300     |
| policy_entropy     | 0.147    |
| total_timesteps    | 16500    |
| value_loss         | 7.66e+04 |
---------------------------------
11.0
11.0
34.8
10.0
---------------------------------
| ep_len_mean        | 34.8     |
| ep_reward_mean     | 151      |
| explained_variance | -0.00103 |
| fps                | 418      |
| nupdates           | 3400     |
| policy_entropy     | 0.7      |
| total_timesteps    | 17000    |
| value_loss         | 45.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 33.4     |
| ep_reward_mean     | 153      |
| explained_variance | -5.24    |
| fps                | 418      |
| nupdates           | 3500     |
| policy_entropy     | 0.635    |
| total_timesteps    | 17500    |
| value_loss         | 107      |
---------------------------------
9.0
9.0
30.18
13.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 30.2     |
| ep_reward_mean     | 160      |
| explained_variance | 0        |
| fps                | 418      |
| nupdates           | 3600     |
| policy_entropy     | 0.187    |
| total_timesteps    | 18000    |
| value_loss         | 11.4     |
---------------------------------
----------------------------------
| ep_len_mean        | 33.4      |
| ep_reward_mean     | 148       |
| explained_variance | -1.19e-07 |
| fps                | 419       |
| nupdates           | 3700      |
| policy_entropy     | 0.259     |
| total_timesteps    | 18500     |
| value_loss         | 95.3      |
----------------------------------
15.0
15.0
35.82
12.0
---------------------------------
| ep_len_mean        | 35.8     |
| ep_reward_mean     | 142      |
| explained_variance | 0.112    |
| fps                | 419      |
| nupdates           | 3800     |
| policy_entropy     | 0.481    |
| total_timesteps    | 19000    |
| value_loss         | 104      |
---------------------------------
----------------------------------
| ep_len_mean        | 35.3      |
| ep_reward_mean     | 142       |
| explained_variance | -1.19e-07 |
| fps                | 420       |
| nupdates           | 3900      |
| policy_entropy     | 0.571     |
| total_timesteps    | 19500     |
| value_loss         | 9.58      |
----------------------------------
11.0
11.0
34.27
11.0
---------------------------------
| ep_len_mean        | 34.3     |
| ep_reward_mean     | 146      |
| explained_variance | 0.000314 |
| fps                | 420      |
| nupdates           | 4000     |
| policy_entropy     | 0.81     |
| total_timesteps    | 20000    |
| value_loss         | 157      |
---------------------------------
---------------------------------
| ep_len_mean        | 35.5     |
| ep_reward_mean     | 141      |
| explained_variance | 0.107    |
| fps                | 420      |
| nupdates           | 4100     |
| policy_entropy     | 0.415    |
| total_timesteps    | 20500    |
| value_loss         | 178      |
---------------------------------
12.0
12.0
38.62
18.5
---------------------------------
| ep_len_mean        | 38.6     |
| ep_reward_mean     | 130      |
| explained_variance | -0.534   |
| fps                | 419      |
| nupdates           | 4200     |
| policy_entropy     | 0.464    |
| total_timesteps    | 21000    |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 38.5     |
| ep_reward_mean     | 134      |
| explained_variance | -0.0125  |
| fps                | 418      |
| nupdates           | 4300     |
| policy_entropy     | 0.742    |
| total_timesteps    | 21500    |
| value_loss         | 3.95e+04 |
---------------------------------
10.0
10.0
36.64
15.0
---------------------------------
| ep_len_mean        | 36.6     |
| ep_reward_mean     | 140      |
| explained_variance | 0.0026   |
| fps                | 417      |
| nupdates           | 4400     |
| policy_entropy     | 0.43     |
| total_timesteps    | 22000    |
| value_loss         | 5.91e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 36.3     |
| ep_reward_mean     | 141      |
| explained_variance | 0.00842  |
| fps                | 418      |
| nupdates           | 4500     |
| policy_entropy     | 0.146    |
| total_timesteps    | 22500    |
| value_loss         | 5.8e+04  |
---------------------------------
10.0
10.0
33.62
12.5
---------------------------------
| ep_len_mean        | 33.6     |
| ep_reward_mean     | 149      |
| explained_variance | -0.0247  |
| fps                | 417      |
| nupdates           | 4600     |
| policy_entropy     | 0.485    |
| total_timesteps    | 23000    |
| value_loss         | 4.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 27.5     |
| ep_reward_mean     | 166      |
| explained_variance | 0.217    |
| fps                | 417      |
| nupdates           | 4700     |
| policy_entropy     | 0.361    |
| total_timesteps    | 23500    |
| value_loss         | 122      |
---------------------------------
8.0
8.0
25.42
28.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 171      |
| explained_variance | -0.0349  |
| fps                | 417      |
| nupdates           | 4800     |
| policy_entropy     | 0.114    |
| total_timesteps    | 24000    |
| value_loss         | 5.85e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 24.2     |
| ep_reward_mean     | 175      |
| explained_variance | -0.251   |
| fps                | 418      |
| nupdates           | 4900     |
| policy_entropy     | 0.459    |
| total_timesteps    | 24500    |
| value_loss         | 9.62     |
---------------------------------
24.0
24.0
25.4
23.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 171      |
| explained_variance | -0.158   |
| fps                | 418      |
| nupdates           | 5000     |
| policy_entropy     | 0.173    |
| total_timesteps    | 25000    |
| value_loss         | 83.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 171      |
| explained_variance | -0.061   |
| fps                | 419      |
| nupdates           | 5100     |
| policy_entropy     | 0.374    |
| total_timesteps    | 25500    |
| value_loss         | 143      |
---------------------------------
33.0
33.0
25.1
13.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 174      |
| explained_variance | 0.513    |
| fps                | 419      |
| nupdates           | 5200     |
| policy_entropy     | 0.547    |
| total_timesteps    | 26000    |
| value_loss         | 45.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 26.3     |
| ep_reward_mean     | 170      |
| explained_variance | -0.396   |
| fps                | 419      |
| nupdates           | 5300     |
| policy_entropy     | 0.517    |
| total_timesteps    | 26500    |
| value_loss         | 5.91     |
---------------------------------
10.0
10.0
23.25
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 23.2     |
| ep_reward_mean     | 179      |
| explained_variance | -0.47    |
| fps                | 419      |
| nupdates           | 5400     |
| policy_entropy     | 0.344    |
| total_timesteps    | 27000    |
| value_loss         | 97.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 21.7     |
| ep_reward_mean     | 186      |
| explained_variance | 0.118    |
| fps                | 418      |
| nupdates           | 5500     |
| policy_entropy     | 0.297    |
| total_timesteps    | 27500    |
| value_loss         | 45.8     |
---------------------------------
11.0
11.0
22.44
20.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 184      |
| explained_variance | 5.78e-06 |
| fps                | 418      |
| nupdates           | 5600     |
| policy_entropy     | 0.729    |
| total_timesteps    | 28000    |
| value_loss         | 4.35     |
---------------------------------
---------------------------------
| ep_len_mean        | 26.7     |
| ep_reward_mean     | 174      |
| explained_variance | -0.00635 |
| fps                | 418      |
| nupdates           | 5700     |
| policy_entropy     | 0.317    |
| total_timesteps    | 28500    |
| value_loss         | 122      |
---------------------------------
56.0
56.0
25.64
13.0
---------------------------------
| ep_len_mean        | 25.6     |
| ep_reward_mean     | 180      |
| explained_variance | -9.65    |
| fps                | 418      |
| nupdates           | 5800     |
| policy_entropy     | 0.568    |
| total_timesteps    | 29000    |
| value_loss         | 66.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 179      |
| explained_variance | 0.0254   |
| fps                | 419      |
| nupdates           | 5900     |
| policy_entropy     | 0.419    |
| total_timesteps    | 29500    |
| value_loss         | 0.347    |
---------------------------------
24.0
24.0
26.67
23.0
---------------------------------
| ep_len_mean        | 26.7     |
| ep_reward_mean     | 178      |
| explained_variance | 0        |
| fps                | 419      |
| nupdates           | 6000     |
| policy_entropy     | 0.509    |
| total_timesteps    | 30000    |
| value_loss         | 3.82     |
---------------------------------
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 191      |
| explained_variance | 0.74     |
| fps                | 419      |
| nupdates           | 6100     |
| policy_entropy     | 0.163    |
| total_timesteps    | 30500    |
| value_loss         | 32.4     |
---------------------------------
10.0
10.0
21.67
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 21.7     |
| ep_reward_mean     | 191      |
| explained_variance | 0.528    |
| fps                | 418      |
| nupdates           | 6200     |
| policy_entropy     | 0.461    |
| total_timesteps    | 31000    |
| value_loss         | 7.07     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.3     |
| ep_reward_mean     | 191      |
| explained_variance | -3.38    |
| fps                | 418      |
| nupdates           | 6300     |
| policy_entropy     | 0.104    |
| total_timesteps    | 31500    |
| value_loss         | 50.9     |
---------------------------------
22.0
22.0
24.73
17.0
---------------------------------
| ep_len_mean        | 24.7     |
| ep_reward_mean     | 187      |
| explained_variance | 0.0268   |
| fps                | 417      |
| nupdates           | 6400     |
| policy_entropy     | 0.872    |
| total_timesteps    | 32000    |
| value_loss         | 3        |
---------------------------------
---------------------------------
| ep_len_mean        | 24.1     |
| ep_reward_mean     | 188      |
| explained_variance | -15.8    |
| fps                | 417      |
| nupdates           | 6500     |
| policy_entropy     | 0.0425   |
| total_timesteps    | 32500    |
| value_loss         | 55       |
---------------------------------
62.0
62.0
23.17
13.0
---------------------------------
| ep_len_mean        | 23.2     |
| ep_reward_mean     | 190      |
| explained_variance | 0        |
| fps                | 417      |
| nupdates           | 6600     |
| policy_entropy     | 0.206    |
| total_timesteps    | 33000    |
| value_loss         | 67.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 194      |
| explained_variance | -10.2    |
| fps                | 416      |
| nupdates           | 6700     |
| policy_entropy     | 0.373    |
| total_timesteps    | 33500    |
| value_loss         | 61.2     |
---------------------------------
28.0
28.0
18.26
17.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 199      |
| explained_variance | -15.2    |
| fps                | 415      |
| nupdates           | 6800     |
| policy_entropy     | 0.346    |
| total_timesteps    | 34000    |
| value_loss         | 44.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 199      |
| explained_variance | -0.368   |
| fps                | 415      |
| nupdates           | 6900     |
| policy_entropy     | 0.148    |
| total_timesteps    | 34500    |
| value_loss         | 15       |
---------------------------------
39.0
39.0
18.69
17.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 199      |
| explained_variance | 0        |
| fps                | 416      |
| nupdates           | 7000     |
| policy_entropy     | 0.918    |
| total_timesteps    | 35000    |
| value_loss         | 0.928    |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 197      |
| explained_variance | -3.18    |
| fps                | 416      |
| nupdates           | 7100     |
| policy_entropy     | 0.39     |
| total_timesteps    | 35500    |
| value_loss         | 78.3     |
---------------------------------
9.0
9.0
18.62
10.5
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 199      |
| explained_variance | -0.0939  |
| fps                | 416      |
| nupdates           | 7200     |
| policy_entropy     | 0.0355   |
| total_timesteps    | 36000    |
| value_loss         | 873      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.0963  |
| fps                | 416      |
| nupdates           | 7300     |
| policy_entropy     | 0.0472   |
| total_timesteps    | 36500    |
| value_loss         | 3.6e+04  |
---------------------------------
9.0
9.0
15.16
9.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 207      |
| explained_variance | -0.0182  |
| fps                | 416      |
| nupdates           | 7400     |
| policy_entropy     | 0.246    |
| total_timesteps    | 37000    |
| value_loss         | 2.77e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0173   |
| fps                | 417      |
| nupdates           | 7500     |
| policy_entropy     | 0.0266   |
| total_timesteps    | 37500    |
| value_loss         | 166      |
---------------------------------
10.0
10.0
15.11
13.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 208      |
| explained_variance | -0.188   |
| fps                | 417      |
| nupdates           | 7600     |
| policy_entropy     | 0.0405   |
| total_timesteps    | 38000    |
| value_loss         | 188      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.0643   |
| fps                | 417      |
| nupdates           | 7700     |
| policy_entropy     | 0.341    |
| total_timesteps    | 38500    |
| value_loss         | 8.68e+03 |
---------------------------------
9.0
9.0
13.79
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.0248   |
| fps                | 417      |
| nupdates           | 7800     |
| policy_entropy     | 0.036    |
| total_timesteps    | 39000    |
| value_loss         | 8.14e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.594    |
| fps                | 417      |
| nupdates           | 7900     |
| policy_entropy     | 0.536    |
| total_timesteps    | 39500    |
| value_loss         | 140      |
---------------------------------
8.0
8.0
16.09
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0.163    |
| fps                | 416      |
| nupdates           | 8000     |
| policy_entropy     | 0.0929   |
| total_timesteps    | 40000    |
| value_loss         | 1.51e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | -4.2     |
| fps                | 417      |
| nupdates           | 8100     |
| policy_entropy     | 0.366    |
| total_timesteps    | 40500    |
| value_loss         | 322      |
---------------------------------
10.0
10.0
15.69
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 206      |
| explained_variance | 0.34     |
| fps                | 417      |
| nupdates           | 8200     |
| policy_entropy     | 0.0284   |
| total_timesteps    | 41000    |
| value_loss         | 7.36e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | -1.67    |
| fps                | 417      |
| nupdates           | 8300     |
| policy_entropy     | 0.211    |
| total_timesteps    | 41500    |
| value_loss         | 263      |
---------------------------------
25.0
25.0
16.82
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.279    |
| fps                | 417      |
| nupdates           | 8400     |
| policy_entropy     | 0.0414   |
| total_timesteps    | 42000    |
| value_loss         | 7.15e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0639   |
| fps                | 418      |
| nupdates           | 8500     |
| policy_entropy     | 0.256    |
| total_timesteps    | 42500    |
| value_loss         | 7.39e+03 |
---------------------------------
8.0
8.0
16.06
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 208      |
| explained_variance | -0.615   |
| fps                | 418      |
| nupdates           | 8600     |
| policy_entropy     | 0.222    |
| total_timesteps    | 43000    |
| value_loss         | 364      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 208      |
| explained_variance | -0.223   |
| fps                | 418      |
| nupdates           | 8700     |
| policy_entropy     | 0.0772   |
| total_timesteps    | 43500    |
| value_loss         | 2.7e+03  |
---------------------------------
9.0
9.0
14.56
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.192    |
| fps                | 418      |
| nupdates           | 8800     |
| policy_entropy     | 0.0366   |
| total_timesteps    | 44000    |
| value_loss         | 156      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.297    |
| fps                | 417      |
| nupdates           | 8900     |
| policy_entropy     | 0.132    |
| total_timesteps    | 44500    |
| value_loss         | 227      |
---------------------------------
9.0
9.0
17.25
11.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 209      |
| explained_variance | -0.144   |
| fps                | 417      |
| nupdates           | 9000     |
| policy_entropy     | 0.0611   |
| total_timesteps    | 45000    |
| value_loss         | 4.05e+03 |
---------------------------------
----------------------------------
| ep_len_mean        | 18        |
| ep_reward_mean     | 204       |
| explained_variance | -2.38e-07 |
| fps                | 417       |
| nupdates           | 9100      |
| policy_entropy     | 0.511     |
| total_timesteps    | 45500     |
| value_loss         | 165       |
----------------------------------
8.0
8.0
19.98
10.0
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 196      |
| explained_variance | 0.121    |
| fps                | 417      |
| nupdates           | 9200     |
| policy_entropy     | 0.155    |
| total_timesteps    | 46000    |
| value_loss         | 49.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 196      |
| explained_variance | -5.42    |
| fps                | 417      |
| nupdates           | 9300     |
| policy_entropy     | 0.0346   |
| total_timesteps    | 46500    |
| value_loss         | 85.8     |
---------------------------------
22.0
22.0
17.67
21.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 199      |
| explained_variance | 0.232    |
| fps                | 417      |
| nupdates           | 9400     |
| policy_entropy     | 0.598    |
| total_timesteps    | 47000    |
| value_loss         | 110      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 205      |
| explained_variance | -5.95    |
| fps                | 417      |
| nupdates           | 9500     |
| policy_entropy     | 0.246    |
| total_timesteps    | 47500    |
| value_loss         | 199      |
---------------------------------
28.0
28.0
17.64
11.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 202      |
| explained_variance | 0.118    |
| fps                | 418      |
| nupdates           | 9600     |
| policy_entropy     | 0.335    |
| total_timesteps    | 48000    |
| value_loss         | 69.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 201      |
| explained_variance | 1.19e-07 |
| fps                | 418      |
| nupdates           | 9700     |
| policy_entropy     | 0.354    |
| total_timesteps    | 48500    |
| value_loss         | 105      |
---------------------------------
10.0
10.0
18.12
10.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 198      |
| explained_variance | -2.26    |
| fps                | 417      |
| nupdates           | 9800     |
| policy_entropy     | 0.299    |
| total_timesteps    | 49000    |
| value_loss         | 65.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 199      |
| explained_variance | -13.1    |
| fps                | 417      |
| nupdates           | 9900     |
| policy_entropy     | 0.0648   |
| total_timesteps    | 49500    |
| value_loss         | 214      |
---------------------------------
9.0
9.0
15.82
9.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 204      |
| explained_variance | 0.376    |
| fps                | 417      |
| nupdates           | 10000    |
| policy_entropy     | 0.543    |
| total_timesteps    | 50000    |
| value_loss         | 89.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.537    |
| fps                | 418      |
| nupdates           | 10100    |
| policy_entropy     | 0.43     |
| total_timesteps    | 50500    |
| value_loss         | 125      |
---------------------------------
9.0
9.0
15.93
20.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.92     |
| fps                | 418      |
| nupdates           | 10200    |
| policy_entropy     | 0.0334   |
| total_timesteps    | 51000    |
| value_loss         | 53.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | -5.75    |
| fps                | 418      |
| nupdates           | 10300    |
| policy_entropy     | 0.0604   |
| total_timesteps    | 51500    |
| value_loss         | 701      |
---------------------------------
9.0
9.0
15.99
10.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | 0.626    |
| fps                | 418      |
| nupdates           | 10400    |
| policy_entropy     | 0.0299   |
| total_timesteps    | 52000    |
| value_loss         | 6.39e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.228    |
| fps                | 418      |
| nupdates           | 10500    |
| policy_entropy     | 0.0833   |
| total_timesteps    | 52500    |
| value_loss         | 1.4e+03  |
---------------------------------
26.0
26.0
16.4
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 207      |
| explained_variance | -1.67    |
| fps                | 418      |
| nupdates           | 10600    |
| policy_entropy     | 0.262    |
| total_timesteps    | 53000    |
| value_loss         | 6.96e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 207      |
| explained_variance | -1.73    |
| fps                | 418      |
| nupdates           | 10700    |
| policy_entropy     | 0.0721   |
| total_timesteps    | 53500    |
| value_loss         | 90.4     |
---------------------------------
22.0
22.0
15.86
16.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.62     |
| fps                | 418      |
| nupdates           | 10800    |
| policy_entropy     | 0.254    |
| total_timesteps    | 54000    |
| value_loss         | 2.03e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0.711    |
| fps                | 418      |
| nupdates           | 10900    |
| policy_entropy     | 0.0282   |
| total_timesteps    | 54500    |
| value_loss         | 3.64e+03 |
---------------------------------
10.0
10.0
15.9
13.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.28     |
| fps                | 418      |
| nupdates           | 11000    |
| policy_entropy     | 0.0419   |
| total_timesteps    | 55000    |
| value_loss         | 1.4e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 207      |
| explained_variance | -0.173   |
| fps                | 418      |
| nupdates           | 11100    |
| policy_entropy     | 0.0236   |
| total_timesteps    | 55500    |
| value_loss         | 349      |
---------------------------------
27.0
27.0
15.97
20.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 206      |
| explained_variance | -0.941   |
| fps                | 418      |
| nupdates           | 11200    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 56000    |
| value_loss         | 172      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 204      |
| explained_variance | -0.311   |
| fps                | 417      |
| nupdates           | 11300    |
| policy_entropy     | 0.574    |
| total_timesteps    | 56500    |
| value_loss         | 165      |
---------------------------------
23.0
23.0
16.55
11.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | 0.755    |
| fps                | 417      |
| nupdates           | 11400    |
| policy_entropy     | 0.119    |
| total_timesteps    | 57000    |
| value_loss         | 70.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 202      |
| explained_variance | -5.2     |
| fps                | 417      |
| nupdates           | 11500    |
| policy_entropy     | 0.602    |
| total_timesteps    | 57500    |
| value_loss         | 807      |
---------------------------------
10.0
10.0
17.76
10.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 202      |
| explained_variance | -0.347   |
| fps                | 417      |
| nupdates           | 11600    |
| policy_entropy     | 0.0481   |
| total_timesteps    | 58000    |
| value_loss         | 91.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 202      |
| explained_variance | 0.0293   |
| fps                | 416      |
| nupdates           | 11700    |
| policy_entropy     | 0.0417   |
| total_timesteps    | 58500    |
| value_loss         | 174      |
---------------------------------
9.0
9.0
15.84
9.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.327   |
| fps                | 416      |
| nupdates           | 11800    |
| policy_entropy     | 0.082    |
| total_timesteps    | 59000    |
| value_loss         | 2.29e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 205      |
| explained_variance | 0.898    |
| fps                | 416      |
| nupdates           | 11900    |
| policy_entropy     | 0.115    |
| total_timesteps    | 59500    |
| value_loss         | 180      |
---------------------------------
10.0
10.0
17.73
20.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 204      |
| explained_variance | -0.264   |
| fps                | 417      |
| nupdates           | 12000    |
| policy_entropy     | 0.038    |
| total_timesteps    | 60000    |
| value_loss         | 325      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 204      |
| explained_variance | -1.56    |
| fps                | 417      |
| nupdates           | 12100    |
| policy_entropy     | 0.0458   |
| total_timesteps    | 60500    |
| value_loss         | 307      |
---------------------------------
10.0
10.0
16.65
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | -1.62    |
| fps                | 417      |
| nupdates           | 12200    |
| policy_entropy     | 0.379    |
| total_timesteps    | 61000    |
| value_loss         | 732      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 209      |
| explained_variance | -1.7     |
| fps                | 417      |
| nupdates           | 12300    |
| policy_entropy     | 0.134    |
| total_timesteps    | 61500    |
| value_loss         | 5.52e+03 |
---------------------------------
9.0
9.0
14.93
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 209      |
| explained_variance | -0.502   |
| fps                | 417      |
| nupdates           | 12400    |
| policy_entropy     | 0.061    |
| total_timesteps    | 62000    |
| value_loss         | 740      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 207      |
| explained_variance | 0.225    |
| fps                | 417      |
| nupdates           | 12500    |
| policy_entropy     | 0.102    |
| total_timesteps    | 62500    |
| value_loss         | 436      |
---------------------------------
24.0
24.0
15.82
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | -1.28    |
| fps                | 417      |
| nupdates           | 12600    |
| policy_entropy     | 0.137    |
| total_timesteps    | 63000    |
| value_loss         | 1.59e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.603    |
| fps                | 415      |
| nupdates           | 12700    |
| policy_entropy     | 0.326    |
| total_timesteps    | 63500    |
| value_loss         | 65.9     |
---------------------------------
10.0
10.0
17.38
16.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 202      |
| explained_variance | 0.496    |
| fps                | 415      |
| nupdates           | 12800    |
| policy_entropy     | 0.187    |
| total_timesteps    | 64000    |
| value_loss         | 98.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 208      |
| explained_variance | -3.7     |
| fps                | 415      |
| nupdates           | 12900    |
| policy_entropy     | 0.612    |
| total_timesteps    | 64500    |
| value_loss         | 293      |
---------------------------------
23.0
23.0
16.31
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 206      |
| explained_variance | -0.427   |
| fps                | 415      |
| nupdates           | 13000    |
| policy_entropy     | 0.0365   |
| total_timesteps    | 65000    |
| value_loss         | 77.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.328    |
| fps                | 415      |
| nupdates           | 13100    |
| policy_entropy     | 0.0403   |
| total_timesteps    | 65500    |
| value_loss         | 252      |
---------------------------------
9.0
9.0
16.45
9.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.385    |
| fps                | 415      |
| nupdates           | 13200    |
| policy_entropy     | 0.125    |
| total_timesteps    | 66000    |
| value_loss         | 856      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 206      |
| explained_variance | 0.696    |
| fps                | 415      |
| nupdates           | 13300    |
| policy_entropy     | 0.0151   |
| total_timesteps    | 66500    |
| value_loss         | 1.06e+03 |
---------------------------------
10.0
10.0
14.86
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 208      |
| explained_variance | -0.0279  |
| fps                | 415      |
| nupdates           | 13400    |
| policy_entropy     | 0.0287   |
| total_timesteps    | 67000    |
| value_loss         | 227      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 206      |
| explained_variance | -1.8     |
| fps                | 415      |
| nupdates           | 13500    |
| policy_entropy     | 0.152    |
| total_timesteps    | 67500    |
| value_loss         | 255      |
---------------------------------
23.0
23.0
16.08
10.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 207      |
| explained_variance | -2.97    |
| fps                | 415      |
| nupdates           | 13600    |
| policy_entropy     | 0.041    |
| total_timesteps    | 68000    |
| value_loss         | 1.48e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | -26.2    |
| fps                | 415      |
| nupdates           | 13700    |
| policy_entropy     | 0.733    |
| total_timesteps    | 68500    |
| value_loss         | 763      |
---------------------------------
41.0
41.0
18.48
10.5
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 202      |
| explained_variance | -0.246   |
| fps                | 415      |
| nupdates           | 13800    |
| policy_entropy     | 0.68     |
| total_timesteps    | 69000    |
| value_loss         | 67.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 204      |
| explained_variance | -0.899   |
| fps                | 415      |
| nupdates           | 13900    |
| policy_entropy     | 0.0213   |
| total_timesteps    | 69500    |
| value_loss         | 1.58e+03 |
---------------------------------
24.0
24.0
18.68
10.5
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 204      |
| explained_variance | -0.558   |
| fps                | 415      |
| nupdates           | 14000    |
| policy_entropy     | 0.146    |
| total_timesteps    | 70000    |
| value_loss         | 2.12e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 206      |
| explained_variance | -0.585   |
| fps                | 414      |
| nupdates           | 14100    |
| policy_entropy     | 0.389    |
| total_timesteps    | 70500    |
| value_loss         | 74.2     |
---------------------------------
36.0
36.0
15.43
15.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.623    |
| fps                | 414      |
| nupdates           | 14200    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 71000    |
| value_loss         | 36.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 205      |
| explained_variance | -9.51    |
| fps                | 414      |
| nupdates           | 14300    |
| policy_entropy     | 0.466    |
| total_timesteps    | 71500    |
| value_loss         | 181      |
---------------------------------
10.0
10.0
22.46
11.0
---------------------------------
| ep_len_mean        | 22.5     |
| ep_reward_mean     | 194      |
| explained_variance | 0.164    |
| fps                | 414      |
| nupdates           | 14400    |
| policy_entropy     | 0.167    |
| total_timesteps    | 72000    |
| value_loss         | 117      |
---------------------------------
---------------------------------
| ep_len_mean        | 23.2     |
| ep_reward_mean     | 192      |
| explained_variance | -2.26    |
| fps                | 414      |
| nupdates           | 14500    |
| policy_entropy     | 0.37     |
| total_timesteps    | 72500    |
| value_loss         | 29.7     |
---------------------------------
9.0
9.0
23.74
10.0
---------------------------------
| ep_len_mean        | 23.7     |
| ep_reward_mean     | 192      |
| explained_variance | 0.859    |
| fps                | 414      |
| nupdates           | 14600    |
| policy_entropy     | 0.372    |
| total_timesteps    | 73000    |
| value_loss         | 74.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 24.7     |
| ep_reward_mean     | 189      |
| explained_variance | -0.177   |
| fps                | 414      |
| nupdates           | 14700    |
| policy_entropy     | 0.29     |
| total_timesteps    | 73500    |
| value_loss         | 1.02e+05 |
---------------------------------
10.0
10.0
17.45
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0682   |
| fps                | 414      |
| nupdates           | 14800    |
| policy_entropy     | 0.0502   |
| total_timesteps    | 74000    |
| value_loss         | 4.08e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 205      |
| explained_variance | 0.155    |
| fps                | 414      |
| nupdates           | 14900    |
| policy_entropy     | 0.0291   |
| total_timesteps    | 74500    |
| value_loss         | 2.39e+04 |
---------------------------------
9.0
9.0
19.15
10.0
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 197      |
| explained_variance | -0.329   |
| fps                | 413      |
| nupdates           | 15000    |
| policy_entropy     | 0.702    |
| total_timesteps    | 75000    |
| value_loss         | 60.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 192      |
| explained_variance | -146     |
| fps                | 413      |
| nupdates           | 15100    |
| policy_entropy     | 0.165    |
| total_timesteps    | 75500    |
| value_loss         | 3.34e+03 |
---------------------------------
8.0
8.0
21.22
10.5
----------------------------------
| ep_len_mean        | 21.2      |
| ep_reward_mean     | 184       |
| explained_variance | -0.000983 |
| fps                | 413       |
| nupdates           | 15200     |
| policy_entropy     | 0.0906    |
| total_timesteps    | 76000     |
| value_loss         | 8.51e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 185      |
| explained_variance | -8.49    |
| fps                | 414      |
| nupdates           | 15300    |
| policy_entropy     | 0.976    |
| total_timesteps    | 76500    |
| value_loss         | 32.6     |
---------------------------------
10.0
10.0
17.5
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 199      |
| explained_variance | 0.252    |
| fps                | 413      |
| nupdates           | 15400    |
| policy_entropy     | 0.0539   |
| total_timesteps    | 77000    |
| value_loss         | 6.73e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.127    |
| fps                | 414      |
| nupdates           | 15500    |
| policy_entropy     | 0.0407   |
| total_timesteps    | 77500    |
| value_loss         | 354      |
---------------------------------
14.0
14.0
15.57
12.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.751    |
| fps                | 414      |
| nupdates           | 15600    |
| policy_entropy     | 0.0276   |
| total_timesteps    | 78000    |
| value_loss         | 49.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.793    |
| fps                | 414      |
| nupdates           | 15700    |
| policy_entropy     | 0.0217   |
| total_timesteps    | 78500    |
| value_loss         | 1.76e+03 |
---------------------------------
21.0
21.0
15.69
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 208      |
| explained_variance | 0.286    |
| fps                | 414      |
| nupdates           | 15800    |
| policy_entropy     | 0.0724   |
| total_timesteps    | 79000    |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 208      |
| explained_variance | -1.46    |
| fps                | 414      |
| nupdates           | 15900    |
| policy_entropy     | 0.194    |
| total_timesteps    | 79500    |
| value_loss         | 136      |
---------------------------------
10.0
10.0
14.71
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.305    |
| fps                | 414      |
| nupdates           | 16000    |
| policy_entropy     | 0.0829   |
| total_timesteps    | 80000    |
| value_loss         | 155      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 203      |
| explained_variance | -0.104   |
| fps                | 414      |
| nupdates           | 16100    |
| policy_entropy     | 0.0733   |
| total_timesteps    | 80500    |
| value_loss         | 193      |
---------------------------------
9.0
9.0
16.82
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 203      |
| explained_variance | -1.1     |
| fps                | 414      |
| nupdates           | 16200    |
| policy_entropy     | 0.79     |
| total_timesteps    | 81000    |
| value_loss         | 55.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 205      |
| explained_variance | -0.109   |
| fps                | 414      |
| nupdates           | 16300    |
| policy_entropy     | 0.352    |
| total_timesteps    | 81500    |
| value_loss         | 50.8     |
---------------------------------
16.0
16.0
17.66
11.0
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 205      |
| explained_variance | 0.473    |
| fps                | 414      |
| nupdates           | 16400    |
| policy_entropy     | 0.76     |
| total_timesteps    | 82000    |
| value_loss         | 156      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 213      |
| explained_variance | 0.577    |
| fps                | 414      |
| nupdates           | 16500    |
| policy_entropy     | 0.142    |
| total_timesteps    | 82500    |
| value_loss         | 157      |
---------------------------------
11.0
11.0
17.17
10.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 207      |
| explained_variance | -1.04    |
| fps                | 414      |
| nupdates           | 16600    |
| policy_entropy     | 0.463    |
| total_timesteps    | 83000    |
| value_loss         | 426      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.374    |
| fps                | 414      |
| nupdates           | 16700    |
| policy_entropy     | 0.0696   |
| total_timesteps    | 83500    |
| value_loss         | 243      |
---------------------------------
10.0
10.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.542    |
| fps                | 414      |
| nupdates           | 16800    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 84000    |
| value_loss         | 59.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.621    |
| fps                | 415      |
| nupdates           | 16900    |
| policy_entropy     | 0.301    |
| total_timesteps    | 84500    |
| value_loss         | 458      |
---------------------------------
10.0
10.0
15.84
19.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.502    |
| fps                | 415      |
| nupdates           | 17000    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 85000    |
| value_loss         | 779      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 207      |
| explained_variance | 0.211    |
| fps                | 415      |
| nupdates           | 17100    |
| policy_entropy     | 0.0691   |
| total_timesteps    | 85500    |
| value_loss         | 194      |
---------------------------------
10.0
10.0
14.85
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.508    |
| fps                | 415      |
| nupdates           | 17200    |
| policy_entropy     | 0.0547   |
| total_timesteps    | 86000    |
| value_loss         | 33.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.333    |
| fps                | 415      |
| nupdates           | 17300    |
| policy_entropy     | 0.121    |
| total_timesteps    | 86500    |
| value_loss         | 206      |
---------------------------------
10.0
10.0
13.61
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 214      |
| explained_variance | -0.116   |
| fps                | 415      |
| nupdates           | 17400    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 87000    |
| value_loss         | 82.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.72     |
| fps                | 415      |
| nupdates           | 17500    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 87500    |
| value_loss         | 22.8     |
---------------------------------
23.0
23.0
13.79
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.0766   |
| fps                | 415      |
| nupdates           | 17600    |
| policy_entropy     | 0.038    |
| total_timesteps    | 88000    |
| value_loss         | 40.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.852    |
| fps                | 415      |
| nupdates           | 17700    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 88500    |
| value_loss         | 39.2     |
---------------------------------
21.0
21.0
14.89
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.84     |
| fps                | 415      |
| nupdates           | 17800    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 89000    |
| value_loss         | 13.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 212      |
| explained_variance | -2.07    |
| fps                | 415      |
| nupdates           | 17900    |
| policy_entropy     | 0.047    |
| total_timesteps    | 89500    |
| value_loss         | 2.11e+03 |
---------------------------------
9.0
9.0
17.64
21.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.309    |
| fps                | 415      |
| nupdates           | 18000    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 90000    |
| value_loss         | 135      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 211      |
| explained_variance | -0.105   |
| fps                | 415      |
| nupdates           | 18100    |
| policy_entropy     | 0.161    |
| total_timesteps    | 90500    |
| value_loss         | 102      |
---------------------------------
11.0
11.0
17.33
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.919    |
| fps                | 415      |
| nupdates           | 18200    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 91000    |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0927   |
| fps                | 415      |
| nupdates           | 18300    |
| policy_entropy     | 0.0638   |
| total_timesteps    | 91500    |
| value_loss         | 125      |
---------------------------------
9.0
9.0
14.25
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.38     |
| fps                | 415      |
| nupdates           | 18400    |
| policy_entropy     | 0.128    |
| total_timesteps    | 92000    |
| value_loss         | 333      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | -1.15    |
| fps                | 415      |
| nupdates           | 18500    |
| policy_entropy     | 0.366    |
| total_timesteps    | 92500    |
| value_loss         | 213      |
---------------------------------
21.0
21.0
14.29
11.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 213      |
| explained_variance | -0.25    |
| fps                | 415      |
| nupdates           | 18600    |
| policy_entropy     | 0.368    |
| total_timesteps    | 93000    |
| value_loss         | 154      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 210      |
| explained_variance | -1.43    |
| fps                | 415      |
| nupdates           | 18700    |
| policy_entropy     | 0.314    |
| total_timesteps    | 93500    |
| value_loss         | 84.6     |
---------------------------------
10.0
10.0
16.08
16.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 415      |
| nupdates           | 18800    |
| policy_entropy     | 0.233    |
| total_timesteps    | 94000    |
| value_loss         | 319      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -0.879   |
| fps                | 415      |
| nupdates           | 18900    |
| policy_entropy     | 0.0339   |
| total_timesteps    | 94500    |
| value_loss         | 1.59e+04 |
---------------------------------
20.0
20.0
17.9
12.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | -2.87    |
| fps                | 415      |
| nupdates           | 19000    |
| policy_entropy     | 0.0603   |
| total_timesteps    | 95000    |
| value_loss         | 651      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.2      |
| fps                | 415      |
| nupdates           | 19100    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 95500    |
| value_loss         | 126      |
---------------------------------
11.0
11.0
14.18
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.885    |
| fps                | 414      |
| nupdates           | 19200    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 96000    |
| value_loss         | 15       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 210      |
| explained_variance | -0.427   |
| fps                | 414      |
| nupdates           | 19300    |
| policy_entropy     | 0.0319   |
| total_timesteps    | 96500    |
| value_loss         | 178      |
---------------------------------
9.0
9.0
14.06
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 213      |
| explained_variance | -3.36    |
| fps                | 414      |
| nupdates           | 19400    |
| policy_entropy     | 0.024    |
| total_timesteps    | 97000    |
| value_loss         | 716      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.774    |
| fps                | 414      |
| nupdates           | 19500    |
| policy_entropy     | 0.0109   |
| total_timesteps    | 97500    |
| value_loss         | 18       |
---------------------------------
22.0
22.0
13.03
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 216      |
| explained_variance | 0.00759  |
| fps                | 414      |
| nupdates           | 19600    |
| policy_entropy     | 0.141    |
| total_timesteps    | 98000    |
| value_loss         | 245      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.224    |
| fps                | 415      |
| nupdates           | 19700    |
| policy_entropy     | 0.00702  |
| total_timesteps    | 98500    |
| value_loss         | 5.83e+03 |
---------------------------------
10.0
10.0
15.85
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.222   |
| fps                | 414      |
| nupdates           | 19800    |
| policy_entropy     | 0.00872  |
| total_timesteps    | 99000    |
| value_loss         | 587      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 205      |
| explained_variance | -0.0067  |
| fps                | 415      |
| nupdates           | 19900    |
| policy_entropy     | 0.00667  |
| total_timesteps    | 99500    |
| value_loss         | 156      |
---------------------------------
10.0
10.0
14.75
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.361    |
| fps                | 415      |
| nupdates           | 20000    |
| policy_entropy     | 0.0285   |
| total_timesteps    | 100000   |
| value_loss         | 284      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.525    |
| fps                | 415      |
| nupdates           | 20100    |
| policy_entropy     | 0.199    |
| total_timesteps    | 100500   |
| value_loss         | 102      |
---------------------------------
10.0
10.0
15.0
10.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0.76     |
| fps                | 415      |
| nupdates           | 20200    |
| policy_entropy     | 0.01     |
| total_timesteps    | 101000   |
| value_loss         | 417      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0505  |
| fps                | 415      |
| nupdates           | 20300    |
| policy_entropy     | 0.0261   |
| total_timesteps    | 101500   |
| value_loss         | 98.1     |
---------------------------------
11.0
11.0
14.0
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | 0.335    |
| fps                | 415      |
| nupdates           | 20400    |
| policy_entropy     | 0.419    |
| total_timesteps    | 102000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | 0.536    |
| fps                | 415      |
| nupdates           | 20500    |
| policy_entropy     | 0.083    |
| total_timesteps    | 102500   |
| value_loss         | 76.9     |
---------------------------------
25.0
25.0
14.42
16.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.219    |
| fps                | 415      |
| nupdates           | 20600    |
| policy_entropy     | 0.0393   |
| total_timesteps    | 103000   |
| value_loss         | 321      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 216      |
| explained_variance | -0.928   |
| fps                | 415      |
| nupdates           | 20700    |
| policy_entropy     | 0.0421   |
| total_timesteps    | 103500   |
| value_loss         | 86.9     |
---------------------------------
11.0
11.0
15.04
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | -0.488   |
| fps                | 415      |
| nupdates           | 20800    |
| policy_entropy     | 0.415    |
| total_timesteps    | 104000   |
| value_loss         | 294      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | -1.24    |
| fps                | 415      |
| nupdates           | 20900    |
| policy_entropy     | 0.0923   |
| total_timesteps    | 104500   |
| value_loss         | 95.6     |
---------------------------------
10.0
10.0
13.87
10.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.0309   |
| fps                | 415      |
| nupdates           | 21000    |
| policy_entropy     | 0.0338   |
| total_timesteps    | 105000   |
| value_loss         | 97.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 213      |
| explained_variance | -0.565   |
| fps                | 415      |
| nupdates           | 21100    |
| policy_entropy     | 0.265    |
| total_timesteps    | 105500   |
| value_loss         | 64.8     |
---------------------------------
11.0
11.0
13.89
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0173   |
| fps                | 415      |
| nupdates           | 21200    |
| policy_entropy     | 0.00942  |
| total_timesteps    | 106000   |
| value_loss         | 217      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.576   |
| fps                | 415      |
| nupdates           | 21300    |
| policy_entropy     | 0.0605   |
| total_timesteps    | 106500   |
| value_loss         | 84.6     |
---------------------------------
24.0
24.0
14.52
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.961    |
| fps                | 415      |
| nupdates           | 21400    |
| policy_entropy     | 0.00932  |
| total_timesteps    | 107000   |
| value_loss         | 3.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.903    |
| fps                | 415      |
| nupdates           | 21500    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 107500   |
| value_loss         | 7.75     |
---------------------------------
22.0
22.0
15.45
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.954    |
| fps                | 415      |
| nupdates           | 21600    |
| policy_entropy     | 0.106    |
| total_timesteps    | 108000   |
| value_loss         | 79.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 215      |
| explained_variance | -0.487   |
| fps                | 415      |
| nupdates           | 21700    |
| policy_entropy     | 0.0999   |
| total_timesteps    | 108500   |
| value_loss         | 54.8     |
---------------------------------
34.0
34.0
14.46
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.978    |
| fps                | 415      |
| nupdates           | 21800    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 109000   |
| value_loss         | 63.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 212      |
| explained_variance | -0.282   |
| fps                | 415      |
| nupdates           | 21900    |
| policy_entropy     | 0.00717  |
| total_timesteps    | 109500   |
| value_loss         | 230      |
---------------------------------
34.0
34.0
15.29
12.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.592    |
| fps                | 415      |
| nupdates           | 22000    |
| policy_entropy     | 0.0604   |
| total_timesteps    | 110000   |
| value_loss         | 71.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 205      |
| explained_variance | -0.75    |
| fps                | 415      |
| nupdates           | 22100    |
| policy_entropy     | 0.144    |
| total_timesteps    | 110500   |
| value_loss         | 1.48e+03 |
---------------------------------
21.0
21.0
18.19
20.5
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 206      |
| explained_variance | 0.263    |
| fps                | 415      |
| nupdates           | 22200    |
| policy_entropy     | 0.342    |
| total_timesteps    | 111000   |
| value_loss         | 138      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.193    |
| fps                | 415      |
| nupdates           | 22300    |
| policy_entropy     | 0.00727  |
| total_timesteps    | 111500   |
| value_loss         | 190      |
---------------------------------
13.0
13.0
14.44
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.484    |
| fps                | 415      |
| nupdates           | 22400    |
| policy_entropy     | 0.0479   |
| total_timesteps    | 112000   |
| value_loss         | 14.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.902    |
| fps                | 415      |
| nupdates           | 22500    |
| policy_entropy     | 0.00778  |
| total_timesteps    | 112500   |
| value_loss         | 20.8     |
---------------------------------
9.0
9.0
14.69
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.75     |
| fps                | 415      |
| nupdates           | 22600    |
| policy_entropy     | 0.016    |
| total_timesteps    | 113000   |
| value_loss         | 60.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 212      |
| explained_variance | -1.22    |
| fps                | 415      |
| nupdates           | 22700    |
| policy_entropy     | 0.0452   |
| total_timesteps    | 113500   |
| value_loss         | 93.4     |
---------------------------------
9.0
9.0
15.11
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.649    |
| fps                | 415      |
| nupdates           | 22800    |
| policy_entropy     | 0.00739  |
| total_timesteps    | 114000   |
| value_loss         | 93       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.205   |
| fps                | 415      |
| nupdates           | 22900    |
| policy_entropy     | 0.324    |
| total_timesteps    | 114500   |
| value_loss         | 158      |
---------------------------------
25.0
25.0
15.77
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | -4.28    |
| fps                | 415      |
| nupdates           | 23000    |
| policy_entropy     | 0.463    |
| total_timesteps    | 115000   |
| value_loss         | 270      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.291    |
| fps                | 415      |
| nupdates           | 23100    |
| policy_entropy     | 0.00432  |
| total_timesteps    | 115500   |
| value_loss         | 107      |
---------------------------------
40.0
40.0
15.08
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.653    |
| fps                | 414      |
| nupdates           | 23200    |
| policy_entropy     | 0.00571  |
| total_timesteps    | 116000   |
| value_loss         | 87.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.494    |
| fps                | 415      |
| nupdates           | 23300    |
| policy_entropy     | 0.193    |
| total_timesteps    | 116500   |
| value_loss         | 36.2     |
---------------------------------
9.0
9.0
15.27
10.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.898    |
| fps                | 415      |
| nupdates           | 23400    |
| policy_entropy     | 0.0676   |
| total_timesteps    | 117000   |
| value_loss         | 16.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | -0.931   |
| fps                | 415      |
| nupdates           | 23500    |
| policy_entropy     | 0.131    |
| total_timesteps    | 117500   |
| value_loss         | 219      |
---------------------------------
25.0
25.0
13.68
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.658    |
| fps                | 415      |
| nupdates           | 23600    |
| policy_entropy     | 0.0498   |
| total_timesteps    | 118000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 218      |
| explained_variance | -0.556   |
| fps                | 415      |
| nupdates           | 23700    |
| policy_entropy     | 0.116    |
| total_timesteps    | 118500   |
| value_loss         | 249      |
---------------------------------
11.0
11.0
13.62
13.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | -39.8    |
| fps                | 414      |
| nupdates           | 23800    |
| policy_entropy     | 0.746    |
| total_timesteps    | 119000   |
| value_loss         | 5.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 206      |
| explained_variance | -2.62    |
| fps                | 415      |
| nupdates           | 23900    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 119500   |
| value_loss         | 184      |
---------------------------------
11.0
11.0
17.46
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | 0.721    |
| fps                | 414      |
| nupdates           | 24000    |
| policy_entropy     | 0.0124   |
| total_timesteps    | 120000   |
| value_loss         | 25.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.868    |
| fps                | 414      |
| nupdates           | 24100    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 120500   |
| value_loss         | 10.4     |
---------------------------------
10.0
10.0
14.54
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0        |
| fps                | 414      |
| nupdates           | 24200    |
| policy_entropy     | 0.559    |
| total_timesteps    | 121000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.131    |
| fps                | 414      |
| nupdates           | 24300    |
| policy_entropy     | 0.0371   |
| total_timesteps    | 121500   |
| value_loss         | 683      |
---------------------------------
11.0
11.0
15.31
11.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.226    |
| fps                | 414      |
| nupdates           | 24400    |
| policy_entropy     | 0.177    |
| total_timesteps    | 122000   |
| value_loss         | 238      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.359   |
| fps                | 414      |
| nupdates           | 24500    |
| policy_entropy     | 0.0059   |
| total_timesteps    | 122500   |
| value_loss         | 60.5     |
---------------------------------
11.0
11.0
13.47
11.5
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.793    |
| fps                | 414      |
| nupdates           | 24600    |
| policy_entropy     | 0.0788   |
| total_timesteps    | 123000   |
| value_loss         | 50.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.887    |
| fps                | 414      |
| nupdates           | 24700    |
| policy_entropy     | 0.00507  |
| total_timesteps    | 123500   |
| value_loss         | 17.8     |
---------------------------------
10.0
10.0
14.07
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.81     |
| fps                | 414      |
| nupdates           | 24800    |
| policy_entropy     | 0.0263   |
| total_timesteps    | 124000   |
| value_loss         | 12.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.0436  |
| fps                | 414      |
| nupdates           | 24900    |
| policy_entropy     | 0.00607  |
| total_timesteps    | 124500   |
| value_loss         | 97.3     |
---------------------------------
9.0
9.0
12.42
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.915    |
| fps                | 414      |
| nupdates           | 25000    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 125000   |
| value_loss         | 5.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.921    |
| fps                | 414      |
| nupdates           | 25100    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 125500   |
| value_loss         | 6.26     |
---------------------------------
10.0
10.0
14.12
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.922    |
| fps                | 414      |
| nupdates           | 25200    |
| policy_entropy     | 0.103    |
| total_timesteps    | 126000   |
| value_loss         | 82.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0        |
| fps                | 414      |
| nupdates           | 25300    |
| policy_entropy     | 0.731    |
| total_timesteps    | 126500   |
| value_loss         | 297      |
---------------------------------
9.0
9.0
18.79
16.0
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 200      |
| explained_variance | -0.0368  |
| fps                | 414      |
| nupdates           | 25400    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 127000   |
| value_loss         | 308      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 200      |
| explained_variance | -1.91    |
| fps                | 414      |
| nupdates           | 25500    |
| policy_entropy     | 0.107    |
| total_timesteps    | 127500   |
| value_loss         | 2.65e+03 |
---------------------------------
10.0
10.0
19.1
21.5
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 198      |
| explained_variance | -0.701   |
| fps                | 414      |
| nupdates           | 25600    |
| policy_entropy     | 0.141    |
| total_timesteps    | 128000   |
| value_loss         | 209      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 196      |
| explained_variance | 0.674    |
| fps                | 414      |
| nupdates           | 25700    |
| policy_entropy     | 0.00563  |
| total_timesteps    | 128500   |
| value_loss         | 90       |
---------------------------------
23.0
23.0
15.39
15.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | -0.293   |
| fps                | 414      |
| nupdates           | 25800    |
| policy_entropy     | 0.754    |
| total_timesteps    | 129000   |
| value_loss         | 92.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | -0.261   |
| fps                | 414      |
| nupdates           | 25900    |
| policy_entropy     | 0.0714   |
| total_timesteps    | 129500   |
| value_loss         | 384      |
---------------------------------
22.0
22.0
14.78
11.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 215      |
| explained_variance | -0.747   |
| fps                | 414      |
| nupdates           | 26000    |
| policy_entropy     | 0.0052   |
| total_timesteps    | 130000   |
| value_loss         | 189      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | -1.1     |
| fps                | 414      |
| nupdates           | 26100    |
| policy_entropy     | 0.178    |
| total_timesteps    | 130500   |
| value_loss         | 290      |
---------------------------------
9.0
9.0
14.51
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.847    |
| fps                | 414      |
| nupdates           | 26200    |
| policy_entropy     | 0.136    |
| total_timesteps    | 131000   |
| value_loss         | 27       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.0421   |
| fps                | 414      |
| nupdates           | 26300    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 131500   |
| value_loss         | 636      |
---------------------------------
10.0
10.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | -4.21    |
| fps                | 414      |
| nupdates           | 26400    |
| policy_entropy     | 0.0218   |
| total_timesteps    | 132000   |
| value_loss         | 234      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.335    |
| fps                | 414      |
| nupdates           | 26500    |
| policy_entropy     | 0.217    |
| total_timesteps    | 132500   |
| value_loss         | 137      |
---------------------------------
10.0
10.0
15.94
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 211      |
| explained_variance | -0.538   |
| fps                | 414      |
| nupdates           | 26600    |
| policy_entropy     | 0.0561   |
| total_timesteps    | 133000   |
| value_loss         | 257      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.0549  |
| fps                | 414      |
| nupdates           | 26700    |
| policy_entropy     | 0.0688   |
| total_timesteps    | 133500   |
| value_loss         | 240      |
---------------------------------
10.0
10.0
16.37
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.705    |
| fps                | 414      |
| nupdates           | 26800    |
| policy_entropy     | 0.00449  |
| total_timesteps    | 134000   |
| value_loss         | 467      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 213      |
| explained_variance | -0.229   |
| fps                | 414      |
| nupdates           | 26900    |
| policy_entropy     | 0.0512   |
| total_timesteps    | 134500   |
| value_loss         | 475      |
---------------------------------
22.0
22.0
16.41
15.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 215      |
| explained_variance | -1.23    |
| fps                | 414      |
| nupdates           | 27000    |
| policy_entropy     | 0.224    |
| total_timesteps    | 135000   |
| value_loss         | 344      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.357    |
| fps                | 414      |
| nupdates           | 27100    |
| policy_entropy     | 0.00615  |
| total_timesteps    | 135500   |
| value_loss         | 177      |
---------------------------------
11.0
11.0
15.44
10.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.823    |
| fps                | 413      |
| nupdates           | 27200    |
| policy_entropy     | 0.0431   |
| total_timesteps    | 136000   |
| value_loss         | 51.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.683    |
| fps                | 414      |
| nupdates           | 27300    |
| policy_entropy     | 0.00307  |
| total_timesteps    | 136500   |
| value_loss         | 27.6     |
---------------------------------
9.0
9.0
14.56
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.534    |
| fps                | 414      |
| nupdates           | 27400    |
| policy_entropy     | 0.0534   |
| total_timesteps    | 137000   |
| value_loss         | 56.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 213      |
| explained_variance | 0.0126   |
| fps                | 414      |
| nupdates           | 27500    |
| policy_entropy     | 0.0345   |
| total_timesteps    | 137500   |
| value_loss         | 114      |
---------------------------------
10.0
10.0
13.24
10.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.681    |
| fps                | 414      |
| nupdates           | 27600    |
| policy_entropy     | 0.034    |
| total_timesteps    | 138000   |
| value_loss         | 41.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.488    |
| fps                | 414      |
| nupdates           | 27700    |
| policy_entropy     | 0.176    |
| total_timesteps    | 138500   |
| value_loss         | 297      |
---------------------------------
11.0
11.0
13.92
16.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.954    |
| fps                | 414      |
| nupdates           | 27800    |
| policy_entropy     | 0.00419  |
| total_timesteps    | 139000   |
| value_loss         | 3.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | -1.56    |
| fps                | 414      |
| nupdates           | 27900    |
| policy_entropy     | 0.0451   |
| total_timesteps    | 139500   |
| value_loss         | 214      |
---------------------------------
9.0
9.0
13.78
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | -0.181   |
| fps                | 414      |
| nupdates           | 28000    |
| policy_entropy     | 0.00453  |
| total_timesteps    | 140000   |
| value_loss         | 228      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 215      |
| explained_variance | -0.22    |
| fps                | 414      |
| nupdates           | 28100    |
| policy_entropy     | 0.00486  |
| total_timesteps    | 140500   |
| value_loss         | 229      |
---------------------------------
13.0
13.0
14.89
10.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.792    |
| fps                | 414      |
| nupdates           | 28200    |
| policy_entropy     | 0.00653  |
| total_timesteps    | 141000   |
| value_loss         | 18       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | -0.494   |
| fps                | 414      |
| nupdates           | 28300    |
| policy_entropy     | 0.213    |
| total_timesteps    | 141500   |
| value_loss         | 169      |
---------------------------------
28.0
28.0
14.57
11.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.191    |
| fps                | 414      |
| nupdates           | 28400    |
| policy_entropy     | 0.0141   |
| total_timesteps    | 142000   |
| value_loss         | 52.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 215      |
| explained_variance | -3.29    |
| fps                | 414      |
| nupdates           | 28500    |
| policy_entropy     | 0.243    |
| total_timesteps    | 142500   |
| value_loss         | 402      |
---------------------------------
10.0
10.0
15.07
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.964    |
| fps                | 414      |
| nupdates           | 28600    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 143000   |
| value_loss         | 3.3      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 213      |
| explained_variance | -0.351   |
| fps                | 414      |
| nupdates           | 28700    |
| policy_entropy     | 0.00447  |
| total_timesteps    | 143500   |
| value_loss         | 799      |
---------------------------------
9.0
9.0
14.65
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.989    |
| fps                | 414      |
| nupdates           | 28800    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 144000   |
| value_loss         | 0.929    |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.913    |
| fps                | 414      |
| nupdates           | 28900    |
| policy_entropy     | 0.00502  |
| total_timesteps    | 144500   |
| value_loss         | 8.28     |
---------------------------------
22.0
22.0
14.43
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.971    |
| fps                | 413      |
| nupdates           | 29000    |
| policy_entropy     | 0.00689  |
| total_timesteps    | 145000   |
| value_loss         | 3.32     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.854    |
| fps                | 413      |
| nupdates           | 29100    |
| policy_entropy     | 0.0453   |
| total_timesteps    | 145500   |
| value_loss         | 250      |
---------------------------------
22.0
22.0
15.35
15.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | -1.75    |
| fps                | 413      |
| nupdates           | 29200    |
| policy_entropy     | 0.0438   |
| total_timesteps    | 146000   |
| value_loss         | 88.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.848    |
| fps                | 413      |
| nupdates           | 29300    |
| policy_entropy     | 0.0595   |
| total_timesteps    | 146500   |
| value_loss         | 30.1     |
---------------------------------
23.0
23.0
15.54
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.823    |
| fps                | 413      |
| nupdates           | 29400    |
| policy_entropy     | 0.0649   |
| total_timesteps    | 147000   |
| value_loss         | 12.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.91     |
| fps                | 413      |
| nupdates           | 29500    |
| policy_entropy     | 0.0341   |
| total_timesteps    | 147500   |
| value_loss         | 22.7     |
---------------------------------
23.0
23.0
14.52
20.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.709    |
| fps                | 413      |
| nupdates           | 29600    |
| policy_entropy     | 0.00593  |
| total_timesteps    | 148000   |
| value_loss         | 37.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.949    |
| fps                | 413      |
| nupdates           | 29700    |
| policy_entropy     | 0.0183   |
| total_timesteps    | 148500   |
| value_loss         | 16.6     |
---------------------------------
23.0
23.0
14.82
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.02     |
| fps                | 413      |
| nupdates           | 29800    |
| policy_entropy     | 0.012    |
| total_timesteps    | 149000   |
| value_loss         | 105      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | -0.873   |
| fps                | 413      |
| nupdates           | 29900    |
| policy_entropy     | 0.0405   |
| total_timesteps    | 149500   |
| value_loss         | 404      |
---------------------------------
11.0
11.0
14.9
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.814    |
| fps                | 413      |
| nupdates           | 30000    |
| policy_entropy     | 0.191    |
| total_timesteps    | 150000   |
| value_loss         | 617      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0156   |
| fps                | 413      |
| nupdates           | 30100    |
| policy_entropy     | 0.0655   |
| total_timesteps    | 150500   |
| value_loss         | 55       |
---------------------------------
10.0
10.0
14.15
11.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.629    |
| fps                | 413      |
| nupdates           | 30200    |
| policy_entropy     | 0.057    |
| total_timesteps    | 151000   |
| value_loss         | 771      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.563    |
| fps                | 413      |
| nupdates           | 30300    |
| policy_entropy     | 0.0269   |
| total_timesteps    | 151500   |
| value_loss         | 101      |
---------------------------------
10.0
10.0
14.59
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.477    |
| fps                | 413      |
| nupdates           | 30400    |
| policy_entropy     | 0.00356  |
| total_timesteps    | 152000   |
| value_loss         | 44       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.987    |
| fps                | 413      |
| nupdates           | 30500    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 152500   |
| value_loss         | 1.61     |
---------------------------------
52.0
52.0
14.42
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | -21.9    |
| fps                | 413      |
| nupdates           | 30600    |
| policy_entropy     | 0.0964   |
| total_timesteps    | 153000   |
| value_loss         | 368      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | -0.00162 |
| fps                | 413      |
| nupdates           | 30700    |
| policy_entropy     | 0.374    |
| total_timesteps    | 153500   |
| value_loss         | 134      |
---------------------------------
23.0
23.0
14.1
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.711    |
| fps                | 413      |
| nupdates           | 30800    |
| policy_entropy     | 0.0251   |
| total_timesteps    | 154000   |
| value_loss         | 25.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.848    |
| fps                | 413      |
| nupdates           | 30900    |
| policy_entropy     | 0.0485   |
| total_timesteps    | 154500   |
| value_loss         | 165      |
---------------------------------
10.0
10.0
14.21
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.645    |
| fps                | 413      |
| nupdates           | 31000    |
| policy_entropy     | 0.0316   |
| total_timesteps    | 155000   |
| value_loss         | 42.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.567    |
| fps                | 413      |
| nupdates           | 31100    |
| policy_entropy     | 0.218    |
| total_timesteps    | 155500   |
| value_loss         | 685      |
---------------------------------
22.0
22.0
14.8
22.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | -2.21    |
| fps                | 413      |
| nupdates           | 31200    |
| policy_entropy     | 0.0317   |
| total_timesteps    | 156000   |
| value_loss         | 131      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.32     |
| fps                | 413      |
| nupdates           | 31300    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 156500   |
| value_loss         | 90.1     |
---------------------------------
21.0
21.0
15.93
16.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.539    |
| fps                | 413      |
| nupdates           | 31400    |
| policy_entropy     | 0.0209   |
| total_timesteps    | 157000   |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.662    |
| fps                | 413      |
| nupdates           | 31500    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 157500   |
| value_loss         | 69.3     |
---------------------------------
10.0
10.0
15.03
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0.798    |
| fps                | 413      |
| nupdates           | 31600    |
| policy_entropy     | 0.00484  |
| total_timesteps    | 158000   |
| value_loss         | 10.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | -3.27    |
| fps                | 413      |
| nupdates           | 31700    |
| policy_entropy     | 0.105    |
| total_timesteps    | 158500   |
| value_loss         | 304      |
---------------------------------
11.0
11.0
14.37
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.159    |
| fps                | 413      |
| nupdates           | 31800    |
| policy_entropy     | 0.198    |
| total_timesteps    | 159000   |
| value_loss         | 58.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | -0.344   |
| fps                | 413      |
| nupdates           | 31900    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 159500   |
| value_loss         | 68.8     |
---------------------------------
10.0
10.0
13.39
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.595    |
| fps                | 413      |
| nupdates           | 32000    |
| policy_entropy     | 0.00302  |
| total_timesteps    | 160000   |
| value_loss         | 36.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.518    |
| fps                | 413      |
| nupdates           | 32100    |
| policy_entropy     | 0.187    |
| total_timesteps    | 160500   |
| value_loss         | 34       |
---------------------------------
11.0
11.0
13.93
11.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.721    |
| fps                | 413      |
| nupdates           | 32200    |
| policy_entropy     | 0.00306  |
| total_timesteps    | 161000   |
| value_loss         | 33.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.902    |
| fps                | 413      |
| nupdates           | 32300    |
| policy_entropy     | 0.00379  |
| total_timesteps    | 161500   |
| value_loss         | 485      |
---------------------------------
22.0
22.0
15.2
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.316    |
| fps                | 413      |
| nupdates           | 32400    |
| policy_entropy     | 0.0156   |
| total_timesteps    | 162000   |
| value_loss         | 192      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.789    |
| fps                | 413      |
| nupdates           | 32500    |
| policy_entropy     | 0.0141   |
| total_timesteps    | 162500   |
| value_loss         | 48.1     |
---------------------------------
25.0
25.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.937    |
| fps                | 413      |
| nupdates           | 32600    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 163000   |
| value_loss         | 28.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.208    |
| fps                | 413      |
| nupdates           | 32700    |
| policy_entropy     | 0.0369   |
| total_timesteps    | 163500   |
| value_loss         | 596      |
---------------------------------
11.0
11.0
14.79
18.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.631    |
| fps                | 413      |
| nupdates           | 32800    |
| policy_entropy     | 0.167    |
| total_timesteps    | 164000   |
| value_loss         | 71       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.721    |
| fps                | 413      |
| nupdates           | 32900    |
| policy_entropy     | 0.00474  |
| total_timesteps    | 164500   |
| value_loss         | 25.8     |
---------------------------------
21.0
21.0
15.4
15.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.868    |
| fps                | 413      |
| nupdates           | 33000    |
| policy_entropy     | 0.00381  |
| total_timesteps    | 165000   |
| value_loss         | 13       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.737    |
| fps                | 413      |
| nupdates           | 33100    |
| policy_entropy     | 0.102    |
| total_timesteps    | 165500   |
| value_loss         | 289      |
---------------------------------
23.0
23.0
15.72
20.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.512    |
| fps                | 413      |
| nupdates           | 33200    |
| policy_entropy     | 0.014    |
| total_timesteps    | 166000   |
| value_loss         | 65.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.407    |
| fps                | 413      |
| nupdates           | 33300    |
| policy_entropy     | 0.0176   |
| total_timesteps    | 166500   |
| value_loss         | 42.3     |
---------------------------------
9.0
9.0
15.04
20.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 220      |
| explained_variance | -1.43    |
| fps                | 413      |
| nupdates           | 33400    |
| policy_entropy     | 0.0384   |
| total_timesteps    | 167000   |
| value_loss         | 163      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.81     |
| fps                | 413      |
| nupdates           | 33500    |
| policy_entropy     | 0.00372  |
| total_timesteps    | 167500   |
| value_loss         | 24.3     |
---------------------------------
11.0
11.0
15.16
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | -2.26    |
| fps                | 413      |
| nupdates           | 33600    |
| policy_entropy     | 0.205    |
| total_timesteps    | 168000   |
| value_loss         | 191      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | -1.58    |
| fps                | 413      |
| nupdates           | 33700    |
| policy_entropy     | 0.0258   |
| total_timesteps    | 168500   |
| value_loss         | 268      |
---------------------------------
10.0
10.0
14.45
10.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 214      |
| explained_variance | -0.44    |
| fps                | 413      |
| nupdates           | 33800    |
| policy_entropy     | 0.00979  |
| total_timesteps    | 169000   |
| value_loss         | 183      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.85     |
| fps                | 413      |
| nupdates           | 33900    |
| policy_entropy     | 0.0748   |
| total_timesteps    | 169500   |
| value_loss         | 14.5     |
---------------------------------
10.0
10.0
13.88
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.783    |
| fps                | 413      |
| nupdates           | 34000    |
| policy_entropy     | 0.0218   |
| total_timesteps    | 170000   |
| value_loss         | 37.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.861    |
| fps                | 413      |
| nupdates           | 34100    |
| policy_entropy     | 0.00869  |
| total_timesteps    | 170500   |
| value_loss         | 11.3     |
---------------------------------
11.0
11.0
14.23
11.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.656    |
| fps                | 413      |
| nupdates           | 34200    |
| policy_entropy     | 0.062    |
| total_timesteps    | 171000   |
| value_loss         | 38       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0        |
| fps                | 413      |
| nupdates           | 34300    |
| policy_entropy     | 0.0821   |
| total_timesteps    | 171500   |
| value_loss         | 114      |
---------------------------------
11.0
11.0
19.95
16.0
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 194      |
| explained_variance | 0.267    |
| fps                | 413      |
| nupdates           | 34400    |
| policy_entropy     | 0.382    |
| total_timesteps    | 172000   |
| value_loss         | 14.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 186      |
| explained_variance | -0.0349  |
| fps                | 413      |
| nupdates           | 34500    |
| policy_entropy     | 0.00807  |
| total_timesteps    | 172500   |
| value_loss         | 0.0261   |
---------------------------------
9.0
9.0
22.67
38.5
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 186      |
| explained_variance | -56.7    |
| fps                | 413      |
| nupdates           | 34600    |
| policy_entropy     | 0.0056   |
| total_timesteps    | 173000   |
| value_loss         | 3.73e-05 |
---------------------------------
---------------------------------
| ep_len_mean        | 34.9     |
| ep_reward_mean     | 158      |
| explained_variance | -0.271   |
| fps                | 413      |
| nupdates           | 34700    |
| policy_entropy     | 0.0838   |
| total_timesteps    | 173500   |
| value_loss         | 336      |
---------------------------------
1230.0
1230.0
34.86
40.5
----------------------------------
| ep_len_mean        | 34.9      |
| ep_reward_mean     | 158       |
| explained_variance | -4.53e-05 |
| fps                | 413       |
| nupdates           | 34800     |
| policy_entropy     | 0.108     |
| total_timesteps    | 174000    |
| value_loss         | 84.1      |
----------------------------------
---------------------------------
| ep_len_mean        | 34.9     |
| ep_reward_mean     | 158      |
| explained_variance | -0.0042  |
| fps                | 413      |
| nupdates           | 34900    |
| policy_entropy     | 0.557    |
| total_timesteps    | 174500   |
| value_loss         | 0.911    |
---------------------------------
1230.0
1230.0
34.86
40.5
---------------------------------
| ep_len_mean        | 34.9     |
| ep_reward_mean     | 158      |
| explained_variance | -0.615   |
| fps                | 413      |
| nupdates           | 35000    |
| policy_entropy     | 0.0274   |
| total_timesteps    | 175000   |
| value_loss         | 0.0194   |
---------------------------------
---------------------------------
| ep_len_mean        | 34.9     |
| ep_reward_mean     | 158      |
| explained_variance | -4.06    |
| fps                | 413      |
| nupdates           | 35100    |
| policy_entropy     | 0.301    |
| total_timesteps    | 175500   |
| value_loss         | 7.37e-05 |
---------------------------------
1230.0
1230.0
34.86
40.5
---------------------------------
| ep_len_mean        | 34.9     |
| ep_reward_mean     | 158      |
| explained_variance | -2.76    |
| fps                | 413      |
| nupdates           | 35200    |
| policy_entropy     | 0.526    |
| total_timesteps    | 176000   |
| value_loss         | 0.000246 |
---------------------------------
---------------------------------
| ep_len_mean        | 63.5     |
| ep_reward_mean     | 73.2     |
| explained_variance | -11.5    |
| fps                | 413      |
| nupdates           | 35300    |
| policy_entropy     | 0.178    |
| total_timesteps    | 176500   |
| value_loss         | 0.0989   |
---------------------------------
2888.0
2888.0
63.5
40.5
---------------------------------
| ep_len_mean        | 63.5     |
| ep_reward_mean     | 73.2     |
| explained_variance | -0.0315  |
| fps                | 413      |
| nupdates           | 35400    |
| policy_entropy     | 0.385    |
| total_timesteps    | 177000   |
| value_loss         | 0.00125  |
---------------------------------
---------------------------------
| ep_len_mean        | 63.5     |
| ep_reward_mean     | 73.2     |
| explained_variance | -22.2    |
| fps                | 413      |
| nupdates           | 35500    |
| policy_entropy     | 0.618    |
| total_timesteps    | 177500   |
| value_loss         | 0.00288  |
---------------------------------
67.0
67.0
77.55
85.5
---------------------------------
| ep_len_mean        | 77.5     |
| ep_reward_mean     | 44.4     |
| explained_variance | -0.0041  |
| fps                | 413      |
| nupdates           | 35600    |
| policy_entropy     | 0.66     |
| total_timesteps    | 178000   |
| value_loss         | 82.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 80       |
| ep_reward_mean     | 34.7     |
| explained_variance | -14.7    |
| fps                | 413      |
| nupdates           | 35700    |
| policy_entropy     | 0.584    |
| total_timesteps    | 178500   |
| value_loss         | 0.00319  |
---------------------------------
11.0
11.0
85.36
47.0
----------------------------------
| ep_len_mean        | 85.4      |
| ep_reward_mean     | 22.3      |
| explained_variance | -1.86e+05 |
| fps                | 413       |
| nupdates           | 35800     |
| policy_entropy     | 0.671     |
| total_timesteps    | 179000    |
| value_loss         | 0.218     |
----------------------------------
---------------------------------
| ep_len_mean        | 85.4     |
| ep_reward_mean     | 22.3     |
| explained_variance | -75.5    |
| fps                | 413      |
| nupdates           | 35900    |
| policy_entropy     | 0.82     |
| total_timesteps    | 179500   |
| value_loss         | 0.172    |
---------------------------------
11.0
11.0
95.9
20.0
---------------------------------
| ep_len_mean        | 95.9     |
| ep_reward_mean     | 0.6      |
| explained_variance | 0.00323  |
| fps                | 413      |
| nupdates           | 36000    |
| policy_entropy     | 0.862    |
| total_timesteps    | 180000   |
| value_loss         | 7.8      |
---------------------------------
----------------------------------
| ep_len_mean        | 99.1      |
| ep_reward_mean     | -9.5      |
| explained_variance | -2.16e+05 |
| fps                | 413       |
| nupdates           | 36100     |
| policy_entropy     | 0.492     |
| total_timesteps    | 180500    |
| value_loss         | 7.79      |
----------------------------------
10.0
10.0
99.1
11.5
---------------------------------
| ep_len_mean        | 99.1     |
| ep_reward_mean     | -9.5     |
| explained_variance | -0.344   |
| fps                | 413      |
| nupdates           | 36200    |
| policy_entropy     | 0.706    |
| total_timesteps    | 181000   |
| value_loss         | 0.409    |
---------------------------------
---------------------------------
| ep_len_mean        | 99.1     |
| ep_reward_mean     | -9.5     |
| explained_variance | -41.7    |
| fps                | 413      |
| nupdates           | 36300    |
| policy_entropy     | 0.632    |
| total_timesteps    | 181500   |
| value_loss         | 0.0192   |
---------------------------------
9.0
9.0
113.95
10.5
---------------------------------
| ep_len_mean        | 114      |
| ep_reward_mean     | -41      |
| explained_variance | -41.6    |
| fps                | 413      |
| nupdates           | 36400    |
| policy_entropy     | 0.698    |
| total_timesteps    | 182000   |
| value_loss         | 0.471    |
---------------------------------
---------------------------------
| ep_len_mean        | 114      |
| ep_reward_mean     | -41      |
| explained_variance | -27      |
| fps                | 413      |
| nupdates           | 36500    |
| policy_entropy     | 0.811    |
| total_timesteps    | 182500   |
| value_loss         | 2.03e-05 |
---------------------------------
9.0
9.0
113.95
10.5
----------------------------------
| ep_len_mean        | 114       |
| ep_reward_mean     | -41       |
| explained_variance | -2.03e-06 |
| fps                | 413       |
| nupdates           | 36600     |
| policy_entropy     | 0.736     |
| total_timesteps    | 183000    |
| value_loss         | 77.4      |
----------------------------------
----------------------------------
| ep_len_mean        | 127       |
| ep_reward_mean     | -77.6     |
| explained_variance | -3.92e+04 |
| fps                | 413       |
| nupdates           | 36700     |
| policy_entropy     | 0.561     |
| total_timesteps    | 183500    |
| value_loss         | 15        |
----------------------------------
31.0
31.0
126.94
15.0
----------------------------------
| ep_len_mean        | 127       |
| ep_reward_mean     | -77.6     |
| explained_variance | -1.25e+04 |
| fps                | 413       |
| nupdates           | 36800     |
| policy_entropy     | 0.788     |
| total_timesteps    | 184000    |
| value_loss         | 0.646     |
----------------------------------
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -35      |
| fps                | 413      |
| nupdates           | 36900    |
| policy_entropy     | 0.775    |
| total_timesteps    | 184500   |
| value_loss         | 0.0206   |
---------------------------------
31.0
31.0
126.94
15.0
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -67.4    |
| fps                | 413      |
| nupdates           | 37000    |
| policy_entropy     | 0.662    |
| total_timesteps    | 185000   |
| value_loss         | 0.0138   |
---------------------------------
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -180     |
| fps                | 413      |
| nupdates           | 37100    |
| policy_entropy     | 0.873    |
| total_timesteps    | 185500   |
| value_loss         | 0.0109   |
---------------------------------
31.0
31.0
126.94
15.0
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -122     |
| fps                | 413      |
| nupdates           | 37200    |
| policy_entropy     | 0.645    |
| total_timesteps    | 186000   |
| value_loss         | 0.338    |
---------------------------------
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -0.0148  |
| fps                | 413      |
| nupdates           | 37300    |
| policy_entropy     | 0.683    |
| total_timesteps    | 186500   |
| value_loss         | 0.000682 |
---------------------------------
31.0
31.0
126.94
15.0
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -70.4    |
| fps                | 413      |
| nupdates           | 37400    |
| policy_entropy     | 0.852    |
| total_timesteps    | 187000   |
| value_loss         | 0.0627   |
---------------------------------
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -77.6    |
| explained_variance | -66.2    |
| fps                | 413      |
| nupdates           | 37500    |
| policy_entropy     | 0.59     |
| total_timesteps    | 187500   |
| value_loss         | 0.296    |
---------------------------------
16.0
16.0
174.31
26.0
---------------------------------
| ep_len_mean        | 174      |
| ep_reward_mean     | -181     |
| explained_variance | -8.29    |
| fps                | 413      |
| nupdates           | 37600    |
| policy_entropy     | 0.0624   |
| total_timesteps    | 188000   |
| value_loss         | 44.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 177      |
| ep_reward_mean     | -191     |
| explained_variance | 2.26e-06 |
| fps                | 413      |
| nupdates           | 37700    |
| policy_entropy     | 0.129    |
| total_timesteps    | 188500   |
| value_loss         | 0.000571 |
---------------------------------
9.0
9.0
180.84
26.5
---------------------------------
| ep_len_mean        | 181      |
| ep_reward_mean     | -200     |
| explained_variance | 0.00725  |
| fps                | 413      |
| nupdates           | 37800    |
| policy_entropy     | 0.217    |
| total_timesteps    | 189000   |
| value_loss         | 5.69e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 183      |
| ep_reward_mean     | -207     |
| explained_variance | 0.953    |
| fps                | 413      |
| nupdates           | 37900    |
| policy_entropy     | 0.073    |
| total_timesteps    | 189500   |
| value_loss         | 41.4     |
---------------------------------
9.0
9.0
121.92
22.5
---------------------------------
| ep_len_mean        | 122      |
| ep_reward_mean     | -41.6    |
| explained_variance | 0.145    |
| fps                | 413      |
| nupdates           | 38000    |
| policy_entropy     | 0.239    |
| total_timesteps    | 190000   |
| value_loss         | 1.02e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 104      |
| ep_reward_mean     | 3.54     |
| explained_variance | 0.94     |
| fps                | 413      |
| nupdates           | 38100    |
| policy_entropy     | 0.331    |
| total_timesteps    | 190500   |
| value_loss         | 31.4     |
---------------------------------
8.0
8.0
89.59
20.5
---------------------------------
| ep_len_mean        | 89.6     |
| ep_reward_mean     | 33.6     |
| explained_variance | 0.0336   |
| fps                | 413      |
| nupdates           | 38200    |
| policy_entropy     | 0.505    |
| total_timesteps    | 191000   |
| value_loss         | 344      |
---------------------------------
---------------------------------
| ep_len_mean        | 82.5     |
| ep_reward_mean     | 33       |
| explained_variance | -67.4    |
| fps                | 413      |
| nupdates           | 38300    |
| policy_entropy     | 0.382    |
| total_timesteps    | 191500   |
| value_loss         | 10       |
---------------------------------
578.0
578.0
82.49
20.5
----------------------------------
| ep_len_mean        | 82.5      |
| ep_reward_mean     | 33        |
| explained_variance | -1.77e+03 |
| fps                | 413       |
| nupdates           | 38400     |
| policy_entropy     | 0.533     |
| total_timesteps    | 192000    |
| value_loss         | 0.00935   |
----------------------------------
---------------------------------
| ep_len_mean        | 82.5     |
| ep_reward_mean     | 33       |
| explained_variance | 5.96e-07 |
| fps                | 413      |
| nupdates           | 38500    |
| policy_entropy     | 0.767    |
| total_timesteps    | 192500   |
| value_loss         | 0.381    |
---------------------------------
84.0
84.0
51.8
20.5
----------------------------------
| ep_len_mean        | 51.8      |
| ep_reward_mean     | 99.9      |
| explained_variance | -2.01e+06 |
| fps                | 413       |
| nupdates           | 38600     |
| policy_entropy     | 0.722     |
| total_timesteps    | 193000    |
| value_loss         | 0.00269   |
----------------------------------
---------------------------------
| ep_len_mean        | 52.2     |
| ep_reward_mean     | 100      |
| explained_variance | -1.74    |
| fps                | 413      |
| nupdates           | 38700    |
| policy_entropy     | 0.634    |
| total_timesteps    | 193500   |
| value_loss         | 19.4     |
---------------------------------
59.0
59.0
51.97
11.5
---------------------------------
| ep_len_mean        | 52       |
| ep_reward_mean     | 108      |
| explained_variance | -0.137   |
| fps                | 413      |
| nupdates           | 38800    |
| policy_entropy     | 0.356    |
| total_timesteps    | 194000   |
| value_loss         | 6.53e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 54.9     |
| ep_reward_mean     | 102      |
| explained_variance | 0.022    |
| fps                | 414      |
| nupdates           | 38900    |
| policy_entropy     | 0.355    |
| total_timesteps    | 194500   |
| value_loss         | 3.07e+04 |
---------------------------------
48.0
48.0
54.95
15.5
---------------------------------
| ep_len_mean        | 55       |
| ep_reward_mean     | 103      |
| explained_variance | 0.104    |
| fps                | 414      |
| nupdates           | 39000    |
| policy_entropy     | 0.418    |
| total_timesteps    | 195000   |
| value_loss         | 8.23e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 52.5     |
| ep_reward_mean     | 109      |
| explained_variance | 0.525    |
| fps                | 414      |
| nupdates           | 39100    |
| policy_entropy     | 0.228    |
| total_timesteps    | 195500   |
| value_loss         | 99.4     |
---------------------------------
35.0
35.0
23.71
13.0
---------------------------------
| ep_len_mean        | 23.7     |
| ep_reward_mean     | 193      |
| explained_variance | -0.36    |
| fps                | 414      |
| nupdates           | 39200    |
| policy_entropy     | 0.537    |
| total_timesteps    | 196000   |
| value_loss         | 1.02e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 201      |
| explained_variance | 0.66     |
| fps                | 414      |
| nupdates           | 39300    |
| policy_entropy     | 0.0848   |
| total_timesteps    | 196500   |
| value_loss         | 181      |
---------------------------------
16.0
16.0
20.01
15.0
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 198      |
| explained_variance | -0.4     |
| fps                | 414      |
| nupdates           | 39400    |
| policy_entropy     | 0.206    |
| total_timesteps    | 197000   |
| value_loss         | 4.34e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 198      |
| explained_variance | -0.349   |
| fps                | 414      |
| nupdates           | 39500    |
| policy_entropy     | 0.341    |
| total_timesteps    | 197500   |
| value_loss         | 1.77e+04 |
---------------------------------
9.0
9.0
19.97
14.5
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 196      |
| explained_variance | 0.367    |
| fps                | 414      |
| nupdates           | 39600    |
| policy_entropy     | 0.142    |
| total_timesteps    | 198000   |
| value_loss         | 1.79e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 193      |
| explained_variance | -0.0739  |
| fps                | 414      |
| nupdates           | 39700    |
| policy_entropy     | 0.75     |
| total_timesteps    | 198500   |
| value_loss         | 167      |
---------------------------------
9.0
9.0
19.26
11.5
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 197      |
| explained_variance | -0.412   |
| fps                | 414      |
| nupdates           | 39800    |
| policy_entropy     | 0.205    |
| total_timesteps    | 199000   |
| value_loss         | 7.81e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 197      |
| explained_variance | -3.78    |
| fps                | 415      |
| nupdates           | 39900    |
| policy_entropy     | 0.339    |
| total_timesteps    | 199500   |
| value_loss         | 1.88e+03 |
---------------------------------
10.0
10.0
19.03
10.0
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 198      |
| explained_variance | -1.82    |
| fps                | 415      |
| nupdates           | 40000    |
| policy_entropy     | 0.594    |
| total_timesteps    | 200000   |
| value_loss         | 475      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -0.316   |
| fps                | 415      |
| nupdates           | 40100    |
| policy_entropy     | 0.0267   |
| total_timesteps    | 200500   |
| value_loss         | 245      |
---------------------------------
9.0
9.0
18.32
10.0
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 203      |
| explained_variance | -0.0301  |
| fps                | 415      |
| nupdates           | 40200    |
| policy_entropy     | 0.57     |
| total_timesteps    | 201000   |
| value_loss         | 78.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 204      |
| explained_variance | -1.13    |
| fps                | 415      |
| nupdates           | 40300    |
| policy_entropy     | 0.487    |
| total_timesteps    | 201500   |
| value_loss         | 264      |
---------------------------------
9.0
9.0
16.23
11.0
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 208      |
| explained_variance | -28      |
| fps                | 415      |
| nupdates           | 40400    |
| policy_entropy     | 0.658    |
| total_timesteps    | 202000   |
| value_loss         | 1.19e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 205      |
| explained_variance | 5.96e-08 |
| fps                | 415      |
| nupdates           | 40500    |
| policy_entropy     | 0.811    |
| total_timesteps    | 202500   |
| value_loss         | 89.5     |
---------------------------------
26.0
26.0
18.37
17.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.183    |
| fps                | 415      |
| nupdates           | 40600    |
| policy_entropy     | 0.657    |
| total_timesteps    | 203000   |
| value_loss         | 515      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 204      |
| explained_variance | -50.3    |
| fps                | 415      |
| nupdates           | 40700    |
| policy_entropy     | 0.628    |
| total_timesteps    | 203500   |
| value_loss         | 1.29e+03 |
---------------------------------
10.0
10.0
21.5
10.5
---------------------------------
| ep_len_mean        | 21.5     |
| ep_reward_mean     | 193      |
| explained_variance | 0.54     |
| fps                | 415      |
| nupdates           | 40800    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 204000   |
| value_loss         | 51       |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 195      |
| explained_variance | -2.29    |
| fps                | 415      |
| nupdates           | 40900    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 204500   |
| value_loss         | 235      |
---------------------------------
10.0
10.0
20.04
10.5
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 196      |
| explained_variance | 0.173    |
| fps                | 416      |
| nupdates           | 41000    |
| policy_entropy     | 0.345    |
| total_timesteps    | 205000   |
| value_loss         | 70.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 207      |
| explained_variance | 0.649    |
| fps                | 416      |
| nupdates           | 41100    |
| policy_entropy     | 0.0209   |
| total_timesteps    | 205500   |
| value_loss         | 154      |
---------------------------------
10.0
10.0
17.71
10.0
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 209      |
| explained_variance | -0.993   |
| fps                | 416      |
| nupdates           | 41200    |
| policy_entropy     | 0.301    |
| total_timesteps    | 206000   |
| value_loss         | 372      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | -0.545   |
| fps                | 416      |
| nupdates           | 41300    |
| policy_entropy     | 0.299    |
| total_timesteps    | 206500   |
| value_loss         | 510      |
---------------------------------
26.0
26.0
15.24
12.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | -1.66    |
| fps                | 416      |
| nupdates           | 41400    |
| policy_entropy     | 0.0784   |
| total_timesteps    | 207000   |
| value_loss         | 810      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 211      |
| explained_variance | -7.54    |
| fps                | 416      |
| nupdates           | 41500    |
| policy_entropy     | 0.407    |
| total_timesteps    | 207500   |
| value_loss         | 500      |
---------------------------------
9.0
9.0
14.89
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 208      |
| explained_variance | -0.273   |
| fps                | 416      |
| nupdates           | 41600    |
| policy_entropy     | 0.162    |
| total_timesteps    | 208000   |
| value_loss         | 718      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 208      |
| explained_variance | -1.28    |
| fps                | 416      |
| nupdates           | 41700    |
| policy_entropy     | 0.0859   |
| total_timesteps    | 208500   |
| value_loss         | 242      |
---------------------------------
9.0
9.0
16.4
11.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.692    |
| fps                | 416      |
| nupdates           | 41800    |
| policy_entropy     | 0.00841  |
| total_timesteps    | 209000   |
| value_loss         | 228      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 207      |
| explained_variance | 0.912    |
| fps                | 416      |
| nupdates           | 41900    |
| policy_entropy     | 0.0276   |
| total_timesteps    | 209500   |
| value_loss         | 10.9     |
---------------------------------
23.0
23.0
15.28
11.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | -0.976   |
| fps                | 416      |
| nupdates           | 42000    |
| policy_entropy     | 0.0911   |
| total_timesteps    | 210000   |
| value_loss         | 269      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.203    |
| fps                | 416      |
| nupdates           | 42100    |
| policy_entropy     | 0.00799  |
| total_timesteps    | 210500   |
| value_loss         | 315      |
---------------------------------
26.0
26.0
15.62
11.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.866    |
| fps                | 416      |
| nupdates           | 42200    |
| policy_entropy     | 0.0224   |
| total_timesteps    | 211000   |
| value_loss         | 22.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.463    |
| fps                | 417      |
| nupdates           | 42300    |
| policy_entropy     | 0.0577   |
| total_timesteps    | 211500   |
| value_loss         | 27       |
---------------------------------
10.0
10.0
15.45
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.629    |
| fps                | 417      |
| nupdates           | 42400    |
| policy_entropy     | 0.163    |
| total_timesteps    | 212000   |
| value_loss         | 9.93     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | -5.46    |
| fps                | 417      |
| nupdates           | 42500    |
| policy_entropy     | 0.234    |
| total_timesteps    | 212500   |
| value_loss         | 839      |
---------------------------------
11.0
11.0
14.76
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | -0.3     |
| fps                | 417      |
| nupdates           | 42600    |
| policy_entropy     | 0.135    |
| total_timesteps    | 213000   |
| value_loss         | 98.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.849    |
| fps                | 417      |
| nupdates           | 42700    |
| policy_entropy     | 0.0471   |
| total_timesteps    | 213500   |
| value_loss         | 11.7     |
---------------------------------
25.0
25.0
16.71
24.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.645    |
| fps                | 417      |
| nupdates           | 42800    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 214000   |
| value_loss         | 51.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.00603  |
| fps                | 417      |
| nupdates           | 42900    |
| policy_entropy     | 0.282    |
| total_timesteps    | 214500   |
| value_loss         | 52.9     |
---------------------------------
10.0
10.0
17.72
15.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.555    |
| fps                | 417      |
| nupdates           | 43000    |
| policy_entropy     | 0.0524   |
| total_timesteps    | 215000   |
| value_loss         | 22.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.928   |
| fps                | 417      |
| nupdates           | 43100    |
| policy_entropy     | 0.107    |
| total_timesteps    | 215500   |
| value_loss         | 871      |
---------------------------------
10.0
10.0
16.38
10.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.0667   |
| fps                | 417      |
| nupdates           | 43200    |
| policy_entropy     | 0.0951   |
| total_timesteps    | 216000   |
| value_loss         | 101      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 211      |
| explained_variance | -0.668   |
| fps                | 417      |
| nupdates           | 43300    |
| policy_entropy     | 0.033    |
| total_timesteps    | 216500   |
| value_loss         | 417      |
---------------------------------
11.0
11.0
17.22
16.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 212      |
| explained_variance | -5.2     |
| fps                | 417      |
| nupdates           | 43400    |
| policy_entropy     | 0.317    |
| total_timesteps    | 217000   |
| value_loss         | 726      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.626    |
| fps                | 417      |
| nupdates           | 43500    |
| policy_entropy     | 0.0619   |
| total_timesteps    | 217500   |
| value_loss         | 332      |
---------------------------------
10.0
10.0
14.45
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.172    |
| fps                | 417      |
| nupdates           | 43600    |
| policy_entropy     | 0.011    |
| total_timesteps    | 218000   |
| value_loss         | 575      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 219      |
| explained_variance | -3.4     |
| fps                | 417      |
| nupdates           | 43700    |
| policy_entropy     | 0.273    |
| total_timesteps    | 218500   |
| value_loss         | 422      |
---------------------------------
11.0
11.0
13.89
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.743    |
| fps                | 417      |
| nupdates           | 43800    |
| policy_entropy     | 0.194    |
| total_timesteps    | 219000   |
| value_loss         | 28.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.529    |
| fps                | 418      |
| nupdates           | 43900    |
| policy_entropy     | 0.042    |
| total_timesteps    | 219500   |
| value_loss         | 223      |
---------------------------------
10.0
10.0
15.41
11.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.937    |
| fps                | 418      |
| nupdates           | 44000    |
| policy_entropy     | 0.0346   |
| total_timesteps    | 220000   |
| value_loss         | 10.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.943    |
| fps                | 418      |
| nupdates           | 44100    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 220500   |
| value_loss         | 9.88     |
---------------------------------
20.0
20.0
16.03
15.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | 0.193    |
| fps                | 418      |
| nupdates           | 44200    |
| policy_entropy     | 0.442    |
| total_timesteps    | 221000   |
| value_loss         | 220      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | -2.89    |
| fps                | 418      |
| nupdates           | 44300    |
| policy_entropy     | 0.0755   |
| total_timesteps    | 221500   |
| value_loss         | 369      |
---------------------------------
10.0
10.0
15.27
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | -0.492   |
| fps                | 418      |
| nupdates           | 44400    |
| policy_entropy     | 0.295    |
| total_timesteps    | 222000   |
| value_loss         | 88.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 215      |
| explained_variance | -1.41    |
| fps                | 418      |
| nupdates           | 44500    |
| policy_entropy     | 0.103    |
| total_timesteps    | 222500   |
| value_loss         | 1.55e+03 |
---------------------------------
12.0
12.0
15.19
11.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.93     |
| fps                | 418      |
| nupdates           | 44600    |
| policy_entropy     | 0.0161   |
| total_timesteps    | 223000   |
| value_loss         | 17.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.793    |
| fps                | 418      |
| nupdates           | 44700    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 223500   |
| value_loss         | 28.9     |
---------------------------------
28.0
28.0
15.54
19.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.262    |
| fps                | 418      |
| nupdates           | 44800    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 224000   |
| value_loss         | 458      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 214      |
| explained_variance | -0.705   |
| fps                | 418      |
| nupdates           | 44900    |
| policy_entropy     | 0.278    |
| total_timesteps    | 224500   |
| value_loss         | 216      |
---------------------------------
21.0
21.0
16.81
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 214      |
| explained_variance | -0.695   |
| fps                | 418      |
| nupdates           | 45000    |
| policy_entropy     | 0.174    |
| total_timesteps    | 225000   |
| value_loss         | 74.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0352   |
| fps                | 419      |
| nupdates           | 45100    |
| policy_entropy     | 0.0271   |
| total_timesteps    | 225500   |
| value_loss         | 182      |
---------------------------------
10.0
10.0
16.64
15.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 213      |
| explained_variance | -3.64    |
| fps                | 419      |
| nupdates           | 45200    |
| policy_entropy     | 0.0899   |
| total_timesteps    | 226000   |
| value_loss         | 191      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.274    |
| fps                | 419      |
| nupdates           | 45300    |
| policy_entropy     | 0.0198   |
| total_timesteps    | 226500   |
| value_loss         | 397      |
---------------------------------
9.0
9.0
17.05
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.935    |
| fps                | 419      |
| nupdates           | 45400    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 227000   |
| value_loss         | 30.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.675    |
| fps                | 419      |
| nupdates           | 45500    |
| policy_entropy     | 0.00913  |
| total_timesteps    | 227500   |
| value_loss         | 27.4     |
---------------------------------
11.0
11.0
16.0
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | 0.539    |
| fps                | 419      |
| nupdates           | 45600    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 228000   |
| value_loss         | 4.98     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | -0.623   |
| fps                | 419      |
| nupdates           | 45700    |
| policy_entropy     | 0.0324   |
| total_timesteps    | 228500   |
| value_loss         | 161      |
---------------------------------
14.0
14.0
14.84
12.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 213      |
| explained_variance | -3.88    |
| fps                | 419      |
| nupdates           | 45800    |
| policy_entropy     | 0.207    |
| total_timesteps    | 229000   |
| value_loss         | 538      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | -2.28    |
| fps                | 419      |
| nupdates           | 45900    |
| policy_entropy     | 0.271    |
| total_timesteps    | 229500   |
| value_loss         | 739      |
---------------------------------
22.0
22.0
15.34
10.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.749    |
| fps                | 419      |
| nupdates           | 46000    |
| policy_entropy     | 0.137    |
| total_timesteps    | 230000   |
| value_loss         | 38.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 215      |
| explained_variance | -3.81    |
| fps                | 419      |
| nupdates           | 46100    |
| policy_entropy     | 0.163    |
| total_timesteps    | 230500   |
| value_loss         | 422      |
---------------------------------
10.0
10.0
16.05
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 215      |
| explained_variance | -0.541   |
| fps                | 419      |
| nupdates           | 46200    |
| policy_entropy     | 0.117    |
| total_timesteps    | 231000   |
| value_loss         | 745      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.889    |
| fps                | 419      |
| nupdates           | 46300    |
| policy_entropy     | 0.0361   |
| total_timesteps    | 231500   |
| value_loss         | 50.9     |
---------------------------------
23.0
23.0
15.82
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.271    |
| fps                | 420      |
| nupdates           | 46400    |
| policy_entropy     | 0.00716  |
| total_timesteps    | 232000   |
| value_loss         | 56.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.622    |
| fps                | 420      |
| nupdates           | 46500    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 232500   |
| value_loss         | 58.4     |
---------------------------------
9.0
9.0
15.5
14.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 217      |
| explained_variance | -4.21    |
| fps                | 420      |
| nupdates           | 46600    |
| policy_entropy     | 0.243    |
| total_timesteps    | 233000   |
| value_loss         | 568      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.561    |
| fps                | 420      |
| nupdates           | 46700    |
| policy_entropy     | 0.121    |
| total_timesteps    | 233500   |
| value_loss         | 70.2     |
---------------------------------
10.0
10.0
15.99
14.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 215      |
| explained_variance | 0.106    |
| fps                | 420      |
| nupdates           | 46800    |
| policy_entropy     | 0.523    |
| total_timesteps    | 234000   |
| value_loss         | 84.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.971    |
| fps                | 420      |
| nupdates           | 46900    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 234500   |
| value_loss         | 9.02     |
---------------------------------
10.0
10.0
15.68
17.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.727    |
| fps                | 420      |
| nupdates           | 47000    |
| policy_entropy     | 0.114    |
| total_timesteps    | 235000   |
| value_loss         | 31.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.993    |
| fps                | 420      |
| nupdates           | 47100    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 235500   |
| value_loss         | 1.62     |
---------------------------------
10.0
10.0
13.62
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.832    |
| fps                | 420      |
| nupdates           | 47200    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 236000   |
| value_loss         | 24.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | -0.962   |
| fps                | 420      |
| nupdates           | 47300    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 236500   |
| value_loss         | 188      |
---------------------------------
10.0
10.0
15.7
20.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.156    |
| fps                | 420      |
| nupdates           | 47400    |
| policy_entropy     | 0.0887   |
| total_timesteps    | 237000   |
| value_loss         | 128      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0        |
| fps                | 420      |
| nupdates           | 47500    |
| policy_entropy     | 0.0419   |
| total_timesteps    | 237500   |
| value_loss         | 151      |
---------------------------------
9.0
9.0
17.05
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.132    |
| fps                | 420      |
| nupdates           | 47600    |
| policy_entropy     | 0.00824  |
| total_timesteps    | 238000   |
| value_loss         | 590      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.53     |
| fps                | 420      |
| nupdates           | 47700    |
| policy_entropy     | 0.4      |
| total_timesteps    | 238500   |
| value_loss         | 18.4     |
---------------------------------
9.0
9.0
17.56
20.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.436    |
| fps                | 421      |
| nupdates           | 47800    |
| policy_entropy     | 0.012    |
| total_timesteps    | 239000   |
| value_loss         | 78.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.751    |
| fps                | 421      |
| nupdates           | 47900    |
| policy_entropy     | 0.013    |
| total_timesteps    | 239500   |
| value_loss         | 48.7     |
---------------------------------
13.0
13.0
17.66
23.0
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 213      |
| explained_variance | -0.876   |
| fps                | 420      |
| nupdates           | 48000    |
| policy_entropy     | 0.244    |
| total_timesteps    | 240000   |
| value_loss         | 116      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.97     |
| fps                | 420      |
| nupdates           | 48100    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 240500   |
| value_loss         | 5.79     |
---------------------------------
9.0
9.0
17.15
11.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 213      |
| explained_variance | -2.67    |
| fps                | 421      |
| nupdates           | 48200    |
| policy_entropy     | 0.263    |
| total_timesteps    | 241000   |
| value_loss         | 380      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.367    |
| fps                | 421      |
| nupdates           | 48300    |
| policy_entropy     | 0.148    |
| total_timesteps    | 241500   |
| value_loss         | 215      |
---------------------------------
21.0
21.0
14.87
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.953    |
| fps                | 421      |
| nupdates           | 48400    |
| policy_entropy     | 0.00947  |
| total_timesteps    | 242000   |
| value_loss         | 17.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | -1.02    |
| fps                | 421      |
| nupdates           | 48500    |
| policy_entropy     | 0.0677   |
| total_timesteps    | 242500   |
| value_loss         | 106      |
---------------------------------
10.0
10.0
15.39
10.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.933    |
| fps                | 421      |
| nupdates           | 48600    |
| policy_entropy     | 0.00783  |
| total_timesteps    | 243000   |
| value_loss         | 12.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.877    |
| fps                | 421      |
| nupdates           | 48700    |
| policy_entropy     | 0.0901   |
| total_timesteps    | 243500   |
| value_loss         | 6.06     |
---------------------------------
12.0
12.0
14.92
15.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | -0.743   |
| fps                | 421      |
| nupdates           | 48800    |
| policy_entropy     | 0.0575   |
| total_timesteps    | 244000   |
| value_loss         | 784      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.628   |
| fps                | 421      |
| nupdates           | 48900    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 244500   |
| value_loss         | 181      |
---------------------------------
10.0
10.0
15.05
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.537    |
| fps                | 421      |
| nupdates           | 49000    |
| policy_entropy     | 0.0749   |
| total_timesteps    | 245000   |
| value_loss         | 94       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.538    |
| fps                | 421      |
| nupdates           | 49100    |
| policy_entropy     | 0.244    |
| total_timesteps    | 245500   |
| value_loss         | 56.8     |
---------------------------------
9.0
9.0
15.03
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0.0797   |
| fps                | 421      |
| nupdates           | 49200    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 246000   |
| value_loss         | 759      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.455    |
| fps                | 421      |
| nupdates           | 49300    |
| policy_entropy     | 0.0247   |
| total_timesteps    | 246500   |
| value_loss         | 20.3     |
---------------------------------
11.0
11.0
15.32
15.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 218      |
| explained_variance | -1.46    |
| fps                | 421      |
| nupdates           | 49400    |
| policy_entropy     | 0.0386   |
| total_timesteps    | 247000   |
| value_loss         | 130      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.235    |
| fps                | 421      |
| nupdates           | 49500    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 247500   |
| value_loss         | 400      |
---------------------------------
28.0
28.0
14.73
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0163  |
| fps                | 421      |
| nupdates           | 49600    |
| policy_entropy     | 0.103    |
| total_timesteps    | 248000   |
| value_loss         | 1.31e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | -0.241   |
| fps                | 421      |
| nupdates           | 49700    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 248500   |
| value_loss         | 55.1     |
---------------------------------
9.0
9.0
13.94
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | -1.38    |
| fps                | 421      |
| nupdates           | 49800    |
| policy_entropy     | 0.046    |
| total_timesteps    | 249000   |
| value_loss         | 169      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | -0.062   |
| fps                | 421      |
| nupdates           | 49900    |
| policy_entropy     | 0.105    |
| total_timesteps    | 249500   |
| value_loss         | 193      |
---------------------------------
9.0
9.0
14.47
15.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.903    |
| fps                | 421      |
| nupdates           | 50000    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 250000   |
| value_loss         | 54.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.107    |
| fps                | 422      |
| nupdates           | 50100    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 250500   |
| value_loss         | 683      |
---------------------------------
9.0
9.0
15.63
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.929    |
| fps                | 422      |
| nupdates           | 50200    |
| policy_entropy     | 0.032    |
| total_timesteps    | 251000   |
| value_loss         | 5.58     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.705    |
| fps                | 422      |
| nupdates           | 50300    |
| policy_entropy     | 0.11     |
| total_timesteps    | 251500   |
| value_loss         | 59.5     |
---------------------------------
10.0
10.0
14.65
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.888    |
| fps                | 422      |
| nupdates           | 50400    |
| policy_entropy     | 0.0425   |
| total_timesteps    | 252000   |
| value_loss         | 12.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 218      |
| explained_variance | -3.39    |
| fps                | 422      |
| nupdates           | 50500    |
| policy_entropy     | 0.245    |
| total_timesteps    | 252500   |
| value_loss         | 287      |
---------------------------------
9.0
9.0
14.32
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | -1.12    |
| fps                | 422      |
| nupdates           | 50600    |
| policy_entropy     | 0.127    |
| total_timesteps    | 253000   |
| value_loss         | 258      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.842    |
| fps                | 422      |
| nupdates           | 50700    |
| policy_entropy     | 0.0306   |
| total_timesteps    | 253500   |
| value_loss         | 15.8     |
---------------------------------
13.0
13.0
15.61
12.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.899    |
| fps                | 422      |
| nupdates           | 50800    |
| policy_entropy     | 0.00359  |
| total_timesteps    | 254000   |
| value_loss         | 19       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.837   |
| fps                | 422      |
| nupdates           | 50900    |
| policy_entropy     | 0.408    |
| total_timesteps    | 254500   |
| value_loss         | 347      |
---------------------------------
9.0
9.0
14.03
11.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | 0.961    |
| fps                | 422      |
| nupdates           | 51000    |
| policy_entropy     | 0.00701  |
| total_timesteps    | 255000   |
| value_loss         | 3.11     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.818    |
| fps                | 422      |
| nupdates           | 51100    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 255500   |
| value_loss         | 24.6     |
---------------------------------
9.0
9.0
14.21
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.589    |
| fps                | 422      |
| nupdates           | 51200    |
| policy_entropy     | 0.244    |
| total_timesteps    | 256000   |
| value_loss         | 20.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.913    |
| fps                | 422      |
| nupdates           | 51300    |
| policy_entropy     | 0.0337   |
| total_timesteps    | 256500   |
| value_loss         | 16.9     |
---------------------------------
25.0
25.0
15.25
15.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.566    |
| fps                | 422      |
| nupdates           | 51400    |
| policy_entropy     | 0.0816   |
| total_timesteps    | 257000   |
| value_loss         | 89.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.309    |
| fps                | 422      |
| nupdates           | 51500    |
| policy_entropy     | 0.18     |
| total_timesteps    | 257500   |
| value_loss         | 45.1     |
---------------------------------
10.0
10.0
14.77
16.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.524    |
| fps                | 422      |
| nupdates           | 51600    |
| policy_entropy     | 0.016    |
| total_timesteps    | 258000   |
| value_loss         | 119      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.808    |
| fps                | 423      |
| nupdates           | 51700    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 258500   |
| value_loss         | 20.3     |
---------------------------------
19.0
19.0
15.18
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.747    |
| fps                | 423      |
| nupdates           | 51800    |
| policy_entropy     | 0.117    |
| total_timesteps    | 259000   |
| value_loss         | 19.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 221      |
| explained_variance | 0.693    |
| fps                | 423      |
| nupdates           | 51900    |
| policy_entropy     | 0.00523  |
| total_timesteps    | 259500   |
| value_loss         | 31.2     |
---------------------------------
10.0
10.0
14.26
10.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.422    |
| fps                | 423      |
| nupdates           | 52000    |
| policy_entropy     | 0.00631  |
| total_timesteps    | 260000   |
| value_loss         | 46.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.805    |
| fps                | 423      |
| nupdates           | 52100    |
| policy_entropy     | 0.0269   |
| total_timesteps    | 260500   |
| value_loss         | 12.7     |
---------------------------------
10.0
10.0
15.36
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.214    |
| fps                | 423      |
| nupdates           | 52200    |
| policy_entropy     | 0.0013   |
| total_timesteps    | 261000   |
| value_loss         | 524      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.876   |
| fps                | 423      |
| nupdates           | 52300    |
| policy_entropy     | 0.0122   |
| total_timesteps    | 261500   |
| value_loss         | 180      |
---------------------------------
10.0
10.0
14.45
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.88     |
| fps                | 423      |
| nupdates           | 52400    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 262000   |
| value_loss         | 5.68     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.969    |
| fps                | 423      |
| nupdates           | 52500    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 262500   |
| value_loss         | 2.69     |
---------------------------------
11.0
11.0
14.33
10.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | -0.341   |
| fps                | 423      |
| nupdates           | 52600    |
| policy_entropy     | 0.0996   |
| total_timesteps    | 263000   |
| value_loss         | 793      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | -8.55    |
| fps                | 423      |
| nupdates           | 52700    |
| policy_entropy     | 0.883    |
| total_timesteps    | 263500   |
| value_loss         | 471      |
---------------------------------
10.0
10.0
15.55
19.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.0177   |
| fps                | 423      |
| nupdates           | 52800    |
| policy_entropy     | 0.0426   |
| total_timesteps    | 264000   |
| value_loss         | 448      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.793    |
| fps                | 423      |
| nupdates           | 52900    |
| policy_entropy     | 0.00987  |
| total_timesteps    | 264500   |
| value_loss         | 47.1     |
---------------------------------
32.0
32.0
16.08
20.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.274    |
| fps                | 423      |
| nupdates           | 53000    |
| policy_entropy     | 0.111    |
| total_timesteps    | 265000   |
| value_loss         | 46.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.846    |
| fps                | 423      |
| nupdates           | 53100    |
| policy_entropy     | 0.00464  |
| total_timesteps    | 265500   |
| value_loss         | 43.7     |
---------------------------------
25.0
25.0
15.18
11.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.959    |
| fps                | 423      |
| nupdates           | 53200    |
| policy_entropy     | 0.137    |
| total_timesteps    | 266000   |
| value_loss         | 4.01     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.896    |
| fps                | 423      |
| nupdates           | 53300    |
| policy_entropy     | 0.0122   |
| total_timesteps    | 266500   |
| value_loss         | 8.71     |
---------------------------------
11.0
11.0
14.9
20.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.763    |
| fps                | 423      |
| nupdates           | 53400    |
| policy_entropy     | 0.00546  |
| total_timesteps    | 267000   |
| value_loss         | 20.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | 0.973    |
| fps                | 424      |
| nupdates           | 53500    |
| policy_entropy     | 0.0345   |
| total_timesteps    | 267500   |
| value_loss         | 4.47     |
---------------------------------
20.0
20.0
14.89
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.664    |
| fps                | 424      |
| nupdates           | 53600    |
| policy_entropy     | 0.0334   |
| total_timesteps    | 268000   |
| value_loss         | 46.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.734    |
| fps                | 424      |
| nupdates           | 53700    |
| policy_entropy     | 0.098    |
| total_timesteps    | 268500   |
| value_loss         | 111      |
---------------------------------
26.0
26.0
14.08
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | -2.44    |
| fps                | 424      |
| nupdates           | 53800    |
| policy_entropy     | 0.062    |
| total_timesteps    | 269000   |
| value_loss         | 557      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.884    |
| fps                | 424      |
| nupdates           | 53900    |
| policy_entropy     | 0.00595  |
| total_timesteps    | 269500   |
| value_loss         | 11.7     |
---------------------------------
19.0
19.0
14.85
19.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.982    |
| fps                | 424      |
| nupdates           | 54000    |
| policy_entropy     | 0.0214   |
| total_timesteps    | 270000   |
| value_loss         | 2.79     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.214    |
| fps                | 424      |
| nupdates           | 54100    |
| policy_entropy     | 0.147    |
| total_timesteps    | 270500   |
| value_loss         | 1.02e+03 |
---------------------------------
20.0
20.0
15.38
15.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 219      |
| explained_variance | -0.0069  |
| fps                | 424      |
| nupdates           | 54200    |
| policy_entropy     | 0.144    |
| total_timesteps    | 271000   |
| value_loss         | 372      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.218   |
| fps                | 424      |
| nupdates           | 54300    |
| policy_entropy     | 0.194    |
| total_timesteps    | 271500   |
| value_loss         | 92.6     |
---------------------------------
18.0
18.0
15.21
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.787    |
| fps                | 424      |
| nupdates           | 54400    |
| policy_entropy     | 0.144    |
| total_timesteps    | 272000   |
| value_loss         | 30.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.935    |
| fps                | 424      |
| nupdates           | 54500    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 272500   |
| value_loss         | 10.4     |
---------------------------------
22.0
22.0
13.34
18.5
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 220      |
| explained_variance | -0.787   |
| fps                | 424      |
| nupdates           | 54600    |
| policy_entropy     | 0.078    |
| total_timesteps    | 273000   |
| value_loss         | 187      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.953    |
| fps                | 424      |
| nupdates           | 54700    |
| policy_entropy     | 0.0178   |
| total_timesteps    | 273500   |
| value_loss         | 10.7     |
---------------------------------
10.0
10.0
14.72
20.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | -1.29    |
| fps                | 424      |
| nupdates           | 54800    |
| policy_entropy     | 0.0535   |
| total_timesteps    | 274000   |
| value_loss         | 386      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.893    |
| fps                | 424      |
| nupdates           | 54900    |
| policy_entropy     | 0.025    |
| total_timesteps    | 274500   |
| value_loss         | 33.1     |
---------------------------------
13.0
13.0
14.48
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 221      |
| explained_variance | 0.865    |
| fps                | 424      |
| nupdates           | 55000    |
| policy_entropy     | 0.0778   |
| total_timesteps    | 275000   |
| value_loss         | 17.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.501    |
| fps                | 424      |
| nupdates           | 55100    |
| policy_entropy     | 0.0216   |
| total_timesteps    | 275500   |
| value_loss         | 609      |
---------------------------------
9.0
9.0
14.91
20.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.792    |
| fps                | 424      |
| nupdates           | 55200    |
| policy_entropy     | 0.123    |
| total_timesteps    | 276000   |
| value_loss         | 7.9      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.536    |
| fps                | 425      |
| nupdates           | 55300    |
| policy_entropy     | 0.184    |
| total_timesteps    | 276500   |
| value_loss         | 223      |
---------------------------------
9.0
9.0
15.32
18.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 218      |
| explained_variance | -1.08    |
| fps                | 425      |
| nupdates           | 55400    |
| policy_entropy     | 0.0381   |
| total_timesteps    | 277000   |
| value_loss         | 738      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.943    |
| fps                | 425      |
| nupdates           | 55500    |
| policy_entropy     | 0.0327   |
| total_timesteps    | 277500   |
| value_loss         | 3.86     |
---------------------------------
21.0
21.0
15.14
15.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.756    |
| fps                | 425      |
| nupdates           | 55600    |
| policy_entropy     | 0.157    |
| total_timesteps    | 278000   |
| value_loss         | 37.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.833    |
| fps                | 425      |
| nupdates           | 55700    |
| policy_entropy     | 0.0178   |
| total_timesteps    | 278500   |
| value_loss         | 94.6     |
---------------------------------
10.0
10.0
15.02
14.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.987    |
| fps                | 425      |
| nupdates           | 55800    |
| policy_entropy     | 0.00705  |
| total_timesteps    | 279000   |
| value_loss         | 584      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.94     |
| fps                | 425      |
| nupdates           | 55900    |
| policy_entropy     | 0.228    |
| total_timesteps    | 279500   |
| value_loss         | 9.66     |
---------------------------------
11.0
11.0
14.02
15.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | 0.995    |
| fps                | 425      |
| nupdates           | 56000    |
| policy_entropy     | 0.00799  |
| total_timesteps    | 280000   |
| value_loss         | 4.29     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.62     |
| fps                | 425      |
| nupdates           | 56100    |
| policy_entropy     | 0.00859  |
| total_timesteps    | 280500   |
| value_loss         | 44.7     |
---------------------------------
10.0
10.0
14.31
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 5.96e-08 |
| fps                | 425      |
| nupdates           | 56200    |
| policy_entropy     | 0.0432   |
| total_timesteps    | 281000   |
| value_loss         | 139      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 208      |
| explained_variance | -858     |
| fps                | 425      |
| nupdates           | 56300    |
| policy_entropy     | 0.312    |
| total_timesteps    | 281500   |
| value_loss         | 1.46e+03 |
---------------------------------
11.0
11.0
17.55
15.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 206      |
| explained_variance | -2.4     |
| fps                | 425      |
| nupdates           | 56400    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 282000   |
| value_loss         | 808      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0.71     |
| fps                | 425      |
| nupdates           | 56500    |
| policy_entropy     | 0.00933  |
| total_timesteps    | 282500   |
| value_loss         | 97.5     |
---------------------------------
9.0
9.0
14.28
10.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | -0.888   |
| fps                | 425      |
| nupdates           | 56600    |
| policy_entropy     | 0.0244   |
| total_timesteps    | 283000   |
| value_loss         | 730      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.944    |
| fps                | 425      |
| nupdates           | 56700    |
| policy_entropy     | 0.108    |
| total_timesteps    | 283500   |
| value_loss         | 2.41     |
---------------------------------
10.0
10.0
13.87
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.0834   |
| fps                | 425      |
| nupdates           | 56800    |
| policy_entropy     | 0.299    |
| total_timesteps    | 284000   |
| value_loss         | 55.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0.904    |
| fps                | 425      |
| nupdates           | 56900    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 284500   |
| value_loss         | 62.1     |
---------------------------------
20.0
20.0
15.62
20.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.964    |
| fps                | 425      |
| nupdates           | 57000    |
| policy_entropy     | 0.00234  |
| total_timesteps    | 285000   |
| value_loss         | 16       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.99     |
| fps                | 426      |
| nupdates           | 57100    |
| policy_entropy     | 0.017    |
| total_timesteps    | 285500   |
| value_loss         | 3.7      |
---------------------------------
18.0
18.0
14.66
18.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | -1.72    |
| fps                | 426      |
| nupdates           | 57200    |
| policy_entropy     | 0.114    |
| total_timesteps    | 286000   |
| value_loss         | 184      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | -0.36    |
| fps                | 426      |
| nupdates           | 57300    |
| policy_entropy     | 0.425    |
| total_timesteps    | 286500   |
| value_loss         | 264      |
---------------------------------
11.0
11.0
14.89
14.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.96     |
| fps                | 426      |
| nupdates           | 57400    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 287000   |
| value_loss         | 3.71     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.961    |
| fps                | 426      |
| nupdates           | 57500    |
| policy_entropy     | 0.00403  |
| total_timesteps    | 287500   |
| value_loss         | 10.3     |
---------------------------------
10.0
10.0
14.91
14.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.608    |
| fps                | 426      |
| nupdates           | 57600    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 288000   |
| value_loss         | 20.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.782    |
| fps                | 426      |
| nupdates           | 57700    |
| policy_entropy     | 0.0257   |
| total_timesteps    | 288500   |
| value_loss         | 5.6      |
---------------------------------
11.0
11.0
14.42
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.236    |
| fps                | 426      |
| nupdates           | 57800    |
| policy_entropy     | 0.00802  |
| total_timesteps    | 289000   |
| value_loss         | 653      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.976    |
| fps                | 426      |
| nupdates           | 57900    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 289500   |
| value_loss         | 3.19     |
---------------------------------
10.0
10.0
14.62
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.825    |
| fps                | 426      |
| nupdates           | 58000    |
| policy_entropy     | 0.00344  |
| total_timesteps    | 290000   |
| value_loss         | 23.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | -0.768   |
| fps                | 426      |
| nupdates           | 58100    |
| policy_entropy     | 0.00899  |
| total_timesteps    | 290500   |
| value_loss         | 176      |
---------------------------------
19.0
19.0
13.86
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.964    |
| fps                | 426      |
| nupdates           | 58200    |
| policy_entropy     | 0.0579   |
| total_timesteps    | 291000   |
| value_loss         | 6.83     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.455    |
| fps                | 426      |
| nupdates           | 58300    |
| policy_entropy     | 0.154    |
| total_timesteps    | 291500   |
| value_loss         | 186      |
---------------------------------
21.0
21.0
13.61
10.5
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.941    |
| fps                | 426      |
| nupdates           | 58400    |
| policy_entropy     | 0.0768   |
| total_timesteps    | 292000   |
| value_loss         | 9.78     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.637    |
| fps                | 426      |
| nupdates           | 58500    |
| policy_entropy     | 0.0586   |
| total_timesteps    | 292500   |
| value_loss         | 37.6     |
---------------------------------
10.0
10.0
14.02
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | 0.313    |
| fps                | 426      |
| nupdates           | 58600    |
| policy_entropy     | 0.168    |
| total_timesteps    | 293000   |
| value_loss         | 18.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.93     |
| fps                | 426      |
| nupdates           | 58700    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 293500   |
| value_loss         | 7.77     |
---------------------------------
20.0
20.0
13.39
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.729    |
| fps                | 426      |
| nupdates           | 58800    |
| policy_entropy     | 0.191    |
| total_timesteps    | 294000   |
| value_loss         | 12.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 223      |
| explained_variance | 0.984    |
| fps                | 426      |
| nupdates           | 58900    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 294500   |
| value_loss         | 2.18     |
---------------------------------
11.0
11.0
13.83
10.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.934    |
| fps                | 426      |
| nupdates           | 59000    |
| policy_entropy     | 0.00635  |
| total_timesteps    | 295000   |
| value_loss         | 14.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.954    |
| fps                | 427      |
| nupdates           | 59100    |
| policy_entropy     | 0.0175   |
| total_timesteps    | 295500   |
| value_loss         | 19.1     |
---------------------------------
20.0
20.0
13.8
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.984    |
| fps                | 427      |
| nupdates           | 59200    |
| policy_entropy     | 0.00835  |
| total_timesteps    | 296000   |
| value_loss         | 1.03e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.96     |
| fps                | 427      |
| nupdates           | 59300    |
| policy_entropy     | 0.0163   |
| total_timesteps    | 296500   |
| value_loss         | 7.92     |
---------------------------------
10.0
10.0
13.85
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.991    |
| fps                | 427      |
| nupdates           | 59400    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 297000   |
| value_loss         | 5.04     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0.983    |
| fps                | 427      |
| nupdates           | 59500    |
| policy_entropy     | 0.0268   |
| total_timesteps    | 297500   |
| value_loss         | 3.54     |
---------------------------------
10.0
10.0
15.02
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 221      |
| explained_variance | 0.404    |
| fps                | 427      |
| nupdates           | 59600    |
| policy_entropy     | 0.145    |
| total_timesteps    | 298000   |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 220      |
| explained_variance | -0.317   |
| fps                | 427      |
| nupdates           | 59700    |
| policy_entropy     | 0.0206   |
| total_timesteps    | 298500   |
| value_loss         | 677      |
---------------------------------
20.0
20.0
15.32
15.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.828    |
| fps                | 427      |
| nupdates           | 59800    |
| policy_entropy     | 0.00172  |
| total_timesteps    | 299000   |
| value_loss         | 59.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.975    |
| fps                | 427      |
| nupdates           | 59900    |
| policy_entropy     | 0.0435   |
| total_timesteps    | 299500   |
| value_loss         | 12.1     |
---------------------------------
17.0
17.0
14.27
14.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.972    |
| fps                | 427      |
| nupdates           | 60000    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 300000   |
| value_loss         | 7.26     |
---------------------------------