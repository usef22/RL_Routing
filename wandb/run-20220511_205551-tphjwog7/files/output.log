WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220C4D1B208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220C4D1B208>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220B7857A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220B7857A90>>: AttributeError: module 'gast' has no attribute 'Index'
___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | 0.00154  |
| fps                | 25       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 976      |
---------------------------------
---------------------------------
| ep_len_mean        | 459      |
| ep_reward_mean     | -2e+03   |
| explained_variance | -0.0242  |
| fps                | 342      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 97.7     |
---------------------------------
461.0
461.0
460.0
460.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 460       |
| ep_reward_mean     | -1.83e+03 |
| explained_variance | -0.0171   |
| fps                | 356       |
| nupdates           | 200       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1000      |
| value_loss         | 527       |
----------------------------------
----------------------------------
| ep_len_mean        | 478       |
| ep_reward_mean     | -1.92e+03 |
| explained_variance | 0.0886    |
| fps                | 356       |
| nupdates           | 300       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1500      |
| value_loss         | 60.2      |
----------------------------------
108.0
108.0
385.25
460.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 385       |
| ep_reward_mean     | -1.46e+03 |
| explained_variance | 0.0068    |
| fps                | 324       |
| nupdates           | 400       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2000      |
| value_loss         | 86.4      |
----------------------------------
---------------------------------
| ep_len_mean        | 418      |
| ep_reward_mean     | -1.5e+03 |
| explained_variance | -0.0251  |
| fps                | 333      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 89.8     |
---------------------------------
24.0
24.0
414.2857142857143
461.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 414       |
| ep_reward_mean     | -1.43e+03 |
| explained_variance | 0.0025    |
| fps                | 338       |
| nupdates           | 600       |
| policy_entropy     | 1.1       |
| total_timesteps    | 3000      |
| value_loss         | 148       |
----------------------------------
---------------------------------
| ep_len_mean        | 310      |
| ep_reward_mean     | -983     |
| explained_variance | 0.00278  |
| fps                | 344      |
| nupdates           | 700      |
| policy_entropy     | 1.08     |
| total_timesteps    | 3500     |
| value_loss         | 246      |
---------------------------------
311.0
311.0
294.2307692307692
103.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 294      |
| ep_reward_mean     | -913     |
| explained_variance | -0.00425 |
| fps                | 346      |
| nupdates           | 800      |
| policy_entropy     | 1.09     |
| total_timesteps    | 4000     |
| value_loss         | 138      |
---------------------------------
---------------------------------
| ep_len_mean        | 294      |
| ep_reward_mean     | -913     |
| explained_variance | 4.93e-05 |
| fps                | 347      |
| nupdates           | 900      |
| policy_entropy     | 1.06     |
| total_timesteps    | 4500     |
| value_loss         | 567      |
---------------------------------
46.0
46.0
303.375
99.0
----------------------------------
| ep_len_mean        | 303       |
| ep_reward_mean     | -962      |
| explained_variance | -0.000377 |
| fps                | 351       |
| nupdates           | 1000      |
| policy_entropy     | 1.08      |
| total_timesteps    | 5000      |
| value_loss         | 173       |
----------------------------------
---------------------------------
| ep_len_mean        | 297      |
| ep_reward_mean     | -931     |
| explained_variance | -0.001   |
| fps                | 353      |
| nupdates           | 1100     |
| policy_entropy     | 1.09     |
| total_timesteps    | 5500     |
| value_loss         | 31.6     |
---------------------------------
563.0
563.0
312.05555555555554
149.5
---------------------------------
| ep_len_mean        | 312      |
| ep_reward_mean     | -973     |
| explained_variance | 1.85e-05 |
| fps                | 354      |
| nupdates           | 1200     |
| policy_entropy     | 1.08     |
| total_timesteps    | 6000     |
| value_loss         | 52.4     |
---------------------------------
----------------------------------
| ep_len_mean        | 320       |
| ep_reward_mean     | -1.01e+03 |
| explained_variance | 0.000148  |
| fps                | 354       |
| nupdates           | 1300      |
| policy_entropy     | 1.07      |
| total_timesteps    | 6500      |
| value_loss         | 55.2      |
----------------------------------
85.0
85.0
293.6521739130435
235.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 294      |
| ep_reward_mean     | -904     |
| explained_variance | 0.000784 |
| fps                | 356      |
| nupdates           | 1400     |
| policy_entropy     | 0.982    |
| total_timesteps    | 7000     |
| value_loss         | 24.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 277      |
| ep_reward_mean     | -838     |
| explained_variance | 2.24e-05 |
| fps                | 358      |
| nupdates           | 1500     |
| policy_entropy     | 1.04     |
| total_timesteps    | 7500     |
| value_loss         | 135      |
---------------------------------
190.0
190.0
265.56666666666666
159.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 266      |
| ep_reward_mean     | -789     |
| explained_variance | 2.6e-05  |
| fps                | 360      |
| nupdates           | 1600     |
| policy_entropy     | 1.08     |
| total_timesteps    | 8000     |
| value_loss         | 209      |
---------------------------------
---------------------------------
| ep_len_mean        | 260      |
| ep_reward_mean     | -767     |
| explained_variance | 0.00017  |
| fps                | 361      |
| nupdates           | 1700     |
| policy_entropy     | 1.09     |
| total_timesteps    | 8500     |
| value_loss         | 95       |
---------------------------------
37.0
37.0
229.97435897435898
102.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 230      |
| ep_reward_mean     | -640     |
| explained_variance | 6.9e-05  |
| fps                | 362      |
| nupdates           | 1800     |
| policy_entropy     | 1.03     |
| total_timesteps    | 9000     |
| value_loss         | 17.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 219      |
| ep_reward_mean     | -595     |
| explained_variance | 9.42e-06 |
| fps                | 364      |
| nupdates           | 1900     |
| policy_entropy     | 1.02     |
| total_timesteps    | 9500     |
| value_loss         | 290      |
---------------------------------
150.0
150.0
203.6326530612245
86.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 204       |
| ep_reward_mean     | -533      |
| explained_variance | -1.67e-05 |
| fps                | 365       |
| nupdates           | 2000      |
| policy_entropy     | 0.833     |
| total_timesteps    | 10000     |
| value_loss         | 580       |
----------------------------------
---------------------------------
| ep_len_mean        | 194      |
| ep_reward_mean     | -498     |
| explained_variance | -0.00907 |
| fps                | 369      |
| nupdates           | 2100     |
| policy_entropy     | 0.943    |
| total_timesteps    | 10500    |
| value_loss         | 259      |
---------------------------------
58.0
58.0
186.16949152542372
66.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 186      |
| ep_reward_mean     | -465     |
| explained_variance | 0.0003   |
| fps                | 370      |
| nupdates           | 2200     |
| policy_entropy     | 0.532    |
| total_timesteps    | 11000    |
| value_loss         | 557      |
---------------------------------
----------------------------------
| ep_len_mean        | 178       |
| ep_reward_mean     | -429      |
| explained_variance | -0.000221 |
| fps                | 373       |
| nupdates           | 2300      |
| policy_entropy     | 0.872     |
| total_timesteps    | 11500     |
| value_loss         | 50.9      |
----------------------------------
9.0
9.0
148.11111111111111
20.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 148       |
| ep_reward_mean     | -313      |
| explained_variance | -5.25e-05 |
| fps                | 375       |
| nupdates           | 2400      |
| policy_entropy     | 0.498     |
| total_timesteps    | 12000     |
| value_loss         | 2.97e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 134      |
| ep_reward_mean     | -255     |
| explained_variance | -0.0278  |
| fps                | 376      |
| nupdates           | 2500     |
| policy_entropy     | 0.729    |
| total_timesteps    | 12500    |
| value_loss         | 75.9     |
---------------------------------
13.0
13.0
106.9
23.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 107      |
| ep_reward_mean     | -140     |
| explained_variance | 0        |
| fps                | 377      |
| nupdates           | 2600     |
| policy_entropy     | 0.262    |
| total_timesteps    | 13000    |
| value_loss         | 556      |
---------------------------------
---------------------------------
| ep_len_mean        | 86.6     |
| ep_reward_mean     | -58.1    |
| explained_variance | 0.0014   |
| fps                | 376      |
| nupdates           | 2700     |
| policy_entropy     | 0.552    |
| total_timesteps    | 13500    |
| value_loss         | 476      |
---------------------------------
29.0
29.0
65.22
26.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 65.2      |
| ep_reward_mean     | 19.7      |
| explained_variance | -0.000389 |
| fps                | 376       |
| nupdates           | 2800      |
| policy_entropy     | 0.456     |
| total_timesteps    | 14000     |
| value_loss         | 4.67e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 54.2     |
| ep_reward_mean     | 61.7     |
| explained_variance | 0.0336   |
| fps                | 377      |
| nupdates           | 2900     |
| policy_entropy     | 0.36     |
| total_timesteps    | 14500    |
| value_loss         | 530      |
---------------------------------
41.0
41.0
42.99
13.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 43       |
| ep_reward_mean     | 109      |
| explained_variance | -0.0715  |
| fps                | 377      |
| nupdates           | 3000     |
| policy_entropy     | 0.697    |
| total_timesteps    | 15000    |
| value_loss         | 39.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.2     |
| ep_reward_mean     | 128      |
| explained_variance | 0.0105   |
| fps                | 378      |
| nupdates           | 3100     |
| policy_entropy     | 0.399    |
| total_timesteps    | 15500    |
| value_loss         | 104      |
---------------------------------
153.0
153.0
40.86
33.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 40.9     |
| ep_reward_mean     | 117      |
| explained_variance | 0.00563  |
| fps                | 379      |
| nupdates           | 3200     |
| policy_entropy     | 0.471    |
| total_timesteps    | 16000    |
| value_loss         | 12.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 41.2     |
| ep_reward_mean     | 116      |
| explained_variance | 0        |
| fps                | 378      |
| nupdates           | 3300     |
| policy_entropy     | 0.47     |
| total_timesteps    | 16500    |
| value_loss         | 98.6     |
---------------------------------
10.0
10.0
39.52
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 39.5     |
| ep_reward_mean     | 122      |
| explained_variance | 0.127    |
| fps                | 379      |
| nupdates           | 3400     |
| policy_entropy     | 0.149    |
| total_timesteps    | 17000    |
| value_loss         | 1.12e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 36       |
| ep_reward_mean     | 140      |
| explained_variance | 0.00441  |
| fps                | 379      |
| nupdates           | 3500     |
| policy_entropy     | 0.952    |
| total_timesteps    | 17500    |
| value_loss         | 39.9     |
---------------------------------
21.0
21.0
36.37
37.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 36.4     |
| ep_reward_mean     | 142      |
| explained_variance | 0        |
| fps                | 379      |
| nupdates           | 3600     |
| policy_entropy     | 0.212    |
| total_timesteps    | 18000    |
| value_loss         | 10.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.1     |
| ep_reward_mean     | 137      |
| explained_variance | 0.066    |
| fps                | 380      |
| nupdates           | 3700     |
| policy_entropy     | 0.151    |
| total_timesteps    | 18500    |
| value_loss         | 815      |
---------------------------------
21.0
21.0
36.2
13.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 36.2     |
| ep_reward_mean     | 142      |
| explained_variance | 0.00417  |
| fps                | 381      |
| nupdates           | 3800     |
| policy_entropy     | 0.312    |
| total_timesteps    | 19000    |
| value_loss         | 7.02e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 29.8     |
| ep_reward_mean     | 165      |
| explained_variance | -0.366   |
| fps                | 382      |
| nupdates           | 3900     |
| policy_entropy     | 0.447    |
| total_timesteps    | 19500    |
| value_loss         | 17.4     |
---------------------------------
27.0
27.0
30.0
19.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 30       |
| ep_reward_mean     | 167      |
| explained_variance | 0        |
| fps                | 383      |
| nupdates           | 4000     |
| policy_entropy     | 0.638    |
| total_timesteps    | 20000    |
| value_loss         | 9.07     |
---------------------------------
----------------------------------
| ep_len_mean        | 30.7      |
| ep_reward_mean     | 165       |
| explained_variance | -0.000128 |
| fps                | 383       |
| nupdates           | 4100      |
| policy_entropy     | 0.895     |
| total_timesteps    | 20500     |
| value_loss         | 79.7      |
----------------------------------
10.0
10.0
30.12
22.0
---------------------------------
| ep_len_mean        | 30.1     |
| ep_reward_mean     | 165      |
| explained_variance | -0.00146 |
| fps                | 384      |
| nupdates           | 4200     |
| policy_entropy     | 0.663    |
| total_timesteps    | 21000    |
| value_loss         | 87.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 28.2     |
| ep_reward_mean     | 173      |
| explained_variance | -3.97    |
| fps                | 384      |
| nupdates           | 4300     |
| policy_entropy     | 0.44     |
| total_timesteps    | 21500    |
| value_loss         | 53.6     |
---------------------------------
20.0
20.0
29.71
25.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 29.7     |
| ep_reward_mean     | 168      |
| explained_variance | 0.000278 |
| fps                | 385      |
| nupdates           | 4400     |
| policy_entropy     | 0.75     |
| total_timesteps    | 22000    |
| value_loss         | 1.98e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 33.3     |
| ep_reward_mean     | 158      |
| explained_variance | 0        |
| fps                | 385      |
| nupdates           | 4500     |
| policy_entropy     | 0.127    |
| total_timesteps    | 22500    |
| value_loss         | 7.09     |
---------------------------------
11.0
11.0
36.74
45.0
---------------------------------
| ep_len_mean        | 36.7     |
| ep_reward_mean     | 150      |
| explained_variance | -0.00163 |
| fps                | 386      |
| nupdates           | 4600     |
| policy_entropy     | 0.679    |
| total_timesteps    | 23000    |
| value_loss         | 81.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 36.4     |
| ep_reward_mean     | 148      |
| explained_variance | -0.00128 |
| fps                | 385      |
| nupdates           | 4700     |
| policy_entropy     | 0.395    |
| total_timesteps    | 23500    |
| value_loss         | 6.07     |
---------------------------------
352.0
352.0
39.69
33.5
----------------------------------
| ep_len_mean        | 39.7      |
| ep_reward_mean     | 140       |
| explained_variance | -5.58e-05 |
| fps                | 385       |
| nupdates           | 4800      |
| policy_entropy     | 0.634     |
| total_timesteps    | 24000     |
| value_loss         | 236       |
----------------------------------
---------------------------------
| ep_len_mean        | 40.7     |
| ep_reward_mean     | 137      |
| explained_variance | -0.0133  |
| fps                | 385      |
| nupdates           | 4900     |
| policy_entropy     | 0.646    |
| total_timesteps    | 24500    |
| value_loss         | 6.67     |
---------------------------------
19.0
19.0
41.07
15.0
----------------------------------
| ep_len_mean        | 41.1      |
| ep_reward_mean     | 135       |
| explained_variance | -0.000576 |
| fps                | 385       |
| nupdates           | 5000      |
| policy_entropy     | 0.315     |
| total_timesteps    | 25000     |
| value_loss         | 222       |
----------------------------------
---------------------------------
| ep_len_mean        | 45.4     |
| ep_reward_mean     | 120      |
| explained_variance | 0        |
| fps                | 385      |
| nupdates           | 5100     |
| policy_entropy     | 0.078    |
| total_timesteps    | 25500    |
| value_loss         | 4.1      |
---------------------------------
53.0
53.0
48.54
25.0
---------------------------------
| ep_len_mean        | 48.5     |
| ep_reward_mean     | 112      |
| explained_variance | 0        |
| fps                | 381      |
| nupdates           | 5200     |
| policy_entropy     | 0.372    |
| total_timesteps    | 26000    |
| value_loss         | 3.68     |
---------------------------------
----------------------------------
| ep_len_mean        | 49.9      |
| ep_reward_mean     | 108       |
| explained_variance | -3.22e-06 |
| fps                | 382       |
| nupdates           | 5300      |
| policy_entropy     | 0.822     |
| total_timesteps    | 26500     |
| value_loss         | 79.5      |
----------------------------------
16.0
16.0
50.13
19.5
---------------------------------
| ep_len_mean        | 50.1     |
| ep_reward_mean     | 108      |
| explained_variance | -1.06    |
| fps                | 383      |
| nupdates           | 5400     |
| policy_entropy     | 0.425    |
| total_timesteps    | 27000    |
| value_loss         | 67.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 42       |
| ep_reward_mean     | 130      |
| explained_variance | -0.0226  |
| fps                | 383      |
| nupdates           | 5500     |
| policy_entropy     | 0.347    |
| total_timesteps    | 27500    |
| value_loss         | 2.98     |
---------------------------------
123.0
123.0
38.77
43.5
---------------------------------
| ep_len_mean        | 38.8     |
| ep_reward_mean     | 141      |
| explained_variance | 0.00105  |
| fps                | 382      |
| nupdates           | 5600     |
| policy_entropy     | 0.749    |
| total_timesteps    | 28000    |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 38.6     |
| ep_reward_mean     | 142      |
| explained_variance | -0.0119  |
| fps                | 382      |
| nupdates           | 5700     |
| policy_entropy     | 0.496    |
| total_timesteps    | 28500    |
| value_loss         | 2.43     |
---------------------------------
10.0
10.0
31.17
10.0
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 166      |
| explained_variance | -11.3    |
| fps                | 383      |
| nupdates           | 5800     |
| policy_entropy     | 0.426    |
| total_timesteps    | 29000    |
| value_loss         | 554      |
---------------------------------
---------------------------------
| ep_len_mean        | 30.4     |
| ep_reward_mean     | 170      |
| explained_variance | -0.0793  |
| fps                | 383      |
| nupdates           | 5900     |
| policy_entropy     | 0.217    |
| total_timesteps    | 29500    |
| value_loss         | 7.48e+04 |
---------------------------------
25.0
25.0
30.07
30.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 30.1     |
| ep_reward_mean     | 172      |
| explained_variance | -0.0257  |
| fps                | 383      |
| nupdates           | 6000     |
| policy_entropy     | 0.506    |
| total_timesteps    | 30000    |
| value_loss         | 2.59e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 29.8     |
| ep_reward_mean     | 171      |
| explained_variance | 0.0138   |
| fps                | 383      |
| nupdates           | 6100     |
| policy_entropy     | 0.74     |
| total_timesteps    | 30500    |
| value_loss         | 60.1     |
---------------------------------
9.0
9.0
32.32
17.0
---------------------------------
| ep_len_mean        | 32.3     |
| ep_reward_mean     | 159      |
| explained_variance | 0        |
| fps                | 383      |
| nupdates           | 6200     |
| policy_entropy     | 0.509    |
| total_timesteps    | 31000    |
| value_loss         | 19.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 33.1     |
| ep_reward_mean     | 155      |
| explained_variance | 0.635    |
| fps                | 384      |
| nupdates           | 6300     |
| policy_entropy     | 0.2      |
| total_timesteps    | 31500    |
| value_loss         | 236      |
---------------------------------
73.0
73.0
36.02
20.5
---------------------------------
| ep_len_mean        | 36       |
| ep_reward_mean     | 148      |
| explained_variance | 0.871    |
| fps                | 385      |
| nupdates           | 6400     |
| policy_entropy     | 0.349    |
| total_timesteps    | 32000    |
| value_loss         | 24       |
---------------------------------
---------------------------------
| ep_len_mean        | 33.6     |
| ep_reward_mean     | 156      |
| explained_variance | -0.00114 |
| fps                | 385      |
| nupdates           | 6500     |
| policy_entropy     | 0.314    |
| total_timesteps    | 32500    |
| value_loss         | 56.1     |
---------------------------------
8.0
8.0
33.41
11.5
---------------------------------
| ep_len_mean        | 33.4     |
| ep_reward_mean     | 151      |
| explained_variance | 0.676    |
| fps                | 385      |
| nupdates           | 6600     |
| policy_entropy     | 0.137    |
| total_timesteps    | 33000    |
| value_loss         | 97.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 33.1     |
| ep_reward_mean     | 150      |
| explained_variance | 0.218    |
| fps                | 385      |
| nupdates           | 6700     |
| policy_entropy     | 0.408    |
| total_timesteps    | 33500    |
| value_loss         | 140      |
---------------------------------
10.0
10.0
28.56
10.0
---------------------------------
| ep_len_mean        | 28.6     |
| ep_reward_mean     | 170      |
| explained_variance | -9.18    |
| fps                | 384      |
| nupdates           | 6800     |
| policy_entropy     | 0.358    |
| total_timesteps    | 34000    |
| value_loss         | 13.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.6     |
| ep_reward_mean     | 179      |
| explained_variance | -0.0062  |
| fps                | 385      |
| nupdates           | 6900     |
| policy_entropy     | 0.441    |
| total_timesteps    | 34500    |
| value_loss         | 54.1     |
---------------------------------
8.0
8.0
28.38
17.5
---------------------------------
| ep_len_mean        | 28.4     |
| ep_reward_mean     | 167      |
| explained_variance | -4.7     |
| fps                | 385      |
| nupdates           | 7000     |
| policy_entropy     | 0.69     |
| total_timesteps    | 35000    |
| value_loss         | 140      |
---------------------------------
---------------------------------
| ep_len_mean        | 30.8     |
| ep_reward_mean     | 158      |
| explained_variance | 0.011    |
| fps                | 386      |
| nupdates           | 7100     |
| policy_entropy     | 0.63     |
| total_timesteps    | 35500    |
| value_loss         | 77.9     |
---------------------------------
10.0
10.0
29.96
19.5
---------------------------------
| ep_len_mean        | 30       |
| ep_reward_mean     | 161      |
| explained_variance | -0.0092  |
| fps                | 386      |
| nupdates           | 7200     |
| policy_entropy     | 0.199    |
| total_timesteps    | 36000    |
| value_loss         | 1.41e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 29       |
| ep_reward_mean     | 165      |
| explained_variance | 0.0695   |
| fps                | 386      |
| nupdates           | 7300     |
| policy_entropy     | 0.676    |
| total_timesteps    | 36500    |
| value_loss         | 27.9     |
---------------------------------
132.0
132.0
30.08
23.5
---------------------------------
| ep_len_mean        | 30.1     |
| ep_reward_mean     | 158      |
| explained_variance | -0.122   |
| fps                | 386      |
| nupdates           | 7400     |
| policy_entropy     | 0.133    |
| total_timesteps    | 37000    |
| value_loss         | 881      |
---------------------------------
---------------------------------
| ep_len_mean        | 30.8     |
| ep_reward_mean     | 153      |
| explained_variance | -3.64    |
| fps                | 386      |
| nupdates           | 7500     |
| policy_entropy     | 0.723    |
| total_timesteps    | 37500    |
| value_loss         | 45.5     |
---------------------------------
13.0
13.0
26.07
18.5
---------------------------------
| ep_len_mean        | 26.1     |
| ep_reward_mean     | 171      |
| explained_variance | 0        |
| fps                | 386      |
| nupdates           | 7600     |
| policy_entropy     | 0.253    |
| total_timesteps    | 38000    |
| value_loss         | 46.5     |
---------------------------------
----------------------------------
| ep_len_mean        | 26.4      |
| ep_reward_mean     | 169       |
| explained_variance | -1.19e-07 |
| fps                | 387       |
| nupdates           | 7700      |
| policy_entropy     | 0.552     |
| total_timesteps    | 38500     |
| value_loss         | 0.051     |
----------------------------------
127.0
127.0
29.64
50.0
---------------------------------
| ep_len_mean        | 29.6     |
| ep_reward_mean     | 162      |
| explained_variance | -0.0244  |
| fps                | 387      |
| nupdates           | 7800     |
| policy_entropy     | 0.393    |
| total_timesteps    | 39000    |
| value_loss         | 24.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 32.5     |
| ep_reward_mean     | 145      |
| explained_variance | 0.0289   |
| fps                | 387      |
| nupdates           | 7900     |
| policy_entropy     | 0.439    |
| total_timesteps    | 39500    |
| value_loss         | 0.00116  |
---------------------------------
10.0
10.0
34.47
27.5
---------------------------------
| ep_len_mean        | 34.5     |
| ep_reward_mean     | 139      |
| explained_variance | 0.152    |
| fps                | 387      |
| nupdates           | 8000     |
| policy_entropy     | 0.59     |
| total_timesteps    | 40000    |
| value_loss         | 9.79     |
---------------------------------
---------------------------------
| ep_len_mean        | 31.6     |
| ep_reward_mean     | 151      |
| explained_variance | 0.000816 |
| fps                | 387      |
| nupdates           | 8100     |
| policy_entropy     | 0.735    |
| total_timesteps    | 40500    |
| value_loss         | 42       |
---------------------------------
12.0
12.0
33.18
17.5
---------------------------------
| ep_len_mean        | 33.2     |
| ep_reward_mean     | 147      |
| explained_variance | 0.00675  |
| fps                | 388      |
| nupdates           | 8200     |
| policy_entropy     | 0.753    |
| total_timesteps    | 41000    |
| value_loss         | 1.72     |
---------------------------------
---------------------------------
| ep_len_mean        | 36.2     |
| ep_reward_mean     | 140      |
| explained_variance | -0.412   |
| fps                | 388      |
| nupdates           | 8300     |
| policy_entropy     | 0.62     |
| total_timesteps    | 41500    |
| value_loss         | 0.000914 |
---------------------------------
9.0
9.0
35.91
11.5
---------------------------------
| ep_len_mean        | 35.9     |
| ep_reward_mean     | 144      |
| explained_variance | 0.0687   |
| fps                | 388      |
| nupdates           | 8400     |
| policy_entropy     | 0.648    |
| total_timesteps    | 42000    |
| value_loss         | 0.000547 |
---------------------------------
---------------------------------
| ep_len_mean        | 38.4     |
| ep_reward_mean     | 136      |
| explained_variance | 0.963    |
| fps                | 389      |
| nupdates           | 8500     |
| policy_entropy     | 0.206    |
| total_timesteps    | 42500    |
| value_loss         | 30.3     |
---------------------------------
155.0
155.0
37.33
12.0
---------------------------------
| ep_len_mean        | 37.3     |
| ep_reward_mean     | 140      |
| explained_variance | 0.00546  |
| fps                | 389      |
| nupdates           | 8600     |
| policy_entropy     | 0.652    |
| total_timesteps    | 43000    |
| value_loss         | 86.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.5     |
| ep_reward_mean     | 146      |
| explained_variance | -0.0232  |
| fps                | 389      |
| nupdates           | 8700     |
| policy_entropy     | 0.767    |
| total_timesteps    | 43500    |
| value_loss         | 24.9     |
---------------------------------
11.0
11.0
43.53
102.0
---------------------------------
| ep_len_mean        | 43.5     |
| ep_reward_mean     | 131      |
| explained_variance | -0.0291  |
| fps                | 389      |
| nupdates           | 8800     |
| policy_entropy     | 0.839    |
| total_timesteps    | 44000    |
| value_loss         | 0.018    |
---------------------------------
---------------------------------
| ep_len_mean        | 46.1     |
| ep_reward_mean     | 122      |
| explained_variance | -165     |
| fps                | 390      |
| nupdates           | 8900     |
| policy_entropy     | 0.724    |
| total_timesteps    | 44500    |
| value_loss         | 0.0294   |
---------------------------------
209.0
209.0
50.7
126.5
---------------------------------
| ep_len_mean        | 50.7     |
| ep_reward_mean     | 113      |
| explained_variance | 0.065    |
| fps                | 390      |
| nupdates           | 9000     |
| policy_entropy     | 0.447    |
| total_timesteps    | 45000    |
| value_loss         | 35.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 54       |
| ep_reward_mean     | 105      |
| explained_variance | -2.28    |
| fps                | 390      |
| nupdates           | 9100     |
| policy_entropy     | 0.799    |
| total_timesteps    | 45500    |
| value_loss         | 4.86     |
---------------------------------
9.0
9.0
57.26
30.5
---------------------------------
| ep_len_mean        | 57.3     |
| ep_reward_mean     | 97.4     |
| explained_variance | -154     |
| fps                | 390      |
| nupdates           | 9200     |
| policy_entropy     | 0.559    |
| total_timesteps    | 46000    |
| value_loss         | 0.00493  |
---------------------------------
---------------------------------
| ep_len_mean        | 59.2     |
| ep_reward_mean     | 93.3     |
| explained_variance | -22.3    |
| fps                | 390      |
| nupdates           | 9300     |
| policy_entropy     | 0.779    |
| total_timesteps    | 46500    |
| value_loss         | 0.000104 |
---------------------------------
12.0
12.0
58.55
12.0
----------------------------------
| ep_len_mean        | 58.5      |
| ep_reward_mean     | 97.2      |
| explained_variance | -1.97e+04 |
| fps                | 391       |
| nupdates           | 9400      |
| policy_entropy     | 0.624     |
| total_timesteps    | 47000     |
| value_loss         | 0.000461  |
----------------------------------
---------------------------------
| ep_len_mean        | 60.9     |
| ep_reward_mean     | 93.9     |
| explained_variance | -1.73    |
| fps                | 391      |
| nupdates           | 9500     |
| policy_entropy     | 0.728    |
| total_timesteps    | 47500    |
| value_loss         | 6.2e-05  |
---------------------------------
14.0
14.0
59.24
10.0
---------------------------------
| ep_len_mean        | 59.2     |
| ep_reward_mean     | 96.8     |
| explained_variance | -0.511   |
| fps                | 390      |
| nupdates           | 9600     |
| policy_entropy     | 0.803    |
| total_timesteps    | 48000    |
| value_loss         | 0.000283 |
---------------------------------
---------------------------------
| ep_len_mean        | 56.7     |
| ep_reward_mean     | 105      |
| explained_variance | 0.336    |
| fps                | 390      |
| nupdates           | 9700     |
| policy_entropy     | 0.217    |
| total_timesteps    | 48500    |
| value_loss         | 135      |
---------------------------------
14.0
14.0
32.67
12.0
---------------------------------
| ep_len_mean        | 32.7     |
| ep_reward_mean     | 167      |
| explained_variance | -18.6    |
| fps                | 389      |
| nupdates           | 9800     |
| policy_entropy     | 0.161    |
| total_timesteps    | 49000    |
| value_loss         | 28.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 28.4     |
| ep_reward_mean     | 177      |
| explained_variance | 0.0518   |
| fps                | 389      |
| nupdates           | 9900     |
| policy_entropy     | 0.379    |
| total_timesteps    | 49500    |
| value_loss         | 29.4     |
---------------------------------
9.0
9.0
24.13
31.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 24.1     |
| ep_reward_mean     | 185      |
| explained_variance | -12.9    |
| fps                | 389      |
| nupdates           | 10000    |
| policy_entropy     | 0.584    |
| total_timesteps    | 50000    |
| value_loss         | 75.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 22       |
| ep_reward_mean     | 191      |
| explained_variance | -0.129   |
| fps                | 387      |
| nupdates           | 10100    |
| policy_entropy     | 0.136    |
| total_timesteps    | 50500    |
| value_loss         | 9.56e+04 |
---------------------------------
26.0
26.0
20.96
13.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 194      |
| explained_variance | 0.0114   |
| fps                | 387      |
| nupdates           | 10200    |
| policy_entropy     | 0.393    |
| total_timesteps    | 51000    |
| value_loss         | 1.23e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 196      |
| explained_variance | -0.0759  |
| fps                | 387      |
| nupdates           | 10300    |
| policy_entropy     | 0.397    |
| total_timesteps    | 51500    |
| value_loss         | 5.74e+04 |
---------------------------------
11.0
11.0
17.63
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 201      |
| explained_variance | -0.343   |
| fps                | 387      |
| nupdates           | 10400    |
| policy_entropy     | 0.0878   |
| total_timesteps    | 52000    |
| value_loss         | 1.29e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 205      |
| explained_variance | -18.6    |
| fps                | 387      |
| nupdates           | 10500    |
| policy_entropy     | 0.452    |
| total_timesteps    | 52500    |
| value_loss         | 244      |
---------------------------------
10.0
10.0
16.97
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 204      |
| explained_variance | -6.55    |
| fps                | 388      |
| nupdates           | 10600    |
| policy_entropy     | 0.175    |
| total_timesteps    | 53000    |
| value_loss         | 9.65e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 203      |
| explained_variance | -0.295   |
| fps                | 388      |
| nupdates           | 10700    |
| policy_entropy     | 0.226    |
| total_timesteps    | 53500    |
| value_loss         | 480      |
---------------------------------
10.0
10.0
18.41
11.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 200      |
| explained_variance | -0.0312  |
| fps                | 388      |
| nupdates           | 10800    |
| policy_entropy     | 0.137    |
| total_timesteps    | 54000    |
| value_loss         | 1.31e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 198      |
| explained_variance | 0.493    |
| fps                | 388      |
| nupdates           | 10900    |
| policy_entropy     | 0.389    |
| total_timesteps    | 54500    |
| value_loss         | 96.9     |
---------------------------------
9.0
9.0
18.08
11.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 200      |
| explained_variance | -9.08    |
| fps                | 389      |
| nupdates           | 11000    |
| policy_entropy     | 0.293    |
| total_timesteps    | 55000    |
| value_loss         | 548      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 200      |
| explained_variance | -0.282   |
| fps                | 389      |
| nupdates           | 11100    |
| policy_entropy     | 0.0933   |
| total_timesteps    | 55500    |
| value_loss         | 1.85e+04 |
---------------------------------
11.0
11.0
17.61
21.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 203      |
| explained_variance | -1.15    |
| fps                | 389      |
| nupdates           | 11200    |
| policy_entropy     | 0.55     |
| total_timesteps    | 56000    |
| value_loss         | 151      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | 0.0817   |
| fps                | 390      |
| nupdates           | 11300    |
| policy_entropy     | 0.302    |
| total_timesteps    | 56500    |
| value_loss         | 229      |
---------------------------------
10.0
10.0
18.58
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -0.258   |
| fps                | 390      |
| nupdates           | 11400    |
| policy_entropy     | 0.0762   |
| total_timesteps    | 57000    |
| value_loss         | 2.69e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 199      |
| explained_variance | 0.031    |
| fps                | 389      |
| nupdates           | 11500    |
| policy_entropy     | 0.507    |
| total_timesteps    | 57500    |
| value_loss         | 2.23e+04 |
---------------------------------
9.0
9.0
20.48
9.5
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 195      |
| explained_variance | -1.95    |
| fps                | 390      |
| nupdates           | 11600    |
| policy_entropy     | 0.139    |
| total_timesteps    | 58000    |
| value_loss         | 5.67e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 194      |
| explained_variance | 0.308    |
| fps                | 390      |
| nupdates           | 11700    |
| policy_entropy     | 0.34     |
| total_timesteps    | 58500    |
| value_loss         | 47.4     |
---------------------------------
17.0
17.0
17.36
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 200      |
| explained_variance | -0.19    |
| fps                | 390      |
| nupdates           | 11800    |
| policy_entropy     | 0.0684   |
| total_timesteps    | 59000    |
| value_loss         | 120      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 207      |
| explained_variance | -2.24    |
| fps                | 390      |
| nupdates           | 11900    |
| policy_entropy     | 0.351    |
| total_timesteps    | 59500    |
| value_loss         | 488      |
---------------------------------
9.0
9.0
16.8
17.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | -4.26    |
| fps                | 390      |
| nupdates           | 12000    |
| policy_entropy     | 0.502    |
| total_timesteps    | 60000    |
| value_loss         | 99       |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -1.03    |
| fps                | 390      |
| nupdates           | 12100    |
| policy_entropy     | 0.381    |
| total_timesteps    | 60500    |
| value_loss         | 57.2     |
---------------------------------
15.0
15.0
19.49
19.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 200      |
| explained_variance | -0.0483  |
| fps                | 390      |
| nupdates           | 12200    |
| policy_entropy     | 0.115    |
| total_timesteps    | 61000    |
| value_loss         | 1.15e+04 |
---------------------------------
----------------------------------
| ep_len_mean        | 20.2      |
| ep_reward_mean     | 196       |
| explained_variance | -1.19e-07 |
| fps                | 389       |
| nupdates           | 12300     |
| policy_entropy     | 0.641     |
| total_timesteps    | 61500     |
| value_loss         | 19.9      |
----------------------------------
50.0
50.0
22.68
26.5
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 189      |
| explained_variance | -4.82    |
| fps                | 389      |
| nupdates           | 12400    |
| policy_entropy     | 0.439    |
| total_timesteps    | 62000    |
| value_loss         | 292      |
---------------------------------
---------------------------------
| ep_len_mean        | 22       |
| ep_reward_mean     | 189      |
| explained_variance | -4.81    |
| fps                | 389      |
| nupdates           | 12500    |
| policy_entropy     | 0.29     |
| total_timesteps    | 62500    |
| value_loss         | 223      |
---------------------------------
10.0
10.0
19.34
10.0
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 195      |
| explained_variance | 0.0215   |
| fps                | 389      |
| nupdates           | 12600    |
| policy_entropy     | 0.058    |
| total_timesteps    | 63000    |
| value_loss         | 90.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 195      |
| explained_variance | -0.204   |
| fps                | 388      |
| nupdates           | 12700    |
| policy_entropy     | 0.101    |
| total_timesteps    | 63500    |
| value_loss         | 2.82e+04 |
---------------------------------
9.0
9.0
17.16
11.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 202      |
| explained_variance | -2.55    |
| fps                | 388      |
| nupdates           | 12800    |
| policy_entropy     | 0.612    |
| total_timesteps    | 64000    |
| value_loss         | 280      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 201      |
| explained_variance | -0.183   |
| fps                | 388      |
| nupdates           | 12900    |
| policy_entropy     | 0.165    |
| total_timesteps    | 64500    |
| value_loss         | 2.57e+04 |
---------------------------------
10.0
10.0
19.46
16.5
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 196      |
| explained_variance | 0.611    |
| fps                | 388      |
| nupdates           | 13000    |
| policy_entropy     | 0.0389   |
| total_timesteps    | 65000    |
| value_loss         | 126      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 203      |
| explained_variance | -0.187   |
| fps                | 387      |
| nupdates           | 13100    |
| policy_entropy     | 0.244    |
| total_timesteps    | 65500    |
| value_loss         | 1.63e+04 |
---------------------------------
9.0
9.0
17.06
9.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0.164    |
| fps                | 387      |
| nupdates           | 13200    |
| policy_entropy     | 0.148    |
| total_timesteps    | 66000    |
| value_loss         | 96.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 203      |
| explained_variance | -4.69    |
| fps                | 387      |
| nupdates           | 13300    |
| policy_entropy     | 0.154    |
| total_timesteps    | 66500    |
| value_loss         | 150      |
---------------------------------
13.0
13.0
17.18
12.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 205      |
| explained_variance | -0.211   |
| fps                | 387      |
| nupdates           | 13400    |
| policy_entropy     | 0.052    |
| total_timesteps    | 67000    |
| value_loss         | 112      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 200      |
| explained_variance | 0        |
| fps                | 387      |
| nupdates           | 13500    |
| policy_entropy     | 0.354    |
| total_timesteps    | 67500    |
| value_loss         | 194      |
---------------------------------
37.0
37.0
17.7
10.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 204      |
| explained_variance | 0.761    |
| fps                | 387      |
| nupdates           | 13600    |
| policy_entropy     | 0.0427   |
| total_timesteps    | 68000    |
| value_loss         | 258      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.339    |
| fps                | 387      |
| nupdates           | 13700    |
| policy_entropy     | 0.0337   |
| total_timesteps    | 68500    |
| value_loss         | 424      |
---------------------------------
10.0
10.0
16.48
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 208      |
| explained_variance | -0.00996 |
| fps                | 386      |
| nupdates           | 13800    |
| policy_entropy     | 0.0733   |
| total_timesteps    | 69000    |
| value_loss         | 3.91e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 207      |
| explained_variance | -0.965   |
| fps                | 386      |
| nupdates           | 13900    |
| policy_entropy     | 0.186    |
| total_timesteps    | 69500    |
| value_loss         | 334      |
---------------------------------
12.0
12.0
17.72
10.0
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 207      |
| explained_variance | -7.91    |
| fps                | 386      |
| nupdates           | 14000    |
| policy_entropy     | 0.695    |
| total_timesteps    | 70000    |
| value_loss         | 149      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 205      |
| explained_variance | -1.48    |
| fps                | 386      |
| nupdates           | 14100    |
| policy_entropy     | 0.0789   |
| total_timesteps    | 70500    |
| value_loss         | 148      |
---------------------------------
38.0
38.0
19.94
13.5
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 202      |
| explained_variance | 0.0137   |
| fps                | 386      |
| nupdates           | 14200    |
| policy_entropy     | 0.563    |
| total_timesteps    | 71000    |
| value_loss         | 67.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 199      |
| explained_variance | 0.11     |
| fps                | 385      |
| nupdates           | 14300    |
| policy_entropy     | 0.22     |
| total_timesteps    | 71500    |
| value_loss         | 2.04e+04 |
---------------------------------
22.0
22.0
18.93
14.5
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 198      |
| explained_variance | -3.5     |
| fps                | 385      |
| nupdates           | 14400    |
| policy_entropy     | 0.566    |
| total_timesteps    | 72000    |
| value_loss         | 197      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 197      |
| explained_variance | 0.101    |
| fps                | 385      |
| nupdates           | 14500    |
| policy_entropy     | 0.0716   |
| total_timesteps    | 72500    |
| value_loss         | 9.7e+03  |
---------------------------------
11.0
11.0
18.41
10.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 198      |
| explained_variance | -1.4     |
| fps                | 385      |
| nupdates           | 14600    |
| policy_entropy     | 0.123    |
| total_timesteps    | 73000    |
| value_loss         | 176      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 203      |
| explained_variance | 0.436    |
| fps                | 385      |
| nupdates           | 14700    |
| policy_entropy     | 0.373    |
| total_timesteps    | 73500    |
| value_loss         | 71.4     |
---------------------------------
26.0
26.0
18.49
17.5
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 201      |
| explained_variance | -2.34    |
| fps                | 384      |
| nupdates           | 14800    |
| policy_entropy     | 0.204    |
| total_timesteps    | 74000    |
| value_loss         | 162      |
---------------------------------
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 196      |
| explained_variance | 0.201    |
| fps                | 384      |
| nupdates           | 14900    |
| policy_entropy     | 0.573    |
| total_timesteps    | 74500    |
| value_loss         | 4.22e+04 |
---------------------------------
20.0
20.0
19.47
13.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 197      |
| explained_variance | 0.254    |
| fps                | 384      |
| nupdates           | 15000    |
| policy_entropy     | 0.0837   |
| total_timesteps    | 75000    |
| value_loss         | 285      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 202      |
| explained_variance | -0.602   |
| fps                | 385      |
| nupdates           | 15100    |
| policy_entropy     | 0.165    |
| total_timesteps    | 75500    |
| value_loss         | 161      |
---------------------------------
10.0
10.0
15.53
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 205      |
| explained_variance | 0.403    |
| fps                | 385      |
| nupdates           | 15200    |
| policy_entropy     | 0.0471   |
| total_timesteps    | 76000    |
| value_loss         | 470      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 206      |
| explained_variance | -1.08    |
| fps                | 385      |
| nupdates           | 15300    |
| policy_entropy     | 0.196    |
| total_timesteps    | 76500    |
| value_loss         | 1.12e+03 |
---------------------------------
10.0
10.0
17.43
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 204      |
| explained_variance | -16.5    |
| fps                | 385      |
| nupdates           | 15400    |
| policy_entropy     | 0.322    |
| total_timesteps    | 77000    |
| value_loss         | 552      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 207      |
| explained_variance | -1.22    |
| fps                | 385      |
| nupdates           | 15500    |
| policy_entropy     | 0.577    |
| total_timesteps    | 77500    |
| value_loss         | 167      |
---------------------------------
20.0
20.0
19.74
11.5
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 202      |
| explained_variance | -2.57    |
| fps                | 385      |
| nupdates           | 15600    |
| policy_entropy     | 0.223    |
| total_timesteps    | 78000    |
| value_loss         | 57.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 198      |
| explained_variance | 0.0765   |
| fps                | 386      |
| nupdates           | 15700    |
| policy_entropy     | 0.137    |
| total_timesteps    | 78500    |
| value_loss         | 3.02e+04 |
---------------------------------
9.0
9.0
20.81
21.5
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 195      |
| explained_variance | -1.43    |
| fps                | 385      |
| nupdates           | 15800    |
| policy_entropy     | 0.422    |
| total_timesteps    | 79000    |
| value_loss         | 236      |
---------------------------------
---------------------------------
| ep_len_mean        | 23.7     |
| ep_reward_mean     | 189      |
| explained_variance | 0.254    |
| fps                | 386      |
| nupdates           | 15900    |
| policy_entropy     | 0.0635   |
| total_timesteps    | 79500    |
| value_loss         | 809      |
---------------------------------
10.0
10.0
26.11
16.5
---------------------------------
| ep_len_mean        | 26.1     |
| ep_reward_mean     | 183      |
| explained_variance | -0.365   |
| fps                | 385      |
| nupdates           | 16000    |
| policy_entropy     | 0.695    |
| total_timesteps    | 80000    |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.6     |
| ep_reward_mean     | 183      |
| explained_variance | -0.831   |
| fps                | 385      |
| nupdates           | 16100    |
| policy_entropy     | 0.448    |
| total_timesteps    | 80500    |
| value_loss         | 86.9     |
---------------------------------
10.0
10.0
25.67
10.5
---------------------------------
| ep_len_mean        | 25.7     |
| ep_reward_mean     | 183      |
| explained_variance | -0.0541  |
| fps                | 385      |
| nupdates           | 16200    |
| policy_entropy     | 0.136    |
| total_timesteps    | 81000    |
| value_loss         | 5.57e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 188      |
| explained_variance | 0.715    |
| fps                | 385      |
| nupdates           | 16300    |
| policy_entropy     | 0.0385   |
| total_timesteps    | 81500    |
| value_loss         | 174      |
---------------------------------
29.0
29.0
19.55
9.5
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 196      |
| explained_variance | 0.369    |
| fps                | 385      |
| nupdates           | 16400    |
| policy_entropy     | 0.148    |
| total_timesteps    | 82000    |
| value_loss         | 3.68e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 196      |
| explained_variance | -0.101   |
| fps                | 385      |
| nupdates           | 16500    |
| policy_entropy     | 0.0386   |
| total_timesteps    | 82500    |
| value_loss         | 1.43e+03 |
---------------------------------
8.0
8.0
17.6
10.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 202      |
| explained_variance | -15.4    |
| fps                | 385      |
| nupdates           | 16600    |
| policy_entropy     | 0.73     |
| total_timesteps    | 83000    |
| value_loss         | 184      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 200      |
| explained_variance | -1.21    |
| fps                | 385      |
| nupdates           | 16700    |
| policy_entropy     | 0.0586   |
| total_timesteps    | 83500    |
| value_loss         | 2.47e+04 |
---------------------------------
16.0
16.0
15.8
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.122    |
| fps                | 385      |
| nupdates           | 16800    |
| policy_entropy     | 0.495    |
| total_timesteps    | 84000    |
| value_loss         | 98.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 202      |
| explained_variance | -0.37    |
| fps                | 385      |
| nupdates           | 16900    |
| policy_entropy     | 0.0873   |
| total_timesteps    | 84500    |
| value_loss         | 2.01e+04 |
---------------------------------
9.0
9.0
15.91
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 202      |
| explained_variance | -0.0133  |
| fps                | 385      |
| nupdates           | 17000    |
| policy_entropy     | 0.146    |
| total_timesteps    | 85000    |
| value_loss         | 2.29e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 202      |
| explained_variance | -1.19    |
| fps                | 385      |
| nupdates           | 17100    |
| policy_entropy     | 0.63     |
| total_timesteps    | 85500    |
| value_loss         | 253      |
---------------------------------
10.0
10.0
18.17
12.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 200      |
| explained_variance | -0.786   |
| fps                | 385      |
| nupdates           | 17200    |
| policy_entropy     | 0.55     |
| total_timesteps    | 86000    |
| value_loss         | 148      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 205      |
| explained_variance | 0.787    |
| fps                | 385      |
| nupdates           | 17300    |
| policy_entropy     | 0.0362   |
| total_timesteps    | 86500    |
| value_loss         | 179      |
---------------------------------
10.0
10.0
19.21
12.5
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 200      |
| explained_variance | -11.9    |
| fps                | 385      |
| nupdates           | 17400    |
| policy_entropy     | 0.403    |
| total_timesteps    | 87000    |
| value_loss         | 169      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 204      |
| explained_variance | -20      |
| fps                | 385      |
| nupdates           | 17500    |
| policy_entropy     | 0.382    |
| total_timesteps    | 87500    |
| value_loss         | 778      |
---------------------------------
9.0
9.0
17.27
11.5
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 204      |
| explained_variance | 0.398    |
| fps                | 385      |
| nupdates           | 17600    |
| policy_entropy     | 0.0336   |
| total_timesteps    | 88000    |
| value_loss         | 391      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.352    |
| fps                | 385      |
| nupdates           | 17700    |
| policy_entropy     | 0.0282   |
| total_timesteps    | 88500    |
| value_loss         | 523      |
---------------------------------
9.0
9.0
15.17
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.459    |
| fps                | 385      |
| nupdates           | 17800    |
| policy_entropy     | 0.0301   |
| total_timesteps    | 89000    |
| value_loss         | 57.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 208      |
| explained_variance | -0.59    |
| fps                | 386      |
| nupdates           | 17900    |
| policy_entropy     | 0.13     |
| total_timesteps    | 89500    |
| value_loss         | 2.12e+03 |
---------------------------------
9.0
9.0
16.77
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0        |
| fps                | 386      |
| nupdates           | 18000    |
| policy_entropy     | 0.191    |
| total_timesteps    | 90000    |
| value_loss         | 342      |
---------------------------------
----------------------------------
| ep_len_mean        | 16.6      |
| ep_reward_mean     | 208       |
| explained_variance | -1.19e-07 |
| fps                | 386       |
| nupdates           | 18100     |
| policy_entropy     | 0.65      |
| total_timesteps    | 90500     |
| value_loss         | 108       |
----------------------------------
10.0
10.0
17.06
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 205      |
| explained_variance | -4.25    |
| fps                | 386      |
| nupdates           | 18200    |
| policy_entropy     | 0.619    |
| total_timesteps    | 91000    |
| value_loss         | 501      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 204      |
| explained_variance | -0.748   |
| fps                | 386      |
| nupdates           | 18300    |
| policy_entropy     | 0.106    |
| total_timesteps    | 91500    |
| value_loss         | 1.72e+03 |
---------------------------------
11.0
11.0
18.55
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.359    |
| fps                | 386      |
| nupdates           | 18400    |
| policy_entropy     | 0.598    |
| total_timesteps    | 92000    |
| value_loss         | 55.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 206      |
| explained_variance | -1.71    |
| fps                | 386      |
| nupdates           | 18500    |
| policy_entropy     | 0.126    |
| total_timesteps    | 92500    |
| value_loss         | 738      |
---------------------------------
25.0
25.0
17.08
11.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 208      |
| explained_variance | -8.27    |
| fps                | 386      |
| nupdates           | 18600    |
| policy_entropy     | 0.0765   |
| total_timesteps    | 93000    |
| value_loss         | 1.22e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | -0.258   |
| fps                | 386      |
| nupdates           | 18700    |
| policy_entropy     | 0.32     |
| total_timesteps    | 93500    |
| value_loss         | 643      |
---------------------------------
13.0
13.0
18.47
13.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 201      |
| explained_variance | -1.38    |
| fps                | 387      |
| nupdates           | 18800    |
| policy_entropy     | 0.192    |
| total_timesteps    | 94000    |
| value_loss         | 224      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 200      |
| explained_variance | -0.438   |
| fps                | 387      |
| nupdates           | 18900    |
| policy_entropy     | 0.317    |
| total_timesteps    | 94500    |
| value_loss         | 8.42e+03 |
---------------------------------
13.0
13.0
19.38
11.5
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 198      |
| explained_variance | -0.361   |
| fps                | 387      |
| nupdates           | 19000    |
| policy_entropy     | 0.191    |
| total_timesteps    | 95000    |
| value_loss         | 1.06e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.166    |
| fps                | 387      |
| nupdates           | 19100    |
| policy_entropy     | 0.345    |
| total_timesteps    | 95500    |
| value_loss         | 206      |
---------------------------------
10.0
10.0
16.68
10.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 206      |
| explained_variance | -4.62    |
| fps                | 386      |
| nupdates           | 19200    |
| policy_entropy     | 0.222    |
| total_timesteps    | 96000    |
| value_loss         | 1.48e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 204      |
| explained_variance | 0.0536   |
| fps                | 387      |
| nupdates           | 19300    |
| policy_entropy     | 0.0391   |
| total_timesteps    | 96500    |
| value_loss         | 3.98e+03 |
---------------------------------
22.0
22.0
17.49
10.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | -1.42    |
| fps                | 387      |
| nupdates           | 19400    |
| policy_entropy     | 0.329    |
| total_timesteps    | 97000    |
| value_loss         | 1.94e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 205      |
| explained_variance | 0.842    |
| fps                | 387      |
| nupdates           | 19500    |
| policy_entropy     | 0.02     |
| total_timesteps    | 97500    |
| value_loss         | 344      |
---------------------------------
21.0
21.0
19.43
20.0
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.0977   |
| fps                | 386      |
| nupdates           | 19600    |
| policy_entropy     | 0.201    |
| total_timesteps    | 98000    |
| value_loss         | 8.53e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 204      |
| explained_variance | -0.623   |
| fps                | 386      |
| nupdates           | 19700    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 98500    |
| value_loss         | 136      |
---------------------------------
9.0
9.0
18.8
10.0
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 201      |
| explained_variance | 0        |
| fps                | 386      |
| nupdates           | 19800    |
| policy_entropy     | 0.258    |
| total_timesteps    | 99000    |
| value_loss         | 97.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 202      |
| explained_variance | -2.76    |
| fps                | 386      |
| nupdates           | 19900    |
| policy_entropy     | 0.0242   |
| total_timesteps    | 99500    |
| value_loss         | 168      |
---------------------------------
10.0
10.0
17.09
10.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 202      |
| explained_variance | 0        |
| fps                | 387      |
| nupdates           | 20000    |
| policy_entropy     | 0.42     |
| total_timesteps    | 100000   |
| value_loss         | 339      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 200      |
| explained_variance | -2.92    |
| fps                | 387      |
| nupdates           | 20100    |
| policy_entropy     | 0.488    |
| total_timesteps    | 100500   |
| value_loss         | 426      |
---------------------------------
9.0
9.0
18.01
10.0
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 202      |
| explained_variance | -0.0429  |
| fps                | 387      |
| nupdates           | 20200    |
| policy_entropy     | 0.438    |
| total_timesteps    | 101000   |
| value_loss         | 345      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 203      |
| explained_variance | -1.5     |
| fps                | 387      |
| nupdates           | 20300    |
| policy_entropy     | 0.104    |
| total_timesteps    | 101500   |
| value_loss         | 1.18e+03 |
---------------------------------
9.0
9.0
17.58
10.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.465    |
| fps                | 387      |
| nupdates           | 20400    |
| policy_entropy     | 0.88     |
| total_timesteps    | 102000   |
| value_loss         | 87.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 206      |
| explained_variance | -0.34    |
| fps                | 387      |
| nupdates           | 20500    |
| policy_entropy     | 0.046    |
| total_timesteps    | 102500   |
| value_loss         | 243      |
---------------------------------
10.0
10.0
16.42
9.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | -0.709   |
| fps                | 387      |
| nupdates           | 20600    |
| policy_entropy     | 0.1      |
| total_timesteps    | 103000   |
| value_loss         | 656      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.753    |
| fps                | 387      |
| nupdates           | 20700    |
| policy_entropy     | 0.0303   |
| total_timesteps    | 103500   |
| value_loss         | 44.4     |
---------------------------------
9.0
9.0
14.9
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 211      |
| explained_variance | -0.0191  |
| fps                | 387      |
| nupdates           | 20800    |
| policy_entropy     | 0.0608   |
| total_timesteps    | 104000   |
| value_loss         | 116      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 210      |
| explained_variance | -2       |
| fps                | 387      |
| nupdates           | 20900    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 104500   |
| value_loss         | 458      |
---------------------------------
10.0
10.0
14.76
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 210      |
| explained_variance | -1.53    |
| fps                | 388      |
| nupdates           | 21000    |
| policy_entropy     | 0.3      |
| total_timesteps    | 105000   |
| value_loss         | 522      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.778    |
| fps                | 388      |
| nupdates           | 21100    |
| policy_entropy     | 0.189    |
| total_timesteps    | 105500   |
| value_loss         | 389      |
---------------------------------
43.0
43.0
16.87
10.5
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 209      |
| explained_variance | -8.46    |
| fps                | 388      |
| nupdates           | 21200    |
| policy_entropy     | 0.185    |
| total_timesteps    | 106000   |
| value_loss         | 2.16e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.145   |
| fps                | 388      |
| nupdates           | 21300    |
| policy_entropy     | 0.3      |
| total_timesteps    | 106500   |
| value_loss         | 54.7     |
---------------------------------
10.0
10.0
16.36
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.303    |
| fps                | 388      |
| nupdates           | 21400    |
| policy_entropy     | 0.0248   |
| total_timesteps    | 107000   |
| value_loss         | 305      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | -0.805   |
| fps                | 388      |
| nupdates           | 21500    |
| policy_entropy     | 0.598    |
| total_timesteps    | 107500   |
| value_loss         | 524      |
---------------------------------
11.0
11.0
15.35
9.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 212      |
| explained_variance | -2.15    |
| fps                | 388      |
| nupdates           | 21600    |
| policy_entropy     | 0.308    |
| total_timesteps    | 108000   |
| value_loss         | 551      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 204      |
| explained_variance | -0.562   |
| fps                | 388      |
| nupdates           | 21700    |
| policy_entropy     | 0.164    |
| total_timesteps    | 108500   |
| value_loss         | 119      |
---------------------------------
8.0
8.0
18.98
10.0
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 199      |
| explained_variance | -4.75    |
| fps                | 388      |
| nupdates           | 21800    |
| policy_entropy     | 0.0754   |
| total_timesteps    | 109000   |
| value_loss         | 1.12e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 200      |
| explained_variance | -11.4    |
| fps                | 388      |
| nupdates           | 21900    |
| policy_entropy     | 0.317    |
| total_timesteps    | 109500   |
| value_loss         | 808      |
---------------------------------
23.0
23.0
17.2
10.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 208      |
| explained_variance | -0.824   |
| fps                | 388      |
| nupdates           | 22000    |
| policy_entropy     | 0.354    |
| total_timesteps    | 110000   |
| value_loss         | 267      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | -5.09    |
| fps                | 388      |
| nupdates           | 22100    |
| policy_entropy     | 0.422    |
| total_timesteps    | 110500   |
| value_loss         | 208      |
---------------------------------
9.0
9.0
17.16
11.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -0.355   |
| fps                | 388      |
| nupdates           | 22200    |
| policy_entropy     | 0.228    |
| total_timesteps    | 111000   |
| value_loss         | 279      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 204      |
| explained_variance | 0.687    |
| fps                | 388      |
| nupdates           | 22300    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 111500   |
| value_loss         | 151      |
---------------------------------
29.0
29.0
18.59
26.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0        |
| fps                | 388      |
| nupdates           | 22400    |
| policy_entropy     | 0.225    |
| total_timesteps    | 112000   |
| value_loss         | 254      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -3.6     |
| fps                | 388      |
| nupdates           | 22500    |
| policy_entropy     | 0.34     |
| total_timesteps    | 112500   |
| value_loss         | 575      |
---------------------------------
10.0
10.0
17.56
10.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.142    |
| fps                | 388      |
| nupdates           | 22600    |
| policy_entropy     | 0.0168   |
| total_timesteps    | 113000   |
| value_loss         | 284      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.812    |
| fps                | 389      |
| nupdates           | 22700    |
| policy_entropy     | 0.0996   |
| total_timesteps    | 113500   |
| value_loss         | 15.1     |
---------------------------------
9.0
9.0
16.83
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | -0.103   |
| fps                | 389      |
| nupdates           | 22800    |
| policy_entropy     | 0.0505   |
| total_timesteps    | 114000   |
| value_loss         | 873      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 207      |
| explained_variance | -0.423   |
| fps                | 389      |
| nupdates           | 22900    |
| policy_entropy     | 0.675    |
| total_timesteps    | 114500   |
| value_loss         | 150      |
---------------------------------
10.0
10.0
18.06
11.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 203      |
| explained_variance | 0.804    |
| fps                | 389      |
| nupdates           | 23000    |
| policy_entropy     | 0.0312   |
| total_timesteps    | 115000   |
| value_loss         | 24.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.299    |
| fps                | 388      |
| nupdates           | 23100    |
| policy_entropy     | 0.0197   |
| total_timesteps    | 115500   |
| value_loss         | 58.4     |
---------------------------------
9.0
9.0
15.79
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 208      |
| explained_variance | -0.504   |
| fps                | 387      |
| nupdates           | 23200    |
| policy_entropy     | 0.132    |
| total_timesteps    | 116000   |
| value_loss         | 133      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | -0.314   |
| fps                | 388      |
| nupdates           | 23300    |
| policy_entropy     | 0.0421   |
| total_timesteps    | 116500   |
| value_loss         | 96       |
---------------------------------
37.0
37.0
15.28
14.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.145    |
| fps                | 388      |
| nupdates           | 23400    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 117000   |
| value_loss         | 284      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.72     |
| fps                | 388      |
| nupdates           | 23500    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 117500   |
| value_loss         | 71.9     |
---------------------------------
12.0
12.0
17.78
15.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.862    |
| fps                | 388      |
| nupdates           | 23600    |
| policy_entropy     | 0.0433   |
| total_timesteps    | 118000   |
| value_loss         | 97.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 207      |
| explained_variance | -0.497   |
| fps                | 388      |
| nupdates           | 23700    |
| policy_entropy     | 0.137    |
| total_timesteps    | 118500   |
| value_loss         | 632      |
---------------------------------
22.0
22.0
17.33
10.5
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.687    |
| fps                | 388      |
| nupdates           | 23800    |
| policy_entropy     | 0.141    |
| total_timesteps    | 119000   |
| value_loss         | 187      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.385    |
| fps                | 388      |
| nupdates           | 23900    |
| policy_entropy     | 0.59     |
| total_timesteps    | 119500   |
| value_loss         | 68.8     |
---------------------------------
9.0
9.0
16.72
15.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 209      |
| explained_variance | -2.5     |
| fps                | 388      |
| nupdates           | 24000    |
| policy_entropy     | 0.182    |
| total_timesteps    | 120000   |
| value_loss         | 518      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 211      |
| explained_variance | -0.359   |
| fps                | 388      |
| nupdates           | 24100    |
| policy_entropy     | 0.173    |
| total_timesteps    | 120500   |
| value_loss         | 336      |
---------------------------------
9.0
9.0
15.42
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 214      |
| explained_variance | -1.39    |
| fps                | 388      |
| nupdates           | 24200    |
| policy_entropy     | 0.344    |
| total_timesteps    | 121000   |
| value_loss         | 573      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 209      |
| explained_variance | -7.82    |
| fps                | 388      |
| nupdates           | 24300    |
| policy_entropy     | 0.25     |
| total_timesteps    | 121500   |
| value_loss         | 1.35e+03 |
---------------------------------
36.0
36.0
17.06
22.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 209      |
| explained_variance | -0.885   |
| fps                | 388      |
| nupdates           | 24400    |
| policy_entropy     | 0.161    |
| total_timesteps    | 122000   |
| value_loss         | 402      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 208      |
| explained_variance | -1.03    |
| fps                | 388      |
| nupdates           | 24500    |
| policy_entropy     | 0.178    |
| total_timesteps    | 122500   |
| value_loss         | 423      |
---------------------------------
10.0
10.0
18.09
10.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 208      |
| explained_variance | 0.208    |
| fps                | 388      |
| nupdates           | 24600    |
| policy_entropy     | 0.171    |
| total_timesteps    | 123000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.878    |
| fps                | 388      |
| nupdates           | 24700    |
| policy_entropy     | 0.0205   |
| total_timesteps    | 123500   |
| value_loss         | 9.77     |
---------------------------------
9.0
9.0
18.08
10.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 209      |
| explained_variance | -0.129   |
| fps                | 388      |
| nupdates           | 24800    |
| policy_entropy     | 0.0223   |
| total_timesteps    | 124000   |
| value_loss         | 471      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.17    |
| fps                | 388      |
| nupdates           | 24900    |
| policy_entropy     | 0.122    |
| total_timesteps    | 124500   |
| value_loss         | 855      |
---------------------------------
20.0
20.0
16.6
9.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.875    |
| fps                | 388      |
| nupdates           | 25000    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 125000   |
| value_loss         | 16.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.309    |
| fps                | 388      |
| nupdates           | 25100    |
| policy_entropy     | 0.0124   |
| total_timesteps    | 125500   |
| value_loss         | 342      |
---------------------------------
11.0
11.0
15.26
25.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 212      |
| explained_variance | -0.516   |
| fps                | 389      |
| nupdates           | 25200    |
| policy_entropy     | 0.165    |
| total_timesteps    | 126000   |
| value_loss         | 223      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.219   |
| fps                | 389      |
| nupdates           | 25300    |
| policy_entropy     | 0.546    |
| total_timesteps    | 126500   |
| value_loss         | 336      |
---------------------------------
11.0
11.0
15.83
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 212      |
| explained_variance | -4.8     |
| fps                | 389      |
| nupdates           | 25400    |
| policy_entropy     | 0.177    |
| total_timesteps    | 127000   |
| value_loss         | 583      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.208    |
| fps                | 389      |
| nupdates           | 25500    |
| policy_entropy     | 0.308    |
| total_timesteps    | 127500   |
| value_loss         | 53.4     |
---------------------------------
11.0
11.0
15.16
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.024    |
| fps                | 389      |
| nupdates           | 25600    |
| policy_entropy     | 0.014    |
| total_timesteps    | 128000   |
| value_loss         | 572      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | -0.0934  |
| fps                | 389      |
| nupdates           | 25700    |
| policy_entropy     | 0.086    |
| total_timesteps    | 128500   |
| value_loss         | 181      |
---------------------------------
12.0
12.0
18.15
12.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 202      |
| explained_variance | -57.4    |
| fps                | 389      |
| nupdates           | 25800    |
| policy_entropy     | 0.35     |
| total_timesteps    | 129000   |
| value_loss         | 3.68e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 203      |
| explained_variance | 0.322    |
| fps                | 389      |
| nupdates           | 25900    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 129500   |
| value_loss         | 134      |
---------------------------------
30.0
30.0
18.06
15.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 205      |
| explained_variance | -6.22    |
| fps                | 389      |
| nupdates           | 26000    |
| policy_entropy     | 0.569    |
| total_timesteps    | 130000   |
| value_loss         | 770      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.274    |
| fps                | 389      |
| nupdates           | 26100    |
| policy_entropy     | 0.102    |
| total_timesteps    | 130500   |
| value_loss         | 98.8     |
---------------------------------
9.0
9.0
15.1
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.0101   |
| fps                | 389      |
| nupdates           | 26200    |
| policy_entropy     | 0.051    |
| total_timesteps    | 131000   |
| value_loss         | 305      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 206      |
| explained_variance | -0.126   |
| fps                | 389      |
| nupdates           | 26300    |
| policy_entropy     | 0.0233   |
| total_timesteps    | 131500   |
| value_loss         | 799      |
---------------------------------
10.0
10.0
16.61
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.77     |
| fps                | 389      |
| nupdates           | 26400    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 132000   |
| value_loss         | 17.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -1.34    |
| fps                | 389      |
| nupdates           | 26500    |
| policy_entropy     | 0.296    |
| total_timesteps    | 132500   |
| value_loss         | 768      |
---------------------------------
10.0
10.0
16.09
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 205      |
| explained_variance | -0.523   |
| fps                | 389      |
| nupdates           | 26600    |
| policy_entropy     | 0.109    |
| total_timesteps    | 133000   |
| value_loss         | 63.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 207      |
| explained_variance | -8.42    |
| fps                | 389      |
| nupdates           | 26700    |
| policy_entropy     | 0.197    |
| total_timesteps    | 133500   |
| value_loss         | 229      |
---------------------------------
10.0
10.0
13.42
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 214      |
| explained_variance | -15.7    |
| fps                | 389      |
| nupdates           | 26800    |
| policy_entropy     | 0.56     |
| total_timesteps    | 134000   |
| value_loss         | 617      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | -8.62    |
| fps                | 389      |
| nupdates           | 26900    |
| policy_entropy     | 0.243    |
| total_timesteps    | 134500   |
| value_loss         | 237      |
---------------------------------
31.0
31.0
14.56
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.00953  |
| fps                | 389      |
| nupdates           | 27000    |
| policy_entropy     | 0.378    |
| total_timesteps    | 135000   |
| value_loss         | 115      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.0399   |
| fps                | 389      |
| nupdates           | 27100    |
| policy_entropy     | 0.276    |
| total_timesteps    | 135500   |
| value_loss         | 68.9     |
---------------------------------
10.0
10.0
15.24
15.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 210      |
| explained_variance | -0.0511  |
| fps                | 389      |
| nupdates           | 27200    |
| policy_entropy     | 0.0328   |
| total_timesteps    | 136000   |
| value_loss         | 35       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0.837    |
| fps                | 389      |
| nupdates           | 27300    |
| policy_entropy     | 0.0476   |
| total_timesteps    | 136500   |
| value_loss         | 90.4     |
---------------------------------
28.0
28.0
15.95
9.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | -0.532   |
| fps                | 389      |
| nupdates           | 27400    |
| policy_entropy     | 0.163    |
| total_timesteps    | 137000   |
| value_loss         | 307      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.937    |
| fps                | 389      |
| nupdates           | 27500    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 137500   |
| value_loss         | 4.24     |
---------------------------------
10.0
10.0
15.56
15.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.816    |
| fps                | 389      |
| nupdates           | 27600    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 138000   |
| value_loss         | 83.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.716    |
| fps                | 389      |
| nupdates           | 27700    |
| policy_entropy     | 0.0391   |
| total_timesteps    | 138500   |
| value_loss         | 68.8     |
---------------------------------
10.0
10.0
16.59
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.558   |
| fps                | 389      |
| nupdates           | 27800    |
| policy_entropy     | 0.162    |
| total_timesteps    | 139000   |
| value_loss         | 467      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 209      |
| explained_variance | 0.31     |
| fps                | 389      |
| nupdates           | 27900    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 139500   |
| value_loss         | 385      |
---------------------------------
11.0
11.0
16.36
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.753    |
| fps                | 389      |
| nupdates           | 28000    |
| policy_entropy     | 0.0123   |
| total_timesteps    | 140000   |
| value_loss         | 11.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | -6.75    |
| fps                | 389      |
| nupdates           | 28100    |
| policy_entropy     | 0.783    |
| total_timesteps    | 140500   |
| value_loss         | 513      |
---------------------------------
9.0
9.0
15.06
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.283    |
| fps                | 389      |
| nupdates           | 28200    |
| policy_entropy     | 0.029    |
| total_timesteps    | 141000   |
| value_loss         | 629      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.647    |
| fps                | 388      |
| nupdates           | 28300    |
| policy_entropy     | 0.204    |
| total_timesteps    | 141500   |
| value_loss         | 20       |
---------------------------------
10.0
10.0
15.14
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.901    |
| fps                | 388      |
| nupdates           | 28400    |
| policy_entropy     | 0.247    |
| total_timesteps    | 142000   |
| value_loss         | 42.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | -0.791   |
| fps                | 388      |
| nupdates           | 28500    |
| policy_entropy     | 0.101    |
| total_timesteps    | 142500   |
| value_loss         | 150      |
---------------------------------
10.0
10.0
14.06
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.482    |
| fps                | 388      |
| nupdates           | 28600    |
| policy_entropy     | 0.0556   |
| total_timesteps    | 143000   |
| value_loss         | 16.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.507    |
| fps                | 388      |
| nupdates           | 28700    |
| policy_entropy     | 0.103    |
| total_timesteps    | 143500   |
| value_loss         | 114      |
---------------------------------
30.0
30.0
13.32
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.243    |
| fps                | 388      |
| nupdates           | 28800    |
| policy_entropy     | 0.0414   |
| total_timesteps    | 144000   |
| value_loss         | 573      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.924    |
| fps                | 388      |
| nupdates           | 28900    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 144500   |
| value_loss         | 8.88     |
---------------------------------
10.0
10.0
14.27
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | -4.13    |
| fps                | 388      |
| nupdates           | 29000    |
| policy_entropy     | 0.273    |
| total_timesteps    | 145000   |
| value_loss         | 625      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.375    |
| fps                | 388      |
| nupdates           | 29100    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 145500   |
| value_loss         | 70.3     |
---------------------------------
9.0
9.0
15.19
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.863    |
| fps                | 388      |
| nupdates           | 29200    |
| policy_entropy     | 0.0341   |
| total_timesteps    | 146000   |
| value_loss         | 68.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.0471   |
| fps                | 389      |
| nupdates           | 29300    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 146500   |
| value_loss         | 237      |
---------------------------------
10.0
10.0
14.08
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | -0.373   |
| fps                | 389      |
| nupdates           | 29400    |
| policy_entropy     | 0.0468   |
| total_timesteps    | 147000   |
| value_loss         | 284      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | -3.77    |
| fps                | 389      |
| nupdates           | 29500    |
| policy_entropy     | 0.0589   |
| total_timesteps    | 147500   |
| value_loss         | 387      |
---------------------------------
10.0
10.0
15.29
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.823    |
| fps                | 389      |
| nupdates           | 29600    |
| policy_entropy     | 0.562    |
| total_timesteps    | 148000   |
| value_loss         | 233      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 208      |
| explained_variance | 0.586    |
| fps                | 389      |
| nupdates           | 29700    |
| policy_entropy     | 0.071    |
| total_timesteps    | 148500   |
| value_loss         | 77.2     |
---------------------------------
10.0
10.0
14.25
20.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.229    |
| fps                | 389      |
| nupdates           | 29800    |
| policy_entropy     | 0.28     |
| total_timesteps    | 149000   |
| value_loss         | 37.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.116    |
| fps                | 389      |
| nupdates           | 29900    |
| policy_entropy     | 0.126    |
| total_timesteps    | 149500   |
| value_loss         | 1.05e+03 |
---------------------------------
9.0
9.0
15.61
20.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | -1.2     |
| fps                | 389      |
| nupdates           | 30000    |
| policy_entropy     | 0.269    |
| total_timesteps    | 150000   |
| value_loss         | 89.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.895    |
| fps                | 389      |
| nupdates           | 30100    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 150500   |
| value_loss         | 20.9     |
---------------------------------
13.0
13.0
16.58
17.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.074    |
| fps                | 389      |
| nupdates           | 30200    |
| policy_entropy     | 0.238    |
| total_timesteps    | 151000   |
| value_loss         | 99.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 210      |
| explained_variance | -0.568   |
| fps                | 389      |
| nupdates           | 30300    |
| policy_entropy     | 0.0614   |
| total_timesteps    | 151500   |
| value_loss         | 91.7     |
---------------------------------
28.0
28.0
15.55
10.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | -0.516   |
| fps                | 389      |
| nupdates           | 30400    |
| policy_entropy     | 0.167    |
| total_timesteps    | 152000   |
| value_loss         | 155      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | -0.538   |
| fps                | 389      |
| nupdates           | 30500    |
| policy_entropy     | 0.0646   |
| total_timesteps    | 152500   |
| value_loss         | 43.6     |
---------------------------------
9.0
9.0
15.95
15.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0        |
| fps                | 389      |
| nupdates           | 30600    |
| policy_entropy     | 0.824    |
| total_timesteps    | 153000   |
| value_loss         | 149      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | -2.52    |
| fps                | 389      |
| nupdates           | 30700    |
| policy_entropy     | 0.185    |
| total_timesteps    | 153500   |
| value_loss         | 362      |
---------------------------------
8.0
8.0
15.23
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | -1.2     |
| fps                | 389      |
| nupdates           | 30800    |
| policy_entropy     | 0.0438   |
| total_timesteps    | 154000   |
| value_loss         | 95.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.221    |
| fps                | 389      |
| nupdates           | 30900    |
| policy_entropy     | 0.0319   |
| total_timesteps    | 154500   |
| value_loss         | 29       |
---------------------------------
9.0
9.0
13.33
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.851    |
| fps                | 389      |
| nupdates           | 31000    |
| policy_entropy     | 0.0397   |
| total_timesteps    | 155000   |
| value_loss         | 25       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.908    |
| fps                | 389      |
| nupdates           | 31100    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 155500   |
| value_loss         | 803      |
---------------------------------
9.0
9.0
16.2
9.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.874    |
| fps                | 389      |
| nupdates           | 31200    |
| policy_entropy     | 0.0209   |
| total_timesteps    | 156000   |
| value_loss         | 8.6      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | -0.923   |
| fps                | 389      |
| nupdates           | 31300    |
| policy_entropy     | 0.461    |
| total_timesteps    | 156500   |
| value_loss         | 56.2     |
---------------------------------
9.0
9.0
14.77
9.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | -2.62    |
| fps                | 388      |
| nupdates           | 31400    |
| policy_entropy     | 0.292    |
| total_timesteps    | 157000   |
| value_loss         | 571      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 211      |
| explained_variance | -1.84    |
| fps                | 389      |
| nupdates           | 31500    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 157500   |
| value_loss         | 265      |
---------------------------------
35.0
35.0
16.87
10.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 210      |
| explained_variance | 0.895    |
| fps                | 389      |
| nupdates           | 31600    |
| policy_entropy     | 0.043    |
| total_timesteps    | 158000   |
| value_loss         | 38.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.994    |
| fps                | 389      |
| nupdates           | 31700    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 158500   |
| value_loss         | 2.18     |
---------------------------------
10.0
10.0
14.25
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.00949 |
| fps                | 389      |
| nupdates           | 31800    |
| policy_entropy     | 0.0974   |
| total_timesteps    | 159000   |
| value_loss         | 21.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.494    |
| fps                | 389      |
| nupdates           | 31900    |
| policy_entropy     | 0.38     |
| total_timesteps    | 159500   |
| value_loss         | 36.1     |
---------------------------------
24.0
24.0
15.11
14.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.517   |
| fps                | 389      |
| nupdates           | 32000    |
| policy_entropy     | 0.0832   |
| total_timesteps    | 160000   |
| value_loss         | 248      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.874    |
| fps                | 389      |
| nupdates           | 32100    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 160500   |
| value_loss         | 10.1     |
---------------------------------
10.0
10.0
15.42
9.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.938    |
| fps                | 389      |
| nupdates           | 32200    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 161000   |
| value_loss         | 11.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.78     |
| fps                | 389      |
| nupdates           | 32300    |
| policy_entropy     | 0.0945   |
| total_timesteps    | 161500   |
| value_loss         | 42.5     |
---------------------------------
10.0
10.0
14.45
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | -1.34    |
| fps                | 389      |
| nupdates           | 32400    |
| policy_entropy     | 0.164    |
| total_timesteps    | 162000   |
| value_loss         | 604      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.317   |
| fps                | 389      |
| nupdates           | 32500    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 162500   |
| value_loss         | 214      |
---------------------------------
26.0
26.0
14.34
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | -0.02    |
| fps                | 389      |
| nupdates           | 32600    |
| policy_entropy     | 0.153    |
| total_timesteps    | 163000   |
| value_loss         | 54.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | -3.51    |
| fps                | 389      |
| nupdates           | 32700    |
| policy_entropy     | 0.149    |
| total_timesteps    | 163500   |
| value_loss         | 621      |
---------------------------------
8.0
8.0
15.46
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 210      |
| explained_variance | -1.02    |
| fps                | 389      |
| nupdates           | 32800    |
| policy_entropy     | 0.0373   |
| total_timesteps    | 164000   |
| value_loss         | 87.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.486   |
| fps                | 389      |
| nupdates           | 32900    |
| policy_entropy     | 0.251    |
| total_timesteps    | 164500   |
| value_loss         | 104      |
---------------------------------
10.0
10.0
14.21
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.712    |
| fps                | 389      |
| nupdates           | 33000    |
| policy_entropy     | 0.022    |
| total_timesteps    | 165000   |
| value_loss         | 37       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | -2.26    |
| fps                | 388      |
| nupdates           | 33100    |
| policy_entropy     | 0.231    |
| total_timesteps    | 165500   |
| value_loss         | 201      |
---------------------------------
10.0
10.0
14.7
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 14.7      |
| ep_reward_mean     | 217       |
| explained_variance | -1.19e-07 |
| fps                | 388       |
| nupdates           | 33200     |
| policy_entropy     | 0.322     |
| total_timesteps    | 166000    |
| value_loss         | 143       |
----------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.575    |
| fps                | 388      |
| nupdates           | 33300    |
| policy_entropy     | 0.0482   |
| total_timesteps    | 166500   |
| value_loss         | 51.4     |
---------------------------------
31.0
31.0
14.54
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | -2.46    |
| fps                | 388      |
| nupdates           | 33400    |
| policy_entropy     | 0.0643   |
| total_timesteps    | 167000   |
| value_loss         | 432      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 215      |
| explained_variance | -0.983   |
| fps                | 388      |
| nupdates           | 33500    |
| policy_entropy     | 0.0352   |
| total_timesteps    | 167500   |
| value_loss         | 284      |
---------------------------------
39.0
39.0
15.15
15.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.825    |
| fps                | 388      |
| nupdates           | 33600    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 168000   |
| value_loss         | 21.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | -93.4    |
| fps                | 388      |
| nupdates           | 33700    |
| policy_entropy     | 0.435    |
| total_timesteps    | 168500   |
| value_loss         | 4.03e+03 |
---------------------------------
11.0
11.0
18.55
13.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -0.714   |
| fps                | 388      |
| nupdates           | 33800    |
| policy_entropy     | 0.142    |
| total_timesteps    | 169000   |
| value_loss         | 1.79e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 200      |
| explained_variance | -5.39    |
| fps                | 388      |
| nupdates           | 33900    |
| policy_entropy     | 0.498    |
| total_timesteps    | 169500   |
| value_loss         | 50.7     |
---------------------------------
9.0
9.0
18.87
10.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 202      |
| explained_variance | -0.692   |
| fps                | 388      |
| nupdates           | 34000    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 170000   |
| value_loss         | 166      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 208      |
| explained_variance | -8.59    |
| fps                | 389      |
| nupdates           | 34100    |
| policy_entropy     | 0.039    |
| total_timesteps    | 170500   |
| value_loss         | 279      |
---------------------------------
8.0
8.0
17.21
10.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 209      |
| explained_variance | -0.833   |
| fps                | 389      |
| nupdates           | 34200    |
| policy_entropy     | 0.0572   |
| total_timesteps    | 171000   |
| value_loss         | 802      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 389      |
| nupdates           | 34300    |
| policy_entropy     | 0.775    |
| total_timesteps    | 171500   |
| value_loss         | 154      |
---------------------------------
9.0
9.0
17.03
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | -5.76    |
| fps                | 389      |
| nupdates           | 34400    |
| policy_entropy     | 0.0286   |
| total_timesteps    | 172000   |
| value_loss         | 218      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.347    |
| fps                | 389      |
| nupdates           | 34500    |
| policy_entropy     | 0.0082   |
| total_timesteps    | 172500   |
| value_loss         | 55.8     |
---------------------------------
13.0
13.0
15.67
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 209      |
| explained_variance | -2.11    |
| fps                | 389      |
| nupdates           | 34600    |
| policy_entropy     | 0.197    |
| total_timesteps    | 173000   |
| value_loss         | 1.28e+03 |
---------------------------------
----------------------------------
| ep_len_mean        | 15        |
| ep_reward_mean     | 211       |
| explained_variance | -1.19e-07 |
| fps                | 389       |
| nupdates           | 34700     |
| policy_entropy     | 0.0972    |
| total_timesteps    | 173500    |
| value_loss         | 365       |
----------------------------------
10.0
10.0
15.76
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.463    |
| fps                | 389      |
| nupdates           | 34800    |
| policy_entropy     | 0.00887  |
| total_timesteps    | 174000   |
| value_loss         | 46.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.771    |
| fps                | 389      |
| nupdates           | 34900    |
| policy_entropy     | 0.0471   |
| total_timesteps    | 174500   |
| value_loss         | 12.4     |
---------------------------------
9.0
9.0
13.53
9.5
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.592    |
| fps                | 389      |
| nupdates           | 35000    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 175000   |
| value_loss         | 49       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 215      |
| explained_variance | -2.34    |
| fps                | 389      |
| nupdates           | 35100    |
| policy_entropy     | 0.353    |
| total_timesteps    | 175500   |
| value_loss         | 802      |
---------------------------------
11.0
11.0
16.32
16.5
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 206      |
| explained_variance | 0.659    |
| fps                | 389      |
| nupdates           | 35200    |
| policy_entropy     | 0.00857  |
| total_timesteps    | 176000   |
| value_loss         | 1.86e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 207      |
| explained_variance | 0.221    |
| fps                | 389      |
| nupdates           | 35300    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 176500   |
| value_loss         | 328      |
---------------------------------
20.0
20.0
16.62
16.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 208      |
| explained_variance | 0.867    |
| fps                | 389      |
| nupdates           | 35400    |
| policy_entropy     | 0.319    |
| total_timesteps    | 177000   |
| value_loss         | 24.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.682    |
| fps                | 389      |
| nupdates           | 35500    |
| policy_entropy     | 0.0517   |
| total_timesteps    | 177500   |
| value_loss         | 79.7     |
---------------------------------
23.0
23.0
16.15
23.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 212      |
| explained_variance | -3.73    |
| fps                | 389      |
| nupdates           | 35600    |
| policy_entropy     | 0.0524   |
| total_timesteps    | 178000   |
| value_loss         | 384      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.806    |
| fps                | 389      |
| nupdates           | 35700    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 178500   |
| value_loss         | 492      |
---------------------------------
11.0
11.0
15.01
10.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | 0.948    |
| fps                | 389      |
| nupdates           | 35800    |
| policy_entropy     | 0.0511   |
| total_timesteps    | 179000   |
| value_loss         | 23.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | -3.22    |
| fps                | 389      |
| nupdates           | 35900    |
| policy_entropy     | 0.0207   |
| total_timesteps    | 179500   |
| value_loss         | 112      |
---------------------------------
11.0
11.0
14.21
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | -0.431   |
| fps                | 389      |
| nupdates           | 36000    |
| policy_entropy     | 0.331    |
| total_timesteps    | 180000   |
| value_loss         | 784      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | -0.0898  |
| fps                | 389      |
| nupdates           | 36100    |
| policy_entropy     | 0.015    |
| total_timesteps    | 180500   |
| value_loss         | 2e+03    |
---------------------------------
11.0
11.0
15.96
10.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | 0.3      |
| fps                | 389      |
| nupdates           | 36200    |
| policy_entropy     | 0.204    |
| total_timesteps    | 181000   |
| value_loss         | 396      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.766    |
| fps                | 389      |
| nupdates           | 36300    |
| policy_entropy     | 0.0444   |
| total_timesteps    | 181500   |
| value_loss         | 86.2     |
---------------------------------
21.0
21.0
14.85
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | -1.78    |
| fps                | 389      |
| nupdates           | 36400    |
| policy_entropy     | 0.026    |
| total_timesteps    | 182000   |
| value_loss         | 852      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.969    |
| fps                | 389      |
| nupdates           | 36500    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 182500   |
| value_loss         | 2.52     |
---------------------------------
10.0
10.0
14.81
20.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.521    |
| fps                | 389      |
| nupdates           | 36600    |
| policy_entropy     | 0.204    |
| total_timesteps    | 183000   |
| value_loss         | 54.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | -0.317   |
| fps                | 389      |
| nupdates           | 36700    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 183500   |
| value_loss         | 86.8     |
---------------------------------
10.0
10.0
13.97
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 212      |
| explained_variance | 0.608    |
| fps                | 389      |
| nupdates           | 36800    |
| policy_entropy     | 0.0415   |
| total_timesteps    | 184000   |
| value_loss         | 72.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 210      |
| explained_variance | -1.16    |
| fps                | 389      |
| nupdates           | 36900    |
| policy_entropy     | 0.214    |
| total_timesteps    | 184500   |
| value_loss         | 117      |
---------------------------------
10.0
10.0
14.88
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 389      |
| nupdates           | 37000    |
| policy_entropy     | 0.486    |
| total_timesteps    | 185000   |
| value_loss         | 30.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 216      |
| explained_variance | 0.284    |
| fps                | 389      |
| nupdates           | 37100    |
| policy_entropy     | 0.00567  |
| total_timesteps    | 185500   |
| value_loss         | 475      |
---------------------------------
10.0
10.0
15.33
15.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | -232     |
| fps                | 389      |
| nupdates           | 37200    |
| policy_entropy     | 0.113    |
| total_timesteps    | 186000   |
| value_loss         | 2.3e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.962   |
| fps                | 389      |
| nupdates           | 37300    |
| policy_entropy     | 0.0346   |
| total_timesteps    | 186500   |
| value_loss         | 238      |
---------------------------------
22.0
22.0
16.68
10.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 208      |
| explained_variance | -1.62    |
| fps                | 389      |
| nupdates           | 37400    |
| policy_entropy     | 0.306    |
| total_timesteps    | 187000   |
| value_loss         | 473      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.787    |
| fps                | 389      |
| nupdates           | 37500    |
| policy_entropy     | 0.146    |
| total_timesteps    | 187500   |
| value_loss         | 10.1     |
---------------------------------
9.0
9.0
14.47
15.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.694    |
| fps                | 389      |
| nupdates           | 37600    |
| policy_entropy     | 0.00881  |
| total_timesteps    | 188000   |
| value_loss         | 60.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | -1.54    |
| fps                | 389      |
| nupdates           | 37700    |
| policy_entropy     | 0.141    |
| total_timesteps    | 188500   |
| value_loss         | 435      |
---------------------------------
9.0
9.0
14.75
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 212      |
| explained_variance | -0.48    |
| fps                | 389      |
| nupdates           | 37800    |
| policy_entropy     | 0.186    |
| total_timesteps    | 189000   |
| value_loss         | 225      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.334    |
| fps                | 389      |
| nupdates           | 37900    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 189500   |
| value_loss         | 44.3     |
---------------------------------
8.0
8.0
14.01
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 213      |
| explained_variance | 0.963    |
| fps                | 389      |
| nupdates           | 38000    |
| policy_entropy     | 0.00917  |
| total_timesteps    | 190000   |
| value_loss         | 16.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.108    |
| fps                | 388      |
| nupdates           | 38100    |
| policy_entropy     | 0.0122   |
| total_timesteps    | 190500   |
| value_loss         | 39.7     |
---------------------------------
19.0
19.0
13.88
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | -0.714   |
| fps                | 388      |
| nupdates           | 38200    |
| policy_entropy     | 0.00893  |
| total_timesteps    | 191000   |
| value_loss         | 197      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | -0.396   |
| fps                | 388      |
| nupdates           | 38300    |
| policy_entropy     | 0.262    |
| total_timesteps    | 191500   |
| value_loss         | 175      |
---------------------------------
10.0
10.0
14.25
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.836    |
| fps                | 388      |
| nupdates           | 38400    |
| policy_entropy     | 0.154    |
| total_timesteps    | 192000   |
| value_loss         | 21.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 212      |
| explained_variance | -0.831   |
| fps                | 388      |
| nupdates           | 38500    |
| policy_entropy     | 0.114    |
| total_timesteps    | 192500   |
| value_loss         | 107      |
---------------------------------
10.0
10.0
14.54
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.749    |
| fps                | 388      |
| nupdates           | 38600    |
| policy_entropy     | 0.00712  |
| total_timesteps    | 193000   |
| value_loss         | 46.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.355    |
| fps                | 388      |
| nupdates           | 38700    |
| policy_entropy     | 0.131    |
| total_timesteps    | 193500   |
| value_loss         | 92.6     |
---------------------------------
12.0
12.0
14.58
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.946    |
| fps                | 388      |
| nupdates           | 38800    |
| policy_entropy     | 0.00673  |
| total_timesteps    | 194000   |
| value_loss         | 15.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0        |
| fps                | 388      |
| nupdates           | 38900    |
| policy_entropy     | 0.616    |
| total_timesteps    | 194500   |
| value_loss         | 146      |
---------------------------------
28.0
28.0
13.44
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.652    |
| fps                | 388      |
| nupdates           | 39000    |
| policy_entropy     | 0.121    |
| total_timesteps    | 195000   |
| value_loss         | 56.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.389    |
| fps                | 388      |
| nupdates           | 39100    |
| policy_entropy     | 0.013    |
| total_timesteps    | 195500   |
| value_loss         | 489      |
---------------------------------
9.0
9.0
15.98
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 207      |
| explained_variance | -1.2     |
| fps                | 388      |
| nupdates           | 39200    |
| policy_entropy     | 0.157    |
| total_timesteps    | 196000   |
| value_loss         | 1.2e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.692    |
| fps                | 388      |
| nupdates           | 39300    |
| policy_entropy     | 0.00816  |
| total_timesteps    | 196500   |
| value_loss         | 38.9     |
---------------------------------
10.0
10.0
16.55
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.842    |
| fps                | 389      |
| nupdates           | 39400    |
| policy_entropy     | 0.0282   |
| total_timesteps    | 197000   |
| value_loss         | 12.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.806    |
| fps                | 389      |
| nupdates           | 39500    |
| policy_entropy     | 0.218    |
| total_timesteps    | 197500   |
| value_loss         | 61.4     |
---------------------------------
23.0
23.0
13.69
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.493    |
| fps                | 389      |
| nupdates           | 39600    |
| policy_entropy     | 0.536    |
| total_timesteps    | 198000   |
| value_loss         | 21.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.592    |
| fps                | 389      |
| nupdates           | 39700    |
| policy_entropy     | 0.0209   |
| total_timesteps    | 198500   |
| value_loss         | 8.91     |
---------------------------------
11.0
11.0
13.13
10.5
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.974    |
| fps                | 389      |
| nupdates           | 39800    |
| policy_entropy     | 0.128    |
| total_timesteps    | 199000   |
| value_loss         | 17.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.961    |
| fps                | 389      |
| nupdates           | 39900    |
| policy_entropy     | 0.195    |
| total_timesteps    | 199500   |
| value_loss         | 38.3     |
---------------------------------
11.0
11.0
13.43
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 214      |
| explained_variance | -2.46    |
| fps                | 389      |
| nupdates           | 40000    |
| policy_entropy     | 0.621    |
| total_timesteps    | 200000   |
| value_loss         | 268      |
---------------------------------
----------------------------------
| ep_len_mean        | 13.3      |
| ep_reward_mean     | 214       |
| explained_variance | -1.19e-07 |
| fps                | 388       |
| nupdates           | 40100     |
| policy_entropy     | 0.186     |
| total_timesteps    | 200500    |
| value_loss         | 295       |
----------------------------------
11.0
11.0
13.83
11.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 214      |
| explained_variance | -2.19    |
| fps                | 388      |
| nupdates           | 40200    |
| policy_entropy     | 0.0967   |
| total_timesteps    | 201000   |
| value_loss         | 461      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 216      |
| explained_variance | -0.456   |
| fps                | 388      |
| nupdates           | 40300    |
| policy_entropy     | 0.767    |
| total_timesteps    | 201500   |
| value_loss         | 206      |
---------------------------------
10.0
10.0
13.77
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.945    |
| fps                | 388      |
| nupdates           | 40400    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 202000   |
| value_loss         | 7.23     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | 0.597    |
| fps                | 389      |
| nupdates           | 40500    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 202500   |
| value_loss         | 17.2     |
---------------------------------
21.0
21.0
14.42
15.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.157    |
| fps                | 389      |
| nupdates           | 40600    |
| policy_entropy     | 0.453    |
| total_timesteps    | 203000   |
| value_loss         | 287      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.929    |
| fps                | 389      |
| nupdates           | 40700    |
| policy_entropy     | 0.034    |
| total_timesteps    | 203500   |
| value_loss         | 41.7     |
---------------------------------
10.0
10.0
13.84
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.834    |
| fps                | 389      |
| nupdates           | 40800    |
| policy_entropy     | 0.00564  |
| total_timesteps    | 204000   |
| value_loss         | 45.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.0301   |
| fps                | 389      |
| nupdates           | 40900    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 204500   |
| value_loss         | 578      |
---------------------------------
10.0
10.0
14.31
11.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.831    |
| fps                | 389      |
| nupdates           | 41000    |
| policy_entropy     | 0.00611  |
| total_timesteps    | 205000   |
| value_loss         | 50.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 214      |
| explained_variance | -2.59    |
| fps                | 389      |
| nupdates           | 41100    |
| policy_entropy     | 0.117    |
| total_timesteps    | 205500   |
| value_loss         | 307      |
---------------------------------
20.0
20.0
14.1
19.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.346   |
| fps                | 389      |
| nupdates           | 41200    |
| policy_entropy     | 0.375    |
| total_timesteps    | 206000   |
| value_loss         | 231      |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 215      |
| explained_variance | -1.49    |
| fps                | 389      |
| nupdates           | 41300    |
| policy_entropy     | 0.103    |
| total_timesteps    | 206500   |
| value_loss         | 401      |
---------------------------------
9.0
9.0
13.74
9.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | -1.47    |
| fps                | 389      |
| nupdates           | 41400    |
| policy_entropy     | 0.106    |
| total_timesteps    | 207000   |
| value_loss         | 141      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 215      |
| explained_variance | -1.27    |
| fps                | 389      |
| nupdates           | 41500    |
| policy_entropy     | 0.0984   |
| total_timesteps    | 207500   |
| value_loss         | 545      |
---------------------------------
9.0
9.0
12.86
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.995    |
| fps                | 389      |
| nupdates           | 41600    |
| policy_entropy     | 0.00779  |
| total_timesteps    | 208000   |
| value_loss         | 1.53     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.468    |
| fps                | 389      |
| nupdates           | 41700    |
| policy_entropy     | 0.144    |
| total_timesteps    | 208500   |
| value_loss         | 97.2     |
---------------------------------
12.0
12.0
13.15
11.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.126    |
| fps                | 389      |
| nupdates           | 41800    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 209000   |
| value_loss         | 74.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.963    |
| fps                | 389      |
| nupdates           | 41900    |
| policy_entropy     | 0.0074   |
| total_timesteps    | 209500   |
| value_loss         | 9.36     |
---------------------------------
40.0
40.0
13.32
9.5
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.886    |
| fps                | 389      |
| nupdates           | 42000    |
| policy_entropy     | 0.0205   |
| total_timesteps    | 210000   |
| value_loss         | 11.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.995    |
| fps                | 389      |
| nupdates           | 42100    |
| policy_entropy     | 0.00802  |
| total_timesteps    | 210500   |
| value_loss         | 3.63     |
---------------------------------
21.0
21.0
13.58
10.5
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.797    |
| fps                | 389      |
| nupdates           | 42200    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 211000   |
| value_loss         | 13.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.99     |
| fps                | 389      |
| nupdates           | 42300    |
| policy_entropy     | 0.00804  |
| total_timesteps    | 211500   |
| value_loss         | 4.98     |
---------------------------------
9.0
9.0
14.13
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | -3.45    |
| fps                | 389      |
| nupdates           | 42400    |
| policy_entropy     | 0.125    |
| total_timesteps    | 212000   |
| value_loss         | 186      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.305    |
| fps                | 389      |
| nupdates           | 42500    |
| policy_entropy     | 0.0197   |
| total_timesteps    | 212500   |
| value_loss         | 140      |
---------------------------------
10.0
10.0
14.24
13.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.245    |
| fps                | 389      |
| nupdates           | 42600    |
| policy_entropy     | 0.092    |
| total_timesteps    | 213000   |
| value_loss         | 382      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.74     |
| fps                | 389      |
| nupdates           | 42700    |
| policy_entropy     | 0.023    |
| total_timesteps    | 213500   |
| value_loss         | 31.1     |
---------------------------------
10.0
10.0
13.35
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.983    |
| fps                | 389      |
| nupdates           | 42800    |
| policy_entropy     | 0.237    |
| total_timesteps    | 214000   |
| value_loss         | 1.93     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.922    |
| fps                | 389      |
| nupdates           | 42900    |
| policy_entropy     | 0.335    |
| total_timesteps    | 214500   |
| value_loss         | 3.77     |
---------------------------------
22.0
22.0
13.51
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.915    |
| fps                | 389      |
| nupdates           | 43000    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 215000   |
| value_loss         | 10.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | 0.831    |
| fps                | 389      |
| nupdates           | 43100    |
| policy_entropy     | 0.00676  |
| total_timesteps    | 215500   |
| value_loss         | 22.7     |
---------------------------------
26.0
26.0
13.44
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.00777  |
| fps                | 389      |
| nupdates           | 43200    |
| policy_entropy     | 0.0363   |
| total_timesteps    | 216000   |
| value_loss         | 17.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.863    |
| fps                | 389      |
| nupdates           | 43300    |
| policy_entropy     | 0.0065   |
| total_timesteps    | 216500   |
| value_loss         | 7.58     |
---------------------------------
21.0
21.0
13.84
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.119    |
| fps                | 389      |
| nupdates           | 43400    |
| policy_entropy     | 0.0891   |
| total_timesteps    | 217000   |
| value_loss         | 13.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.271    |
| fps                | 389      |
| nupdates           | 43500    |
| policy_entropy     | 0.0379   |
| total_timesteps    | 217500   |
| value_loss         | 28.4     |
---------------------------------
9.0
9.0
14.19
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.35     |
| fps                | 389      |
| nupdates           | 43600    |
| policy_entropy     | 0.028    |
| total_timesteps    | 218000   |
| value_loss         | 17.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 214      |
| explained_variance | 0.899    |
| fps                | 389      |
| nupdates           | 43700    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 218500   |
| value_loss         | 9.04     |
---------------------------------
19.0
19.0
13.82
9.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.961    |
| fps                | 389      |
| nupdates           | 43800    |
| policy_entropy     | 0.00983  |
| total_timesteps    | 219000   |
| value_loss         | 8.99     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 217      |
| explained_variance | -1.06    |
| fps                | 389      |
| nupdates           | 43900    |
| policy_entropy     | 0.0784   |
| total_timesteps    | 219500   |
| value_loss         | 364      |
---------------------------------
10.0
10.0
13.4
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.974    |
| fps                | 389      |
| nupdates           | 44000    |
| policy_entropy     | 0.172    |
| total_timesteps    | 220000   |
| value_loss         | 12.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 218      |
| explained_variance | -2.19    |
| fps                | 389      |
| nupdates           | 44100    |
| policy_entropy     | 0.121    |
| total_timesteps    | 220500   |
| value_loss         | 436      |
---------------------------------
10.0
10.0
14.17
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.724    |
| fps                | 389      |
| nupdates           | 44200    |
| policy_entropy     | 0.268    |
| total_timesteps    | 221000   |
| value_loss         | 29.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 218      |
| explained_variance | -2.79    |
| fps                | 389      |
| nupdates           | 44300    |
| policy_entropy     | 0.103    |
| total_timesteps    | 221500   |
| value_loss         | 306      |
---------------------------------
10.0
10.0
14.14
19.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -0.132   |
| fps                | 389      |
| nupdates           | 44400    |
| policy_entropy     | 0.011    |
| total_timesteps    | 222000   |
| value_loss         | 105      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.971    |
| fps                | 389      |
| nupdates           | 44500    |
| policy_entropy     | 0.104    |
| total_timesteps    | 222500   |
| value_loss         | 3.3      |
---------------------------------
10.0
10.0
13.96
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.746    |
| fps                | 389      |
| nupdates           | 44600    |
| policy_entropy     | 0.036    |
| total_timesteps    | 223000   |
| value_loss         | 8.59     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.393    |
| fps                | 389      |
| nupdates           | 44700    |
| policy_entropy     | 0.395    |
| total_timesteps    | 223500   |
| value_loss         | 269      |
---------------------------------
21.0
21.0
11.91
9.5
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.521    |
| fps                | 389      |
| nupdates           | 44800    |
| policy_entropy     | 0.00556  |
| total_timesteps    | 224000   |
| value_loss         | 307      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0        |
| fps                | 389      |
| nupdates           | 44900    |
| policy_entropy     | 0.28     |
| total_timesteps    | 224500   |
| value_loss         | 88.6     |
---------------------------------
23.0
23.0
17.94
27.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 201      |
| explained_variance | -0.195   |
| fps                | 389      |
| nupdates           | 45000    |
| policy_entropy     | 0.167    |
| total_timesteps    | 225000   |
| value_loss         | 2.12e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 198      |
| explained_variance | -0.438   |
| fps                | 389      |
| nupdates           | 45100    |
| policy_entropy     | 0.0476   |
| total_timesteps    | 225500   |
| value_loss         | 2.07e+04 |
---------------------------------
20.0
20.0
19.59
10.5
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 198      |
| explained_variance | -9.57    |
| fps                | 389      |
| nupdates           | 45200    |
| policy_entropy     | 0.0926   |
| total_timesteps    | 226000   |
| value_loss         | 1.24e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.614    |
| fps                | 389      |
| nupdates           | 45300    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 226500   |
| value_loss         | 227      |
---------------------------------
27.0
27.0
14.08
19.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.364    |
| fps                | 389      |
| nupdates           | 45400    |
| policy_entropy     | 0.0599   |
| total_timesteps    | 227000   |
| value_loss         | 23.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 215      |
| explained_variance | -0.884   |
| fps                | 389      |
| nupdates           | 45500    |
| policy_entropy     | 0.0753   |
| total_timesteps    | 227500   |
| value_loss         | 139      |
---------------------------------
20.0
20.0
14.67
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | -0.487   |
| fps                | 389      |
| nupdates           | 45600    |
| policy_entropy     | 0.0051   |
| total_timesteps    | 228000   |
| value_loss         | 207      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 215      |
| explained_variance | -0.0752  |
| fps                | 389      |
| nupdates           | 45700    |
| policy_entropy     | 0.00871  |
| total_timesteps    | 228500   |
| value_loss         | 29.1     |
---------------------------------
19.0
19.0
13.72
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.933    |
| fps                | 390      |
| nupdates           | 45800    |
| policy_entropy     | 0.203    |
| total_timesteps    | 229000   |
| value_loss         | 2.19     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.82     |
| fps                | 390      |
| nupdates           | 45900    |
| policy_entropy     | 0.00393  |
| total_timesteps    | 229500   |
| value_loss         | 478      |
---------------------------------
22.0
22.0
13.0
10.5
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 217      |
| explained_variance | 0.973    |
| fps                | 390      |
| nupdates           | 46000    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 230000   |
| value_loss         | 12.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.906    |
| fps                | 390      |
| nupdates           | 46100    |
| policy_entropy     | 0.176    |
| total_timesteps    | 230500   |
| value_loss         | 15.1     |
---------------------------------
9.0
9.0
14.81
9.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.589    |
| fps                | 390      |
| nupdates           | 46200    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 231000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | 0.818    |
| fps                | 390      |
| nupdates           | 46300    |
| policy_entropy     | 0.00674  |
| total_timesteps    | 231500   |
| value_loss         | 31.5     |
---------------------------------
20.0
20.0
14.05
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.761    |
| fps                | 389      |
| nupdates           | 46400    |
| policy_entropy     | 0.00684  |
| total_timesteps    | 232000   |
| value_loss         | 788      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.24     |
| fps                | 389      |
| nupdates           | 46500    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 232500   |
| value_loss         | 13.1     |
---------------------------------
9.0
9.0
13.65
10.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.546    |
| fps                | 389      |
| nupdates           | 46600    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 233000   |
| value_loss         | 272      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.371    |
| fps                | 389      |
| nupdates           | 46700    |
| policy_entropy     | 0.11     |
| total_timesteps    | 233500   |
| value_loss         | 27.5     |
---------------------------------
9.0
9.0
14.37
10.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.598    |
| fps                | 389      |
| nupdates           | 46800    |
| policy_entropy     | 0.00765  |
| total_timesteps    | 234000   |
| value_loss         | 178      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.932    |
| fps                | 389      |
| nupdates           | 46900    |
| policy_entropy     | 0.0264   |
| total_timesteps    | 234500   |
| value_loss         | 12.7     |
---------------------------------
13.0
13.0
13.71
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.805   |
| fps                | 389      |
| nupdates           | 47000    |
| policy_entropy     | 0.00701  |
| total_timesteps    | 235000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.943    |
| fps                | 389      |
| nupdates           | 47100    |
| policy_entropy     | 0.3      |
| total_timesteps    | 235500   |
| value_loss         | 3.28     |
---------------------------------
9.0
9.0
14.36
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 216      |
| explained_variance | -1.28    |
| fps                | 389      |
| nupdates           | 47200    |
| policy_entropy     | 0.0598   |
| total_timesteps    | 236000   |
| value_loss         | 258      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.928    |
| fps                | 389      |
| nupdates           | 47300    |
| policy_entropy     | 0.0224   |
| total_timesteps    | 236500   |
| value_loss         | 12.2     |
---------------------------------
11.0
11.0
13.19
10.5
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.553    |
| fps                | 389      |
| nupdates           | 47400    |
| policy_entropy     | 0.0493   |
| total_timesteps    | 237000   |
| value_loss         | 36.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.717    |
| fps                | 389      |
| nupdates           | 47500    |
| policy_entropy     | 0.00289  |
| total_timesteps    | 237500   |
| value_loss         | 24.4     |
---------------------------------
9.0
9.0
12.29
9.5
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 218      |
| explained_variance | -3.74    |
| fps                | 388      |
| nupdates           | 47600    |
| policy_entropy     | 0.14     |
| total_timesteps    | 238000   |
| value_loss         | 457      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 216      |
| explained_variance | -1.45    |
| fps                | 388      |
| nupdates           | 47700    |
| policy_entropy     | 0.133    |
| total_timesteps    | 238500   |
| value_loss         | 885      |
---------------------------------
27.0
27.0
14.5
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0        |
| fps                | 388      |
| nupdates           | 47800    |
| policy_entropy     | 0.0866   |
| total_timesteps    | 239000   |
| value_loss         | 377      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 206      |
| explained_variance | -0.103   |
| fps                | 388      |
| nupdates           | 47900    |
| policy_entropy     | 0.393    |
| total_timesteps    | 239500   |
| value_loss         | 87.7     |
---------------------------------
9.0
9.0
15.26
9.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 208      |
| explained_variance | -0.422   |
| fps                | 388      |
| nupdates           | 48000    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 240000   |
| value_loss         | 58.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0289  |
| fps                | 388      |
| nupdates           | 48100    |
| policy_entropy     | 0.12     |
| total_timesteps    | 240500   |
| value_loss         | 23.9     |
---------------------------------
9.0
9.0
13.5
9.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.992    |
| fps                | 389      |
| nupdates           | 48200    |
| policy_entropy     | 0.00422  |
| total_timesteps    | 241000   |
| value_loss         | 5.31     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.302    |
| fps                | 389      |
| nupdates           | 48300    |
| policy_entropy     | 0.216    |
| total_timesteps    | 241500   |
| value_loss         | 61.3     |
---------------------------------
10.0
10.0
13.7
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.967    |
| fps                | 389      |
| nupdates           | 48400    |
| policy_entropy     | 0.192    |
| total_timesteps    | 242000   |
| value_loss         | 1.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.994    |
| fps                | 389      |
| nupdates           | 48500    |
| policy_entropy     | 0.00617  |
| total_timesteps    | 242500   |
| value_loss         | 2.55     |
---------------------------------
9.0
9.0
15.14
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.124    |
| fps                | 389      |
| nupdates           | 48600    |
| policy_entropy     | 0.0195   |
| total_timesteps    | 243000   |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.963    |
| fps                | 389      |
| nupdates           | 48700    |
| policy_entropy     | 0.00295  |
| total_timesteps    | 243500   |
| value_loss         | 22.1     |
---------------------------------
21.0
21.0
14.66
15.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | -0.387   |
| fps                | 389      |
| nupdates           | 48800    |
| policy_entropy     | 0.201    |
| total_timesteps    | 244000   |
| value_loss         | 267      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | -5.47    |
| fps                | 389      |
| nupdates           | 48900    |
| policy_entropy     | 0.0431   |
| total_timesteps    | 244500   |
| value_loss         | 355      |
---------------------------------
8.0
8.0
13.05
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.89     |
| fps                | 389      |
| nupdates           | 49000    |
| policy_entropy     | 0.00564  |
| total_timesteps    | 245000   |
| value_loss         | 5.66     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | -0.273   |
| fps                | 389      |
| nupdates           | 49100    |
| policy_entropy     | 0.0106   |
| total_timesteps    | 245500   |
| value_loss         | 186      |
---------------------------------
11.0
11.0
14.04
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | -2.81    |
| fps                | 389      |
| nupdates           | 49200    |
| policy_entropy     | 0.122    |
| total_timesteps    | 246000   |
| value_loss         | 681      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.175    |
| fps                | 389      |
| nupdates           | 49300    |
| policy_entropy     | 0.184    |
| total_timesteps    | 246500   |
| value_loss         | 299      |
---------------------------------
20.0
20.0
13.73
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | -1.93    |
| fps                | 389      |
| nupdates           | 49400    |
| policy_entropy     | 0.039    |
| total_timesteps    | 247000   |
| value_loss         | 1.07e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 220      |
| explained_variance | -0.308   |
| fps                | 389      |
| nupdates           | 49500    |
| policy_entropy     | 0.248    |
| total_timesteps    | 247500   |
| value_loss         | 57.3     |
---------------------------------
10.0
10.0
13.69
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.422    |
| fps                | 389      |
| nupdates           | 49600    |
| policy_entropy     | 0.00348  |
| total_timesteps    | 248000   |
| value_loss         | 642      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 221      |
| explained_variance | -0.562   |
| fps                | 389      |
| nupdates           | 49700    |
| policy_entropy     | 0.0805   |
| total_timesteps    | 248500   |
| value_loss         | 946      |
---------------------------------
9.0
9.0
13.52
10.5
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.799    |
| fps                | 389      |
| nupdates           | 49800    |
| policy_entropy     | 0.00545  |
| total_timesteps    | 249000   |
| value_loss         | 64.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | -2.39    |
| fps                | 389      |
| nupdates           | 49900    |
| policy_entropy     | 0.78     |
| total_timesteps    | 249500   |
| value_loss         | 244      |
---------------------------------
10.0
10.0
14.04
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 215      |
| explained_variance | -1.09    |
| fps                | 389      |
| nupdates           | 50000    |
| policy_entropy     | 0.0929   |
| total_timesteps    | 250000   |
| value_loss         | 324      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0418   |
| fps                | 389      |
| nupdates           | 50100    |
| policy_entropy     | 0.144    |
| total_timesteps    | 250500   |
| value_loss         | 26.9     |
---------------------------------
9.0
9.0
14.54
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.0927   |
| fps                | 389      |
| nupdates           | 50200    |
| policy_entropy     | 0.0728   |
| total_timesteps    | 251000   |
| value_loss         | 59.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.538    |
| fps                | 389      |
| nupdates           | 50300    |
| policy_entropy     | 0.104    |
| total_timesteps    | 251500   |
| value_loss         | 28.7     |
---------------------------------
10.0
10.0
14.36
15.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.408    |
| fps                | 389      |
| nupdates           | 50400    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 252000   |
| value_loss         | 520      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.939    |
| fps                | 389      |
| nupdates           | 50500    |
| policy_entropy     | 0.00642  |
| total_timesteps    | 252500   |
| value_loss         | 2.03     |
---------------------------------
10.0
10.0
15.47
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.989    |
| fps                | 389      |
| nupdates           | 50600    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 253000   |
| value_loss         | 1.64     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.731    |
| fps                | 389      |
| nupdates           | 50700    |
| policy_entropy     | 0.00538  |
| total_timesteps    | 253500   |
| value_loss         | 86.5     |
---------------------------------
23.0
23.0
14.94
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | -1.62    |
| fps                | 389      |
| nupdates           | 50800    |
| policy_entropy     | 0.0655   |
| total_timesteps    | 254000   |
| value_loss         | 156      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 220      |
| explained_variance | 0.858    |
| fps                | 389      |
| nupdates           | 50900    |
| policy_entropy     | 0.0789   |
| total_timesteps    | 254500   |
| value_loss         | 18.4     |
---------------------------------
10.0
10.0
14.15
11.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.892    |
| fps                | 389      |
| nupdates           | 51000    |
| policy_entropy     | 0.00458  |
| total_timesteps    | 255000   |
| value_loss         | 5.08     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.878    |
| fps                | 389      |
| nupdates           | 51100    |
| policy_entropy     | 0.00678  |
| total_timesteps    | 255500   |
| value_loss         | 9.61     |
---------------------------------
11.0
11.0
14.44
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | -4.26    |
| fps                | 389      |
| nupdates           | 51200    |
| policy_entropy     | 0.0702   |
| total_timesteps    | 256000   |
| value_loss         | 467      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 214      |
| explained_variance | -0.0147  |
| fps                | 389      |
| nupdates           | 51300    |
| policy_entropy     | 0.0653   |
| total_timesteps    | 256500   |
| value_loss         | 805      |
---------------------------------
26.0
26.0
15.42
15.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.661    |
| fps                | 389      |
| nupdates           | 51400    |
| policy_entropy     | 0.076    |
| total_timesteps    | 257000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.691    |
| fps                | 389      |
| nupdates           | 51500    |
| policy_entropy     | 0.0513   |
| total_timesteps    | 257500   |
| value_loss         | 63.4     |
---------------------------------
10.0
10.0
14.69
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | -5.75    |
| fps                | 389      |
| nupdates           | 51600    |
| policy_entropy     | 0.523    |
| total_timesteps    | 258000   |
| value_loss         | 478      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.981    |
| fps                | 389      |
| nupdates           | 51700    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 258500   |
| value_loss         | 3.8      |
---------------------------------
20.0
20.0
14.96
17.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | -0.513   |
| fps                | 389      |
| nupdates           | 51800    |
| policy_entropy     | 0.387    |
| total_timesteps    | 259000   |
| value_loss         | 126      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.18     |
| fps                | 389      |
| nupdates           | 51900    |
| policy_entropy     | 0.00558  |
| total_timesteps    | 259500   |
| value_loss         | 371      |
---------------------------------
10.0
10.0
15.21
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.915    |
| fps                | 389      |
| nupdates           | 52000    |
| policy_entropy     | 0.00881  |
| total_timesteps    | 260000   |
| value_loss         | 13.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.929    |
| fps                | 389      |
| nupdates           | 52100    |
| policy_entropy     | 0.0171   |
| total_timesteps    | 260500   |
| value_loss         | 3.95     |
---------------------------------
10.0
10.0
15.02
10.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.443    |
| fps                | 389      |
| nupdates           | 52200    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 261000   |
| value_loss         | 361      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | -5.35    |
| fps                | 389      |
| nupdates           | 52300    |
| policy_entropy     | 0.0657   |
| total_timesteps    | 261500   |
| value_loss         | 313      |
---------------------------------
19.0
19.0
14.02
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | 0.605    |
| fps                | 389      |
| nupdates           | 52400    |
| policy_entropy     | 0.175    |
| total_timesteps    | 262000   |
| value_loss         | 20.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | -0.101   |
| fps                | 388      |
| nupdates           | 52500    |
| policy_entropy     | 0.146    |
| total_timesteps    | 262500   |
| value_loss         | 87.6     |
---------------------------------
9.0
9.0
14.4
19.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.101    |
| fps                | 388      |
| nupdates           | 52600    |
| policy_entropy     | 0.128    |
| total_timesteps    | 263000   |
| value_loss         | 44.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.0507  |
| fps                | 388      |
| nupdates           | 52700    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 263500   |
| value_loss         | 114      |
---------------------------------
10.0
10.0
14.13
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.761    |
| fps                | 388      |
| nupdates           | 52800    |
| policy_entropy     | 0.00473  |
| total_timesteps    | 264000   |
| value_loss         | 31.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.641    |
| fps                | 388      |
| nupdates           | 52900    |
| policy_entropy     | 0.0053   |
| total_timesteps    | 264500   |
| value_loss         | 51.8     |
---------------------------------
10.0
10.0
13.5
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.595    |
| fps                | 388      |
| nupdates           | 53000    |
| policy_entropy     | 0.0854   |
| total_timesteps    | 265000   |
| value_loss         | 67.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | -2.57    |
| fps                | 388      |
| nupdates           | 53100    |
| policy_entropy     | 0.0525   |
| total_timesteps    | 265500   |
| value_loss         | 360      |
---------------------------------
36.0
36.0
14.74
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.932    |
| fps                | 388      |
| nupdates           | 53200    |
| policy_entropy     | 0.00426  |
| total_timesteps    | 266000   |
| value_loss         | 22.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.324    |
| fps                | 388      |
| nupdates           | 53300    |
| policy_entropy     | 0.00648  |
| total_timesteps    | 266500   |
| value_loss         | 505      |
---------------------------------
10.0
10.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.891    |
| fps                | 388      |
| nupdates           | 53400    |
| policy_entropy     | 0.0041   |
| total_timesteps    | 267000   |
| value_loss         | 11.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.993    |
| fps                | 388      |
| nupdates           | 53500    |
| policy_entropy     | 0.0889   |
| total_timesteps    | 267500   |
| value_loss         | 0.556    |
---------------------------------
11.0
11.0
14.51
15.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.978    |
| fps                | 388      |
| nupdates           | 53600    |
| policy_entropy     | 0.00865  |
| total_timesteps    | 268000   |
| value_loss         | 2.87     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.424    |
| fps                | 388      |
| nupdates           | 53700    |
| policy_entropy     | 0.258    |
| total_timesteps    | 268500   |
| value_loss         | 561      |
---------------------------------
10.0
10.0
14.32
14.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.95     |
| fps                | 388      |
| nupdates           | 53800    |
| policy_entropy     | 0.00482  |
| total_timesteps    | 269000   |
| value_loss         | 1.12e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 215      |
| explained_variance | -0.48    |
| fps                | 388      |
| nupdates           | 53900    |
| policy_entropy     | 0.00413  |
| total_timesteps    | 269500   |
| value_loss         | 445      |
---------------------------------
10.0
10.0
15.9
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.866    |
| fps                | 388      |
| nupdates           | 54000    |
| policy_entropy     | 0.00504  |
| total_timesteps    | 270000   |
| value_loss         | 11       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | -1.26    |
| fps                | 388      |
| nupdates           | 54100    |
| policy_entropy     | 0.0324   |
| total_timesteps    | 270500   |
| value_loss         | 248      |
---------------------------------
9.0
9.0
13.66
12.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.966    |
| fps                | 388      |
| nupdates           | 54200    |
| policy_entropy     | 0.00863  |
| total_timesteps    | 271000   |
| value_loss         | 19.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.727    |
| fps                | 388      |
| nupdates           | 54300    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 271500   |
| value_loss         | 59.9     |
---------------------------------
20.0
20.0
14.35
11.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | -1.57    |
| fps                | 388      |
| nupdates           | 54400    |
| policy_entropy     | 0.0974   |
| total_timesteps    | 272000   |
| value_loss         | 361      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.991    |
| fps                | 388      |
| nupdates           | 54500    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 272500   |
| value_loss         | 6.11     |
---------------------------------
11.0
11.0
14.24
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.922    |
| fps                | 388      |
| nupdates           | 54600    |
| policy_entropy     | 0.00833  |
| total_timesteps    | 273000   |
| value_loss         | 4.05     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | -0.846   |
| fps                | 388      |
| nupdates           | 54700    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 273500   |
| value_loss         | 904      |
---------------------------------
9.0
9.0
13.57
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.892    |
| fps                | 388      |
| nupdates           | 54800    |
| policy_entropy     | 0.0104   |
| total_timesteps    | 274000   |
| value_loss         | 18.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.966    |
| fps                | 388      |
| nupdates           | 54900    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 274500   |
| value_loss         | 12       |
---------------------------------
10.0
10.0
13.87
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.98     |
| fps                | 388      |
| nupdates           | 55000    |
| policy_entropy     | 0.00994  |
| total_timesteps    | 275000   |
| value_loss         | 20.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.281    |
| fps                | 387      |
| nupdates           | 55100    |
| policy_entropy     | 0.00642  |
| total_timesteps    | 275500   |
| value_loss         | 366      |
---------------------------------
10.0
10.0
14.07
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.251    |
| fps                | 387      |
| nupdates           | 55200    |
| policy_entropy     | 0.0505   |
| total_timesteps    | 276000   |
| value_loss         | 61.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 222      |
| explained_variance | -2.01    |
| fps                | 386      |
| nupdates           | 55300    |
| policy_entropy     | 0.0539   |
| total_timesteps    | 276500   |
| value_loss         | 880      |
---------------------------------
10.0
10.0
14.62
19.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.00724  |
| fps                | 386      |
| nupdates           | 55400    |
| policy_entropy     | 0.11     |
| total_timesteps    | 277000   |
| value_loss         | 90.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | -1.52    |
| fps                | 386      |
| nupdates           | 55500    |
| policy_entropy     | 0.0478   |
| total_timesteps    | 277500   |
| value_loss         | 503      |
---------------------------------
21.0
21.0
15.15
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | -2.52    |
| fps                | 386      |
| nupdates           | 55600    |
| policy_entropy     | 0.489    |
| total_timesteps    | 278000   |
| value_loss         | 125      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | -0.413   |
| fps                | 386      |
| nupdates           | 55700    |
| policy_entropy     | 0.104    |
| total_timesteps    | 278500   |
| value_loss         | 72.6     |
---------------------------------
10.0
10.0
14.94
19.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.968    |
| fps                | 386      |
| nupdates           | 55800    |
| policy_entropy     | 0.287    |
| total_timesteps    | 279000   |
| value_loss         | 0.868    |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.704    |
| fps                | 386      |
| nupdates           | 55900    |
| policy_entropy     | 0.00441  |
| total_timesteps    | 279500   |
| value_loss         | 32       |
---------------------------------
21.0
21.0
14.79
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.926    |
| fps                | 386      |
| nupdates           | 56000    |
| policy_entropy     | 0.00981  |
| total_timesteps    | 280000   |
| value_loss         | 6.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | -2.36    |
| fps                | 386      |
| nupdates           | 56100    |
| policy_entropy     | 0.0515   |
| total_timesteps    | 280500   |
| value_loss         | 627      |
---------------------------------
20.0
20.0
14.43
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.959    |
| fps                | 385      |
| nupdates           | 56200    |
| policy_entropy     | 0.00915  |
| total_timesteps    | 281000   |
| value_loss         | 17.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | -1.41    |
| fps                | 385      |
| nupdates           | 56300    |
| policy_entropy     | 0.0468   |
| total_timesteps    | 281500   |
| value_loss         | 706      |
---------------------------------
10.0
10.0
13.54
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 221      |
| explained_variance | -2.43    |
| fps                | 385      |
| nupdates           | 56400    |
| policy_entropy     | 0.0609   |
| total_timesteps    | 282000   |
| value_loss         | 277      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | -0.343   |
| fps                | 385      |
| nupdates           | 56500    |
| policy_entropy     | 0.167    |
| total_timesteps    | 282500   |
| value_loss         | 169      |
---------------------------------
20.0
20.0
14.35
20.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.86     |
| fps                | 385      |
| nupdates           | 56600    |
| policy_entropy     | 0.209    |
| total_timesteps    | 283000   |
| value_loss         | 31.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.293    |
| fps                | 385      |
| nupdates           | 56700    |
| policy_entropy     | 0.00511  |
| total_timesteps    | 283500   |
| value_loss         | 579      |
---------------------------------
10.0
10.0
13.98
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.906    |
| fps                | 385      |
| nupdates           | 56800    |
| policy_entropy     | 0.00526  |
| total_timesteps    | 284000   |
| value_loss         | 7.71     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.489    |
| fps                | 385      |
| nupdates           | 56900    |
| policy_entropy     | 0.0661   |
| total_timesteps    | 284500   |
| value_loss         | 57.8     |
---------------------------------
10.0
10.0
14.42
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.516    |
| fps                | 385      |
| nupdates           | 57000    |
| policy_entropy     | 0.201    |
| total_timesteps    | 285000   |
| value_loss         | 19.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | -0.807   |
| fps                | 385      |
| nupdates           | 57100    |
| policy_entropy     | 0.0547   |
| total_timesteps    | 285500   |
| value_loss         | 692      |
---------------------------------
10.0
10.0
14.39
15.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.836    |
| fps                | 385      |
| nupdates           | 57200    |
| policy_entropy     | 0.00401  |
| total_timesteps    | 286000   |
| value_loss         | 97.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.582    |
| fps                | 385      |
| nupdates           | 57300    |
| policy_entropy     | 0.0171   |
| total_timesteps    | 286500   |
| value_loss         | 361      |
---------------------------------
10.0
10.0
13.88
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.983    |
| fps                | 385      |
| nupdates           | 57400    |
| policy_entropy     | 0.0267   |
| total_timesteps    | 287000   |
| value_loss         | 2.29     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.977    |
| fps                | 385      |
| nupdates           | 57500    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 287500   |
| value_loss         | 29.4     |
---------------------------------
10.0
10.0
13.4
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.0527   |
| fps                | 385      |
| nupdates           | 57600    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 288000   |
| value_loss         | 54.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.976    |
| fps                | 385      |
| nupdates           | 57700    |
| policy_entropy     | 0.00632  |
| total_timesteps    | 288500   |
| value_loss         | 1.61     |
---------------------------------
20.0
20.0
13.5
15.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0        |
| fps                | 385      |
| nupdates           | 57800    |
| policy_entropy     | 0.047    |
| total_timesteps    | 289000   |
| value_loss         | 281      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.104    |
| fps                | 385      |
| nupdates           | 57900    |
| policy_entropy     | 0.00518  |
| total_timesteps    | 289500   |
| value_loss         | 484      |
---------------------------------
9.0
9.0
16.06
11.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.968    |
| fps                | 385      |
| nupdates           | 58000    |
| policy_entropy     | 0.00278  |
| total_timesteps    | 290000   |
| value_loss         | 27.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 210      |
| explained_variance | -4.98    |
| fps                | 385      |
| nupdates           | 58100    |
| policy_entropy     | 0.0405   |
| total_timesteps    | 290500   |
| value_loss         | 543      |
---------------------------------
17.0
17.0
14.46
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | -1.86    |
| fps                | 385      |
| nupdates           | 58200    |
| policy_entropy     | 0.0265   |
| total_timesteps    | 291000   |
| value_loss         | 1.01e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.94     |
| fps                | 385      |
| nupdates           | 58300    |
| policy_entropy     | 0.00977  |
| total_timesteps    | 291500   |
| value_loss         | 6.18     |
---------------------------------
11.0
11.0
15.04
15.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.946    |
| fps                | 385      |
| nupdates           | 58400    |
| policy_entropy     | 0.00453  |
| total_timesteps    | 292000   |
| value_loss         | 672      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.954    |
| fps                | 385      |
| nupdates           | 58500    |
| policy_entropy     | 0.00416  |
| total_timesteps    | 292500   |
| value_loss         | 1.28e+03 |
---------------------------------
20.0
20.0
14.53
16.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.954    |
| fps                | 384      |
| nupdates           | 58600    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 293000   |
| value_loss         | 2.91     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.977    |
| fps                | 384      |
| nupdates           | 58700    |
| policy_entropy     | 0.011    |
| total_timesteps    | 293500   |
| value_loss         | 4.1      |
---------------------------------
10.0
10.0
15.38
10.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 218      |
| explained_variance | -1.8     |
| fps                | 384      |
| nupdates           | 58800    |
| policy_entropy     | 0.0442   |
| total_timesteps    | 294000   |
| value_loss         | 377      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.98     |
| fps                | 384      |
| nupdates           | 58900    |
| policy_entropy     | 0.0885   |
| total_timesteps    | 294500   |
| value_loss         | 1.13     |
---------------------------------
9.0
9.0
15.16
14.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.947    |
| fps                | 384      |
| nupdates           | 59000    |
| policy_entropy     | 0.00711  |
| total_timesteps    | 295000   |
| value_loss         | 7.08     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.97     |
| fps                | 384      |
| nupdates           | 59100    |
| policy_entropy     | 0.0975   |
| total_timesteps    | 295500   |
| value_loss         | 3.16     |
---------------------------------
12.0
12.0
14.94
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.956    |
| fps                | 384      |
| nupdates           | 59200    |
| policy_entropy     | 0.00494  |
| total_timesteps    | 296000   |
| value_loss         | 4.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.873    |
| fps                | 384      |
| nupdates           | 59300    |
| policy_entropy     | 0.012    |
| total_timesteps    | 296500   |
| value_loss         | 13       |
---------------------------------
10.0
10.0
14.06
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.95     |
| fps                | 384      |
| nupdates           | 59400    |
| policy_entropy     | 0.00539  |
| total_timesteps    | 297000   |
| value_loss         | 2.4      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | -0.0263  |
| fps                | 384      |
| nupdates           | 59500    |
| policy_entropy     | 0.0471   |
| total_timesteps    | 297500   |
| value_loss         | 481      |
---------------------------------
10.0
10.0
13.6
14.5
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.96     |
| fps                | 384      |
| nupdates           | 59600    |
| policy_entropy     | 0.0706   |
| total_timesteps    | 298000   |
| value_loss         | 15.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.972    |
| fps                | 384      |
| nupdates           | 59700    |
| policy_entropy     | 0.0122   |
| total_timesteps    | 298500   |
| value_loss         | 1.99     |
---------------------------------
10.0
10.0
13.87
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 223      |
| explained_variance | 0.971    |
| fps                | 384      |
| nupdates           | 59800    |
| policy_entropy     | 0.00453  |
| total_timesteps    | 299000   |
| value_loss         | 20.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 223      |
| explained_variance | 0.895    |
| fps                | 384      |
| nupdates           | 59900    |
| policy_entropy     | 0.104    |
| total_timesteps    | 299500   |
| value_loss         | 30.9     |
---------------------------------
9.0
9.0
13.35
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 223      |
| explained_variance | -1.99    |
| fps                | 384      |
| nupdates           | 60000    |
| policy_entropy     | 0.0513   |
| total_timesteps    | 300000   |
| value_loss         | 266      |
---------------------------------