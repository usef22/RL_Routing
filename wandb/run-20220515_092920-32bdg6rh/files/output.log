WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021014FFFC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021014FFFC18>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021018BC1E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021018BC1E48>>: AttributeError: module 'gast' has no attribute 'Index'
___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 5}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | -0.0082  |
| fps                | 31       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 145      |
| ep_reward_mean     | -264     |
| explained_variance | -0.0121  |
| fps                | 409      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 1.1e+03  |
---------------------------------
463.0
463.0
224.25
181.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_CUMULATIVE_50_200_best_model
---------------------------------
| ep_len_mean        | 224      |
| ep_reward_mean     | -540     |
| explained_variance | 0.0659   |
| fps                | 434      |
| nupdates           | 200      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1000     |
| value_loss         | 106      |
---------------------------------
---------------------------------
| ep_len_mean        | 172      |
| ep_reward_mean     | -356     |
| explained_variance | 0.0627   |
| fps                | 441      |
| nupdates           | 300      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1500     |
| value_loss         | 281      |
---------------------------------
136.0
136.0
150.92307692307693
134.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_CUMULATIVE_50_200_best_model
---------------------------------
| ep_len_mean        | 151      |
| ep_reward_mean     | -269     |
| explained_variance | 0.0534   |
| fps                | 428      |
| nupdates           | 400      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2000     |
| value_loss         | 207      |
---------------------------------
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -261     |
| explained_variance | 0.0882   |
| fps                | 426      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 196      |
---------------------------------
225.0
225.0
158.16666666666666
145.5
---------------------------------
| ep_len_mean        | 158      |
| ep_reward_mean     | -292     |
| explained_variance | 0.0152   |
| fps                | 435      |
| nupdates           | 600      |
| policy_entropy     | 1.1      |
| total_timesteps    | 3000     |
| value_loss         | 165      |
---------------------------------
---------------------------------
| ep_len_mean        | 175      |
| ep_reward_mean     | -334     |
| explained_variance | -0.0094  |
| fps                | 441      |
| nupdates           | 700      |
| policy_entropy     | 1.09     |
| total_timesteps    | 3500     |
| value_loss         | 187      |
---------------------------------
322.0
322.0
181.95
182.0
---------------------------------
| ep_len_mean        | 182      |
| ep_reward_mean     | -356     |
| explained_variance | 0.00191  |
| fps                | 445      |
| nupdates           | 800      |
| policy_entropy     | 1.06     |
| total_timesteps    | 4000     |
| value_loss         | 158      |
---------------------------------
---------------------------------
| ep_len_mean        | 195      |
| ep_reward_mean     | -392     |
| explained_variance | 0.0065   |
| fps                | 448      |
| nupdates           | 900      |
| policy_entropy     | 1.09     |
| total_timesteps    | 4500     |
| value_loss         | 220      |
---------------------------------
78.0
78.0
199.08
263.5
---------------------------------
| ep_len_mean        | 199      |
| ep_reward_mean     | -411     |
| explained_variance | 0.00128  |
| fps                | 450      |
| nupdates           | 1000     |
| policy_entropy     | 1.09     |
| total_timesteps    | 5000     |
| value_loss         | 6.27     |
---------------------------------
---------------------------------
| ep_len_mean        | 198      |
| ep_reward_mean     | -408     |
| explained_variance | 0.000276 |
| fps                | 453      |
| nupdates           | 1100     |
| policy_entropy     | 1.09     |
| total_timesteps    | 5500     |
| value_loss         | 239      |
---------------------------------
278.0
278.0
200.3448275862069
236.5
---------------------------------
| ep_len_mean        | 200      |
| ep_reward_mean     | -414     |
| explained_variance | 5.96e-07 |
| fps                | 455      |
| nupdates           | 1200     |
| policy_entropy     | 1.09     |
| total_timesteps    | 6000     |
| value_loss         | 145      |
---------------------------------
---------------------------------
| ep_len_mean        | 195      |
| ep_reward_mean     | -394     |
| explained_variance | 0        |
| fps                | 455      |
| nupdates           | 1300     |
| policy_entropy     | 1.03     |
| total_timesteps    | 6500     |
| value_loss         | 142      |
---------------------------------
61.0
61.0
186.69444444444446
170.0
---------------------------------
| ep_len_mean        | 187      |
| ep_reward_mean     | -368     |
| explained_variance | 2.93e-05 |
| fps                | 457      |
| nupdates           | 1400     |
| policy_entropy     | 1        |
| total_timesteps    | 7000     |
| value_loss         | 389      |
---------------------------------
----------------------------------
| ep_len_mean        | 188       |
| ep_reward_mean     | -370      |
| explained_variance | -6.32e-06 |
| fps                | 456       |
| nupdates           | 1500      |
| policy_entropy     | 1.05      |
| total_timesteps    | 7500      |
| value_loss         | 118       |
----------------------------------
79.0
79.0
180.72093023255815
93.0
---------------------------------
| ep_len_mean        | 181      |
| ep_reward_mean     | -349     |
| explained_variance | 3.81e-05 |
| fps                | 456      |
| nupdates           | 1600     |
| policy_entropy     | 1.05     |
| total_timesteps    | 8000     |
| value_loss         | 114      |
---------------------------------
---------------------------------
| ep_len_mean        | 177      |
| ep_reward_mean     | -331     |
| explained_variance | -0.00115 |
| fps                | 456      |
| nupdates           | 1700     |
| policy_entropy     | 0.941    |
| total_timesteps    | 8500     |
| value_loss         | 67.1     |
---------------------------------
18.0
18.0
159.66071428571428
63.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_CUMULATIVE_50_200_best_model
---------------------------------
| ep_len_mean        | 160      |
| ep_reward_mean     | -267     |
| explained_variance | 5.25e-06 |
| fps                | 455      |
| nupdates           | 1800     |
| policy_entropy     | 1        |
| total_timesteps    | 9000     |
| value_loss         | 53.1     |
---------------------------------
----------------------------------
| ep_len_mean        | 143       |
| ep_reward_mean     | -210      |
| explained_variance | -0.000598 |
| fps                | 453       |
| nupdates           | 1900      |
| policy_entropy     | 0.878     |
| total_timesteps    | 9500      |
| value_loss         | 218       |
----------------------------------
51.0
51.0
127.82051282051282
36.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_CUMULATIVE_50_200_best_model
---------------------------------
| ep_len_mean        | 128      |
| ep_reward_mean     | -146     |
| explained_variance | -0.00165 |
| fps                | 447      |
| nupdates           | 2000     |
| policy_entropy     | 0.571    |
| total_timesteps    | 10000    |
| value_loss         | 126      |
