WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BBE454A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BBE454A8>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BBE12320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BBE12320>>: AttributeError: module 'gast' has no attribute 'Index'
___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | 0.0727   |
| fps                | 25       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 234      |
| ep_reward_mean     | -597     |
| explained_variance | -0.0527  |
| fps                | 358      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 99.3     |
---------------------------------
112.0
112.0
210.5
229.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 210      |
| ep_reward_mean     | -515     |
| explained_variance | 0.0143   |
| fps                | 388      |
| nupdates           | 200      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1000     |
| value_loss         | 174      |
---------------------------------
----------------------------------
| ep_len_mean        | 249       |
| ep_reward_mean     | -670      |
| explained_variance | -0.000862 |
| fps                | 401       |
| nupdates           | 300       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1500      |
| value_loss         | 8.26e+03  |
----------------------------------
314.0
314.0
249.33333333333334
267.5
----------------------------------
| ep_len_mean        | 249       |
| ep_reward_mean     | -670      |
| explained_variance | -3.11e-05 |
| fps                | 406       |
| nupdates           | 400       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2000      |
| value_loss         | 92.1      |
----------------------------------
---------------------------------
| ep_len_mean        | 318      |
| ep_reward_mean     | -907     |
| explained_variance | -0.0388  |
| fps                | 409      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 223      |
---------------------------------
535.0
535.0
345.375
293.0
----------------------------------
| ep_len_mean        | 345       |
| ep_reward_mean     | -1.05e+03 |
| explained_variance | -0.0159   |
| fps                | 412       |
| nupdates           | 600       |
| policy_entropy     | 1.1       |
| total_timesteps    | 3000      |
| value_loss         | 124       |
----------------------------------
----------------------------------
| ep_len_mean        | 345       |
| ep_reward_mean     | -1.05e+03 |
| explained_variance | -0.000823 |
| fps                | 416       |
| nupdates           | 700       |
| policy_entropy     | 1.08      |
| total_timesteps    | 3500      |
| value_loss         | 139       |
----------------------------------
185.0
185.0
332.8333333333333
288.5
----------------------------------
| ep_len_mean        | 333       |
| ep_reward_mean     | -1.03e+03 |
| explained_variance | 0.0221    |
| fps                | 417       |
| nupdates           | 800       |
| policy_entropy     | 1.09      |
| total_timesteps    | 4000      |
| value_loss         | 85.2      |
----------------------------------
---------------------------------
| ep_len_mean        | 300      |
| ep_reward_mean     | -912     |
| explained_variance | 0.125    |
| fps                | 410      |
| nupdates           | 900      |
| policy_entropy     | 1.07     |
| total_timesteps    | 4500     |
| value_loss         | 37.7     |
---------------------------------
76.0
76.0
285.5625
168.0
---------------------------------
| ep_len_mean        | 286      |
| ep_reward_mean     | -857     |
| explained_variance | 0.00215  |
| fps                | 410      |
| nupdates           | 1000     |
| policy_entropy     | 1.08     |
| total_timesteps    | 5000     |
| value_loss         | 232      |
---------------------------------
---------------------------------
| ep_len_mean        | 290      |
| ep_reward_mean     | -856     |
| explained_variance | 0.0028   |
| fps                | 413      |
| nupdates           | 1100     |
| policy_entropy     | 1.06     |
| total_timesteps    | 5500     |
| value_loss         | 474      |
---------------------------------
314.0
314.0
293.8
182.0
---------------------------------
| ep_len_mean        | 294      |
| ep_reward_mean     | -870     |
| explained_variance | 0.00144  |
| fps                | 414      |
| nupdates           | 1200     |
| policy_entropy     | 1.07     |
| total_timesteps    | 6000     |
| value_loss         | 87.2     |
---------------------------------
----------------------------------
| ep_len_mean        | 297       |
| ep_reward_mean     | -889      |
| explained_variance | -0.000145 |
| fps                | 415       |
| nupdates           | 1300      |
| policy_entropy     | 1.09      |
| total_timesteps    | 6500      |
| value_loss         | 326       |
----------------------------------
85.0
85.0
276.92
273.5
---------------------------------
| ep_len_mean        | 277      |
| ep_reward_mean     | -804     |
| explained_variance | 0.000331 |
| fps                | 416      |
| nupdates           | 1400     |
| policy_entropy     | 1.03     |
| total_timesteps    | 7000     |
| value_loss         | 221      |
---------------------------------
---------------------------------
| ep_len_mean        | 264      |
| ep_reward_mean     | -749     |
| explained_variance | 1.69e-05 |
| fps                | 415      |
| nupdates           | 1500     |
| policy_entropy     | 0.893    |
| total_timesteps    | 7500     |
| value_loss         | 114      |
---------------------------------
86.0
86.0
254.76666666666668
162.0
----------------------------------
| ep_len_mean        | 255       |
| ep_reward_mean     | -714      |
| explained_variance | -0.000288 |
| fps                | 414       |
| nupdates           | 1600      |
| policy_entropy     | 1.04      |
| total_timesteps    | 8000      |
| value_loss         | 24.1      |
----------------------------------
---------------------------------
| ep_len_mean        | 256      |
| ep_reward_mean     | -723     |
| explained_variance | 6.97e-05 |
| fps                | 412      |
| nupdates           | 1700     |
| policy_entropy     | 0.989    |
| total_timesteps    | 8500     |
| value_loss         | 109      |
---------------------------------
239.0
239.0
249.27777777777777
192.0
----------------------------------
| ep_len_mean        | 249       |
| ep_reward_mean     | -690      |
| explained_variance | -0.000545 |
| fps                | 412       |
| nupdates           | 1800      |
| policy_entropy     | 0.996     |
| total_timesteps    | 9000      |
| value_loss         | 103       |
----------------------------------
----------------------------------
| ep_len_mean        | 241       |
| ep_reward_mean     | -657      |
| explained_variance | -0.000461 |
| fps                | 411       |
| nupdates           | 1900      |
| policy_entropy     | 1.04      |
| total_timesteps    | 9500      |
| value_loss         | 212       |
----------------------------------
60.0
60.0
221.62222222222223
103.5
----------------------------------
| ep_len_mean        | 222       |
| ep_reward_mean     | -585      |
| explained_variance | -0.000147 |
| fps                | 411       |
| nupdates           | 2000      |
| policy_entropy     | 0.928     |
| total_timesteps    | 10000     |
| value_loss         | 87.2      |
----------------------------------
---------------------------------
| ep_len_mean        | 191      |
| ep_reward_mean     | -465     |
| explained_variance | -0.00213 |
| fps                | 409      |
| nupdates           | 2100     |
| policy_entropy     | 0.692    |
| total_timesteps    | 10500    |
| value_loss         | 58       |
---------------------------------
75.0
75.0
165.86363636363637
41.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 166      |
| ep_reward_mean     | -366     |
| explained_variance | 0.00113  |
| fps                | 410      |
| nupdates           | 2200     |
| policy_entropy     | 0.496    |
| total_timesteps    | 11000    |
| value_loss         | 145      |
---------------------------------
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -304     |
| explained_variance | 0.000119 |
| fps                | 410      |
| nupdates           | 2300     |
| policy_entropy     | 0.946    |
| total_timesteps    | 11500    |
| value_loss         | 55.4     |
---------------------------------
26.0
26.0
136.49425287356323
25.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 136      |
| ep_reward_mean     | -252     |
| explained_variance | 0.0001   |
| fps                | 411      |
| nupdates           | 2400     |
| policy_entropy     | 0.55     |
| total_timesteps    | 12000    |
| value_loss         | 88.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 127      |
| ep_reward_mean     | -215     |
| explained_variance | 1e-05    |
| fps                | 411      |
| nupdates           | 2500     |
| policy_entropy     | 0.562    |
| total_timesteps    | 12500    |
| value_loss         | 111      |
---------------------------------
14.0
14.0
89.89
20.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 89.9      |
| ep_reward_mean     | -71.5     |
| explained_variance | -6.85e-05 |
| fps                | 411       |
| nupdates           | 2600      |
| policy_entropy     | 0.45      |
| total_timesteps    | 13000     |
| value_loss         | 33.4      |
----------------------------------
---------------------------------
| ep_len_mean        | 68.7     |
| ep_reward_mean     | 9.7      |
| explained_variance | 0.000334 |
| fps                | 409      |
| nupdates           | 2700     |
| policy_entropy     | 0.856    |
| total_timesteps    | 13500    |
| value_loss         | 378      |
---------------------------------
81.0
81.0
52.44
38.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 52.4     |
| ep_reward_mean     | 74       |
| explained_variance | 0        |
| fps                | 409      |
| nupdates           | 2800     |
| policy_entropy     | 0.65     |
| total_timesteps    | 14000    |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 41.6     |
| ep_reward_mean     | 116      |
| explained_variance | -0.00248 |
| fps                | 410      |
| nupdates           | 2900     |
| policy_entropy     | 0.695    |
| total_timesteps    | 14500    |
| value_loss         | 38.5     |
---------------------------------
13.0
13.0
41.42
18.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 41.4     |
| ep_reward_mean     | 118      |
| explained_variance | -0.248   |
| fps                | 411      |
| nupdates           | 3000     |
| policy_entropy     | 0.53     |
| total_timesteps    | 15000    |
| value_loss         | 56.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 39.6     |
| ep_reward_mean     | 123      |
| explained_variance | -0.0358  |
| fps                | 410      |
| nupdates           | 3100     |
| policy_entropy     | 0.372    |
| total_timesteps    | 15500    |
| value_loss         | 7.77e+04 |
---------------------------------
52.0
52.0
34.17
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 34.2     |
| ep_reward_mean     | 142      |
| explained_variance | -0.603   |
| fps                | 410      |
| nupdates           | 3200     |
| policy_entropy     | 0.12     |
| total_timesteps    | 16000    |
| value_loss         | 101      |
---------------------------------
---------------------------------
| ep_len_mean        | 33.4     |
| ep_reward_mean     | 149      |
| explained_variance | -0.0685  |
| fps                | 411      |
| nupdates           | 3300     |
| policy_entropy     | 0.366    |
| total_timesteps    | 16500    |
| value_loss         | 42.2     |
---------------------------------
10.0
10.0
29.4
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 29.4     |
| ep_reward_mean     | 161      |
| explained_variance | -0.042   |
| fps                | 409      |
| nupdates           | 3400     |
| policy_entropy     | 0.175    |
| total_timesteps    | 17000    |
| value_loss         | 1.78e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 30.3     |
| ep_reward_mean     | 160      |
| explained_variance | 0.236    |
| fps                | 410      |
| nupdates           | 3500     |
| policy_entropy     | 0.33     |
| total_timesteps    | 17500    |
| value_loss         | 375      |
---------------------------------
14.0
14.0
28.97
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 29       |
| ep_reward_mean     | 164      |
| explained_variance | 0.08     |
| fps                | 410      |
| nupdates           | 3600     |
| policy_entropy     | 0.316    |
| total_timesteps    | 18000    |
| value_loss         | 8.25e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 27.7     |
| ep_reward_mean     | 169      |
| explained_variance | 0.00132  |
| fps                | 410      |
| nupdates           | 3700     |
| policy_entropy     | 0.446    |
| total_timesteps    | 18500    |
| value_loss         | 10.5     |
---------------------------------
9.0
9.0
26.57
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 26.6     |
| ep_reward_mean     | 175      |
| explained_variance | -0.0289  |
| fps                | 410      |
| nupdates           | 3800     |
| policy_entropy     | 0.207    |
| total_timesteps    | 19000    |
| value_loss         | 8.37e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 25.8     |
| ep_reward_mean     | 176      |
| explained_variance | -0.0216  |
| fps                | 410      |
| nupdates           | 3900     |
| policy_entropy     | 0.277    |
| total_timesteps    | 19500    |
| value_loss         | 5.35e+04 |
---------------------------------
9.0
9.0
23.94
21.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 23.9     |
| ep_reward_mean     | 182      |
| explained_variance | 0        |
| fps                | 409      |
| nupdates           | 4000     |
| policy_entropy     | 0.357    |
| total_timesteps    | 20000    |
| value_loss         | 9.73     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 181      |
| explained_variance | -0.0597  |
| fps                | 408      |
| nupdates           | 4100     |
| policy_entropy     | 0.451    |
| total_timesteps    | 20500    |
| value_loss         | 5.45e+04 |
---------------------------------
9.0
9.0
24.83
10.5
---------------------------------
| ep_len_mean        | 24.8     |
| ep_reward_mean     | 180      |
| explained_variance | -0.0225  |
| fps                | 408      |
| nupdates           | 4200     |
| policy_entropy     | 0.307    |
| total_timesteps    | 21000    |
| value_loss         | 1.8e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 27.3     |
| ep_reward_mean     | 172      |
| explained_variance | -0.0319  |
| fps                | 408      |
| nupdates           | 4300     |
| policy_entropy     | 0.554    |
| total_timesteps    | 21500    |
| value_loss         | 129      |
---------------------------------
29.0
29.0
28.63
15.0
---------------------------------
| ep_len_mean        | 28.6     |
| ep_reward_mean     | 168      |
| explained_variance | 0.176    |
| fps                | 408      |
| nupdates           | 4400     |
| policy_entropy     | 0.626    |
| total_timesteps    | 22000    |
| value_loss         | 6.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 30.3     |
| ep_reward_mean     | 167      |
| explained_variance | -1.06    |
| fps                | 409      |
| nupdates           | 4500     |
| policy_entropy     | 0.449    |
| total_timesteps    | 22500    |
| value_loss         | 50.1     |
---------------------------------
49.0
49.0
29.03
12.0
---------------------------------
| ep_len_mean        | 29       |
| ep_reward_mean     | 170      |
| explained_variance | 0.198    |
| fps                | 407      |
| nupdates           | 4600     |
| policy_entropy     | 0.148    |
| total_timesteps    | 23000    |
| value_loss         | 142      |
---------------------------------
---------------------------------
| ep_len_mean        | 26.3     |
| ep_reward_mean     | 176      |
| explained_variance | -0.0309  |
| fps                | 407      |
| nupdates           | 4700     |
| policy_entropy     | 0.134    |
| total_timesteps    | 23500    |
| value_loss         | 1.96e+04 |
---------------------------------
21.0
21.0
27.71
13.5
---------------------------------
| ep_len_mean        | 27.7     |
| ep_reward_mean     | 173      |
| explained_variance | 0.572    |
| fps                | 408      |
| nupdates           | 4800     |
| policy_entropy     | 0.278    |
| total_timesteps    | 24000    |
| value_loss         | 216      |
---------------------------------
---------------------------------
| ep_len_mean        | 26.9     |
| ep_reward_mean     | 176      |
| explained_variance | 0        |
| fps                | 408      |
| nupdates           | 4900     |
| policy_entropy     | 0.418    |
| total_timesteps    | 24500    |
| value_loss         | 487      |
---------------------------------
17.0
17.0
27.2
36.0
---------------------------------
| ep_len_mean        | 27.2     |
| ep_reward_mean     | 165      |
| explained_variance | -0.859   |
| fps                | 408      |
| nupdates           | 5000     |
| policy_entropy     | 0.485    |
| total_timesteps    | 25000    |
| value_loss         | 41.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 27       |
| ep_reward_mean     | 164      |
| explained_variance | -0.0159  |
| fps                | 406      |
| nupdates           | 5100     |
| policy_entropy     | 0.542    |
| total_timesteps    | 25500    |
| value_loss         | 51.9     |
---------------------------------
63.0
63.0
27.73
19.5
---------------------------------
| ep_len_mean        | 27.7     |
| ep_reward_mean     | 163      |
| explained_variance | 0.0021   |
| fps                | 407      |
| nupdates           | 5200     |
| policy_entropy     | 0.519    |
| total_timesteps    | 26000    |
| value_loss         | 6.31e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 26.9     |
| ep_reward_mean     | 167      |
| explained_variance | -0.06    |
| fps                | 406      |
| nupdates           | 5300     |
| policy_entropy     | 0.0976   |
| total_timesteps    | 26500    |
| value_loss         | 2.02e+04 |
---------------------------------
10.0
10.0
24.3
19.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 24.3     |
| ep_reward_mean     | 185      |
| explained_variance | -0.0685  |
| fps                | 406      |
| nupdates           | 5400     |
| policy_entropy     | 0.198    |
| total_timesteps    | 27000    |
| value_loss         | 1.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 189      |
| explained_variance | -0.0185  |
| fps                | 406      |
| nupdates           | 5500     |
| policy_entropy     | 0.525    |
| total_timesteps    | 27500    |
| value_loss         | 4.93     |
---------------------------------
10.0
10.0
25.1
25.5
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 183      |
| explained_variance | 0        |
| fps                | 405      |
| nupdates           | 5600     |
| policy_entropy     | 0.227    |
| total_timesteps    | 28000    |
| value_loss         | 74.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 26.8     |
| ep_reward_mean     | 175      |
| explained_variance | 0.00126  |
| fps                | 404      |
| nupdates           | 5700     |
| policy_entropy     | 0.25     |
| total_timesteps    | 28500    |
| value_loss         | 8.55e+04 |
---------------------------------
48.0
48.0
25.52
20.5
----------------------------------
| ep_len_mean        | 25.5      |
| ep_reward_mean     | 178       |
| explained_variance | -0.000951 |
| fps                | 403       |
| nupdates           | 5800      |
| policy_entropy     | 0.808     |
| total_timesteps    | 29000     |
| value_loss         | 72.9      |
----------------------------------
---------------------------------
| ep_len_mean        | 27.6     |
| ep_reward_mean     | 170      |
| explained_variance | 0.597    |
| fps                | 403      |
| nupdates           | 5900     |
| policy_entropy     | 0.221    |
| total_timesteps    | 29500    |
| value_loss         | 81.4     |
---------------------------------
15.0
15.0
29.27
24.0
---------------------------------
| ep_len_mean        | 29.3     |
| ep_reward_mean     | 164      |
| explained_variance | 0.889    |
| fps                | 402      |
| nupdates           | 6000     |
| policy_entropy     | 0.186    |
| total_timesteps    | 30000    |
| value_loss         | 14.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 30.1     |
| ep_reward_mean     | 162      |
| explained_variance | -0.0267  |
| fps                | 402      |
| nupdates           | 6100     |
| policy_entropy     | 0.431    |
| total_timesteps    | 30500    |
| value_loss         | 47.9     |
---------------------------------
13.0
13.0
24.8
19.0
---------------------------------
| ep_len_mean        | 24.8     |
| ep_reward_mean     | 180      |
| explained_variance | -0.117   |
| fps                | 402      |
| nupdates           | 6200     |
| policy_entropy     | 0.165    |
| total_timesteps    | 31000    |
| value_loss         | 30.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 27       |
| ep_reward_mean     | 171      |
| explained_variance | -0.00601 |
| fps                | 401      |
| nupdates           | 6300     |
| policy_entropy     | 0.483    |
| total_timesteps    | 31500    |
| value_loss         | 34.9     |
---------------------------------
23.0
23.0
25.49
18.0
---------------------------------
| ep_len_mean        | 25.5     |
| ep_reward_mean     | 176      |
| explained_variance | 1.19e-07 |
| fps                | 399      |
| nupdates           | 6400     |
| policy_entropy     | 0.524    |
| total_timesteps    | 32000    |
| value_loss         | 2.82     |
---------------------------------
---------------------------------
| ep_len_mean        | 26.3     |
| ep_reward_mean     | 175      |
| explained_variance | -0.0907  |
| fps                | 398      |
| nupdates           | 6500     |
| policy_entropy     | 0.357    |
| total_timesteps    | 32500    |
| value_loss         | 18.9     |
---------------------------------
10.0
10.0
24.37
10.0
---------------------------------
| ep_len_mean        | 24.4     |
| ep_reward_mean     | 179      |
| explained_variance | 0.0015   |
| fps                | 398      |
| nupdates           | 6600     |
| policy_entropy     | 0.338    |
| total_timesteps    | 33000    |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 177      |
| explained_variance | -0.00164 |
| fps                | 398      |
| nupdates           | 6700     |
| policy_entropy     | 0.578    |
| total_timesteps    | 33500    |
| value_loss         | 0.951    |
---------------------------------
12.0
12.0
22.49
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 22.5     |
| ep_reward_mean     | 187      |
| explained_variance | -0.0219  |
| fps                | 398      |
| nupdates           | 6800     |
| policy_entropy     | 0.515    |
| total_timesteps    | 34000    |
| value_loss         | 67.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 196      |
| explained_variance | 0.23     |
| fps                | 398      |
| nupdates           | 6900     |
| policy_entropy     | 0.648    |
| total_timesteps    | 34500    |
| value_loss         | 16.8     |
---------------------------------
10.0
10.0
20.64
28.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 196      |
| explained_variance | -0.0225  |
| fps                | 397      |
| nupdates           | 7000     |
| policy_entropy     | 0.523    |
| total_timesteps    | 35000    |
| value_loss         | 4.92e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 21.6     |
| ep_reward_mean     | 191      |
| explained_variance | -0.0133  |
| fps                | 397      |
| nupdates           | 7100     |
| policy_entropy     | 0.246    |
| total_timesteps    | 35500    |
| value_loss         | 10.3     |
---------------------------------
41.0
41.0
22.98
16.0
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 185      |
| explained_variance | -0.228   |
| fps                | 397      |
| nupdates           | 7200     |
| policy_entropy     | 0.312    |
| total_timesteps    | 36000    |
| value_loss         | 265      |
---------------------------------
---------------------------------
| ep_len_mean        | 23.8     |
| ep_reward_mean     | 184      |
| explained_variance | -0.106   |
| fps                | 397      |
| nupdates           | 7300     |
| policy_entropy     | 0.286    |
| total_timesteps    | 36500    |
| value_loss         | 249      |
---------------------------------
44.0
44.0
25.98
28.5
---------------------------------
| ep_len_mean        | 26       |
| ep_reward_mean     | 178      |
| explained_variance | -0.281   |
| fps                | 397      |
| nupdates           | 7400     |
| policy_entropy     | 0.365    |
| total_timesteps    | 37000    |
| value_loss         | 8.76     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.3     |
| ep_reward_mean     | 180      |
| explained_variance | -239     |
| fps                | 397      |
| nupdates           | 7500     |
| policy_entropy     | 0.258    |
| total_timesteps    | 37500    |
| value_loss         | 38.2     |
---------------------------------
66.0
66.0
22.18
11.5
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 195      |
| explained_variance | 0.156    |
| fps                | 396      |
| nupdates           | 7600     |
| policy_entropy     | 0.112    |
| total_timesteps    | 38000    |
| value_loss         | 523      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 199      |
| explained_variance | 0.497    |
| fps                | 396      |
| nupdates           | 7700     |
| policy_entropy     | 0.119    |
| total_timesteps    | 38500    |
| value_loss         | 165      |
---------------------------------
17.0
17.0
20.63
25.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 197      |
| explained_variance | 0.929    |
| fps                | 396      |
| nupdates           | 7800     |
| policy_entropy     | 0.23     |
| total_timesteps    | 39000    |
| value_loss         | 85.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 196      |
| explained_variance | 0.000907 |
| fps                | 396      |
| nupdates           | 7900     |
| policy_entropy     | 0.56     |
| total_timesteps    | 39500    |
| value_loss         | 37.7     |
---------------------------------
9.0
9.0
21.26
16.5
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 191      |
| explained_variance | 0.259    |
| fps                | 395      |
| nupdates           | 8000     |
| policy_entropy     | 0.228    |
| total_timesteps    | 40000    |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 190      |
| explained_variance | -0.772   |
| fps                | 395      |
| nupdates           | 8100     |
| policy_entropy     | 0.279    |
| total_timesteps    | 40500    |
| value_loss         | 129      |
---------------------------------
19.0
19.0
19.41
11.0
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 194      |
| explained_variance | 0.046    |
| fps                | 396      |
| nupdates           | 8200     |
| policy_entropy     | 0.675    |
| total_timesteps    | 41000    |
| value_loss         | 61       |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 194      |
| explained_variance | -3.65    |
| fps                | 396      |
| nupdates           | 8300     |
| policy_entropy     | 0.675    |
| total_timesteps    | 41500    |
| value_loss         | 1.63     |
---------------------------------
9.0
9.0
21.01
27.5
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 192      |
| explained_variance | -0.0106  |
| fps                | 396      |
| nupdates           | 8400     |
| policy_entropy     | 0.244    |
| total_timesteps    | 42000    |
| value_loss         | 212      |
---------------------------------
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 185      |
| explained_variance | -0.176   |
| fps                | 396      |
| nupdates           | 8500     |
| policy_entropy     | 0.137    |
| total_timesteps    | 42500    |
| value_loss         | 5.38e+04 |
---------------------------------
18.0
18.0
22.19
12.0
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 185      |
| explained_variance | -0.00753 |
| fps                | 396      |
| nupdates           | 8600     |
| policy_entropy     | 0.503    |
| total_timesteps    | 43000    |
| value_loss         | 33.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 23.5     |
| ep_reward_mean     | 179      |
| explained_variance | 0.787    |
| fps                | 396      |
| nupdates           | 8700     |
| policy_entropy     | 0.182    |
| total_timesteps    | 43500    |
| value_loss         | 92       |
---------------------------------
26.0
26.0
23.02
10.0
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 180      |
| explained_variance | -2.7     |
| fps                | 396      |
| nupdates           | 8800     |
| policy_entropy     | 0.562    |
| total_timesteps    | 44000    |
| value_loss         | 124      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.5     |
| ep_reward_mean     | 186      |
| explained_variance | -3.44    |
| fps                | 396      |
| nupdates           | 8900     |
| policy_entropy     | 0.125    |
| total_timesteps    | 44500    |
| value_loss         | 634      |
---------------------------------
101.0
101.0
21.78
10.0
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 187      |
| explained_variance | 0.071    |
| fps                | 396      |
| nupdates           | 9000     |
| policy_entropy     | 0.151    |
| total_timesteps    | 45000    |
| value_loss         | 512      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.5     |
| ep_reward_mean     | 183      |
| explained_variance | -0.0125  |
| fps                | 396      |
| nupdates           | 9100     |
| policy_entropy     | 0.684    |
| total_timesteps    | 45500    |
| value_loss         | 24.1     |
---------------------------------
17.0
17.0
25.28
36.0
---------------------------------
| ep_len_mean        | 25.3     |
| ep_reward_mean     | 176      |
| explained_variance | -1.65    |
| fps                | 396      |
| nupdates           | 9200     |
| policy_entropy     | 0.422    |
| total_timesteps    | 46000    |
| value_loss         | 5.59     |
---------------------------------
---------------------------------
| ep_len_mean        | 28.5     |
| ep_reward_mean     | 155      |
| explained_variance | 0.000402 |
| fps                | 396      |
| nupdates           | 9300     |
| policy_entropy     | 0.345    |
| total_timesteps    | 46500    |
| value_loss         | 9.9      |
---------------------------------
20.0
20.0
30.38
22.0
---------------------------------
| ep_len_mean        | 30.4     |
| ep_reward_mean     | 143      |
| explained_variance | 0.011    |
| fps                | 396      |
| nupdates           | 9400     |
| policy_entropy     | 1.01     |
| total_timesteps    | 47000    |
| value_loss         | 0.197    |
---------------------------------
---------------------------------
| ep_len_mean        | 31       |
| ep_reward_mean     | 140      |
| explained_variance | -0.436   |
| fps                | 397      |
| nupdates           | 9500     |
| policy_entropy     | 0.731    |
| total_timesteps    | 47500    |
| value_loss         | 0.249    |
---------------------------------
17.0
17.0
33.1
18.0
---------------------------------
| ep_len_mean        | 33.1     |
| ep_reward_mean     | 134      |
| explained_variance | -0.265   |
| fps                | 397      |
| nupdates           | 9600     |
| policy_entropy     | 0.142    |
| total_timesteps    | 48000    |
| value_loss         | 6.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 33.5     |
| ep_reward_mean     | 133      |
| explained_variance | -0.0477  |
| fps                | 397      |
| nupdates           | 9700     |
| policy_entropy     | 0.283    |
| total_timesteps    | 48500    |
| value_loss         | 2.99e+04 |
---------------------------------
47.0
47.0
31.37
33.0
---------------------------------
| ep_len_mean        | 31.4     |
| ep_reward_mean     | 137      |
| explained_variance | -0.177   |
| fps                | 397      |
| nupdates           | 9800     |
| policy_entropy     | 0.438    |
| total_timesteps    | 49000    |
| value_loss         | 40.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.5     |
| ep_reward_mean     | 174      |
| explained_variance | -0.631   |
| fps                | 397      |
| nupdates           | 9900     |
| policy_entropy     | 0.365    |
| total_timesteps    | 49500    |
| value_loss         | 45       |
---------------------------------
41.0
41.0
21.16
10.0
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 188      |
| explained_variance | 0.239    |
| fps                | 397      |
| nupdates           | 10000    |
| policy_entropy     | 0.0851   |
| total_timesteps    | 50000    |
| value_loss         | 252      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 191      |
| explained_variance | 0.148    |
| fps                | 397      |
| nupdates           | 10100    |
| policy_entropy     | 0.0735   |
| total_timesteps    | 50500    |
| value_loss         | 838      |
---------------------------------
11.0
11.0
18.12
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 199      |
| explained_variance | -0.0189  |
| fps                | 397      |
| nupdates           | 10200    |
| policy_entropy     | 0.377    |
| total_timesteps    | 51000    |
| value_loss         | 2.36e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 199      |
| explained_variance | 0.128    |
| fps                | 398      |
| nupdates           | 10300    |
| policy_entropy     | 0.0844   |
| total_timesteps    | 51500    |
| value_loss         | 1.11e+05 |
---------------------------------
36.0
36.0
18.67
10.0
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 197      |
| explained_variance | -0.842   |
| fps                | 397      |
| nupdates           | 10400    |
| policy_entropy     | 0.337    |
| total_timesteps    | 52000    |
| value_loss         | 160      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 199      |
| explained_variance | 0        |
| fps                | 397      |
| nupdates           | 10500    |
| policy_entropy     | 0.465    |
| total_timesteps    | 52500    |
| value_loss         | 12.1     |
---------------------------------
24.0
24.0
18.88
11.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 197      |
| explained_variance | -0.143   |
| fps                | 397      |
| nupdates           | 10600    |
| policy_entropy     | 0.138    |
| total_timesteps    | 53000    |
| value_loss         | 5.67e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 191      |
| explained_variance | -10.9    |
| fps                | 396      |
| nupdates           | 10700    |
| policy_entropy     | 0.245    |
| total_timesteps    | 53500    |
| value_loss         | 317      |
---------------------------------
34.0
34.0
21.19
18.0
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 187      |
| explained_variance | -0.537   |
| fps                | 396      |
| nupdates           | 10800    |
| policy_entropy     | 0.503    |
| total_timesteps    | 54000    |
| value_loss         | 10.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 185      |
| explained_variance | -0.935   |
| fps                | 396      |
| nupdates           | 10900    |
| policy_entropy     | 0.0762   |
| total_timesteps    | 54500    |
| value_loss         | 1.16e+03 |
---------------------------------
9.0
9.0
19.98
9.5
----------------------------------
| ep_len_mean        | 20        |
| ep_reward_mean     | 190       |
| explained_variance | -6.04e-05 |
| fps                | 396       |
| nupdates           | 11000     |
| policy_entropy     | 0.622     |
| total_timesteps    | 55000     |
| value_loss         | 2.04e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 198      |
| explained_variance | -5.26    |
| fps                | 396      |
| nupdates           | 11100    |
| policy_entropy     | 0.265    |
| total_timesteps    | 55500    |
| value_loss         | 1.02e+03 |
---------------------------------
9.0
9.0
17.62
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 199      |
| explained_variance | -7.85    |
| fps                | 396      |
| nupdates           | 11200    |
| policy_entropy     | 0.384    |
| total_timesteps    | 56000    |
| value_loss         | 87       |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 200      |
| explained_variance | 0.31     |
| fps                | 396      |
| nupdates           | 11300    |
| policy_entropy     | 0.122    |
| total_timesteps    | 56500    |
| value_loss         | 5.24e+04 |
---------------------------------
8.0
8.0
17.57
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 200      |
| explained_variance | 0        |
| fps                | 396      |
| nupdates           | 11400    |
| policy_entropy     | 0.317    |
| total_timesteps    | 57000    |
| value_loss         | 111      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 193      |
| explained_variance | -1.26    |
| fps                | 396      |
| nupdates           | 11500    |
| policy_entropy     | 0.269    |
| total_timesteps    | 57500    |
| value_loss         | 92.9     |
---------------------------------
10.0
10.0
21.82
27.0
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 189      |
| explained_variance | -8.13    |
| fps                | 395      |
| nupdates           | 11600    |
| policy_entropy     | 0.488    |
| total_timesteps    | 58000    |
| value_loss         | 11.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 21.6     |
| ep_reward_mean     | 191      |
| explained_variance | -0.109   |
| fps                | 396      |
| nupdates           | 11700    |
| policy_entropy     | 0.396    |
| total_timesteps    | 58500    |
| value_loss         | 4.8e+04  |
---------------------------------
38.0
38.0
23.75
27.5
---------------------------------
| ep_len_mean        | 23.8     |
| ep_reward_mean     | 185      |
| explained_variance | -0.0903  |
| fps                | 395      |
| nupdates           | 11800    |
| policy_entropy     | 0.0633   |
| total_timesteps    | 59000    |
| value_loss         | 2.47e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 23.3     |
| ep_reward_mean     | 189      |
| explained_variance | 0.499    |
| fps                | 395      |
| nupdates           | 11900    |
| policy_entropy     | 0.172    |
| total_timesteps    | 59500    |
| value_loss         | 80.5     |
---------------------------------
21.0
21.0
22.3
12.5
---------------------------------
| ep_len_mean        | 22.3     |
| ep_reward_mean     | 192      |
| explained_variance | -1.13    |
| fps                | 395      |
| nupdates           | 12000    |
| policy_entropy     | 0.611    |
| total_timesteps    | 60000    |
| value_loss         | 133      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 196      |
| explained_variance | -27      |
| fps                | 395      |
| nupdates           | 12100    |
| policy_entropy     | 0.202    |
| total_timesteps    | 60500    |
| value_loss         | 229      |
---------------------------------
51.0
51.0
18.9
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 201      |
| explained_variance | -0.0679  |
| fps                | 395      |
| nupdates           | 12200    |
| policy_entropy     | 0.0489   |
| total_timesteps    | 61000    |
| value_loss         | 2.3e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.672    |
| fps                | 395      |
| nupdates           | 12300    |
| policy_entropy     | 0.0602   |
| total_timesteps    | 61500    |
| value_loss         | 306      |
---------------------------------
9.0
9.0
17.91
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 205      |
| explained_variance | -0.523   |
| fps                | 395      |
| nupdates           | 12400    |
| policy_entropy     | 0.0268   |
| total_timesteps    | 62000    |
| value_loss         | 494      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 208      |
| explained_variance | -0.414   |
| fps                | 395      |
| nupdates           | 12500    |
| policy_entropy     | 0.0642   |
| total_timesteps    | 62500    |
| value_loss         | 361      |
---------------------------------
19.0
19.0
14.94
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 210      |
| explained_variance | -0.0588  |
| fps                | 395      |
| nupdates           | 12600    |
| policy_entropy     | 0.0897   |
| total_timesteps    | 63000    |
| value_loss         | 1.1e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 208      |
| explained_variance | 0.78     |
| fps                | 395      |
| nupdates           | 12700    |
| policy_entropy     | 0.322    |
| total_timesteps    | 63500    |
| value_loss         | 39.3     |
---------------------------------
52.0
52.0
16.29
11.5
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 203      |
| explained_variance | 0.499    |
| fps                | 394      |
| nupdates           | 12800    |
| policy_entropy     | 0.0531   |
| total_timesteps    | 64000    |
| value_loss         | 55       |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 198      |
| explained_variance | 0.469    |
| fps                | 394      |
| nupdates           | 12900    |
| policy_entropy     | 0.209    |
| total_timesteps    | 64500    |
| value_loss         | 99.3     |
---------------------------------
9.0
9.0
19.78
10.5
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 194      |
| explained_variance | 0.213    |
| fps                | 394      |
| nupdates           | 13000    |
| policy_entropy     | 0.0393   |
| total_timesteps    | 65000    |
| value_loss         | 852      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 196      |
| explained_variance | 0.0785   |
| fps                | 394      |
| nupdates           | 13100    |
| policy_entropy     | 0.0904   |
| total_timesteps    | 65500    |
| value_loss         | 1.22e+04 |
---------------------------------
28.0
28.0
18.49
10.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 201      |
| explained_variance | -3.52    |
| fps                | 394      |
| nupdates           | 13200    |
| policy_entropy     | 0.125    |
| total_timesteps    | 66000    |
| value_loss         | 166      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 201      |
| explained_variance | -1.43    |
| fps                | 394      |
| nupdates           | 13300    |
| policy_entropy     | 0.409    |
| total_timesteps    | 66500    |
| value_loss         | 7.5      |
---------------------------------
16.0
16.0
18.61
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -0.111   |
| fps                | 394      |
| nupdates           | 13400    |
| policy_entropy     | 0.0719   |
| total_timesteps    | 67000    |
| value_loss         | 3.24e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 199      |
| explained_variance | 0.79     |
| fps                | 394      |
| nupdates           | 13500    |
| policy_entropy     | 0.105    |
| total_timesteps    | 67500    |
| value_loss         | 40.4     |
---------------------------------
10.0
10.0
19.72
10.0
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 197      |
| explained_variance | -30.9    |
| fps                | 394      |
| nupdates           | 13600    |
| policy_entropy     | 0.0869   |
| total_timesteps    | 68000    |
| value_loss         | 72.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 197      |
| explained_variance | -20.9    |
| fps                | 394      |
| nupdates           | 13700    |
| policy_entropy     | 0.39     |
| total_timesteps    | 68500    |
| value_loss         | 166      |
---------------------------------
72.0
72.0
21.43
24.5
---------------------------------
| ep_len_mean        | 21.4     |
| ep_reward_mean     | 193      |
| explained_variance | -0.221   |
| fps                | 394      |
| nupdates           | 13800    |
| policy_entropy     | 0.0297   |
| total_timesteps    | 69000    |
| value_loss         | 262      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.6     |
| ep_reward_mean     | 188      |
| explained_variance | -1.21    |
| fps                | 394      |
| nupdates           | 13900    |
| policy_entropy     | 0.206    |
| total_timesteps    | 69500    |
| value_loss         | 411      |
---------------------------------
28.0
28.0
24.06
20.0
---------------------------------
| ep_len_mean        | 24.1     |
| ep_reward_mean     | 184      |
| explained_variance | 0.379    |
| fps                | 393      |
| nupdates           | 14000    |
| policy_entropy     | 0.311    |
| total_timesteps    | 70000    |
| value_loss         | 40.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 23.4     |
| ep_reward_mean     | 187      |
| explained_variance | -5.03    |
| fps                | 393      |
| nupdates           | 14100    |
| policy_entropy     | 0.34     |
| total_timesteps    | 70500    |
| value_loss         | 6.5      |
---------------------------------
9.0
9.0
22.35
10.0
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 189      |
| explained_variance | -2.78    |
| fps                | 393      |
| nupdates           | 14200    |
| policy_entropy     | 0.104    |
| total_timesteps    | 71000    |
| value_loss         | 7.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.3     |
| ep_reward_mean     | 195      |
| explained_variance | -9.87    |
| fps                | 393      |
| nupdates           | 14300    |
| policy_entropy     | 0.374    |
| total_timesteps    | 71500    |
| value_loss         | 257      |
---------------------------------
9.0
9.0
18.41
9.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 200      |
| explained_variance | 0        |
| fps                | 393      |
| nupdates           | 14400    |
| policy_entropy     | 0.567    |
| total_timesteps    | 72000    |
| value_loss         | 6.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 198      |
| explained_variance | -7.81    |
| fps                | 394      |
| nupdates           | 14500    |
| policy_entropy     | 0.081    |
| total_timesteps    | 72500    |
| value_loss         | 91.4     |
---------------------------------
25.0
25.0
20.27
27.5
---------------------------------
| ep_len_mean        | 20.3     |
| ep_reward_mean     | 193      |
| explained_variance | -0.0292  |
| fps                | 394      |
| nupdates           | 14600    |
| policy_entropy     | 0.195    |
| total_timesteps    | 73000    |
| value_loss         | 1.96e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 192      |
| explained_variance | 0.247    |
| fps                | 394      |
| nupdates           | 14700    |
| policy_entropy     | 0.14     |
| total_timesteps    | 73500    |
| value_loss         | 1.05e+04 |
---------------------------------
9.0
9.0
20.55
10.0
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 191      |
| explained_variance | -1.98    |
| fps                | 394      |
| nupdates           | 14800    |
| policy_entropy     | 0.122    |
| total_timesteps    | 74000    |
| value_loss         | 4.22e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 191      |
| explained_variance | -0.395   |
| fps                | 394      |
| nupdates           | 14900    |
| policy_entropy     | 0.218    |
| total_timesteps    | 74500    |
| value_loss         | 214      |
---------------------------------
9.0
9.0
18.24
11.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 197      |
| explained_variance | -3.26    |
| fps                | 394      |
| nupdates           | 15000    |
| policy_entropy     | 0.364    |
| total_timesteps    | 75000    |
| value_loss         | 185      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 198      |
| explained_variance | 0.0675   |
| fps                | 394      |
| nupdates           | 15100    |
| policy_entropy     | 0.175    |
| total_timesteps    | 75500    |
| value_loss         | 127      |
---------------------------------
9.0
9.0
18.18
10.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 198      |
| explained_variance | 0        |
| fps                | 394      |
| nupdates           | 15200    |
| policy_entropy     | 0.442    |
| total_timesteps    | 76000    |
| value_loss         | 80.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 203      |
| explained_variance | 0.0301   |
| fps                | 394      |
| nupdates           | 15300    |
| policy_entropy     | 0.385    |
| total_timesteps    | 76500    |
| value_loss         | 152      |
---------------------------------
28.0
28.0
17.88
10.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 200      |
| explained_variance | 0.172    |
| fps                | 395      |
| nupdates           | 15400    |
| policy_entropy     | 0.459    |
| total_timesteps    | 77000    |
| value_loss         | 6.13e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 199      |
| explained_variance | 0.7      |
| fps                | 395      |
| nupdates           | 15500    |
| policy_entropy     | 0.227    |
| total_timesteps    | 77500    |
| value_loss         | 55.2     |
---------------------------------
10.0
10.0
20.17
16.0
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 195      |
| explained_variance | -0.0994  |
| fps                | 395      |
| nupdates           | 15600    |
| policy_entropy     | 0.142    |
| total_timesteps    | 78000    |
| value_loss         | 1.72e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 197      |
| explained_variance | 0.448    |
| fps                | 395      |
| nupdates           | 15700    |
| policy_entropy     | 0.145    |
| total_timesteps    | 78500    |
| value_loss         | 457      |
---------------------------------
47.0
47.0
20.34
18.0
---------------------------------
| ep_len_mean        | 20.3     |
| ep_reward_mean     | 197      |
| explained_variance | 0.408    |
| fps                | 395      |
| nupdates           | 15800    |
| policy_entropy     | 0.493    |
| total_timesteps    | 79000    |
| value_loss         | 93.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 197      |
| explained_variance | -3.01    |
| fps                | 394      |
| nupdates           | 15900    |
| policy_entropy     | 0.185    |
| total_timesteps    | 79500    |
| value_loss         | 559      |
---------------------------------
10.0
10.0
19.47
11.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 197      |
| explained_variance | 0.329    |
| fps                | 394      |
| nupdates           | 16000    |
| policy_entropy     | 0.0369   |
| total_timesteps    | 80000    |
| value_loss         | 590      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 200      |
| explained_variance | -1.97    |
| fps                | 394      |
| nupdates           | 16100    |
| policy_entropy     | 0.431    |
| total_timesteps    | 80500    |
| value_loss         | 168      |
---------------------------------
13.0
13.0
19.69
25.5
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 198      |
| explained_variance | -0.259   |
| fps                | 393      |
| nupdates           | 16200    |
| policy_entropy     | 0.205    |
| total_timesteps    | 81000    |
| value_loss         | 237      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 201      |
| explained_variance | -1.01    |
| fps                | 393      |
| nupdates           | 16300    |
| policy_entropy     | 0.03     |
| total_timesteps    | 81500    |
| value_loss         | 245      |
---------------------------------
9.0
9.0
18.27
10.0
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 202      |
| explained_variance | -0.323   |
| fps                | 393      |
| nupdates           | 16400    |
| policy_entropy     | 0.104    |
| total_timesteps    | 82000    |
| value_loss         | 7.22e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 203      |
| explained_variance | 0        |
| fps                | 393      |
| nupdates           | 16500    |
| policy_entropy     | 0.538    |
| total_timesteps    | 82500    |
| value_loss         | 98.3     |
---------------------------------
26.0
26.0
16.4
15.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.756    |
| fps                | 393      |
| nupdates           | 16600    |
| policy_entropy     | 0.0696   |
| total_timesteps    | 83000    |
| value_loss         | 80.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 203      |
| explained_variance | 0        |
| fps                | 393      |
| nupdates           | 16700    |
| policy_entropy     | 0.264    |
| total_timesteps    | 83500    |
| value_loss         | 89.4     |
---------------------------------
47.0
47.0
19.02
25.5
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 200      |
| explained_variance | -0.992   |
| fps                | 393      |
| nupdates           | 16800    |
| policy_entropy     | 0.0749   |
| total_timesteps    | 84000    |
| value_loss         | 452      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | 0.167    |
| fps                | 393      |
| nupdates           | 16900    |
| policy_entropy     | 0.043    |
| total_timesteps    | 84500    |
| value_loss         | 114      |
---------------------------------
33.0
33.0
18.31
10.5
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 204      |
| explained_variance | -0.93    |
| fps                | 393      |
| nupdates           | 17000    |
| policy_entropy     | 0.175    |
| total_timesteps    | 85000    |
| value_loss         | 5.51e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 205      |
| explained_variance | 0.853    |
| fps                | 393      |
| nupdates           | 17100    |
| policy_entropy     | 0.448    |
| total_timesteps    | 85500    |
| value_loss         | 10       |
---------------------------------
33.0
33.0
16.96
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 206      |
| explained_variance | 0.152    |
| fps                | 393      |
| nupdates           | 17200    |
| policy_entropy     | 0.337    |
| total_timesteps    | 86000    |
| value_loss         | 297      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -0.322   |
| fps                | 393      |
| nupdates           | 17300    |
| policy_entropy     | 0.0895   |
| total_timesteps    | 86500    |
| value_loss         | 1.4e+03  |
---------------------------------
13.0
13.0
19.9
12.5
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 198      |
| explained_variance | -0.32    |
| fps                | 393      |
| nupdates           | 17400    |
| policy_entropy     | 0.229    |
| total_timesteps    | 87000    |
| value_loss         | 500      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 199      |
| explained_variance | -0.199   |
| fps                | 393      |
| nupdates           | 17500    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 87500    |
| value_loss         | 7.54e+03 |
---------------------------------
27.0
27.0
19.57
10.0
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 199      |
| explained_variance | -3.27    |
| fps                | 393      |
| nupdates           | 17600    |
| policy_entropy     | 0.144    |
| total_timesteps    | 88000    |
| value_loss         | 445      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 201      |
| explained_variance | -3.56    |
| fps                | 393      |
| nupdates           | 17700    |
| policy_entropy     | 0.254    |
| total_timesteps    | 88500    |
| value_loss         | 293      |
---------------------------------
42.0
42.0
17.21
10.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 393      |
| nupdates           | 17800    |
| policy_entropy     | 0.344    |
| total_timesteps    | 89000    |
| value_loss         | 293      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 209      |
| explained_variance | -1.01    |
| fps                | 394      |
| nupdates           | 17900    |
| policy_entropy     | 0.182    |
| total_timesteps    | 89500    |
| value_loss         | 53.9     |
---------------------------------
9.0
9.0
17.48
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | 0.383    |
| fps                | 394      |
| nupdates           | 18000    |
| policy_entropy     | 0.293    |
| total_timesteps    | 90000    |
| value_loss         | 1.71e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 207      |
| explained_variance | 0.208    |
| fps                | 394      |
| nupdates           | 18100    |
| policy_entropy     | 0.0728   |
| total_timesteps    | 90500    |
| value_loss         | 2.85e+03 |
---------------------------------
42.0
42.0
17.47
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | 0.662    |
| fps                | 394      |
| nupdates           | 18200    |
| policy_entropy     | 0.028    |
| total_timesteps    | 91000    |
| value_loss         | 490      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | -0.198   |
| fps                | 394      |
| nupdates           | 18300    |
| policy_entropy     | 0.0308   |
| total_timesteps    | 91500    |
| value_loss         | 811      |
---------------------------------
35.0
35.0
16.28
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.296    |
| fps                | 394      |
| nupdates           | 18400    |
| policy_entropy     | 0.451    |
| total_timesteps    | 92000    |
| value_loss         | 27.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 207      |
| explained_variance | 0.436    |
| fps                | 394      |
| nupdates           | 18500    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 92500    |
| value_loss         | 292      |
---------------------------------
10.0
10.0
17.49
17.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 202      |
| explained_variance | -0.0314  |
| fps                | 394      |
| nupdates           | 18600    |
| policy_entropy     | 0.0207   |
| total_timesteps    | 93000    |
| value_loss         | 442      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 200      |
| explained_variance | -2.38    |
| fps                | 394      |
| nupdates           | 18700    |
| policy_entropy     | 0.0928   |
| total_timesteps    | 93500    |
| value_loss         | 749      |
---------------------------------
30.0
30.0
17.63
9.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 201      |
| explained_variance | 0.281    |
| fps                | 394      |
| nupdates           | 18800    |
| policy_entropy     | 0.222    |
| total_timesteps    | 94000    |
| value_loss         | 117      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 199      |
| explained_variance | -0.854   |
| fps                | 394      |
| nupdates           | 18900    |
| policy_entropy     | 0.135    |
| total_timesteps    | 94500    |
| value_loss         | 263      |
---------------------------------
11.0
11.0
18.38
13.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 198      |
| explained_variance | -0.0774  |
| fps                | 394      |
| nupdates           | 19000    |
| policy_entropy     | 0.231    |
| total_timesteps    | 95000    |
| value_loss         | 305      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 199      |
| explained_variance | -0.269   |
| fps                | 394      |
| nupdates           | 19100    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 95500    |
| value_loss         | 1.12e+04 |
---------------------------------
11.0
11.0
19.42
10.0
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 197      |
| explained_variance | 0.253    |
| fps                | 394      |
| nupdates           | 19200    |
| policy_entropy     | 0.00944  |
| total_timesteps    | 96000    |
| value_loss         | 339      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 197      |
| explained_variance | -10.5    |
| fps                | 394      |
| nupdates           | 19300    |
| policy_entropy     | 0.418    |
| total_timesteps    | 96500    |
| value_loss         | 353      |
---------------------------------
26.0
26.0
16.6
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0        |
| fps                | 394      |
| nupdates           | 19400    |
| policy_entropy     | 0.675    |
| total_timesteps    | 97000    |
| value_loss         | 66.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 208      |
| explained_variance | -1.06    |
| fps                | 394      |
| nupdates           | 19500    |
| policy_entropy     | 0.484    |
| total_timesteps    | 97500    |
| value_loss         | 657      |
---------------------------------
11.0
11.0
16.35
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0        |
| fps                | 394      |
| nupdates           | 19600    |
| policy_entropy     | 0.675    |
| total_timesteps    | 98000    |
| value_loss         | 129      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 206      |
| explained_variance | -2.69    |
| fps                | 395      |
| nupdates           | 19700    |
| policy_entropy     | 0.144    |
| total_timesteps    | 98500    |
| value_loss         | 664      |
---------------------------------
10.0
10.0
16.58
18.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | 0.541    |
| fps                | 394      |
| nupdates           | 19800    |
| policy_entropy     | 0.0247   |
| total_timesteps    | 99000    |
| value_loss         | 122      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | -0.216   |
| fps                | 395      |
| nupdates           | 19900    |
| policy_entropy     | 0.0306   |
| total_timesteps    | 99500    |
| value_loss         | 217      |
---------------------------------
21.0
21.0
16.62
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | -7.13    |
| fps                | 395      |
| nupdates           | 20000    |
| policy_entropy     | 0.494    |
| total_timesteps    | 100000   |
| value_loss         | 474      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 205      |
| explained_variance | 0.713    |
| fps                | 395      |
| nupdates           | 20100    |
| policy_entropy     | 0.257    |
| total_timesteps    | 100500   |
| value_loss         | 230      |
---------------------------------
13.0
13.0
17.5
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 205      |
| explained_variance | 0.0183   |
| fps                | 395      |
| nupdates           | 20200    |
| policy_entropy     | 0.151    |
| total_timesteps    | 101000   |
| value_loss         | 187      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 203      |
| explained_variance | -0.472   |
| fps                | 395      |
| nupdates           | 20300    |
| policy_entropy     | 0.149    |
| total_timesteps    | 101500   |
| value_loss         | 268      |
---------------------------------
10.0
10.0
16.5
10.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 204      |
| explained_variance | 0.267    |
| fps                | 395      |
| nupdates           | 20400    |
| policy_entropy     | 0.00683  |
| total_timesteps    | 102000   |
| value_loss         | 398      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 203      |
| explained_variance | 0.621    |
| fps                | 395      |
| nupdates           | 20500    |
| policy_entropy     | 0.051    |
| total_timesteps    | 102500   |
| value_loss         | 83.7     |
---------------------------------
30.0
30.0
16.09
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 206      |
| explained_variance | -0.0566  |
| fps                | 394      |
| nupdates           | 20600    |
| policy_entropy     | 0.13     |
| total_timesteps    | 103000   |
| value_loss         | 74       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 208      |
| explained_variance | -0.164   |
| fps                | 394      |
| nupdates           | 20700    |
| policy_entropy     | 0.00705  |
| total_timesteps    | 103500   |
| value_loss         | 278      |
---------------------------------
9.0
9.0
15.33
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.706    |
| fps                | 394      |
| nupdates           | 20800    |
| policy_entropy     | 0.156    |
| total_timesteps    | 104000   |
| value_loss         | 55.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 210      |
| explained_variance | -4.86    |
| fps                | 393      |
| nupdates           | 20900    |
| policy_entropy     | 0.333    |
| total_timesteps    | 104500   |
| value_loss         | 504      |
---------------------------------
9.0
9.0
15.37
11.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.168    |
| fps                | 393      |
| nupdates           | 21000    |
| policy_entropy     | 0.00941  |
| total_timesteps    | 105000   |
| value_loss         | 318      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 206      |
| explained_variance | -5.11    |
| fps                | 393      |
| nupdates           | 21100    |
| policy_entropy     | 0.193    |
| total_timesteps    | 105500   |
| value_loss         | 264      |
---------------------------------
9.0
9.0
15.17
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0463   |
| fps                | 393      |
| nupdates           | 21200    |
| policy_entropy     | 0.0071   |
| total_timesteps    | 106000   |
| value_loss         | 166      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 205      |
| explained_variance | 0.777    |
| fps                | 393      |
| nupdates           | 21300    |
| policy_entropy     | 0.0513   |
| total_timesteps    | 106500   |
| value_loss         | 41.6     |
---------------------------------
11.0
11.0
15.48
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 207      |
| explained_variance | 0.217    |
| fps                | 393      |
| nupdates           | 21400    |
| policy_entropy     | 0.0156   |
| total_timesteps    | 107000   |
| value_loss         | 3.62e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 208      |
| explained_variance | -1.6     |
| fps                | 393      |
| nupdates           | 21500    |
| policy_entropy     | 0.406    |
| total_timesteps    | 107500   |
| value_loss         | 309      |
---------------------------------
11.0
11.0
14.85
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.247    |
| fps                | 393      |
| nupdates           | 21600    |
| policy_entropy     | 0.154    |
| total_timesteps    | 108000   |
| value_loss         | 139      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.282    |
| fps                | 393      |
| nupdates           | 21700    |
| policy_entropy     | 0.199    |
| total_timesteps    | 108500   |
| value_loss         | 143      |
---------------------------------
10.0
10.0
15.1
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 211      |
| explained_variance | -1.49    |
| fps                | 393      |
| nupdates           | 21800    |
| policy_entropy     | 0.0468   |
| total_timesteps    | 109000   |
| value_loss         | 92.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 210      |
| explained_variance | -1.15    |
| fps                | 393      |
| nupdates           | 21900    |
| policy_entropy     | 0.128    |
| total_timesteps    | 109500   |
| value_loss         | 335      |
---------------------------------
11.0
11.0
13.85
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.567    |
| fps                | 393      |
| nupdates           | 22000    |
| policy_entropy     | 0.0244   |
| total_timesteps    | 110000   |
| value_loss         | 47.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 214      |
| explained_variance | 0.574    |
| fps                | 393      |
| nupdates           | 22100    |
| policy_entropy     | 0.02     |
| total_timesteps    | 110500   |
| value_loss         | 120      |
---------------------------------
22.0
22.0
14.48
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.226    |
| fps                | 393      |
| nupdates           | 22200    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 111000   |
| value_loss         | 293      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 211      |
| explained_variance | -6.1     |
| fps                | 393      |
| nupdates           | 22300    |
| policy_entropy     | 0.0509   |
| total_timesteps    | 111500   |
| value_loss         | 234      |
---------------------------------
11.0
11.0
14.94
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 209      |
| explained_variance | -2.07    |
| fps                | 393      |
| nupdates           | 22400    |
| policy_entropy     | 0.147    |
| total_timesteps    | 112000   |
| value_loss         | 84.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 208      |
| explained_variance | 0.0142   |
| fps                | 393      |
| nupdates           | 22500    |
| policy_entropy     | 0.238    |
| total_timesteps    | 112500   |
| value_loss         | 363      |
---------------------------------
9.0
9.0
15.07
13.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 209      |
| explained_variance | -7.78    |
| fps                | 393      |
| nupdates           | 22600    |
| policy_entropy     | 0.326    |
| total_timesteps    | 113000   |
| value_loss         | 1.11e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 210      |
| explained_variance | 0.155    |
| fps                | 393      |
| nupdates           | 22700    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 113500   |
| value_loss         | 308      |
---------------------------------
11.0
11.0
14.45
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.92     |
| fps                | 393      |
| nupdates           | 22800    |
| policy_entropy     | 0.0481   |
| total_timesteps    | 114000   |
| value_loss         | 4.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | -0.0561  |
| fps                | 393      |
| nupdates           | 22900    |
| policy_entropy     | 0.00919  |
| total_timesteps    | 114500   |
| value_loss         | 273      |
---------------------------------
10.0
10.0
15.71
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.78     |
| fps                | 392      |
| nupdates           | 23000    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 115000   |
| value_loss         | 87.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.765    |
| fps                | 392      |
| nupdates           | 23100    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 115500   |
| value_loss         | 71.3     |
---------------------------------
13.0
13.0
16.98
11.5
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 213      |
| explained_variance | -4.69    |
| fps                | 392      |
| nupdates           | 23200    |
| policy_entropy     | 0.261    |
| total_timesteps    | 116000   |
| value_loss         | 195      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.48     |
| fps                | 392      |
| nupdates           | 23300    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 116500   |
| value_loss         | 325      |
---------------------------------
18.0
18.0
18.35
14.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 209      |
| explained_variance | -0.773   |
| fps                | 392      |
| nupdates           | 23400    |
| policy_entropy     | 0.02     |
| total_timesteps    | 117000   |
| value_loss         | 1.67e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 207      |
| explained_variance | -0.236   |
| fps                | 392      |
| nupdates           | 23500    |
| policy_entropy     | 0.0399   |
| total_timesteps    | 117500   |
| value_loss         | 1.74e+03 |
---------------------------------
10.0
10.0
17.78
14.5
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.57     |
| fps                | 393      |
| nupdates           | 23600    |
| policy_entropy     | 0.0222   |
| total_timesteps    | 118000   |
| value_loss         | 90.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0863   |
| fps                | 393      |
| nupdates           | 23700    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 118500   |
| value_loss         | 67.3     |
---------------------------------
9.0
9.0
15.7
20.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.524    |
| fps                | 393      |
| nupdates           | 23800    |
| policy_entropy     | 0.216    |
| total_timesteps    | 119000   |
| value_loss         | 271      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.926    |
| fps                | 393      |
| nupdates           | 23900    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 119500   |
| value_loss         | 15.8     |
---------------------------------
10.0
10.0
15.58
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.342    |
| fps                | 393      |
| nupdates           | 24000    |
| policy_entropy     | 0.00933  |
| total_timesteps    | 120000   |
| value_loss         | 55.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | -0.928   |
| fps                | 393      |
| nupdates           | 24100    |
| policy_entropy     | 0.24     |
| total_timesteps    | 120500   |
| value_loss         | 278      |
---------------------------------
10.0
10.0
15.04
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | -0.638   |
| fps                | 392      |
| nupdates           | 24200    |
| policy_entropy     | 0.0205   |
| total_timesteps    | 121000   |
| value_loss         | 96       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.807    |
| fps                | 391      |
| nupdates           | 24300    |
| policy_entropy     | 0.42     |
| total_timesteps    | 121500   |
| value_loss         | 18.5     |
---------------------------------
11.0
11.0
15.53
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 209      |
| explained_variance | -0.664   |
| fps                | 391      |
| nupdates           | 24400    |
| policy_entropy     | 0.166    |
| total_timesteps    | 122000   |
| value_loss         | 97.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.821    |
| fps                | 391      |
| nupdates           | 24500    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 122500   |
| value_loss         | 14.1     |
---------------------------------
20.0
20.0
15.14
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.358    |
| fps                | 391      |
| nupdates           | 24600    |
| policy_entropy     | 0.0216   |
| total_timesteps    | 123000   |
| value_loss         | 226      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.605    |
| fps                | 391      |
| nupdates           | 24700    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 123500   |
| value_loss         | 55.1     |
---------------------------------
10.0
10.0
15.41
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | -7.1     |
| fps                | 391      |
| nupdates           | 24800    |
| policy_entropy     | 0.672    |
| total_timesteps    | 124000   |
| value_loss         | 466      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.168    |
| fps                | 391      |
| nupdates           | 24900    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 124500   |
| value_loss         | 118      |
---------------------------------
16.0
16.0
15.94
13.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0        |
| fps                | 391      |
| nupdates           | 25000    |
| policy_entropy     | 0.478    |
| total_timesteps    | 125000   |
| value_loss         | 116      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 216      |
| explained_variance | -0.465   |
| fps                | 391      |
| nupdates           | 25100    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 125500   |
| value_loss         | 186      |
---------------------------------
10.0
10.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.291    |
| fps                | 391      |
| nupdates           | 25200    |
| policy_entropy     | 0.014    |
| total_timesteps    | 126000   |
| value_loss         | 88.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.346   |
| fps                | 391      |
| nupdates           | 25300    |
| policy_entropy     | 0.227    |
| total_timesteps    | 126500   |
| value_loss         | 67.8     |
---------------------------------
23.0
23.0
15.13
17.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | -0.00199 |
| fps                | 391      |
| nupdates           | 25400    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 127000   |
| value_loss         | 137      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 217      |
| explained_variance | -1.06    |
| fps                | 391      |
| nupdates           | 25500    |
| policy_entropy     | 0.17     |
| total_timesteps    | 127500   |
| value_loss         | 352      |
---------------------------------
21.0
21.0
15.57
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.373    |
| fps                | 391      |
| nupdates           | 25600    |
| policy_entropy     | 0.0388   |
| total_timesteps    | 128000   |
| value_loss         | 135      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.735    |
| fps                | 390      |
| nupdates           | 25700    |
| policy_entropy     | 0.0935   |
| total_timesteps    | 128500   |
| value_loss         | 26.5     |
---------------------------------
10.0
10.0
15.15
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.923    |
| fps                | 390      |
| nupdates           | 25800    |
| policy_entropy     | 0.0467   |
| total_timesteps    | 129000   |
| value_loss         | 24.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.63     |
| fps                | 390      |
| nupdates           | 25900    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 129500   |
| value_loss         | 86.9     |
---------------------------------
11.0
11.0
14.73
20.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.503    |
| fps                | 390      |
| nupdates           | 26000    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 130000   |
| value_loss         | 54.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | -0.386   |
| fps                | 390      |
| nupdates           | 26100    |
| policy_entropy     | 0.16     |
| total_timesteps    | 130500   |
| value_loss         | 232      |
---------------------------------
10.0
10.0
15.51
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.58     |
| fps                | 390      |
| nupdates           | 26200    |
| policy_entropy     | 0.0519   |
| total_timesteps    | 131000   |
| value_loss         | 13.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.96     |
| fps                | 390      |
| nupdates           | 26300    |
| policy_entropy     | 0.144    |
| total_timesteps    | 131500   |
| value_loss         | 21.5     |
---------------------------------
22.0
22.0
14.7
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | -0.0709  |
| fps                | 390      |
| nupdates           | 26400    |
| policy_entropy     | 0.0229   |
| total_timesteps    | 132000   |
| value_loss         | 142      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | -1.32    |
| fps                | 391      |
| nupdates           | 26500    |
| policy_entropy     | 0.0774   |
| total_timesteps    | 132500   |
| value_loss         | 261      |
---------------------------------
21.0
21.0
14.91
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.0877   |
| fps                | 391      |
| nupdates           | 26600    |
| policy_entropy     | 0.156    |
| total_timesteps    | 133000   |
| value_loss         | 41.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.671    |
| fps                | 391      |
| nupdates           | 26700    |
| policy_entropy     | 0.0192   |
| total_timesteps    | 133500   |
| value_loss         | 8.5      |
---------------------------------
9.0
9.0
14.86
15.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.871    |
| fps                | 391      |
| nupdates           | 26800    |
| policy_entropy     | 0.00458  |
| total_timesteps    | 134000   |
| value_loss         | 23       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.777    |
| fps                | 391      |
| nupdates           | 26900    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 134500   |
| value_loss         | 22.2     |
---------------------------------
9.0
9.0
14.04
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 215      |
| explained_variance | 0.125    |
| fps                | 391      |
| nupdates           | 27000    |
| policy_entropy     | 0.053    |
| total_timesteps    | 135000   |
| value_loss         | 29.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 214      |
| explained_variance | -0.436   |
| fps                | 391      |
| nupdates           | 27100    |
| policy_entropy     | 0.173    |
| total_timesteps    | 135500   |
| value_loss         | 375      |
---------------------------------
10.0
10.0
14.0
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 214      |
| explained_variance | -0.158   |
| fps                | 390      |
| nupdates           | 27200    |
| policy_entropy     | 0.0044   |
| total_timesteps    | 136000   |
| value_loss         | 224      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0        |
| fps                | 390      |
| nupdates           | 27300    |
| policy_entropy     | 0.0694   |
| total_timesteps    | 136500   |
| value_loss         | 126      |
---------------------------------
20.0
20.0
17.39
10.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 205      |
| explained_variance | -0.496   |
| fps                | 390      |
| nupdates           | 27400    |
| policy_entropy     | 0.0168   |
| total_timesteps    | 137000   |
| value_loss         | 2.03e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 207      |
| explained_variance | -1.07    |
| fps                | 390      |
| nupdates           | 27500    |
| policy_entropy     | 0.0856   |
| total_timesteps    | 137500   |
| value_loss         | 163      |
---------------------------------
22.0
22.0
13.72
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.676   |
| fps                | 390      |
| nupdates           | 27600    |
| policy_entropy     | 0.231    |
| total_timesteps    | 138000   |
| value_loss         | 317      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 219      |
| explained_variance | -1.51    |
| fps                | 390      |
| nupdates           | 27700    |
| policy_entropy     | 0.0518   |
| total_timesteps    | 138500   |
| value_loss         | 326      |
---------------------------------
10.0
10.0
13.98
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.75     |
| fps                | 390      |
| nupdates           | 27800    |
| policy_entropy     | 0.117    |
| total_timesteps    | 139000   |
| value_loss         | 9.81     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | -44.6    |
| fps                | 390      |
| nupdates           | 27900    |
| policy_entropy     | 0.0299   |
| total_timesteps    | 139500   |
| value_loss         | 1.23e+04 |
---------------------------------
9.0
9.0
15.68
10.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.707    |
| fps                | 390      |
| nupdates           | 28000    |
| policy_entropy     | 0.00307  |
| total_timesteps    | 140000   |
| value_loss         | 139      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 211      |
| explained_variance | -0.207   |
| fps                | 390      |
| nupdates           | 28100    |
| policy_entropy     | 0.434    |
| total_timesteps    | 140500   |
| value_loss         | 154      |
---------------------------------
21.0
21.0
13.7
15.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.573    |
| fps                | 390      |
| nupdates           | 28200    |
| policy_entropy     | 0.187    |
| total_timesteps    | 141000   |
| value_loss         | 19.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 216      |
| explained_variance | -0.86    |
| fps                | 390      |
| nupdates           | 28300    |
| policy_entropy     | 0.0453   |
| total_timesteps    | 141500   |
| value_loss         | 140      |
---------------------------------
10.0
10.0
13.84
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.814    |
| fps                | 390      |
| nupdates           | 28400    |
| policy_entropy     | 0.0874   |
| total_timesteps    | 142000   |
| value_loss         | 13.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.449    |
| fps                | 390      |
| nupdates           | 28500    |
| policy_entropy     | 0.0303   |
| total_timesteps    | 142500   |
| value_loss         | 42.2     |
---------------------------------
10.0
10.0
13.38
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | -1.49    |
| fps                | 390      |
| nupdates           | 28600    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 143000   |
| value_loss         | 157      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | -0.973   |
| fps                | 390      |
| nupdates           | 28700    |
| policy_entropy     | 0.0509   |
| total_timesteps    | 143500   |
| value_loss         | 39.4     |
---------------------------------
9.0
9.0
15.27
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.724    |
| fps                | 390      |
| nupdates           | 28800    |
| policy_entropy     | 0.106    |
| total_timesteps    | 144000   |
| value_loss         | 79.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | -1.3     |
| fps                | 390      |
| nupdates           | 28900    |
| policy_entropy     | 0.0518   |
| total_timesteps    | 144500   |
| value_loss         | 174      |
---------------------------------
10.0
10.0
16.69
10.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.979    |
| fps                | 390      |
| nupdates           | 29000    |
| policy_entropy     | 0.0176   |
| total_timesteps    | 145000   |
| value_loss         | 3.09     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.607    |
| fps                | 390      |
| nupdates           | 29100    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 145500   |
| value_loss         | 66       |
---------------------------------
11.0
11.0
13.88
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.872    |
| fps                | 390      |
| nupdates           | 29200    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 146000   |
| value_loss         | 29       |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | -0.0942  |
| fps                | 390      |
| nupdates           | 29300    |
| policy_entropy     | 0.0608   |
| total_timesteps    | 146500   |
| value_loss         | 56.9     |
---------------------------------
20.0
20.0
13.97
20.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.932    |
| fps                | 390      |
| nupdates           | 29400    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 147000   |
| value_loss         | 28.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | -1.24    |
| fps                | 390      |
| nupdates           | 29500    |
| policy_entropy     | 0.0759   |
| total_timesteps    | 147500   |
| value_loss         | 381      |
---------------------------------
25.0
25.0
14.59
11.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.78     |
| fps                | 390      |
| nupdates           | 29600    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 148000   |
| value_loss         | 11.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 210      |
| explained_variance | -114     |
| fps                | 390      |
| nupdates           | 29700    |
| policy_entropy     | 0.078    |
| total_timesteps    | 148500   |
| value_loss         | 2.79e+03 |
---------------------------------
9.0
9.0
17.24
20.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 209      |
| explained_variance | -1.31    |
| fps                | 390      |
| nupdates           | 29800    |
| policy_entropy     | 0.075    |
| total_timesteps    | 149000   |
| value_loss         | 241      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.645    |
| fps                | 390      |
| nupdates           | 29900    |
| policy_entropy     | 0.155    |
| total_timesteps    | 149500   |
| value_loss         | 20.6     |
---------------------------------
20.0
20.0
14.23
14.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.821    |
| fps                | 390      |
| nupdates           | 30000    |
| policy_entropy     | 0.224    |
| total_timesteps    | 150000   |
| value_loss         | 106      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.936    |
| fps                | 390      |
| nupdates           | 30100    |
| policy_entropy     | 0.162    |
| total_timesteps    | 150500   |
| value_loss         | 8.13     |
---------------------------------
21.0
21.0
13.42
15.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 220      |
| explained_variance | -0.414   |
| fps                | 390      |
| nupdates           | 30200    |
| policy_entropy     | 0.109    |
| total_timesteps    | 151000   |
| value_loss         | 214      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | -1.93    |
| fps                | 390      |
| nupdates           | 30300    |
| policy_entropy     | 0.114    |
| total_timesteps    | 151500   |
| value_loss         | 283      |
---------------------------------
20.0
20.0
13.36
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.945    |
| fps                | 390      |
| nupdates           | 30400    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 152000   |
| value_loss         | 6.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.791   |
| fps                | 390      |
| nupdates           | 30500    |
| policy_entropy     | 0.0551   |
| total_timesteps    | 152500   |
| value_loss         | 517      |
---------------------------------
9.0
9.0
12.9
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.837    |
| fps                | 390      |
| nupdates           | 30600    |
| policy_entropy     | 0.00973  |
| total_timesteps    | 153000   |
| value_loss         | 6.29     |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 219      |
| explained_variance | 0.525    |
| fps                | 390      |
| nupdates           | 30700    |
| policy_entropy     | 0.0753   |
| total_timesteps    | 153500   |
| value_loss         | 416      |
---------------------------------
19.0
19.0
13.21
11.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.716    |
| fps                | 390      |
| nupdates           | 30800    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 154000   |
| value_loss         | 13.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.879    |
| fps                | 390      |
| nupdates           | 30900    |
| policy_entropy     | 0.102    |
| total_timesteps    | 154500   |
| value_loss         | 17.5     |
---------------------------------
20.0
20.0
15.1
20.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 216      |
| explained_variance | -0.876   |
| fps                | 390      |
| nupdates           | 31000    |
| policy_entropy     | 0.093    |
| total_timesteps    | 155000   |
| value_loss         | 89.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.951    |
| fps                | 390      |
| nupdates           | 31100    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 155500   |
| value_loss         | 15.7     |
---------------------------------
19.0
19.0
14.59
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.838    |
| fps                | 390      |
| nupdates           | 31200    |
| policy_entropy     | 0.00564  |
| total_timesteps    | 156000   |
| value_loss         | 74.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.958    |
| fps                | 390      |
| nupdates           | 31300    |
| policy_entropy     | 0.00402  |
| total_timesteps    | 156500   |
| value_loss         | 7.74     |
---------------------------------
10.0
10.0
14.04
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | 0.935    |
| fps                | 390      |
| nupdates           | 31400    |
| policy_entropy     | 0.184    |
| total_timesteps    | 157000   |
| value_loss         | 12.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.934    |
| fps                | 390      |
| nupdates           | 31500    |
| policy_entropy     | 0.0825   |
| total_timesteps    | 157500   |
| value_loss         | 5.92     |
---------------------------------
10.0
10.0
15.03
15.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.408    |
| fps                | 389      |
| nupdates           | 31600    |
| policy_entropy     | 0.157    |
| total_timesteps    | 158000   |
| value_loss         | 30.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.826    |
| fps                | 389      |
| nupdates           | 31700    |
| policy_entropy     | 0.0106   |
| total_timesteps    | 158500   |
| value_loss         | 42.5     |
---------------------------------
21.0
21.0
14.87
18.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 222      |
| explained_variance | -2.38    |
| fps                | 389      |
| nupdates           | 31800    |
| policy_entropy     | 0.0413   |
| total_timesteps    | 159000   |
| value_loss         | 661      |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | -0.608   |
| fps                | 389      |
| nupdates           | 31900    |
| policy_entropy     | 0.145    |
| total_timesteps    | 159500   |
| value_loss         | 189      |
---------------------------------
11.0
11.0
13.97
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | -0.245   |
| fps                | 389      |
| nupdates           | 32000    |
| policy_entropy     | 0.0858   |
| total_timesteps    | 160000   |
| value_loss         | 175      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.872    |
| fps                | 389      |
| nupdates           | 32100    |
| policy_entropy     | 0.00745  |
| total_timesteps    | 160500   |
| value_loss         | 350      |
---------------------------------
11.0
11.0
14.2
11.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.914    |
| fps                | 389      |
| nupdates           | 32200    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 161000   |
| value_loss         | 7.06     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.625   |
| fps                | 389      |
| nupdates           | 32300    |
| policy_entropy     | 0.0042   |
| total_timesteps    | 161500   |
| value_loss         | 199      |
---------------------------------
10.0
10.0
15.04
20.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.597    |
| fps                | 389      |
| nupdates           | 32400    |
| policy_entropy     | 0.0109   |
| total_timesteps    | 162000   |
| value_loss         | 39.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.27     |
| fps                | 389      |
| nupdates           | 32500    |
| policy_entropy     | 0.0307   |
| total_timesteps    | 162500   |
| value_loss         | 488      |
---------------------------------
23.0
23.0
14.49
15.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.451    |
| fps                | 389      |
| nupdates           | 32600    |
| policy_entropy     | 0.0738   |
| total_timesteps    | 163000   |
| value_loss         | 557      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.674    |
| fps                | 389      |
| nupdates           | 32700    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 163500   |
| value_loss         | 26.2     |
---------------------------------
19.0
19.0
16.28
10.5
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.818    |
| fps                | 389      |
| nupdates           | 32800    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 164000   |
| value_loss         | 37.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0737   |
| fps                | 389      |
| nupdates           | 32900    |
| policy_entropy     | 0.00793  |
| total_timesteps    | 164500   |
| value_loss         | 531      |
---------------------------------
11.0
11.0
14.27
9.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.683    |
| fps                | 389      |
| nupdates           | 33000    |
| policy_entropy     | 0.00449  |
| total_timesteps    | 165000   |
| value_loss         | 29.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.895    |
| fps                | 389      |
| nupdates           | 33100    |
| policy_entropy     | 0.00507  |
| total_timesteps    | 165500   |
| value_loss         | 423      |
---------------------------------
11.0
11.0
15.02
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 222      |
| explained_variance | -1.24    |
| fps                | 389      |
| nupdates           | 33200    |
| policy_entropy     | 0.0462   |
| total_timesteps    | 166000   |
| value_loss         | 366      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.476    |
| fps                | 389      |
| nupdates           | 33300    |
| policy_entropy     | 0.133    |
| total_timesteps    | 166500   |
| value_loss         | 25.3     |
---------------------------------
11.0
11.0
14.19
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.961    |
| fps                | 389      |
| nupdates           | 33400    |
| policy_entropy     | 0.00719  |
| total_timesteps    | 167000   |
| value_loss         | 6.4      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.0345   |
| fps                | 389      |
| nupdates           | 33500    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 167500   |
| value_loss         | 63.6     |
---------------------------------
19.0
19.0
13.69
19.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | -0.998   |
| fps                | 389      |
| nupdates           | 33600    |
| policy_entropy     | 0.043    |
| total_timesteps    | 168000   |
| value_loss         | 259      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.823    |
| fps                | 389      |
| nupdates           | 33700    |
| policy_entropy     | 0.00657  |
| total_timesteps    | 168500   |
| value_loss         | 46.1     |
---------------------------------
10.0
10.0
14.04
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | -0.423   |
| fps                | 389      |
| nupdates           | 33800    |
| policy_entropy     | 0.147    |
| total_timesteps    | 169000   |
| value_loss         | 59.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | -1.83    |
| fps                | 389      |
| nupdates           | 33900    |
| policy_entropy     | 0.033    |
| total_timesteps    | 169500   |
| value_loss         | 133      |
---------------------------------
17.0
17.0
14.08
17.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.875    |
| fps                | 389      |
| nupdates           | 34000    |
| policy_entropy     | 0.00802  |
| total_timesteps    | 170000   |
| value_loss         | 49.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.918    |
| fps                | 389      |
| nupdates           | 34100    |
| policy_entropy     | 0.0504   |
| total_timesteps    | 170500   |
| value_loss         | 5.4      |
---------------------------------
27.0
27.0
14.34
10.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.889    |
| fps                | 389      |
| nupdates           | 34200    |
| policy_entropy     | 0.155    |
| total_timesteps    | 171000   |
| value_loss         | 99.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | -5.39    |
| fps                | 389      |
| nupdates           | 34300    |
| policy_entropy     | 0.0871   |
| total_timesteps    | 171500   |
| value_loss         | 274      |
---------------------------------
10.0
10.0
14.3
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.994    |
| fps                | 389      |
| nupdates           | 34400    |
| policy_entropy     | 0.0378   |
| total_timesteps    | 172000   |
| value_loss         | 1.34     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | -0.0349  |
| fps                | 389      |
| nupdates           | 34500    |
| policy_entropy     | 0.0183   |
| total_timesteps    | 172500   |
| value_loss         | 42.3     |
---------------------------------
11.0
11.0
13.4
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.865    |
| fps                | 389      |
| nupdates           | 34600    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 173000   |
| value_loss         | 47.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -0.0939  |
| fps                | 389      |
| nupdates           | 34700    |
| policy_entropy     | 0.00378  |
| total_timesteps    | 173500   |
| value_loss         | 57.4     |
---------------------------------
11.0
11.0
14.42
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | -0.996   |
| fps                | 389      |
| nupdates           | 34800    |
| policy_entropy     | 0.0531   |
| total_timesteps    | 174000   |
| value_loss         | 293      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | -1.04    |
| fps                | 389      |
| nupdates           | 34900    |
| policy_entropy     | 0.0488   |
| total_timesteps    | 174500   |
| value_loss         | 373      |
---------------------------------
10.0
10.0
14.26
19.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.967    |
| fps                | 389      |
| nupdates           | 35000    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 175000   |
| value_loss         | 14.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.324    |
| fps                | 389      |
| nupdates           | 35100    |
| policy_entropy     | 0.118    |
| total_timesteps    | 175500   |
| value_loss         | 122      |
---------------------------------
21.0
21.0
15.05
20.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.965    |
| fps                | 389      |
| nupdates           | 35200    |
| policy_entropy     | 0.121    |
| total_timesteps    | 176000   |
| value_loss         | 4.13     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.843    |
| fps                | 389      |
| nupdates           | 35300    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 176500   |
| value_loss         | 12.2     |
---------------------------------
20.0
20.0
14.68
14.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | -2.04    |
| fps                | 389      |
| nupdates           | 35400    |
| policy_entropy     | 0.391    |
| total_timesteps    | 177000   |
| value_loss         | 134      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | -0.527   |
| fps                | 389      |
| nupdates           | 35500    |
| policy_entropy     | 0.0649   |
| total_timesteps    | 177500   |
| value_loss         | 319      |
---------------------------------
19.0
19.0
15.07
16.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.483    |
| fps                | 389      |
| nupdates           | 35600    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 178000   |
| value_loss         | 421      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | -0.0954  |
| fps                | 389      |
| nupdates           | 35700    |
| policy_entropy     | 0.0457   |
| total_timesteps    | 178500   |
| value_loss         | 400      |
---------------------------------
20.0
20.0
14.88
15.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.631    |
| fps                | 389      |
| nupdates           | 35800    |
| policy_entropy     | 0.129    |
| total_timesteps    | 179000   |
| value_loss         | 8.42     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.696    |
| fps                | 389      |
| nupdates           | 35900    |
| policy_entropy     | 0.0811   |
| total_timesteps    | 179500   |
| value_loss         | 11.8     |
---------------------------------
9.0
9.0
14.43
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 222      |
| explained_variance | -1.18    |
| fps                | 389      |
| nupdates           | 36000    |
| policy_entropy     | 0.0602   |
| total_timesteps    | 180000   |
| value_loss         | 671      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 221      |
| explained_variance | -2.95    |
| fps                | 389      |
| nupdates           | 36100    |
| policy_entropy     | 0.0829   |
| total_timesteps    | 180500   |
| value_loss         | 304      |
---------------------------------
9.0
9.0
13.14
10.5
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.821    |
| fps                | 389      |
| nupdates           | 36200    |
| policy_entropy     | 0.00966  |
| total_timesteps    | 181000   |
| value_loss         | 78.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 221      |
| explained_variance | -1.24    |
| fps                | 389      |
| nupdates           | 36300    |
| policy_entropy     | 0.0527   |
| total_timesteps    | 181500   |
| value_loss         | 239      |
---------------------------------
20.0
20.0
14.63
19.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.718    |
| fps                | 389      |
| nupdates           | 36400    |
| policy_entropy     | 0.057    |
| total_timesteps    | 182000   |
| value_loss         | 110      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | -2.1     |
| fps                | 388      |
| nupdates           | 36500    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 182500   |
| value_loss         | 75.7     |
---------------------------------
21.0
21.0
15.71
20.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.883    |
| fps                | 388      |
| nupdates           | 36600    |
| policy_entropy     | 0.349    |
| total_timesteps    | 183000   |
| value_loss         | 75.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.871    |
| fps                | 388      |
| nupdates           | 36700    |
| policy_entropy     | 0.0199   |
| total_timesteps    | 183500   |
| value_loss         | 52.4     |
---------------------------------
11.0
11.0
14.11
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.993    |
| fps                | 388      |
| nupdates           | 36800    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 184000   |
| value_loss         | 2.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.973    |
| fps                | 388      |
| nupdates           | 36900    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 184500   |
| value_loss         | 5.81     |
---------------------------------
23.0
23.0
15.05
20.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.936    |
| fps                | 388      |
| nupdates           | 37000    |
| policy_entropy     | 0.152    |
| total_timesteps    | 185000   |
| value_loss         | 4.02     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.921    |
| fps                | 388      |
| nupdates           | 37100    |
| policy_entropy     | 0.00433  |
| total_timesteps    | 185500   |
| value_loss         | 658      |
---------------------------------
21.0
21.0
15.34
14.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.774    |
| fps                | 388      |
| nupdates           | 37200    |
| policy_entropy     | 0.00278  |
| total_timesteps    | 186000   |
| value_loss         | 21.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.575    |
| fps                | 388      |
| nupdates           | 37300    |
| policy_entropy     | 0.124    |
| total_timesteps    | 186500   |
| value_loss         | 41.7     |
---------------------------------
20.0
20.0
14.17
17.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.981    |
| fps                | 388      |
| nupdates           | 37400    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 187000   |
| value_loss         | 4.95     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | -0.588   |
| fps                | 388      |
| nupdates           | 37500    |
| policy_entropy     | 0.127    |
| total_timesteps    | 187500   |
| value_loss         | 54.2     |
---------------------------------
26.0
26.0
14.64
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.151   |
| fps                | 388      |
| nupdates           | 37600    |
| policy_entropy     | 0.005    |
| total_timesteps    | 188000   |
| value_loss         | 42.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.477    |
| fps                | 388      |
| nupdates           | 37700    |
| policy_entropy     | 0.00282  |
| total_timesteps    | 188500   |
| value_loss         | 95.9     |
---------------------------------
19.0
19.0
14.16
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.328    |
| fps                | 388      |
| nupdates           | 37800    |
| policy_entropy     | 0.157    |
| total_timesteps    | 189000   |
| value_loss         | 36.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | -1.62    |
| fps                | 388      |
| nupdates           | 37900    |
| policy_entropy     | 0.183    |
| total_timesteps    | 189500   |
| value_loss         | 538      |
---------------------------------
9.0
9.0
13.67
14.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | -3.11    |
| fps                | 388      |
| nupdates           | 38000    |
| policy_entropy     | 0.0315   |
| total_timesteps    | 190000   |
| value_loss         | 313      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.628    |
| fps                | 388      |
| nupdates           | 38100    |
| policy_entropy     | 0.00234  |
| total_timesteps    | 190500   |
| value_loss         | 30.6     |
---------------------------------
31.0
31.0
15.64
20.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.228    |
| fps                | 388      |
| nupdates           | 38200    |
| policy_entropy     | 0.0051   |
| total_timesteps    | 191000   |
| value_loss         | 479      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 219      |
| explained_variance | -0.635   |
| fps                | 388      |
| nupdates           | 38300    |
| policy_entropy     | 0.121    |
| total_timesteps    | 191500   |
| value_loss         | 74.6     |
---------------------------------
11.0
11.0
14.89
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.993    |
| fps                | 388      |
| nupdates           | 38400    |
| policy_entropy     | 0.0083   |
| total_timesteps    | 192000   |
| value_loss         | 5.16     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.936    |
| fps                | 388      |
| nupdates           | 38500    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 192500   |
| value_loss         | 4.48     |
---------------------------------
9.0
9.0
13.81
12.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.799    |
| fps                | 388      |
| nupdates           | 38600    |
| policy_entropy     | 0.066    |
| total_timesteps    | 193000   |
| value_loss         | 44.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.94     |
| fps                | 388      |
| nupdates           | 38700    |
| policy_entropy     | 0.142    |
| total_timesteps    | 193500   |
| value_loss         | 2.11     |
---------------------------------
11.0
11.0
15.37
11.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.305    |
| fps                | 388      |
| nupdates           | 38800    |
| policy_entropy     | 0.00455  |
| total_timesteps    | 194000   |
| value_loss         | 386      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.963    |
| fps                | 388      |
| nupdates           | 38900    |
| policy_entropy     | 0.00488  |
| total_timesteps    | 194500   |
| value_loss         | 327      |
---------------------------------
11.0
11.0
14.74
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.194    |
| fps                | 388      |
| nupdates           | 39000    |
| policy_entropy     | 0.00955  |
| total_timesteps    | 195000   |
| value_loss         | 510      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.893    |
| fps                | 388      |
| nupdates           | 39100    |
| policy_entropy     | 0.00901  |
| total_timesteps    | 195500   |
| value_loss         | 18.1     |
---------------------------------
9.0
9.0
14.19
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.854    |
| fps                | 388      |
| nupdates           | 39200    |
| policy_entropy     | 0.00481  |
| total_timesteps    | 196000   |
| value_loss         | 8.41     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | 0.873    |
| fps                | 388      |
| nupdates           | 39300    |
| policy_entropy     | 0.011    |
| total_timesteps    | 196500   |
| value_loss         | 14.8     |
---------------------------------
21.0
21.0
14.53
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | -0.864   |
| fps                | 388      |
| nupdates           | 39400    |
| policy_entropy     | 0.039    |
| total_timesteps    | 197000   |
| value_loss         | 313      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | -1.86    |
| fps                | 388      |
| nupdates           | 39500    |
| policy_entropy     | 0.0356   |
| total_timesteps    | 197500   |
| value_loss         | 132      |
---------------------------------
10.0
10.0
14.16
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | -1.81    |
| fps                | 388      |
| nupdates           | 39600    |
| policy_entropy     | 0.0361   |
| total_timesteps    | 198000   |
| value_loss         | 608      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.928    |
| fps                | 388      |
| nupdates           | 39700    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 198500   |
| value_loss         | 17.2     |
---------------------------------
21.0
21.0
14.08
19.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.763    |
| fps                | 388      |
| nupdates           | 39800    |
| policy_entropy     | 0.02     |
| total_timesteps    | 199000   |
| value_loss         | 17       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.961    |
| fps                | 388      |
| nupdates           | 39900    |
| policy_entropy     | 0.00673  |
| total_timesteps    | 199500   |
| value_loss         | 6.5      |
---------------------------------
11.0
11.0
13.96
11.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | 0.846    |
| fps                | 388      |
| nupdates           | 40000    |
| policy_entropy     | 0.00307  |
| total_timesteps    | 200000   |
| value_loss         | 15.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.584    |
| fps                | 388      |
| nupdates           | 40100    |
| policy_entropy     | 0.175    |
| total_timesteps    | 200500   |
| value_loss         | 25.1     |
---------------------------------
11.0
11.0
14.91
20.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | -0.217   |
| fps                | 388      |
| nupdates           | 40200    |
| policy_entropy     | 0.00556  |
| total_timesteps    | 201000   |
| value_loss         | 443      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | -0.95    |
| fps                | 388      |
| nupdates           | 40300    |
| policy_entropy     | 0.0476   |
| total_timesteps    | 201500   |
| value_loss         | 195      |
---------------------------------
9.0
9.0
14.48
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | -0.132   |
| fps                | 388      |
| nupdates           | 40400    |
| policy_entropy     | 0.0593   |
| total_timesteps    | 202000   |
| value_loss         | 263      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.956    |
| fps                | 388      |
| nupdates           | 40500    |
| policy_entropy     | 0.00603  |
| total_timesteps    | 202500   |
| value_loss         | 26.4     |
---------------------------------
9.0
9.0
13.71
10.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | -0.931   |
| fps                | 388      |
| nupdates           | 40600    |
| policy_entropy     | 0.0219   |
| total_timesteps    | 203000   |
| value_loss         | 405      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | -2.57    |
| fps                | 388      |
| nupdates           | 40700    |
| policy_entropy     | 0.0193   |
| total_timesteps    | 203500   |
| value_loss         | 390      |
---------------------------------
20.0
20.0
14.19
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.346    |
| fps                | 388      |
| nupdates           | 40800    |
| policy_entropy     | 0.101    |
| total_timesteps    | 204000   |
| value_loss         | 34.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.531    |
| fps                | 388      |
| nupdates           | 40900    |
| policy_entropy     | 0.105    |
| total_timesteps    | 204500   |
| value_loss         | 10.2     |
---------------------------------
9.0
9.0
14.06
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.946    |
| fps                | 388      |
| nupdates           | 41000    |
| policy_entropy     | 0.0125   |
| total_timesteps    | 205000   |
| value_loss         | 3.31     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | 0.677    |
| fps                | 388      |
| nupdates           | 41100    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 205500   |
| value_loss         | 49.9     |
---------------------------------
21.0
21.0
13.7
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.962    |
| fps                | 388      |
| nupdates           | 41200    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 206000   |
| value_loss         | 2.29     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.969    |
| fps                | 388      |
| nupdates           | 41300    |
| policy_entropy     | 0.141    |
| total_timesteps    | 206500   |
| value_loss         | 32.2     |
---------------------------------
10.0
10.0
13.49
19.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.334    |
| fps                | 388      |
| nupdates           | 41400    |
| policy_entropy     | 0.00161  |
| total_timesteps    | 207000   |
| value_loss         | 322      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 221      |
| explained_variance | -0.645   |
| fps                | 388      |
| nupdates           | 41500    |
| policy_entropy     | 0.00297  |
| total_timesteps    | 207500   |
| value_loss         | 189      |
---------------------------------
10.0
10.0
13.51
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.514    |
| fps                | 388      |
| nupdates           | 41600    |
| policy_entropy     | 0.0334   |
| total_timesteps    | 208000   |
| value_loss         | 237      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.985    |
| fps                | 388      |
| nupdates           | 41700    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 208500   |
| value_loss         | 2.22     |
---------------------------------
20.0
20.0
13.89
11.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.665    |
| fps                | 388      |
| nupdates           | 41800    |
| policy_entropy     | 0.00741  |
| total_timesteps    | 209000   |
| value_loss         | 81.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.772    |
| fps                | 388      |
| nupdates           | 41900    |
| policy_entropy     | 0.00173  |
| total_timesteps    | 209500   |
| value_loss         | 107      |
---------------------------------
20.0
20.0
14.06
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | -0.418   |
| fps                | 388      |
| nupdates           | 42000    |
| policy_entropy     | 0.156    |
| total_timesteps    | 210000   |
| value_loss         | 54.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | -0.817   |
| fps                | 388      |
| nupdates           | 42100    |
| policy_entropy     | 0.02     |
| total_timesteps    | 210500   |
| value_loss         | 300      |
---------------------------------
20.0
20.0
14.38
15.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.951    |
| fps                | 388      |
| nupdates           | 42200    |
| policy_entropy     | 0.00586  |
| total_timesteps    | 211000   |
| value_loss         | 9.51     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | -0.0018  |
| fps                | 388      |
| nupdates           | 42300    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 211500   |
| value_loss         | 102      |
---------------------------------
21.0
21.0
14.51
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 221      |
| explained_variance | -1.53    |
| fps                | 388      |
| nupdates           | 42400    |
| policy_entropy     | 0.012    |
| total_timesteps    | 212000   |
| value_loss         | 826      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.717    |
| fps                | 388      |
| nupdates           | 42500    |
| policy_entropy     | 0.0021   |
| total_timesteps    | 212500   |
| value_loss         | 24.6     |
---------------------------------
23.0
23.0
13.66
11.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.964    |
| fps                | 388      |
| nupdates           | 42600    |
| policy_entropy     | 0.00299  |
| total_timesteps    | 213000   |
| value_loss         | 542      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.232    |
| fps                | 388      |
| nupdates           | 42700    |
| policy_entropy     | 0.0345   |
| total_timesteps    | 213500   |
| value_loss         | 182      |
---------------------------------
9.0
9.0
13.99
19.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.86     |
| fps                | 388      |
| nupdates           | 42800    |
| policy_entropy     | 0.148    |
| total_timesteps    | 214000   |
| value_loss         | 98.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.357    |
| fps                | 388      |
| nupdates           | 42900    |
| policy_entropy     | 0.00535  |
| total_timesteps    | 214500   |
| value_loss         | 278      |
---------------------------------
20.0
20.0
14.93
20.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.973    |
| fps                | 388      |
| nupdates           | 43000    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 215000   |
| value_loss         | 3.95     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.192    |
| fps                | 388      |
| nupdates           | 43100    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 215500   |
| value_loss         | 573      |
---------------------------------
10.0
10.0
13.85
10.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.894    |
| fps                | 388      |
| nupdates           | 43200    |
| policy_entropy     | 0.00302  |
| total_timesteps    | 216000   |
| value_loss         | 700      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 220      |
| explained_variance | -3.21    |
| fps                | 388      |
| nupdates           | 43300    |
| policy_entropy     | 0.191    |
| total_timesteps    | 216500   |
| value_loss         | 91.7     |
---------------------------------
9.0
9.0
13.9
11.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.365    |
| fps                | 388      |
| nupdates           | 43400    |
| policy_entropy     | 0.00298  |
| total_timesteps    | 217000   |
| value_loss         | 243      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.907    |
| fps                | 388      |
| nupdates           | 43500    |
| policy_entropy     | 0.00709  |
| total_timesteps    | 217500   |
| value_loss         | 7.35     |
---------------------------------
19.0
19.0
14.52
17.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.781    |
| fps                | 388      |
| nupdates           | 43600    |
| policy_entropy     | 0.301    |
| total_timesteps    | 218000   |
| value_loss         | 26.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.942    |
| fps                | 388      |
| nupdates           | 43700    |
| policy_entropy     | 0.0402   |
| total_timesteps    | 218500   |
| value_loss         | 9.53     |
---------------------------------
10.0
10.0
14.65
11.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.845    |
| fps                | 388      |
| nupdates           | 43800    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 219000   |
| value_loss         | 18.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | -0.806   |
| fps                | 388      |
| nupdates           | 43900    |
| policy_entropy     | 0.0249   |
| total_timesteps    | 219500   |
| value_loss         | 281      |
---------------------------------
20.0
20.0
13.49
11.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.516    |
| fps                | 388      |
| nupdates           | 44000    |
| policy_entropy     | 0.0662   |
| total_timesteps    | 220000   |
| value_loss         | 75.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | -0.834   |
| fps                | 388      |
| nupdates           | 44100    |
| policy_entropy     | 0.0217   |
| total_timesteps    | 220500   |
| value_loss         | 707      |
---------------------------------
22.0
22.0
15.03
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 221      |
| explained_variance | 0        |
| fps                | 388      |
| nupdates           | 44200    |
| policy_entropy     | 0.0224   |
| total_timesteps    | 221000   |
| value_loss         | 277      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | -2.19    |
| fps                | 388      |
| nupdates           | 44300    |
| policy_entropy     | 0.00879  |
| total_timesteps    | 221500   |
| value_loss         | 654      |
---------------------------------
10.0
10.0
15.23
11.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.954    |
| fps                | 388      |
| nupdates           | 44400    |
| policy_entropy     | 0.00226  |
| total_timesteps    | 222000   |
| value_loss         | 15.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.732    |
| fps                | 388      |
| nupdates           | 44500    |
| policy_entropy     | 0.00468  |
| total_timesteps    | 222500   |
| value_loss         | 31       |
---------------------------------
10.0
10.0
14.33
15.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.928    |
| fps                | 388      |
| nupdates           | 44600    |
| policy_entropy     | 0.00372  |
| total_timesteps    | 223000   |
| value_loss         | 282      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.288    |
| fps                | 388      |
| nupdates           | 44700    |
| policy_entropy     | 0.0201   |
| total_timesteps    | 223500   |
| value_loss         | 278      |
---------------------------------
14.0
14.0
15.0
10.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | -0.511   |
| fps                | 388      |
| nupdates           | 44800    |
| policy_entropy     | 0.227    |
| total_timesteps    | 224000   |
| value_loss         | 250      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0439   |
| fps                | 388      |
| nupdates           | 44900    |
| policy_entropy     | 0.00578  |
| total_timesteps    | 224500   |
| value_loss         | 802      |
---------------------------------
22.0
22.0
15.93
10.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 214      |
| explained_variance | -0.394   |
| fps                | 388      |
| nupdates           | 45000    |
| policy_entropy     | 0.0313   |
| total_timesteps    | 225000   |
| value_loss         | 171      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.929    |
| fps                | 388      |
| nupdates           | 45100    |
| policy_entropy     | 0.00519  |
| total_timesteps    | 225500   |
| value_loss         | 10.8     |
---------------------------------
11.0
11.0
13.97
11.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.519    |
| fps                | 388      |
| nupdates           | 45200    |
| policy_entropy     | 0.109    |
| total_timesteps    | 226000   |
| value_loss         | 19.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.978    |
| fps                | 388      |
| nupdates           | 45300    |
| policy_entropy     | 0.00954  |
| total_timesteps    | 226500   |
| value_loss         | 2.98     |
---------------------------------
21.0
21.0
14.64
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | -1.06    |
| fps                | 388      |
| nupdates           | 45400    |
| policy_entropy     | 0.0271   |
| total_timesteps    | 227000   |
| value_loss         | 448      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0.973    |
| fps                | 388      |
| nupdates           | 45500    |
| policy_entropy     | 0.026    |
| total_timesteps    | 227500   |
| value_loss         | 8.04     |
---------------------------------
10.0
10.0
14.96
19.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0        |
| fps                | 388      |
| nupdates           | 45600    |
| policy_entropy     | 0.0281   |
| total_timesteps    | 228000   |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 208      |
| explained_variance | 0.355    |
| fps                | 388      |
| nupdates           | 45700    |
| policy_entropy     | 0.145    |
| total_timesteps    | 228500   |
| value_loss         | 6.75e+03 |
---------------------------------
17.0
17.0
16.87
11.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.146    |
| fps                | 388      |
| nupdates           | 45800    |
| policy_entropy     | 0.00225  |
| total_timesteps    | 229000   |
| value_loss         | 451      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 211      |
| explained_variance | 0.763    |
| fps                | 388      |
| nupdates           | 45900    |
| policy_entropy     | 0.00968  |
| total_timesteps    | 229500   |
| value_loss         | 49.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.844    |
| fps                | 388      |
| nupdates           | 46100    |
| policy_entropy     | 0.00425  |
| total_timesteps    | 230500   |
| value_loss         | 31.1     |
---------------------------------
11.0
11.0
14.99
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | -0.12    |
| fps                | 388      |
| nupdates           | 46200    |
| policy_entropy     | 0.00333  |
| total_timesteps    | 231000   |
| value_loss         | 437      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.739    |
| fps                | 388      |
| nupdates           | 46300    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 231500   |
| value_loss         | 7.63     |
---------------------------------
10.0
10.0
14.13
15.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.912    |
| fps                | 388      |
| nupdates           | 46400    |
| policy_entropy     | 0.147    |
| total_timesteps    | 232000   |
| value_loss         | 24.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 223      |
| explained_variance | -0.736   |
| fps                | 388      |
| nupdates           | 46500    |
| policy_entropy     | 0.0021   |
| total_timesteps    | 232500   |
| value_loss         | 80.5     |
---------------------------------
19.0
19.0
14.06
14.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.981    |
| fps                | 388      |
| nupdates           | 46600    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 233000   |
| value_loss         | 2.89     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0.973    |
| fps                | 388      |
| nupdates           | 46700    |
| policy_entropy     | 0.0161   |
| total_timesteps    | 233500   |
| value_loss         | 2.62     |
---------------------------------
10.0
10.0
13.7
11.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 222      |
| explained_variance | -1.08    |
| fps                | 388      |
| nupdates           | 46800    |
| policy_entropy     | 0.0286   |
| total_timesteps    | 234000   |
| value_loss         | 652      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.803    |
| fps                | 388      |
| nupdates           | 46900    |
| policy_entropy     | 0.00447  |
| total_timesteps    | 234500   |
| value_loss         | 29.1     |
---------------------------------
19.0
19.0
13.39
11.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.996    |
| fps                | 388      |
| nupdates           | 47000    |
| policy_entropy     | 0.0062   |
| total_timesteps    | 235000   |
| value_loss         | 7.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.894    |
| fps                | 388      |
| nupdates           | 47100    |
| policy_entropy     | 0.0903   |
| total_timesteps    | 235500   |
| value_loss         | 3.19     |
---------------------------------
19.0
19.0
14.39
19.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | -0.952   |
| fps                | 388      |
| nupdates           | 47200    |
| policy_entropy     | 0.0303   |
| total_timesteps    | 236000   |
| value_loss         | 872      |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | 0.997    |
| fps                | 388      |
| nupdates           | 47300    |
| policy_entropy     | 0.00821  |
| total_timesteps    | 236500   |
| value_loss         | 1.13     |
---------------------------------
21.0
21.0
14.32
20.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | -2.2     |
| fps                | 388      |
| nupdates           | 47400    |
| policy_entropy     | 0.0333   |
| total_timesteps    | 237000   |
| value_loss         | 213      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.991    |
| fps                | 388      |
| nupdates           | 47500    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 237500   |
| value_loss         | 2.61     |
---------------------------------
22.0
22.0
13.54
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 220      |
| explained_variance | -0.263   |
| fps                | 388      |
| nupdates           | 47600    |
| policy_entropy     | 0.178    |
| total_timesteps    | 238000   |
| value_loss         | 54.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | -0.521   |
| fps                | 388      |
| nupdates           | 47700    |
| policy_entropy     | 0.004    |
| total_timesteps    | 238500   |
| value_loss         | 185      |
---------------------------------
11.0
11.0
13.63
20.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.89     |
| fps                | 388      |
| nupdates           | 47800    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 239000   |
| value_loss         | 11.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.995    |
| fps                | 388      |
| nupdates           | 47900    |
| policy_entropy     | 0.0933   |
| total_timesteps    | 239500   |
| value_loss         | 0.28     |
---------------------------------
10.0
10.0
13.99
11.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.77     |
| fps                | 388      |
| nupdates           | 48000    |
| policy_entropy     | 0.00232  |
| total_timesteps    | 240000   |
| value_loss         | 25.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.629    |
| fps                | 388      |
| nupdates           | 48100    |
| policy_entropy     | 0.015    |
| total_timesteps    | 240500   |
| value_loss         | 39.7     |
---------------------------------
20.0
20.0
13.91
19.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.918    |
| fps                | 388      |
| nupdates           | 48200    |
| policy_entropy     | 0.00448  |
| total_timesteps    | 241000   |
| value_loss         | 2.6      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.805    |
| fps                | 388      |
| nupdates           | 48300    |
| policy_entropy     | 0.00258  |
| total_timesteps    | 241500   |
| value_loss         | 20.5     |
---------------------------------
19.0
19.0
14.81
19.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | -5.9     |
| fps                | 388      |
| nupdates           | 48400    |
| policy_entropy     | 0.0307   |
| total_timesteps    | 242000   |
| value_loss         | 702      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.435    |
| fps                | 388      |
| nupdates           | 48500    |
| policy_entropy     | 0.00679  |
| total_timesteps    | 242500   |
| value_loss         | 296      |
---------------------------------
20.0
20.0
14.65
20.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.284    |
| fps                | 387      |
| nupdates           | 48600    |
| policy_entropy     | 0.00704  |
| total_timesteps    | 243000   |
| value_loss         | 320      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | -0.963   |
| fps                | 388      |
| nupdates           | 48700    |
| policy_entropy     | 0.0325   |
| total_timesteps    | 243500   |
| value_loss         | 508      |
---------------------------------
9.0
9.0
14.49
20.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.94     |
| fps                | 387      |
| nupdates           | 48800    |
| policy_entropy     | 0.00179  |
| total_timesteps    | 244000   |
| value_loss         | 14.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.593    |
| fps                | 388      |
| nupdates           | 48900    |
| policy_entropy     | 0.00418  |
| total_timesteps    | 244500   |
| value_loss         | 14.8     |
---------------------------------
10.0
10.0
14.51
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | -0.236   |
| fps                | 388      |
| nupdates           | 49000    |
| policy_entropy     | 0.0231   |
| total_timesteps    | 245000   |
| value_loss         | 701      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | -0.584   |
| fps                | 388      |
| nupdates           | 49100    |
| policy_entropy     | 0.0417   |
| total_timesteps    | 245500   |
| value_loss         | 153      |
---------------------------------
10.0
10.0
13.77
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | -2.11    |
| fps                | 388      |
| nupdates           | 49200    |
| policy_entropy     | 0.161    |
| total_timesteps    | 246000   |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.171    |
| fps                | 388      |
| nupdates           | 49300    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 246500   |
| value_loss         | 272      |
---------------------------------
10.0
10.0
14.4
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.881    |
| fps                | 388      |
| nupdates           | 49400    |
| policy_entropy     | 0.0065   |
| total_timesteps    | 247000   |
| value_loss         | 14.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | -1.99    |
| fps                | 388      |
| nupdates           | 49500    |
| policy_entropy     | 0.0267   |
| total_timesteps    | 247500   |
| value_loss         | 342      |
---------------------------------
18.0
18.0
14.32
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.895    |
| fps                | 388      |
| nupdates           | 49600    |
| policy_entropy     | 0.00229  |
| total_timesteps    | 248000   |
| value_loss         | 9.08     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.141    |
| fps                | 388      |
| nupdates           | 49700    |
| policy_entropy     | 0.00996  |
| total_timesteps    | 248500   |
| value_loss         | 62.3     |
---------------------------------
9.0
9.0
14.44
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.928    |
| fps                | 388      |
| nupdates           | 49800    |
| policy_entropy     | 0.00371  |
| total_timesteps    | 249000   |
| value_loss         | 2.54     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.973    |
| fps                | 388      |
| nupdates           | 49900    |
| policy_entropy     | 0.18     |
| total_timesteps    | 249500   |
| value_loss         | 0.768    |
---------------------------------
18.0
18.0
14.59
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.77     |
| fps                | 388      |
| nupdates           | 50000    |
| policy_entropy     | 0.0961   |
| total_timesteps    | 250000   |
| value_loss         | 20.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 221      |
| explained_variance | -1.61    |
| fps                | 388      |
| nupdates           | 50100    |
| policy_entropy     | 0.0248   |
| total_timesteps    | 250500   |
| value_loss         | 355      |
---------------------------------
9.0
9.0
13.9
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | -0.392   |
| fps                | 388      |
| nupdates           | 50200    |
| policy_entropy     | 0.0318   |
| total_timesteps    | 251000   |
| value_loss         | 167      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.962    |
| fps                | 388      |
| nupdates           | 50300    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 251500   |
| value_loss         | 1.91     |
---------------------------------
20.0
20.0
14.13
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.991    |
| fps                | 388      |
| nupdates           | 50400    |
| policy_entropy     | 0.00251  |
| total_timesteps    | 252000   |
| value_loss         | 3        |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.961    |
| fps                | 388      |
| nupdates           | 50500    |
| policy_entropy     | 0.00969  |
| total_timesteps    | 252500   |
| value_loss         | 20.9     |
---------------------------------
28.0
28.0
13.97
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.993    |
| fps                | 388      |
| nupdates           | 50600    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 253000   |
| value_loss         | 3.78     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 220      |
| explained_variance | -0.108   |
| fps                | 388      |
| nupdates           | 50700    |
| policy_entropy     | 0.15     |
| total_timesteps    | 253500   |
| value_loss         | 90.3     |
---------------------------------
9.0
9.0
13.2
11.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.875    |
| fps                | 388      |
| nupdates           | 50800    |
| policy_entropy     | 0.0565   |
| total_timesteps    | 254000   |
| value_loss         | 9.35     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0.989    |
| fps                | 388      |
| nupdates           | 50900    |
| policy_entropy     | 0.00627  |
| total_timesteps    | 254500   |
| value_loss         | 1.08     |
---------------------------------
10.0
10.0
14.33
10.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.836    |
| fps                | 388      |
| nupdates           | 51000    |
| policy_entropy     | 0.0847   |
| total_timesteps    | 255000   |
| value_loss         | 13       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.935    |
| fps                | 388      |
| nupdates           | 51100    |
| policy_entropy     | 0.00556  |
| total_timesteps    | 255500   |
| value_loss         | 7.06     |
---------------------------------
21.0
21.0
14.49
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.986    |
| fps                | 388      |
| nupdates           | 51200    |
| policy_entropy     | 0.0053   |
| total_timesteps    | 256000   |
| value_loss         | 7.91     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | -1.69    |
| fps                | 388      |
| nupdates           | 51300    |
| policy_entropy     | 0.0258   |
| total_timesteps    | 256500   |
| value_loss         | 389      |
---------------------------------
20.0
20.0
13.41
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.924    |
| fps                | 388      |
| nupdates           | 51400    |
| policy_entropy     | 0.00858  |
| total_timesteps    | 257000   |
| value_loss         | 19.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.112    |
| fps                | 388      |
| nupdates           | 51500    |
| policy_entropy     | 0.00614  |
| total_timesteps    | 257500   |
| value_loss         | 120      |
---------------------------------
9.0
9.0
13.76
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.983    |
| fps                | 388      |
| nupdates           | 51600    |
| policy_entropy     | 0.00295  |
| total_timesteps    | 258000   |
| value_loss         | 4.25     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.967    |
| fps                | 388      |
| nupdates           | 51700    |
| policy_entropy     | 0.00415  |
| total_timesteps    | 258500   |
| value_loss         | 3.5      |
---------------------------------
11.0
11.0
13.7
15.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.526    |
| fps                | 388      |
| nupdates           | 51800    |
| policy_entropy     | 0.142    |
| total_timesteps    | 259000   |
| value_loss         | 21       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.555    |
| fps                | 388      |
| nupdates           | 51900    |
| policy_entropy     | 0.011    |
| total_timesteps    | 259500   |
| value_loss         | 12.5     |
---------------------------------
20.0
20.0
15.03
10.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 221      |
| explained_variance | 0.0577   |
| fps                | 388      |
| nupdates           | 52000    |
| policy_entropy     | 0.00496  |
| total_timesteps    | 260000   |
| value_loss         | 430      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.682    |
| fps                | 387      |
| nupdates           | 52100    |
| policy_entropy     | 0.0734   |
| total_timesteps    | 260500   |
| value_loss         | 8.57     |
---------------------------------
11.0
11.0
14.81
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 223      |
| explained_variance | -0.761   |
| fps                | 387      |
| nupdates           | 52200    |
| policy_entropy     | 0.0274   |
| total_timesteps    | 261000   |
| value_loss         | 678      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.134    |
| fps                | 387      |
| nupdates           | 52300    |
| policy_entropy     | 0.134    |
| total_timesteps    | 261500   |
| value_loss         | 75.9     |
---------------------------------
11.0
11.0
13.72
10.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.953    |
| fps                | 387      |
| nupdates           | 52400    |
| policy_entropy     | 0.00629  |
| total_timesteps    | 262000   |
| value_loss         | 7.66     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.736    |
| fps                | 387      |
| nupdates           | 52500    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 262500   |
| value_loss         | 45.5     |
---------------------------------
10.0
10.0
12.84
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.941    |
| fps                | 387      |
| nupdates           | 52600    |
| policy_entropy     | 0.00297  |
| total_timesteps    | 263000   |
| value_loss         | 967      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | -4.56    |
| fps                | 387      |
| nupdates           | 52700    |
| policy_entropy     | 0.0328   |
| total_timesteps    | 263500   |
| value_loss         | 511      |
---------------------------------
39.0
39.0
13.74
11.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.616    |
| fps                | 387      |
| nupdates           | 52800    |
| policy_entropy     | 0.00251  |
| total_timesteps    | 264000   |
| value_loss         | 55.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.249    |
| fps                | 387      |
| nupdates           | 52900    |
| policy_entropy     | 0.00237  |
| total_timesteps    | 264500   |
| value_loss         | 407      |
---------------------------------
9.0
9.0
14.25
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.987    |
| fps                | 387      |
| nupdates           | 53000    |
| policy_entropy     | 0.167    |
| total_timesteps    | 265000   |
| value_loss         | 0.444    |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.977    |
| fps                | 387      |
| nupdates           | 53100    |
| policy_entropy     | 0.0767   |
| total_timesteps    | 265500   |
| value_loss         | 1.42     |
---------------------------------
21.0
21.0
13.53
15.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.712    |
| fps                | 387      |
| nupdates           | 53200    |
| policy_entropy     | 0.0756   |
| total_timesteps    | 266000   |
| value_loss         | 29.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.921    |
| fps                | 387      |
| nupdates           | 53300    |
| policy_entropy     | 0.0874   |
| total_timesteps    | 266500   |
| value_loss         | 3.38     |
---------------------------------
20.0
20.0
13.8
10.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.921    |
| fps                | 387      |
| nupdates           | 53400    |
| policy_entropy     | 0.0049   |
| total_timesteps    | 267000   |
| value_loss         | 8.35     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.873    |
| fps                | 387      |
| nupdates           | 53500    |
| policy_entropy     | 0.0018   |
| total_timesteps    | 267500   |
| value_loss         | 83.2     |
---------------------------------
10.0
10.0
13.86
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.268    |
| fps                | 387      |
| nupdates           | 53600    |
| policy_entropy     | 0.00158  |
| total_timesteps    | 268000   |
| value_loss         | 402      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.525    |
| fps                | 387      |
| nupdates           | 53700    |
| policy_entropy     | 0.0021   |
| total_timesteps    | 268500   |
| value_loss         | 268      |
---------------------------------
9.0
9.0
14.22
18.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.0726   |
| fps                | 387      |
| nupdates           | 53800    |
| policy_entropy     | 0.024    |
| total_timesteps    | 269000   |
| value_loss         | 120      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 222      |
| explained_variance | -0.884   |
| fps                | 387      |
| nupdates           | 53900    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 269500   |
| value_loss         | 738      |
---------------------------------
9.0
9.0
15.26
14.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 221      |
| explained_variance | -3.29    |
| fps                | 387      |
| nupdates           | 54000    |
| policy_entropy     | 0.0669   |
| total_timesteps    | 270000   |
| value_loss         | 315      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | -1.4     |
| fps                | 387      |
| nupdates           | 54100    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 270500   |
| value_loss         | 346      |
---------------------------------
10.0
10.0
14.5
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.92     |
| fps                | 387      |
| nupdates           | 54200    |
| policy_entropy     | 0.00494  |
| total_timesteps    | 271000   |
| value_loss         | 7.56     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.892    |
| fps                | 387      |
| nupdates           | 54300    |
| policy_entropy     | 0.00178  |
| total_timesteps    | 271500   |
| value_loss         | 27.5     |
---------------------------------
10.0
10.0
12.89
10.5
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.986    |
| fps                | 387      |
| nupdates           | 54400    |
| policy_entropy     | 0.00678  |
| total_timesteps    | 272000   |
| value_loss         | 0.875    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.922    |
| fps                | 387      |
| nupdates           | 54500    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 272500   |
| value_loss         | 7.96     |
---------------------------------
19.0
19.0
14.42
18.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.919    |
| fps                | 387      |
| nupdates           | 54600    |
| policy_entropy     | 0.00451  |
| total_timesteps    | 273000   |
| value_loss         | 7.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.08     |
| fps                | 387      |
| nupdates           | 54700    |
| policy_entropy     | 0.0156   |
| total_timesteps    | 273500   |
| value_loss         | 462      |
---------------------------------
10.0
10.0
14.14
14.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.991    |
| fps                | 387      |
| nupdates           | 54800    |
| policy_entropy     | 0.069    |
| total_timesteps    | 274000   |
| value_loss         | 0.293    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | -1.92    |
| fps                | 387      |
| nupdates           | 54900    |
| policy_entropy     | 0.0357   |
| total_timesteps    | 274500   |
| value_loss         | 131      |
---------------------------------
21.0
21.0
14.8
20.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 221      |
| explained_variance | -0.659   |
| fps                | 387      |
| nupdates           | 55000    |
| policy_entropy     | 0.0338   |
| total_timesteps    | 275000   |
| value_loss         | 783      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0.786    |
| fps                | 387      |
| nupdates           | 55100    |
| policy_entropy     | 0.0851   |
| total_timesteps    | 275500   |
| value_loss         | 11.1     |
---------------------------------
11.0
11.0
14.52
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 222      |
| explained_variance | -11.4    |
| fps                | 387      |
| nupdates           | 55200    |
| policy_entropy     | 0.577    |
| total_timesteps    | 276000   |
| value_loss         | 271      |
---------------------------------
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 194      |
| explained_variance | -0.174   |
| fps                | 387      |
| nupdates           | 55300    |
| policy_entropy     | 0.456    |
| total_timesteps    | 276500   |
| value_loss         | 1.16e+05 |
---------------------------------
12.0
12.0
21.1
11.0
---------------------------------
| ep_len_mean        | 21.1     |
| ep_reward_mean     | 193      |
| explained_variance | -9.06    |
| fps                | 387      |
| nupdates           | 55400    |
| policy_entropy     | 0.0925   |
| total_timesteps    | 277000   |
| value_loss         | 115      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 191      |
| explained_variance | 0.526    |
| fps                | 387      |
| nupdates           | 55500    |
| policy_entropy     | 0.00489  |
| total_timesteps    | 277500   |
| value_loss         | 116      |
---------------------------------
9.0
9.0
13.18
10.5
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.918    |
| fps                | 387      |
| nupdates           | 55600    |
| policy_entropy     | 0.00713  |
| total_timesteps    | 278000   |
| value_loss         | 17.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.935    |
| fps                | 387      |
| nupdates           | 55700    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 278500   |
| value_loss         | 10.3     |
---------------------------------
26.0
26.0
14.34
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.137    |
| fps                | 387      |
| nupdates           | 55800    |
| policy_entropy     | 0.015    |
| total_timesteps    | 279000   |
| value_loss         | 26.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | -0.689   |
| fps                | 387      |
| nupdates           | 55900    |
| policy_entropy     | 0.0502   |
| total_timesteps    | 279500   |
| value_loss         | 880      |
---------------------------------
23.0
23.0
13.9
10.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | -1.01    |
| fps                | 387      |
| nupdates           | 56000    |
| policy_entropy     | 0.0508   |
| total_timesteps    | 280000   |
| value_loss         | 207      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.821    |
| fps                | 387      |
| nupdates           | 56100    |
| policy_entropy     | 0.0045   |
| total_timesteps    | 280500   |
| value_loss         | 46.8     |
---------------------------------
11.0
11.0
15.16
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.404    |
| fps                | 387      |
| nupdates           | 56200    |
| policy_entropy     | 0.0058   |
| total_timesteps    | 281000   |
| value_loss         | 491      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.969    |
| fps                | 387      |
| nupdates           | 56300    |
| policy_entropy     | 0.00673  |
| total_timesteps    | 281500   |
| value_loss         | 14.1     |
---------------------------------
20.0
20.0
13.02
15.0
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 220      |
| explained_variance | 0.98     |
| fps                | 387      |
| nupdates           | 56400    |
| policy_entropy     | 0.0764   |
| total_timesteps    | 282000   |
| value_loss         | 1.18     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.998    |
| fps                | 387      |
| nupdates           | 56500    |
| policy_entropy     | 0.00632  |
| total_timesteps    | 282500   |
| value_loss         | 2.74     |
---------------------------------
19.0
19.0
14.24
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.355    |
| fps                | 387      |
| nupdates           | 56600    |
| policy_entropy     | 0.00416  |
| total_timesteps    | 283000   |
| value_loss         | 535      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.941    |
| fps                | 387      |
| nupdates           | 56700    |
| policy_entropy     | 0.0195   |
| total_timesteps    | 283500   |
| value_loss         | 2.8      |
---------------------------------
10.0
10.0
13.86
10.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.993    |
| fps                | 387      |
| nupdates           | 56800    |
| policy_entropy     | 0.00867  |
| total_timesteps    | 284000   |
| value_loss         | 1.07     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.82     |
| fps                | 387      |
| nupdates           | 56900    |
| policy_entropy     | 0.00195  |
| total_timesteps    | 284500   |
| value_loss         | 73.3     |
---------------------------------
11.0
11.0
13.5
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 221      |
| explained_variance | -0.403   |
| fps                | 387      |
| nupdates           | 57000    |
| policy_entropy     | 0.0394   |
| total_timesteps    | 285000   |
| value_loss         | 310      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.973    |
| fps                | 387      |
| nupdates           | 57100    |
| policy_entropy     | 0.0129   |
| total_timesteps    | 285500   |
| value_loss         | 3.04     |
---------------------------------
19.0
19.0
14.74
18.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.444    |
| fps                | 387      |
| nupdates           | 57200    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 286000   |
| value_loss         | 367      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.972    |
| fps                | 387      |
| nupdates           | 57300    |
| policy_entropy     | 0.00537  |
| total_timesteps    | 286500   |
| value_loss         | 1.36     |
---------------------------------
20.0
20.0
13.76
14.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | -2.3     |
| fps                | 387      |
| nupdates           | 57400    |
| policy_entropy     | 0.0484   |
| total_timesteps    | 287000   |
| value_loss         | 149      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.918    |
| fps                | 387      |
| nupdates           | 57500    |
| policy_entropy     | 0.00555  |
| total_timesteps    | 287500   |
| value_loss         | 6.37     |
---------------------------------
10.0
10.0
13.82
11.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | -0.55    |
| fps                | 387      |
| nupdates           | 57600    |
| policy_entropy     | 0.242    |
| total_timesteps    | 288000   |
| value_loss         | 430      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.841    |
| fps                | 387      |
| nupdates           | 57700    |
| policy_entropy     | 0.0202   |
| total_timesteps    | 288500   |
| value_loss         | 24.5     |
---------------------------------
17.0
17.0
13.96
13.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 222      |
| explained_variance | 0.559    |
| fps                | 387      |
| nupdates           | 57800    |
| policy_entropy     | 0.0879   |
| total_timesteps    | 289000   |
| value_loss         | 80.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 223      |
| explained_variance | 0.857    |
| fps                | 387      |
| nupdates           | 57900    |
| policy_entropy     | 0.00331  |
| total_timesteps    | 289500   |
| value_loss         | 7.52     |
---------------------------------
10.0
10.0
14.68
20.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.951    |
| fps                | 387      |
| nupdates           | 58000    |
| policy_entropy     | 0.00131  |
| total_timesteps    | 290000   |
| value_loss         | 14.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0.986    |
| fps                | 387      |
| nupdates           | 58100    |
| policy_entropy     | 0.0571   |
| total_timesteps    | 290500   |
| value_loss         | 6.96     |
---------------------------------
21.0
21.0
14.68
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.913    |
| fps                | 387      |
| nupdates           | 58200    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 291000   |
| value_loss         | 17.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.985    |
| fps                | 387      |
| nupdates           | 58300    |
| policy_entropy     | 0.0225   |
| total_timesteps    | 291500   |
| value_loss         | 1.2      |
---------------------------------
9.0
9.0
13.44
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.422    |
| fps                | 387      |
| nupdates           | 58400    |
| policy_entropy     | 0.16     |
| total_timesteps    | 292000   |
| value_loss         | 74.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.331    |
| fps                | 387      |
| nupdates           | 58500    |
| policy_entropy     | 0.00305  |
| total_timesteps    | 292500   |
| value_loss         | 409      |
---------------------------------
10.0
10.0
13.27
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 220      |
| explained_variance | -1.56    |
| fps                | 387      |
| nupdates           | 58600    |
| policy_entropy     | 0.0399   |
| total_timesteps    | 293000   |
| value_loss         | 342      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.95     |
| fps                | 387      |
| nupdates           | 58700    |
| policy_entropy     | 0.00397  |
| total_timesteps    | 293500   |
| value_loss         | 6.34     |
---------------------------------
19.0
19.0
13.96
14.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | 0.898    |
| fps                | 387      |
| nupdates           | 58800    |
| policy_entropy     | 0.00352  |
| total_timesteps    | 294000   |
| value_loss         | 27.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.928    |
| fps                | 387      |
| nupdates           | 58900    |
| policy_entropy     | 0.00424  |
| total_timesteps    | 294500   |
| value_loss         | 6.28     |
---------------------------------
10.0
10.0
14.44
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.95     |
| fps                | 387      |
| nupdates           | 59000    |
| policy_entropy     | 0.00179  |
| total_timesteps    | 295000   |
| value_loss         | 636      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.844    |
| fps                | 387      |
| nupdates           | 59100    |
| policy_entropy     | 0.00625  |
| total_timesteps    | 295500   |
| value_loss         | 19.1     |
---------------------------------
20.0
20.0
14.57
19.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.878    |
| fps                | 387      |
| nupdates           | 59200    |
| policy_entropy     | 0.00492  |
| total_timesteps    | 296000   |
| value_loss         | 15.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 220      |
| explained_variance | 0.919    |
| fps                | 387      |
| nupdates           | 59300    |
| policy_entropy     | 0.00137  |
| total_timesteps    | 296500   |
| value_loss         | 31       |
---------------------------------
18.0
18.0
14.9
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.959    |
| fps                | 387      |
| nupdates           | 59400    |
| policy_entropy     | 0.143    |
| total_timesteps    | 297000   |
| value_loss         | 4.24     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 223      |
| explained_variance | -0.423   |
| fps                | 387      |
| nupdates           | 59500    |
| policy_entropy     | 0.0226   |
| total_timesteps    | 297500   |
| value_loss         | 237      |
---------------------------------
19.0
19.0
14.71
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.943    |
| fps                | 387      |
| nupdates           | 59600    |
| policy_entropy     | 0.000925 |
| total_timesteps    | 298000   |
| value_loss         | 4.68     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.954    |
| fps                | 387      |
| nupdates           | 59700    |
| policy_entropy     | 0.044    |
| total_timesteps    | 298500   |
| value_loss         | 3.26     |
---------------------------------
21.0
21.0
14.43
19.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 222      |
| explained_variance | -1.68    |
| fps                | 387      |
| nupdates           | 59800    |
| policy_entropy     | 0.00865  |
| total_timesteps    | 299000   |
| value_loss         | 59.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | -0.776   |
| fps                | 387      |
| nupdates           | 59900    |
| policy_entropy     | 0.129    |
| total_timesteps    | 299500   |
| value_loss         | 218      |
---------------------------------
11.0
11.0
14.39
16.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.989    |
| fps                | 387      |
| nupdates           | 60000    |
| policy_entropy     | 0.0754   |
| total_timesteps    | 300000   |
| value_loss         | 2.64     |
---------------------------------