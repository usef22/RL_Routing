___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000164948A3278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000164948A3278>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000164A944BA90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000164A944BA90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\a2c\a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\tensorflow\python\ops\clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\a2c\a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\tensorflow\python\training\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\a2c\a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.
---------------------------------
| explained_variance | -0.0422  |
| fps                | 7        |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 116      |
---------------------------------
---------------------------------
| ep_len_mean        | 197      |
| ep_reward_mean     | -402     |
| explained_variance | -0.0157  |
| fps                | 294      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 174      |
---------------------------------
336.0
336.0
243.33333333333334
197.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 243      |
| ep_reward_mean     | -639     |
| explained_variance | -0.0217  |
| fps                | 364      |
| nupdates           | 200      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1000     |
| value_loss         | 280      |
---------------------------------
---------------------------------
| ep_len_mean        | 238      |
| ep_reward_mean     | -662     |
| explained_variance | 0.000419 |
| fps                | 397      |
| nupdates           | 300      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1500     |
| value_loss         | 329      |
---------------------------------
130.0
130.0
224.625
210.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 225       |
| ep_reward_mean     | -628      |
| explained_variance | -0.000674 |
| fps                | 412       |
| nupdates           | 400       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2000      |
| value_loss         | 262       |
----------------------------------
---------------------------------
| ep_len_mean        | 206      |
| ep_reward_mean     | -563     |
| explained_variance | -0.0272  |
| fps                | 419      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 349      |
---------------------------------
544.0
544.0
234.0
227.0
---------------------------------
| ep_len_mean        | 234      |
| ep_reward_mean     | -664     |
| explained_variance | 8.34e-06 |
| fps                | 429      |
| nupdates           | 600      |
| policy_entropy     | 1.1      |
| total_timesteps    | 3000     |
| value_loss         | 39.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 237      |
| ep_reward_mean     | -677     |
| explained_variance | -0.0409  |
| fps                | 437      |
| nupdates           | 700      |
| policy_entropy     | 1.09     |
| total_timesteps    | 3500     |
| value_loss         | 129      |
---------------------------------
215.0
215.0
235.4
213.5
---------------------------------
| ep_len_mean        | 235      |
| ep_reward_mean     | -675     |
| explained_variance | -0.0127  |
| fps                | 443      |
| nupdates           | 800      |
| policy_entropy     | 1.08     |
| total_timesteps    | 4000     |
| value_loss         | 38.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 243      |
| ep_reward_mean     | -706     |
| explained_variance | -0.00274 |
| fps                | 442      |
| nupdates           | 900      |
| policy_entropy     | 0.999    |
| total_timesteps    | 4500     |
| value_loss         | 84.1     |
---------------------------------
152.0
152.0
223.54545454545453
153.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 224       |
| ep_reward_mean     | -614      |
| explained_variance | -6.07e-05 |
| fps                | 444       |
| nupdates           | 1000      |
| policy_entropy     | 1.05      |
| total_timesteps    | 5000      |
| value_loss         | 84.2      |
----------------------------------
---------------------------------
| ep_len_mean        | 235      |
| ep_reward_mean     | -660     |
| explained_variance | -0.00384 |
| fps                | 449      |
| nupdates           | 1100     |
| policy_entropy     | 1.02     |
| total_timesteps    | 5500     |
| value_loss         | 145      |
---------------------------------
143.0
143.0
230.53846153846155
153.0
---------------------------------
| ep_len_mean        | 231      |
| ep_reward_mean     | -636     |
| explained_variance | 0.00226  |
| fps                | 452      |
| nupdates           | 1200     |
| policy_entropy     | 1.05     |
| total_timesteps    | 6000     |
| value_loss         | 153      |
---------------------------------
---------------------------------
| ep_len_mean        | 232      |
| ep_reward_mean     | -631     |
| explained_variance | 0.000724 |
| fps                | 455      |
| nupdates           | 1300     |
| policy_entropy     | 1.04     |
| total_timesteps    | 6500     |
| value_loss         | 73.9     |
---------------------------------
66.0
66.0
216.46875
154.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 216      |
| ep_reward_mean     | -575     |
| explained_variance | 0.00692  |
| fps                | 456      |
| nupdates           | 1400     |
| policy_entropy     | 1.05     |
| total_timesteps    | 7000     |
| value_loss         | 120      |
---------------------------------
---------------------------------
| ep_len_mean        | 214      |
| ep_reward_mean     | -565     |
| explained_variance | 0.000608 |
| fps                | 458      |
| nupdates           | 1500     |
| policy_entropy     | 1.07     |
| total_timesteps    | 7500     |
| value_loss         | 8.39     |
---------------------------------
65.0
65.0
211.2972972972973
145.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 211      |
| ep_reward_mean     | -554     |
| explained_variance | 1.88e-05 |
| fps                | 460      |
| nupdates           | 1600     |
| policy_entropy     | 1.08     |
| total_timesteps    | 8000     |
| value_loss         | 67.5     |
---------------------------------
----------------------------------
| ep_len_mean        | 206       |
| ep_reward_mean     | -534      |
| explained_variance | -2.53e-05 |
| fps                | 461       |
| nupdates           | 1700      |
| policy_entropy     | 1.05      |
| total_timesteps    | 8500      |
| value_loss         | 43        |
----------------------------------
63.0
63.0
191.14893617021278
71.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 191       |
| ep_reward_mean     | -472      |
| explained_variance | -0.000266 |
| fps                | 463       |
| nupdates           | 1800      |
| policy_entropy     | 1.06      |
| total_timesteps    | 9000      |
| value_loss         | 246       |
----------------------------------
---------------------------------
| ep_len_mean        | 193      |
| ep_reward_mean     | -478     |
| explained_variance | 0.000194 |
| fps                | 464      |
| nupdates           | 1900     |
| policy_entropy     | 0.755    |
| total_timesteps    | 9500     |
| value_loss         | 61.5     |
---------------------------------
61.0
61.0
181.64814814814815
65.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 182      |
| ep_reward_mean     | -434     |
| explained_variance | 2.04e-05 |
| fps                | 463      |
| nupdates           | 2000     |
| policy_entropy     | 1        |
| total_timesteps    | 10000    |
| value_loss         | 139      |
---------------------------------
----------------------------------
| ep_len_mean        | 175       |
| ep_reward_mean     | -405      |
| explained_variance | -0.000114 |
| fps                | 464       |
| nupdates           | 2100      |
| policy_entropy     | 0.954     |
| total_timesteps    | 10500     |
| value_loss         | 19        |
----------------------------------
41.0
41.0
163.67164179104478
61.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 164      |
| ep_reward_mean     | -360     |
| explained_variance | 1.01e-06 |
| fps                | 464      |
| nupdates           | 2200     |
| policy_entropy     | 0.934    |
| total_timesteps    | 11000    |
| value_loss         | 366      |
---------------------------------
---------------------------------
| ep_len_mean        | 143      |
| ep_reward_mean     | -282     |
| explained_variance | -0.00398 |
| fps                | 465      |
| nupdates           | 2300     |
| policy_entropy     | 0.704    |
| total_timesteps    | 11500    |
| value_loss         | 115      |
---------------------------------
52.0
52.0
132.64444444444445
48.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 133       |
| ep_reward_mean     | -241      |
| explained_variance | -8.58e-06 |
| fps                | 466       |
| nupdates           | 2400      |
| policy_entropy     | 0.968     |
| total_timesteps    | 12000     |
| value_loss         | 418       |
----------------------------------
---------------------------------
| ep_len_mean        | 120      |
| ep_reward_mean     | -196     |
| explained_variance | -0.0022  |
| fps                | 466      |
| nupdates           | 2500     |
| policy_entropy     | 0.776    |
| total_timesteps    | 12500    |
| value_loss         | 53.8     |
---------------------------------
25.0
25.0
64.19
13.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 64.2     |
| ep_reward_mean     | 20.9     |
| explained_variance | 0.00303  |
| fps                | 466      |
| nupdates           | 2600     |
| policy_entropy     | 0.566    |
| total_timesteps    | 13000    |
| value_loss         | 259      |
---------------------------------
---------------------------------
| ep_len_mean        | 44.5     |
| ep_reward_mean     | 99.3     |
| explained_variance | 0.00179  |
| fps                | 467      |
| nupdates           | 2700     |
| policy_entropy     | 0.705    |
| total_timesteps    | 13500    |
| value_loss         | 116      |
---------------------------------
11.0
11.0
34.87
18.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 34.9     |
| ep_reward_mean     | 137      |
| explained_variance | 4.77e-07 |
| fps                | 466      |
| nupdates           | 2800     |
| policy_entropy     | 0.368    |
| total_timesteps    | 14000    |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 149      |
| explained_variance | 0.0083   |
| fps                | 461      |
| nupdates           | 2900     |
| policy_entropy     | 0.376    |
| total_timesteps    | 14500    |
| value_loss         | 144      |
---------------------------------
9.0
9.0
30.07
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 30.1      |
| ep_reward_mean     | 153       |
| explained_variance | -1.19e-07 |
| fps                | 461       |
| nupdates           | 3000      |
| policy_entropy     | 0.386     |
| total_timesteps    | 15000     |
| value_loss         | 544       |
----------------------------------
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 148      |
| explained_variance | -0.0437  |
| fps                | 461      |
| nupdates           | 3100     |
| policy_entropy     | 0.32     |
| total_timesteps    | 15500    |
| value_loss         | 34.5     |
---------------------------------
11.0
11.0
27.28
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 27.3     |
| ep_reward_mean     | 160      |
| explained_variance | -0.0183  |
| fps                | 461      |
| nupdates           | 3200     |
| policy_entropy     | 0.24     |
| total_timesteps    | 16000    |
| value_loss         | 6.11e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 29.7     |
| ep_reward_mean     | 153      |
| explained_variance | 0        |
| fps                | 460      |
| nupdates           | 3300     |
| policy_entropy     | 0.0951   |
| total_timesteps    | 16500    |
| value_loss         | 13       |
---------------------------------
10.0
10.0
27.52
12.5
---------------------------------
| ep_len_mean        | 27.5     |
| ep_reward_mean     | 160      |
| explained_variance | 0.00413  |
| fps                | 460      |
| nupdates           | 3400     |
| policy_entropy     | 0.366    |
| total_timesteps    | 17000    |
| value_loss         | 138      |
---------------------------------
---------------------------------
| ep_len_mean        | 28.7     |
| ep_reward_mean     | 160      |
| explained_variance | 1.19e-07 |
| fps                | 460      |
| nupdates           | 3500     |
| policy_entropy     | 0.151    |
| total_timesteps    | 17500    |
| value_loss         | 11.5     |
---------------------------------
62.0
62.0
26.84
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 26.8     |
| ep_reward_mean     | 175      |
| explained_variance | 0        |
| fps                | 460      |
| nupdates           | 3600     |
| policy_entropy     | 0.232    |
| total_timesteps    | 18000    |
| value_loss         | 98       |
---------------------------------
---------------------------------
| ep_len_mean        | 24.6     |
| ep_reward_mean     | 180      |
| explained_variance | -0.0102  |
| fps                | 460      |
| nupdates           | 3700     |
| policy_entropy     | 0.854    |
| total_timesteps    | 18500    |
| value_loss         | 45.6     |
---------------------------------
13.0
13.0
27.15
11.0
---------------------------------
| ep_len_mean        | 27.1     |
| ep_reward_mean     | 172      |
| explained_variance | -0.0129  |
| fps                | 460      |
| nupdates           | 3800     |
| policy_entropy     | 0.425    |
| total_timesteps    | 19000    |
| value_loss         | 93.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 27.1     |
| ep_reward_mean     | 172      |
| explained_variance | 0.00234  |
| fps                | 459      |
| nupdates           | 3900     |
| policy_entropy     | 0.587    |
| total_timesteps    | 19500    |
| value_loss         | 91.2     |
---------------------------------
9.0
9.0
35.32
11.0
---------------------------------
| ep_len_mean        | 35.3     |
| ep_reward_mean     | 138      |
| explained_variance | 0.618    |
| fps                | 459      |
| nupdates           | 4000     |
| policy_entropy     | 0.245    |
| total_timesteps    | 20000    |
| value_loss         | 62.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 36.6     |
| ep_reward_mean     | 135      |
| explained_variance | -5.74    |
| fps                | 460      |
| nupdates           | 4100     |
| policy_entropy     | 0.27     |
| total_timesteps    | 20500    |
| value_loss         | 122      |
---------------------------------
27.0
27.0
32.04
10.5
---------------------------------
| ep_len_mean        | 32       |
| ep_reward_mean     | 142      |
| explained_variance | -0.0215  |
| fps                | 460      |
| nupdates           | 4200     |
| policy_entropy     | 0.526    |
| total_timesteps    | 21000    |
| value_loss         | 5.63e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 36       |
| ep_reward_mean     | 134      |
| explained_variance | -0.0143  |
| fps                | 460      |
| nupdates           | 4300     |
| policy_entropy     | 0.184    |
| total_timesteps    | 21500    |
| value_loss         | 5.87e+04 |
---------------------------------
9.0
9.0
33.86
11.0
---------------------------------
| ep_len_mean        | 33.9     |
| ep_reward_mean     | 145      |
| explained_variance | 0        |
| fps                | 459      |
| nupdates           | 4400     |
| policy_entropy     | 0.225    |
| total_timesteps    | 22000    |
| value_loss         | 7.31     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 189      |
| explained_variance | 0        |
| fps                | 460      |
| nupdates           | 4500     |
| policy_entropy     | 0.393    |
| total_timesteps    | 22500    |
| value_loss         | 7.13     |
---------------------------------
19.0
19.0
21.3
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 186      |
| explained_variance | -5.8     |
| fps                | 460      |
| nupdates           | 4600     |
| policy_entropy     | 0.174    |
| total_timesteps    | 23000    |
| value_loss         | 40.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 196      |
| explained_variance | -3.51    |
| fps                | 459      |
| nupdates           | 4700     |
| policy_entropy     | 0.163    |
| total_timesteps    | 23500    |
| value_loss         | 27       |
---------------------------------
13.0
13.0
12.14
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 207      |
| explained_variance | -0.0907  |
| fps                | 459      |
| nupdates           | 4800     |
| policy_entropy     | 0.135    |
| total_timesteps    | 24000    |
| value_loss         | 121      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 208      |
| explained_variance | -31      |
| fps                | 460      |
| nupdates           | 4900     |
| policy_entropy     | 0.177    |
| total_timesteps    | 24500    |
| value_loss         | 147      |
---------------------------------
14.0
14.0
14.25
9.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 203      |
| explained_variance | 0        |
| fps                | 460      |
| nupdates           | 5000     |
| policy_entropy     | 0.442    |
| total_timesteps    | 25000    |
| value_loss         | 125      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 198      |
| explained_variance | -0.164   |
| fps                | 460      |
| nupdates           | 5100     |
| policy_entropy     | 0.165    |
| total_timesteps    | 25500    |
| value_loss         | 2.4e+04  |
---------------------------------
9.0
9.0
18.59
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 189      |
| explained_variance | 0.708    |
| fps                | 460      |
| nupdates           | 5200     |
| policy_entropy     | 0.19     |
| total_timesteps    | 26000    |
| value_loss         | 330      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 190      |
| explained_variance | -0.361   |
| fps                | 460      |
| nupdates           | 5300     |
| policy_entropy     | 0.334    |
| total_timesteps    | 26500    |
| value_loss         | 97.4     |
---------------------------------
18.0
18.0
18.23
10.0
----------------------------------
| ep_len_mean        | 18.2      |
| ep_reward_mean     | 191       |
| explained_variance | -1.19e-07 |
| fps                | 460       |
| nupdates           | 5400      |
| policy_entropy     | 0.42      |
| total_timesteps    | 27000     |
| value_loss         | 7.13      |
----------------------------------
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 187      |
| explained_variance | -0.612   |
| fps                | 460      |
| nupdates           | 5500     |
| policy_entropy     | 0.617    |
| total_timesteps    | 27500    |
| value_loss         | 211      |
---------------------------------
11.0
11.0
18.32
16.5
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 196      |
| explained_variance | 0.665    |
| fps                | 461      |
| nupdates           | 5600     |
| policy_entropy     | 0.152    |
| total_timesteps    | 28000    |
| value_loss         | 39.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 194      |
| explained_variance | 0.0629   |
| fps                | 461      |
| nupdates           | 5700     |
| policy_entropy     | 0.494    |
| total_timesteps    | 28500    |
| value_loss         | 1.81e+04 |
---------------------------------
42.0
42.0
17.23
12.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 197      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 5800     |
| policy_entropy     | 0.529    |
| total_timesteps    | 29000    |
| value_loss         | 12.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 199      |
| explained_variance | -0.125   |
| fps                | 461      |
| nupdates           | 5900     |
| policy_entropy     | 0.162    |
| total_timesteps    | 29500    |
| value_loss         | 5.6e+04  |
---------------------------------
11.0
11.0
15.52
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 200      |
| explained_variance | -0.683   |
| fps                | 461      |
| nupdates           | 6000     |
| policy_entropy     | 0.639    |
| total_timesteps    | 30000    |
| value_loss         | 42.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 199      |
| explained_variance | -18.8    |
| fps                | 461      |
| nupdates           | 6100     |
| policy_entropy     | 0.586    |
| total_timesteps    | 30500    |
| value_loss         | 232      |
---------------------------------
14.0
14.0
17.51
13.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 197      |
| explained_variance | -0.789   |
| fps                | 461      |
| nupdates           | 6200     |
| policy_entropy     | 0.488    |
| total_timesteps    | 31000    |
| value_loss         | 183      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 196      |
| explained_variance | -0.0088  |
| fps                | 462      |
| nupdates           | 6300     |
| policy_entropy     | 0.101    |
| total_timesteps    | 31500    |
| value_loss         | 1.7e+04  |
---------------------------------
10.0
10.0
16.75
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 200      |
| explained_variance | 0.195    |
| fps                | 462      |
| nupdates           | 6400     |
| policy_entropy     | 0.197    |
| total_timesteps    | 32000    |
| value_loss         | 2.77e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 205      |
| explained_variance | -0.539   |
| fps                | 462      |
| nupdates           | 6500     |
| policy_entropy     | 0.404    |
| total_timesteps    | 32500    |
| value_loss         | 74.9     |
---------------------------------
10.0
10.0
13.66
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 207      |
| explained_variance | -0.809   |
| fps                | 462      |
| nupdates           | 6600     |
| policy_entropy     | 0.479    |
| total_timesteps    | 33000    |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 206      |
| explained_variance | -0.16    |
| fps                | 462      |
| nupdates           | 6700     |
| policy_entropy     | 0.317    |
| total_timesteps    | 33500    |
| value_loss         | 1.61e+04 |
---------------------------------
83.0
83.0
16.45
10.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 203      |
| explained_variance | -0.98    |
| fps                | 462      |
| nupdates           | 6800     |
| policy_entropy     | 0.0673   |
| total_timesteps    | 34000    |
| value_loss         | 38.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 201      |
| explained_variance | 0.0381   |
| fps                | 462      |
| nupdates           | 6900     |
| policy_entropy     | 0.131    |
| total_timesteps    | 34500    |
| value_loss         | 1.42e+04 |
---------------------------------
10.0
10.0
17.2
10.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 202      |
| explained_variance | -3.12    |
| fps                | 462      |
| nupdates           | 7000     |
| policy_entropy     | 0.399    |
| total_timesteps    | 35000    |
| value_loss         | 215      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 199      |
| explained_variance | -0.482   |
| fps                | 462      |
| nupdates           | 7100     |
| policy_entropy     | 0.0724   |
| total_timesteps    | 35500    |
| value_loss         | 4.14e+03 |
---------------------------------
31.0
31.0
16.81
10.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 201      |
| explained_variance | -0.114   |
| fps                | 462      |
| nupdates           | 7200     |
| policy_entropy     | 0.208    |
| total_timesteps    | 36000    |
| value_loss         | 7.24e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 205      |
| explained_variance | -0.098   |
| fps                | 462      |
| nupdates           | 7300     |
| policy_entropy     | 0.0805   |
| total_timesteps    | 36500    |
| value_loss         | 6.5e+03  |
---------------------------------
10.0
10.0
15.37
12.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.38     |
| fps                | 462      |
| nupdates           | 7400     |
| policy_entropy     | 0.118    |
| total_timesteps    | 37000    |
| value_loss         | 139      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 199      |
| explained_variance | -7.56    |
| fps                | 462      |
| nupdates           | 7500     |
| policy_entropy     | 0.459    |
| total_timesteps    | 37500    |
| value_loss         | 2.84e+04 |
---------------------------------
46.0
46.0
17.66
11.0
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 198      |
| explained_variance | 0.675    |
| fps                | 462      |
| nupdates           | 7600     |
| policy_entropy     | 0.0756   |
| total_timesteps    | 38000    |
| value_loss         | 325      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 193      |
| explained_variance | 0.00483  |
| fps                | 462      |
| nupdates           | 7700     |
| policy_entropy     | 0.131    |
| total_timesteps    | 38500    |
| value_loss         | 386      |
---------------------------------
10.0
10.0
14.72
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 203      |
| explained_variance | 0.536    |
| fps                | 462      |
| nupdates           | 7800     |
| policy_entropy     | 0.0752   |
| total_timesteps    | 39000    |
| value_loss         | 40.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 202      |
| explained_variance | -0.176   |
| fps                | 462      |
| nupdates           | 7900     |
| policy_entropy     | 0.207    |
| total_timesteps    | 39500    |
| value_loss         | 5.17e+03 |
---------------------------------
29.0
29.0
15.15
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 204      |
| explained_variance | -0.071   |
| fps                | 462      |
| nupdates           | 8000     |
| policy_entropy     | 0.298    |
| total_timesteps    | 40000    |
| value_loss         | 4.82e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 202      |
| explained_variance | 0.845    |
| fps                | 462      |
| nupdates           | 8100     |
| policy_entropy     | 0.0603   |
| total_timesteps    | 40500    |
| value_loss         | 17.7     |
---------------------------------
10.0
10.0
17.26
10.5
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 200      |
| explained_variance | 0.155    |
| fps                | 462      |
| nupdates           | 8200     |
| policy_entropy     | 0.0557   |
| total_timesteps    | 41000    |
| value_loss         | 23.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 202      |
| explained_variance | 0.29     |
| fps                | 462      |
| nupdates           | 8300     |
| policy_entropy     | 0.0436   |
| total_timesteps    | 41500    |
| value_loss         | 677      |
---------------------------------
20.0
20.0
18.7
10.5
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 197      |
| explained_variance | -0.827   |
| fps                | 462      |
| nupdates           | 8400     |
| policy_entropy     | 0.113    |
| total_timesteps    | 42000    |
| value_loss         | 3.76e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 202      |
| explained_variance | -0.865   |
| fps                | 463      |
| nupdates           | 8500     |
| policy_entropy     | 0.429    |
| total_timesteps    | 42500    |
| value_loss         | 238      |
---------------------------------
12.0
12.0
16.73
11.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 204      |
| explained_variance | -0.163   |
| fps                | 463      |
| nupdates           | 8600     |
| policy_entropy     | 0.525    |
| total_timesteps    | 43000    |
| value_loss         | 54.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.165    |
| fps                | 463      |
| nupdates           | 8700     |
| policy_entropy     | 0.185    |
| total_timesteps    | 43500    |
| value_loss         | 97.3     |
---------------------------------
10.0
10.0
17.19
11.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 204      |
| explained_variance | 0.0337   |
| fps                | 463      |
| nupdates           | 8800     |
| policy_entropy     | 0.115    |
| total_timesteps    | 44000    |
| value_loss         | 4.43e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 204      |
| explained_variance | 0.184    |
| fps                | 462      |
| nupdates           | 8900     |
| policy_entropy     | 0.0544   |
| total_timesteps    | 44500    |
| value_loss         | 3.5e+03  |
---------------------------------
9.0
9.0
17.01
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 203      |
| explained_variance | -1.31    |
| fps                | 463      |
| nupdates           | 9000     |
| policy_entropy     | 0.206    |
| total_timesteps    | 45000    |
| value_loss         | 3.7e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 205      |
| explained_variance | 0.271    |
| fps                | 463      |
| nupdates           | 9100     |
| policy_entropy     | 0.0872   |
| total_timesteps    | 45500    |
| value_loss         | 1.06e+03 |
---------------------------------
10.0
10.0
15.14
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0        |
| fps                | 463      |
| nupdates           | 9200     |
| policy_entropy     | 0.251    |
| total_timesteps    | 46000    |
| value_loss         | 58.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 202      |
| explained_variance | 0.697    |
| fps                | 463      |
| nupdates           | 9300     |
| policy_entropy     | 0.449    |
| total_timesteps    | 46500    |
| value_loss         | 54.5     |
---------------------------------
11.0
11.0
16.73
11.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 200      |
| explained_variance | -2.9     |
| fps                | 463      |
| nupdates           | 9400     |
| policy_entropy     | 0.0371   |
| total_timesteps    | 47000    |
| value_loss         | 713      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 200      |
| explained_variance | -0.507   |
| fps                | 463      |
| nupdates           | 9500     |
| policy_entropy     | 0.0784   |
| total_timesteps    | 47500    |
| value_loss         | 40.6     |
---------------------------------
10.0
10.0
16.22
11.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 202      |
| explained_variance | 0.424    |
| fps                | 463      |
| nupdates           | 9600     |
| policy_entropy     | 0.178    |
| total_timesteps    | 48000    |
| value_loss         | 84.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 204      |
| explained_variance | -3.55    |
| fps                | 463      |
| nupdates           | 9700     |
| policy_entropy     | 0.129    |
| total_timesteps    | 48500    |
| value_loss         | 8.39e+03 |
---------------------------------
10.0
10.0
16.03
11.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 203      |
| explained_variance | -0.0627  |
| fps                | 463      |
| nupdates           | 9800     |
| policy_entropy     | 0.239    |
| total_timesteps    | 49000    |
| value_loss         | 301      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 463      |
| nupdates           | 9900     |
| policy_entropy     | 0.258    |
| total_timesteps    | 49500    |
| value_loss         | 74.9     |
---------------------------------
9.0
9.0
14.48
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 207      |
| explained_variance | -0.0186  |
| fps                | 463      |
| nupdates           | 10000    |
| policy_entropy     | 0.073    |
| total_timesteps    | 50000    |
| value_loss         | 1.56e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 207      |
| explained_variance | 0        |
| fps                | 463      |
| nupdates           | 10100    |
| policy_entropy     | 0.288    |
| total_timesteps    | 50500    |
| value_loss         | 104      |
---------------------------------
9.0
9.0
14.04
9.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 206      |
| explained_variance | 0.77     |
| fps                | 463      |
| nupdates           | 10200    |
| policy_entropy     | 0.0443   |
| total_timesteps    | 51000    |
| value_loss         | 2.56e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 206      |
| explained_variance | -0.132   |
| fps                | 463      |
| nupdates           | 10300    |
| policy_entropy     | 0.0658   |
| total_timesteps    | 51500    |
| value_loss         | 1.7e+03  |
---------------------------------
9.0
9.0
16.12
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0.622    |
| fps                | 463      |
| nupdates           | 10400    |
| policy_entropy     | 0.0531   |
| total_timesteps    | 52000    |
| value_loss         | 48.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 206      |
| explained_variance | -0.102   |
| fps                | 463      |
| nupdates           | 10500    |
| policy_entropy     | 0.0761   |
| total_timesteps    | 52500    |
| value_loss         | 1.14e+03 |
---------------------------------
10.0
10.0
14.66
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 207      |
| explained_variance | -36.8    |
| fps                | 463      |
| nupdates           | 10600    |
| policy_entropy     | 0.394    |
| total_timesteps    | 53000    |
| value_loss         | 1.05e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 210      |
| explained_variance | 0.495    |
| fps                | 463      |
| nupdates           | 10700    |
| policy_entropy     | 0.112    |
| total_timesteps    | 53500    |
| value_loss         | 67.3     |
---------------------------------
10.0
10.0
15.06
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 209      |
| explained_variance | -1.54    |
| fps                | 463      |
| nupdates           | 10800    |
| policy_entropy     | 0.531    |
| total_timesteps    | 54000    |
| value_loss         | 582      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 204      |
| explained_variance | 0.901    |
| fps                | 463      |
| nupdates           | 10900    |
| policy_entropy     | 0.0446   |
| total_timesteps    | 54500    |
| value_loss         | 1.75e+03 |
---------------------------------
27.0
27.0
15.49
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 204      |
| explained_variance | -2.94    |
| fps                | 463      |
| nupdates           | 11000    |
| policy_entropy     | 0.251    |
| total_timesteps    | 55000    |
| value_loss         | 290      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0631   |
| fps                | 463      |
| nupdates           | 11100    |
| policy_entropy     | 0.123    |
| total_timesteps    | 55500    |
| value_loss         | 922      |
---------------------------------
11.0
11.0
15.87
11.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 201      |
| explained_variance | 0.495    |
| fps                | 463      |
| nupdates           | 11200    |
| policy_entropy     | 0.0289   |
| total_timesteps    | 56000    |
| value_loss         | 3.52e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 201      |
| explained_variance | 0.84     |
| fps                | 463      |
| nupdates           | 11300    |
| policy_entropy     | 0.0413   |
| total_timesteps    | 56500    |
| value_loss         | 10.7     |
---------------------------------
10.0
10.0
16.47
10.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.491    |
| fps                | 463      |
| nupdates           | 11400    |
| policy_entropy     | 0.395    |
| total_timesteps    | 57000    |
| value_loss         | 125      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 202      |
| explained_variance | 0        |
| fps                | 464      |
| nupdates           | 11500    |
| policy_entropy     | 0.548    |
| total_timesteps    | 57500    |
| value_loss         | 77       |
---------------------------------
9.0
9.0
15.43
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.93     |
| fps                | 464      |
| nupdates           | 11600    |
| policy_entropy     | 0.0763   |
| total_timesteps    | 58000    |
| value_loss         | 11.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.621    |
| fps                | 464      |
| nupdates           | 11700    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 58500    |
| value_loss         | 696      |
---------------------------------
9.0
9.0
15.33
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 203      |
| explained_variance | 0.025    |
| fps                | 463      |
| nupdates           | 11800    |
| policy_entropy     | 0.024    |
| total_timesteps    | 59000    |
| value_loss         | 520      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0        |
| fps                | 463      |
| nupdates           | 11900    |
| policy_entropy     | 0.329    |
| total_timesteps    | 59500    |
| value_loss         | 87.8     |
---------------------------------
21.0
21.0
16.69
16.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 199      |
| explained_variance | 0.875    |
| fps                | 463      |
| nupdates           | 12000    |
| policy_entropy     | 0.0483   |
| total_timesteps    | 60000    |
| value_loss         | 14.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 202      |
| explained_variance | 0.692    |
| fps                | 463      |
| nupdates           | 12100    |
| policy_entropy     | 0.0404   |
| total_timesteps    | 60500    |
| value_loss         | 25.3     |
---------------------------------
9.0
9.0
15.87
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 205      |
| explained_variance | 0.965    |
| fps                | 463      |
| nupdates           | 12200    |
| policy_entropy     | 0.0314   |
| total_timesteps    | 61000    |
| value_loss         | 9.95     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.876    |
| fps                | 464      |
| nupdates           | 12300    |
| policy_entropy     | 0.0287   |
| total_timesteps    | 61500    |
| value_loss         | 20.4     |
---------------------------------
21.0
21.0
15.81
23.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.74     |
| fps                | 464      |
| nupdates           | 12400    |
| policy_entropy     | 0.0345   |
| total_timesteps    | 62000    |
| value_loss         | 16.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 204      |
| explained_variance | -0.109   |
| fps                | 464      |
| nupdates           | 12500    |
| policy_entropy     | 0.435    |
| total_timesteps    | 62500    |
| value_loss         | 51.3     |
---------------------------------
10.0
10.0
16.49
10.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.192    |
| fps                | 464      |
| nupdates           | 12600    |
| policy_entropy     | 0.118    |
| total_timesteps    | 63000    |
| value_loss         | 461      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 210      |
| explained_variance | -0.838   |
| fps                | 464      |
| nupdates           | 12700    |
| policy_entropy     | 0.596    |
| total_timesteps    | 63500    |
| value_loss         | 89.1     |
---------------------------------
10.0
10.0
13.36
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.244    |
| fps                | 464      |
| nupdates           | 12800    |
| policy_entropy     | 0.205    |
| total_timesteps    | 64000    |
| value_loss         | 70.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 208      |
| explained_variance | -0.691   |
| fps                | 464      |
| nupdates           | 12900    |
| policy_entropy     | 0.0793   |
| total_timesteps    | 64500    |
| value_loss         | 318      |
---------------------------------
10.0
10.0
14.71
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 206      |
| explained_variance | -3.21    |
| fps                | 464      |
| nupdates           | 13000    |
| policy_entropy     | 0.202    |
| total_timesteps    | 65000    |
| value_loss         | 268      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | -30.2    |
| fps                | 463      |
| nupdates           | 13100    |
| policy_entropy     | 0.276    |
| total_timesteps    | 65500    |
| value_loss         | 1.13e+03 |
---------------------------------
11.0
11.0
14.54
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 207      |
| explained_variance | 0.382    |
| fps                | 463      |
| nupdates           | 13200    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 66000    |
| value_loss         | 235      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 205      |
| explained_variance | 0.83     |
| fps                | 463      |
| nupdates           | 13300    |
| policy_entropy     | 0.0166   |
| total_timesteps    | 66500    |
| value_loss         | 14.9     |
---------------------------------
10.0
10.0
15.55
10.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 204      |
| explained_variance | -3.61    |
| fps                | 463      |
| nupdates           | 13400    |
| policy_entropy     | 0.264    |
| total_timesteps    | 67000    |
| value_loss         | 585      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 206      |
| explained_variance | 0.874    |
| fps                | 463      |
| nupdates           | 13500    |
| policy_entropy     | 0.023    |
| total_timesteps    | 67500    |
| value_loss         | 3.85     |
---------------------------------
35.0
35.0
14.3
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 208      |
| explained_variance | -1.59    |
| fps                | 463      |
| nupdates           | 13600    |
| policy_entropy     | 0.0896   |
| total_timesteps    | 68000    |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.71     |
| fps                | 463      |
| nupdates           | 13700    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 68500    |
| value_loss         | 84.3     |
---------------------------------
10.0
10.0
16.0
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 204      |
| explained_variance | 0.0934   |
| fps                | 463      |
| nupdates           | 13800    |
| policy_entropy     | 0.0278   |
| total_timesteps    | 69000    |
| value_loss         | 181      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 206      |
| explained_variance | 0        |
| fps                | 463      |
| nupdates           | 13900    |
| policy_entropy     | 0.535    |
| total_timesteps    | 69500    |
| value_loss         | 144      |
---------------------------------
10.0
10.0
13.39
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 211      |
| explained_variance | -1.87    |
| fps                | 463      |
| nupdates           | 14000    |
| policy_entropy     | 0.0785   |
| total_timesteps    | 70000    |
| value_loss         | 79.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.183    |
| fps                | 463      |
| nupdates           | 14100    |
| policy_entropy     | 0.0541   |
| total_timesteps    | 70500    |
| value_loss         | 121      |
---------------------------------
10.0
10.0
13.74
9.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 208      |
| explained_variance | -1.14    |
| fps                | 463      |
| nupdates           | 14200    |
| policy_entropy     | 0.158    |
| total_timesteps    | 71000    |
| value_loss         | 182      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 208      |
| explained_variance | -1.57    |
| fps                | 463      |
| nupdates           | 14300    |
| policy_entropy     | 0.421    |
| total_timesteps    | 71500    |
| value_loss         | 215      |
---------------------------------
23.0
23.0
14.05
11.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0.89     |
| fps                | 463      |
| nupdates           | 14400    |
| policy_entropy     | 0.0332   |
| total_timesteps    | 72000    |
| value_loss         | 52.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.905    |
| fps                | 463      |
| nupdates           | 14500    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 72500    |
| value_loss         | 7.82     |
---------------------------------
9.0
9.0
14.35
9.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.873    |
| fps                | 463      |
| nupdates           | 14600    |
| policy_entropy     | 0.0118   |
| total_timesteps    | 73000    |
| value_loss         | 12.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 208      |
| explained_variance | 0.974    |
| fps                | 463      |
| nupdates           | 14700    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 73500    |
| value_loss         | 2.08     |
---------------------------------
10.0
10.0
15.07
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 205      |
| explained_variance | 0.693    |
| fps                | 463      |
| nupdates           | 14800    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 74000    |
| value_loss         | 18.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 202      |
| explained_variance | 0.472    |
| fps                | 463      |
| nupdates           | 14900    |
| policy_entropy     | 0.097    |
| total_timesteps    | 74500    |
| value_loss         | 961      |
---------------------------------
11.0
11.0
16.49
10.5
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 201      |
| explained_variance | 0.135    |
| fps                | 463      |
| nupdates           | 15000    |
| policy_entropy     | 0.421    |
| total_timesteps    | 75000    |
| value_loss         | 1.23e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 203      |
| explained_variance | 0.136    |
| fps                | 463      |
| nupdates           | 15100    |
| policy_entropy     | 0.168    |
| total_timesteps    | 75500    |
| value_loss         | 78.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0.389    |
| fps                | 463      |
| nupdates           | 15300    |
| policy_entropy     | 0.375    |
| total_timesteps    | 76500    |
| value_loss         | 339      |
---------------------------------
9.0
9.0
15.21
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.966    |
| fps                | 463      |
| nupdates           | 15400    |
| policy_entropy     | 0.0772   |
| total_timesteps    | 77000    |
| value_loss         | 124      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 205      |
| explained_variance | 0.59     |
| fps                | 463      |
| nupdates           | 15500    |
| policy_entropy     | 0.0201   |
| total_timesteps    | 77500    |
| value_loss         | 47.8     |
---------------------------------
10.0
10.0
15.09
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0.786    |
| fps                | 463      |
| nupdates           | 15600    |
| policy_entropy     | 0.0241   |
| total_timesteps    | 78000    |
| value_loss         | 48       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 206      |
| explained_variance | -0.221   |
| fps                | 463      |
| nupdates           | 15700    |
| policy_entropy     | 0.072    |
| total_timesteps    | 78500    |
| value_loss         | 121      |
---------------------------------
27.0
27.0
15.35
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 205      |
| explained_variance | -3.64    |
| fps                | 463      |
| nupdates           | 15800    |
| policy_entropy     | 0.331    |
| total_timesteps    | 79000    |
| value_loss         | 924      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 202      |
| explained_variance | 0.844    |
| fps                | 463      |
| nupdates           | 15900    |
| policy_entropy     | 0.0459   |
| total_timesteps    | 79500    |
| value_loss         | 16.7     |
---------------------------------
10.0
10.0
15.08
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 203      |
| explained_variance | 0.919    |
| fps                | 463      |
| nupdates           | 16000    |
| policy_entropy     | 0.0601   |
| total_timesteps    | 80000    |
| value_loss         | 2.02     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.994    |
| fps                | 463      |
| nupdates           | 16100    |
| policy_entropy     | 0.024    |
| total_timesteps    | 80500    |
| value_loss         | 2.11     |
---------------------------------
10.0
10.0
13.75
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.0607   |
| fps                | 463      |
| nupdates           | 16200    |
| policy_entropy     | 0.0383   |
| total_timesteps    | 81000    |
| value_loss         | 117      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 208      |
| explained_variance | -0.708   |
| fps                | 463      |
| nupdates           | 16300    |
| policy_entropy     | 0.291    |
| total_timesteps    | 81500    |
| value_loss         | 314      |
---------------------------------
9.0
9.0
14.66
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 205      |
| explained_variance | 0.011    |
| fps                | 463      |
| nupdates           | 16400    |
| policy_entropy     | 0.159    |
| total_timesteps    | 82000    |
| value_loss         | 43.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.997    |
| fps                | 463      |
| nupdates           | 16500    |
| policy_entropy     | 0.0371   |
| total_timesteps    | 82500    |
| value_loss         | 0.564    |
---------------------------------
10.0
10.0
14.08
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 207      |
| explained_variance | -1.17    |
| fps                | 463      |
| nupdates           | 16600    |
| policy_entropy     | 0.259    |
| total_timesteps    | 83000    |
| value_loss         | 607      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 207      |
| explained_variance | -2.26    |
| fps                | 463      |
| nupdates           | 16700    |
| policy_entropy     | 0.214    |
| total_timesteps    | 83500    |
| value_loss         | 1.13e+03 |
---------------------------------
9.0
9.0
14.66
9.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 207      |
| explained_variance | 0.993    |
| fps                | 463      |
| nupdates           | 16800    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 84000    |
| value_loss         | 0.336    |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.306    |
| fps                | 463      |
| nupdates           | 16900    |
| policy_entropy     | 0.206    |
| total_timesteps    | 84500    |
| value_loss         | 220      |
---------------------------------
9.0
9.0
13.36
9.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 209      |
| explained_variance | -0.911   |
| fps                | 463      |
| nupdates           | 17000    |
| policy_entropy     | 0.201    |
| total_timesteps    | 85000    |
| value_loss         | 247      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.336    |
| fps                | 463      |
| nupdates           | 17100    |
| policy_entropy     | 0.345    |
| total_timesteps    | 85500    |
| value_loss         | 195      |
---------------------------------
10.0
10.0
14.45
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0        |
| fps                | 463      |
| nupdates           | 17200    |
| policy_entropy     | 0.279    |
| total_timesteps    | 86000    |
| value_loss         | 126      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.891    |
| fps                | 462      |
| nupdates           | 17300    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 86500    |
| value_loss         | 4.12     |
---------------------------------
9.0
9.0
13.89
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.969    |
| fps                | 462      |
| nupdates           | 17400    |
| policy_entropy     | 0.017    |
| total_timesteps    | 87000    |
| value_loss         | 1.01     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.967    |
| fps                | 461      |
| nupdates           | 17500    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 87500    |
| value_loss         | 11.1     |
---------------------------------
10.0
10.0
13.79
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.569    |
| fps                | 461      |
| nupdates           | 17600    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 88000    |
| value_loss         | 54.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 17700    |
| policy_entropy     | 0.335    |
| total_timesteps    | 88500    |
| value_loss         | 140      |
---------------------------------
11.0
11.0
13.29
10.5
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.604    |
| fps                | 461      |
| nupdates           | 17800    |
| policy_entropy     | 0.0303   |
| total_timesteps    | 89000    |
| value_loss         | 55.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.174    |
| fps                | 460      |
| nupdates           | 17900    |
| policy_entropy     | 0.0984   |
| total_timesteps    | 89500    |
| value_loss         | 102      |
---------------------------------
10.0
10.0
13.77
10.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.988    |
| fps                | 460      |
| nupdates           | 18000    |
| policy_entropy     | 0.0181   |
| total_timesteps    | 90000    |
| value_loss         | 2.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.64     |
| fps                | 458      |
| nupdates           | 18100    |
| policy_entropy     | 0.00785  |
| total_timesteps    | 90500    |
| value_loss         | 1.55e+03 |
---------------------------------
11.0
11.0
14.76
17.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 203      |
| explained_variance | 0.421    |
| fps                | 458      |
| nupdates           | 18200    |
| policy_entropy     | 0.0129   |
| total_timesteps    | 91000    |
| value_loss         | 293      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 204      |
| explained_variance | 0.551    |
| fps                | 458      |
| nupdates           | 18300    |
| policy_entropy     | 0.036    |
| total_timesteps    | 91500    |
| value_loss         | 25.1     |
---------------------------------
44.0
44.0
13.57
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 206      |
| explained_variance | 0.967    |
| fps                | 456      |
| nupdates           | 18400    |
| policy_entropy     | 0.00738  |
| total_timesteps    | 92000    |
| value_loss         | 5.24     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.988    |
| fps                | 456      |
| nupdates           | 18500    |
| policy_entropy     | 0.012    |
| total_timesteps    | 92500    |
| value_loss         | 1.06     |
---------------------------------
23.0
23.0
11.79
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.921    |
| fps                | 456      |
| nupdates           | 18600    |
| policy_entropy     | 0.0527   |
| total_timesteps    | 93000    |
| value_loss         | 15.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.595    |
| fps                | 456      |
| nupdates           | 18700    |
| policy_entropy     | 0.017    |
| total_timesteps    | 93500    |
| value_loss         | 50.1     |
---------------------------------
10.0
10.0
13.54
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.708    |
| fps                | 456      |
| nupdates           | 18800    |
| policy_entropy     | 0.026    |
| total_timesteps    | 94000    |
| value_loss         | 21.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.666    |
| fps                | 456      |
| nupdates           | 18900    |
| policy_entropy     | 0.141    |
| total_timesteps    | 94500    |
| value_loss         | 9.33     |
---------------------------------
24.0
24.0
13.04
10.0
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 211      |
| explained_variance | 0.962    |
| fps                | 456      |
| nupdates           | 19000    |
| policy_entropy     | 0.0142   |
| total_timesteps    | 95000    |
| value_loss         | 1.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.847    |
| fps                | 456      |
| nupdates           | 19100    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 95500    |
| value_loss         | 5.76     |
---------------------------------
9.0
9.0
12.22
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.954    |
| fps                | 456      |
| nupdates           | 19200    |
| policy_entropy     | 0.013    |
| total_timesteps    | 96000    |
| value_loss         | 1.49     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.779    |
| fps                | 456      |
| nupdates           | 19300    |
| policy_entropy     | 0.0586   |
| total_timesteps    | 96500    |
| value_loss         | 15       |
---------------------------------
10.0
10.0
12.7
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.12     |
| fps                | 456      |
| nupdates           | 19400    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 97000    |
| value_loss         | 13.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 211      |
| explained_variance | -0.235   |
| fps                | 456      |
| nupdates           | 19500    |
| policy_entropy     | 0.0194   |
| total_timesteps    | 97500    |
| value_loss         | 18.2     |
---------------------------------
24.0
24.0
13.05
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.0706   |
| fps                | 456      |
| nupdates           | 19600    |
| policy_entropy     | 0.267    |
| total_timesteps    | 98000    |
| value_loss         | 218      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 207      |
| explained_variance | 0.922    |
| fps                | 456      |
| nupdates           | 19700    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 98500    |
| value_loss         | 28.4     |
---------------------------------
10.0
10.0
13.85
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.92     |
| fps                | 456      |
| nupdates           | 19800    |
| policy_entropy     | 0.0163   |
| total_timesteps    | 99000    |
| value_loss         | 2.63     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 207      |
| explained_variance | 0.962    |
| fps                | 455      |
| nupdates           | 19900    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 99500    |
| value_loss         | 3.06     |
---------------------------------
10.0
10.0
13.3
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.89     |
| fps                | 455      |
| nupdates           | 20000    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 100000   |
| value_loss         | 13.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.889    |
| fps                | 455      |
| nupdates           | 20100    |
| policy_entropy     | 0.0141   |
| total_timesteps    | 100500   |
| value_loss         | 8.2      |
---------------------------------
10.0
10.0
13.08
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.633    |
| fps                | 456      |
| nupdates           | 20200    |
| policy_entropy     | 0.0747   |
| total_timesteps    | 101000   |
| value_loss         | 21.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 206      |
| explained_variance | 0.325    |
| fps                | 456      |
| nupdates           | 20300    |
| policy_entropy     | 0.0212   |
| total_timesteps    | 101500   |
| value_loss         | 104      |
---------------------------------
30.0
30.0
14.9
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 205      |
| explained_variance | -0.631   |
| fps                | 456      |
| nupdates           | 20400    |
| policy_entropy     | 0.077    |
| total_timesteps    | 102000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.992    |
| fps                | 456      |
| nupdates           | 20500    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 102500   |
| value_loss         | 0.996    |
---------------------------------
9.0
9.0
13.64
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.98     |
| fps                | 456      |
| nupdates           | 20600    |
| policy_entropy     | 0.00633  |
| total_timesteps    | 103000   |
| value_loss         | 4.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 206      |
| explained_variance | 0.779    |
| fps                | 456      |
| nupdates           | 20700    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 103500   |
| value_loss         | 9.74     |
---------------------------------
10.0
10.0
12.79
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 210      |
| explained_variance | -1.37    |
| fps                | 456      |
| nupdates           | 20800    |
| policy_entropy     | 0.691    |
| total_timesteps    | 104000   |
| value_loss         | 656      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 205      |
| explained_variance | 0.995    |
| fps                | 455      |
| nupdates           | 20900    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 104500   |
| value_loss         | 0.851    |
---------------------------------
11.0
11.0
13.87
10.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 206      |
| explained_variance | 0.996    |
| fps                | 455      |
| nupdates           | 21000    |
| policy_entropy     | 0.0202   |
| total_timesteps    | 105000   |
| value_loss         | 12.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.994    |
| fps                | 454      |
| nupdates           | 21100    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 105500   |
| value_loss         | 1.03     |
---------------------------------
13.0
13.0
12.2
10.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.964    |
| fps                | 454      |
| nupdates           | 21200    |
| policy_entropy     | 0.0477   |
| total_timesteps    | 106000   |
| value_loss         | 1.37     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.986    |
| fps                | 453      |
| nupdates           | 21300    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 106500   |
| value_loss         | 1.17     |
---------------------------------
9.0
9.0
12.5
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.987    |
| fps                | 453      |
| nupdates           | 21400    |
| policy_entropy     | 0.00966  |
| total_timesteps    | 107000   |
| value_loss         | 4.86     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 210      |
| explained_variance | -2.56    |
| fps                | 452      |
| nupdates           | 21500    |
| policy_entropy     | 0.126    |
| total_timesteps    | 107500   |
| value_loss         | 140      |
---------------------------------
10.0
10.0
11.83
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | -3.05    |
| fps                | 451      |
| nupdates           | 21600    |
| policy_entropy     | 0.119    |
| total_timesteps    | 108000   |
| value_loss         | 158      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.396    |
| fps                | 451      |
| nupdates           | 21700    |
| policy_entropy     | 0.138    |
| total_timesteps    | 108500   |
| value_loss         | 440      |
---------------------------------
10.0
10.0
11.45
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.994    |
| fps                | 450      |
| nupdates           | 21800    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 109000   |
| value_loss         | 0.234    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 209      |
| explained_variance | -6.04    |
| fps                | 450      |
| nupdates           | 21900    |
| policy_entropy     | 0.416    |
| total_timesteps    | 109500   |
| value_loss         | 457      |
---------------------------------
22.0
22.0
13.74
11.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 207      |
| explained_variance | -2.69    |
| fps                | 449      |
| nupdates           | 22000    |
| policy_entropy     | 0.282    |
| total_timesteps    | 110000   |
| value_loss         | 170      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0.987    |
| fps                | 449      |
| nupdates           | 22100    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 110500   |
| value_loss         | 0.832    |
---------------------------------
10.0
10.0
12.7
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.98     |
| fps                | 449      |
| nupdates           | 22200    |
| policy_entropy     | 0.0125   |
| total_timesteps    | 111000   |
| value_loss         | 0.685    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.96     |
| fps                | 449      |
| nupdates           | 22300    |
| policy_entropy     | 0.011    |
| total_timesteps    | 111500   |
| value_loss         | 1.69     |
---------------------------------
26.0
26.0
12.63
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.984    |
| fps                | 448      |
| nupdates           | 22400    |
| policy_entropy     | 0.00775  |
| total_timesteps    | 112000   |
| value_loss         | 3.57     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.989    |
| fps                | 448      |
| nupdates           | 22500    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 112500   |
| value_loss         | 0.91     |
---------------------------------
10.0
10.0
11.74
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.158    |
| fps                | 448      |
| nupdates           | 22600    |
| policy_entropy     | 0.0532   |
| total_timesteps    | 113000   |
| value_loss         | 49.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.991    |
| fps                | 448      |
| nupdates           | 22700    |
| policy_entropy     | 0.0197   |
| total_timesteps    | 113500   |
| value_loss         | 4.99     |
---------------------------------
11.0
11.0
12.58
11.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.586    |
| fps                | 448      |
| nupdates           | 22800    |
| policy_entropy     | 0.0235   |
| total_timesteps    | 114000   |
| value_loss         | 13.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.987    |
| fps                | 447      |
| nupdates           | 22900    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 114500   |
| value_loss         | 1.85     |
---------------------------------
9.0
9.0
12.81
9.5
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 212      |
| explained_variance | -0.125   |
| fps                | 447      |
| nupdates           | 23000    |
| policy_entropy     | 0.278    |
| total_timesteps    | 115000   |
| value_loss         | 153      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.79     |
| fps                | 445      |
| nupdates           | 23100    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 115500   |
| value_loss         | 229      |
---------------------------------
10.0
10.0
13.27
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.993    |
| fps                | 444      |
| nupdates           | 23200    |
| policy_entropy     | 0.00628  |
| total_timesteps    | 116000   |
| value_loss         | 1.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 210      |
| explained_variance | 0.976    |
| fps                | 444      |
| nupdates           | 23300    |
| policy_entropy     | 0.0418   |
| total_timesteps    | 116500   |
| value_loss         | 16.4     |
---------------------------------
10.0
10.0
13.23
10.5
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.85     |
| fps                | 444      |
| nupdates           | 23400    |
| policy_entropy     | 0.0118   |
| total_timesteps    | 117000   |
| value_loss         | 4.9      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.994    |
| fps                | 444      |
| nupdates           | 23500    |
| policy_entropy     | 0.0634   |
| total_timesteps    | 117500   |
| value_loss         | 1.27     |
---------------------------------
9.0
9.0
13.91
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.98     |
| fps                | 443      |
| nupdates           | 23600    |
| policy_entropy     | 0.0274   |
| total_timesteps    | 118000   |
| value_loss         | 3.87     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0.99     |
| fps                | 443      |
| nupdates           | 23700    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 118500   |
| value_loss         | 3.04     |
---------------------------------
27.0
27.0
13.26
11.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 210      |
| explained_variance | -0.474   |
| fps                | 443      |
| nupdates           | 23800    |
| policy_entropy     | 0.215    |
| total_timesteps    | 119000   |
| value_loss         | 450      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.726    |
| fps                | 443      |
| nupdates           | 23900    |
| policy_entropy     | 0.224    |
| total_timesteps    | 119500   |
| value_loss         | 155      |
---------------------------------
11.0
11.0
12.8
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.724    |
| fps                | 443      |
| nupdates           | 24000    |
| policy_entropy     | 0.00945  |
| total_timesteps    | 120000   |
| value_loss         | 26.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 208      |
| explained_variance | -1.59    |
| fps                | 443      |
| nupdates           | 24100    |
| policy_entropy     | 0.135    |
| total_timesteps    | 120500   |
| value_loss         | 65.8     |
---------------------------------
10.0
10.0
13.5
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.968    |
| fps                | 443      |
| nupdates           | 24200    |
| policy_entropy     | 0.00963  |
| total_timesteps    | 121000   |
| value_loss         | 3.25     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.9      |
| fps                | 443      |
| nupdates           | 24300    |
| policy_entropy     | 0.031    |
| total_timesteps    | 121500   |
| value_loss         | 5.8      |
---------------------------------
10.0
10.0
11.85
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 11.8      |
| ep_reward_mean     | 213       |
| explained_variance | -1.19e-07 |
| fps                | 443       |
| nupdates           | 24400     |
| policy_entropy     | 0.383     |
| total_timesteps    | 122000    |
| value_loss         | 319       |
----------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.973    |
| fps                | 442      |
| nupdates           | 24500    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 122500   |
| value_loss         | 6.89     |
---------------------------------
20.0
20.0
12.81
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.977    |
| fps                | 441      |
| nupdates           | 24600    |
| policy_entropy     | 0.00606  |
| total_timesteps    | 123000   |
| value_loss         | 4.73     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.993    |
| fps                | 440      |
| nupdates           | 24700    |
| policy_entropy     | 0.00902  |
| total_timesteps    | 123500   |
| value_loss         | 0.415    |
---------------------------------
11.0
11.0
13.8
16.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.877    |
| fps                | 439      |
| nupdates           | 24800    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 124000   |
| value_loss         | 12.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.985    |
| fps                | 438      |
| nupdates           | 24900    |
| policy_entropy     | 0.00965  |
| total_timesteps    | 124500   |
| value_loss         | 2.47     |
---------------------------------
10.0
10.0
12.36
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.994    |
| fps                | 437      |
| nupdates           | 25000    |
| policy_entropy     | 0.019    |
| total_timesteps    | 125000   |
| value_loss         | 1.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.682    |
| fps                | 437      |
| nupdates           | 25100    |
| policy_entropy     | 0.0298   |
| total_timesteps    | 125500   |
| value_loss         | 26.5     |
---------------------------------
10.0
10.0
12.43
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 207      |
| explained_variance | -0.629   |
| fps                | 435      |
| nupdates           | 25200    |
| policy_entropy     | 0.444    |
| total_timesteps    | 126000   |
| value_loss         | 259      |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 208      |
| explained_variance | 0.913    |
| fps                | 434      |
| nupdates           | 25300    |
| policy_entropy     | 0.0719   |
| total_timesteps    | 126500   |
| value_loss         | 9.23     |
---------------------------------
10.0
10.0
13.4
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.991    |
| fps                | 433      |
| nupdates           | 25400    |
| policy_entropy     | 0.00614  |
| total_timesteps    | 127000   |
| value_loss         | 4.19     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | -2.56    |
| fps                | 433      |
| nupdates           | 25500    |
| policy_entropy     | 0.0937   |
| total_timesteps    | 127500   |
| value_loss         | 140      |
---------------------------------
11.0
11.0
13.44
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.981    |
| fps                | 432      |
| nupdates           | 25600    |
| policy_entropy     | 0.00902  |
| total_timesteps    | 128000   |
| value_loss         | 0.925    |
---------------------------------
----------------------------------
| ep_len_mean        | 13.1      |
| ep_reward_mean     | 208       |
| explained_variance | -1.19e-07 |
| fps                | 431       |
| nupdates           | 25700     |
| policy_entropy     | 0.207     |
| total_timesteps    | 128500    |
| value_loss         | 131       |
----------------------------------
10.0
10.0
12.22
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.997    |
| fps                | 430      |
| nupdates           | 25800    |
| policy_entropy     | 0.00851  |
| total_timesteps    | 129000   |
| value_loss         | 0.512    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.98     |
| fps                | 430      |
| nupdates           | 25900    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 129500   |
| value_loss         | 3.04     |
---------------------------------
10.0
10.0
11.79
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.993    |
| fps                | 429      |
| nupdates           | 26000    |
| policy_entropy     | 0.0087   |
| total_timesteps    | 130000   |
| value_loss         | 1.55     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 212      |
| explained_variance | -4.47    |
| fps                | 429      |
| nupdates           | 26100    |
| policy_entropy     | 0.143    |
| total_timesteps    | 130500   |
| value_loss         | 177      |
---------------------------------
73.0
73.0
13.15
10.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 209      |
| explained_variance | -406     |
| fps                | 429      |
| nupdates           | 26200    |
| policy_entropy     | 0.107    |
| total_timesteps    | 131000   |
| value_loss         | 9.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 205      |
| explained_variance | -6.18    |
| fps                | 429      |
| nupdates           | 26300    |
| policy_entropy     | 0.031    |
| total_timesteps    | 131500   |
| value_loss         | 142      |
---------------------------------
10.0
10.0
14.61
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 205      |
| explained_variance | -1.51    |
| fps                | 428      |
| nupdates           | 26400    |
| policy_entropy     | 0.135    |
| total_timesteps    | 132000   |
| value_loss         | 329      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.91     |
| fps                | 428      |
| nupdates           | 26500    |
| policy_entropy     | 0.00651  |
| total_timesteps    | 132500   |
| value_loss         | 4.78     |
---------------------------------
9.0
9.0
11.78
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.977    |
| fps                | 427      |
| nupdates           | 26600    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 133000   |
| value_loss         | 2.78     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.981    |
| fps                | 427      |
| nupdates           | 26700    |
| policy_entropy     | 0.0125   |
| total_timesteps    | 133500   |
| value_loss         | 1.78     |
---------------------------------
9.0
9.0
13.1
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.699   |
| fps                | 427      |
| nupdates           | 26800    |
| policy_entropy     | 0.109    |
| total_timesteps    | 134000   |
| value_loss         | 1.79e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 211      |
| explained_variance | -41.9    |
| fps                | 427      |
| nupdates           | 26900    |
| policy_entropy     | 0.373    |
| total_timesteps    | 134500   |
| value_loss         | 1.44e+03 |
---------------------------------
38.0
38.0
13.29
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 210      |
| explained_variance | -1.44    |
| fps                | 427      |
| nupdates           | 27000    |
| policy_entropy     | 0.277    |
| total_timesteps    | 135000   |
| value_loss         | 279      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.98     |
| fps                | 426      |
| nupdates           | 27100    |
| policy_entropy     | 0.00523  |
| total_timesteps    | 135500   |
| value_loss         | 3.28     |
---------------------------------
10.0
10.0
13.76
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | -3.15    |
| fps                | 426      |
| nupdates           | 27200    |
| policy_entropy     | 0.25     |
| total_timesteps    | 136000   |
| value_loss         | 485      |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 210      |
| explained_variance | 0.986    |
| fps                | 426      |
| nupdates           | 27300    |
| policy_entropy     | 0.0078   |
| total_timesteps    | 136500   |
| value_loss         | 1.09     |
---------------------------------
10.0
10.0
12.7
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | -1.14    |
| fps                | 426      |
| nupdates           | 27400    |
| policy_entropy     | 0.21     |
| total_timesteps    | 137000   |
| value_loss         | 351      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.86     |
| fps                | 426      |
| nupdates           | 27500    |
| policy_entropy     | 0.0669   |
| total_timesteps    | 137500   |
| value_loss         | 14       |
---------------------------------
9.0
9.0
12.76
15.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.862    |
| fps                | 426      |
| nupdates           | 27600    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 138000   |
| value_loss         | 41.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.968    |
| fps                | 425      |
| nupdates           | 27700    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 138500   |
| value_loss         | 5.5      |
---------------------------------
9.0
9.0
12.65
10.5
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 210      |
| explained_variance | -0.281   |
| fps                | 425      |
| nupdates           | 27800    |
| policy_entropy     | 0.305    |
| total_timesteps    | 139000   |
| value_loss         | 67.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 425      |
| nupdates           | 27900    |
| policy_entropy     | 0.48     |
| total_timesteps    | 139500   |
| value_loss         | 110      |
---------------------------------
28.0
28.0
13.0
10.0
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 209      |
| explained_variance | -28.7    |
| fps                | 425      |
| nupdates           | 28000    |
| policy_entropy     | 0.539    |
| total_timesteps    | 140000   |
| value_loss         | 3.6e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.875    |
| fps                | 425      |
| nupdates           | 28100    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 140500   |
| value_loss         | 11.2     |
---------------------------------
9.0
9.0
12.02
15.5
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 212      |
| explained_variance | 0.94     |
| fps                | 425      |
| nupdates           | 28200    |
| policy_entropy     | 0.006    |
| total_timesteps    | 141000   |
| value_loss         | 15.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.762    |
| fps                | 425      |
| nupdates           | 28300    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 141500   |
| value_loss         | 18       |
---------------------------------
20.0
20.0
13.7
10.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 209      |
| explained_variance | 5.96e-08 |
| fps                | 425      |
| nupdates           | 28400    |
| policy_entropy     | 0.354    |
| total_timesteps    | 142000   |
| value_loss         | 132      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.996    |
| fps                | 425      |
| nupdates           | 28500    |
| policy_entropy     | 0.021    |
| total_timesteps    | 142500   |
| value_loss         | 0.992    |
---------------------------------
11.0
11.0
13.14
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.996    |
| fps                | 424      |
| nupdates           | 28600    |
| policy_entropy     | 0.0237   |
| total_timesteps    | 143000   |
| value_loss         | 0.435    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 215      |
| explained_variance | -10.1    |
| fps                | 424      |
| nupdates           | 28700    |
| policy_entropy     | 0.151    |
| total_timesteps    | 143500   |
| value_loss         | 389      |
---------------------------------
10.0
10.0
11.43
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.994    |
| fps                | 424      |
| nupdates           | 28800    |
| policy_entropy     | 0.0708   |
| total_timesteps    | 144000   |
| value_loss         | 1.51     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.994    |
| fps                | 424      |
| nupdates           | 28900    |
| policy_entropy     | 0.00357  |
| total_timesteps    | 144500   |
| value_loss         | 5.05     |
---------------------------------
10.0
10.0
13.93
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 206      |
| explained_variance | 0.324    |
| fps                | 424      |
| nupdates           | 29000    |
| policy_entropy     | 0.199    |
| total_timesteps    | 145000   |
| value_loss         | 40.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 204      |
| explained_variance | 0.995    |
| fps                | 424      |
| nupdates           | 29100    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 145500   |
| value_loss         | 0.848    |
---------------------------------
10.0
10.0
14.53
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 206      |
| explained_variance | -2       |
| fps                | 423      |
| nupdates           | 29200    |
| policy_entropy     | 0.0831   |
| total_timesteps    | 146000   |
| value_loss         | 423      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.803    |
| fps                | 423      |
| nupdates           | 29300    |
| policy_entropy     | 0.146    |
| total_timesteps    | 146500   |
| value_loss         | 28.9     |
---------------------------------
9.0
9.0
12.26
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.987    |
| fps                | 423      |
| nupdates           | 29400    |
| policy_entropy     | 0.0075   |
| total_timesteps    | 147000   |
| value_loss         | 0.566    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 213      |
| explained_variance | -0.027   |
| fps                | 423      |
| nupdates           | 29500    |
| policy_entropy     | 0.126    |
| total_timesteps    | 147500   |
| value_loss         | 14.3     |
---------------------------------
31.0
31.0
12.35
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.933    |
| fps                | 422      |
| nupdates           | 29600    |
| policy_entropy     | 0.00373  |
| total_timesteps    | 148000   |
| value_loss         | 28.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 210      |
| explained_variance | -39.9    |
| fps                | 422      |
| nupdates           | 29700    |
| policy_entropy     | 0.215    |
| total_timesteps    | 148500   |
| value_loss         | 1.99e+03 |
---------------------------------
11.0
11.0
13.23
10.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.984    |
| fps                | 421      |
| nupdates           | 29800    |
| policy_entropy     | 0.00836  |
| total_timesteps    | 149000   |
| value_loss         | 2.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.0968   |
| fps                | 421      |
| nupdates           | 29900    |
| policy_entropy     | 0.365    |
| total_timesteps    | 149500   |
| value_loss         | 297      |
---------------------------------
10.0
10.0
12.56
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.967    |
| fps                | 421      |
| nupdates           | 30000    |
| policy_entropy     | 0.0085   |
| total_timesteps    | 150000   |
| value_loss         | 1.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.989    |
| fps                | 420      |
| nupdates           | 30100    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 150500   |
| value_loss         | 1.16     |
---------------------------------
22.0
22.0
11.97
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 212      |
| explained_variance | 0.979    |
| fps                | 420      |
| nupdates           | 30200    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 151000   |
| value_loss         | 4.31     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.423    |
| fps                | 420      |
| nupdates           | 30300    |
| policy_entropy     | 0.03     |
| total_timesteps    | 151500   |
| value_loss         | 133      |
---------------------------------
20.0
20.0
12.9
10.5
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.5      |
| fps                | 420      |
| nupdates           | 30400    |
| policy_entropy     | 0.14     |
| total_timesteps    | 152000   |
| value_loss         | 52.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.891    |
| fps                | 420      |
| nupdates           | 30500    |
| policy_entropy     | 0.086    |
| total_timesteps    | 152500   |
| value_loss         | 10.3     |
---------------------------------
11.0
11.0
12.12
11.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0.938    |
| fps                | 419      |
| nupdates           | 30600    |
| policy_entropy     | 0.00485  |
| total_timesteps    | 153000   |
| value_loss         | 23.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.983    |
| fps                | 419      |
| nupdates           | 30700    |
| policy_entropy     | 0.00377  |
| total_timesteps    | 153500   |
| value_loss         | 2.32     |
---------------------------------
9.0
9.0
11.94
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.973    |
| fps                | 419      |
| nupdates           | 30800    |
| policy_entropy     | 0.0707   |
| total_timesteps    | 154000   |
| value_loss         | 7.78     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.959    |
| fps                | 419      |
| nupdates           | 30900    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 154500   |
| value_loss         | 0.724    |
---------------------------------
10.0
10.0
12.39
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.961    |
| fps                | 419      |
| nupdates           | 31000    |
| policy_entropy     | 0.0067   |
| total_timesteps    | 155000   |
| value_loss         | 3.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.963    |
| fps                | 419      |
| nupdates           | 31100    |
| policy_entropy     | 0.0457   |
| total_timesteps    | 155500   |
| value_loss         | 1.84     |
---------------------------------
11.0
11.0
12.69
10.5
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.986    |
| fps                | 419      |
| nupdates           | 31200    |
| policy_entropy     | 0.00774  |
| total_timesteps    | 156000   |
| value_loss         | 3.76     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | -6.66    |
| fps                | 419      |
| nupdates           | 31300    |
| policy_entropy     | 0.139    |
| total_timesteps    | 156500   |
| value_loss         | 673      |
---------------------------------
9.0
9.0
12.29
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.996    |
| fps                | 418      |
| nupdates           | 31400    |
| policy_entropy     | 0.0347   |
| total_timesteps    | 157000   |
| value_loss         | 0.577    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.987    |
| fps                | 418      |
| nupdates           | 31500    |
| policy_entropy     | 0.0152   |
| total_timesteps    | 157500   |
| value_loss         | 2.95     |
---------------------------------
9.0
9.0
11.75
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.692    |
| fps                | 418      |
| nupdates           | 31600    |
| policy_entropy     | 0.00262  |
| total_timesteps    | 158000   |
| value_loss         | 46.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.978    |
| fps                | 418      |
| nupdates           | 31700    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 158500   |
| value_loss         | 0.658    |
---------------------------------
9.0
9.0
12.19
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.609    |
| fps                | 418      |
| nupdates           | 31800    |
| policy_entropy     | 0.00272  |
| total_timesteps    | 159000   |
| value_loss         | 52.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 213      |
| explained_variance | 0.795    |
| fps                | 418      |
| nupdates           | 31900    |
| policy_entropy     | 0.0757   |
| total_timesteps    | 159500   |
| value_loss         | 348      |
---------------------------------
10.0
10.0
12.62
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.946    |
| fps                | 418      |
| nupdates           | 32000    |
| policy_entropy     | 0.135    |
| total_timesteps    | 160000   |
| value_loss         | 9.17     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 210      |
| explained_variance | 1.19e-07 |
| fps                | 418      |
| nupdates           | 32100    |
| policy_entropy     | 0.212    |
| total_timesteps    | 160500   |
| value_loss         | 114      |
---------------------------------
9.0
9.0
13.83
9.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.712    |
| fps                | 418      |
| nupdates           | 32200    |
| policy_entropy     | 0.00311  |
| total_timesteps    | 161000   |
| value_loss         | 48       |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 212      |
| explained_variance | 0.981    |
| fps                | 418      |
| nupdates           | 32300    |
| policy_entropy     | 0.00986  |
| total_timesteps    | 161500   |
| value_loss         | 0.893    |
---------------------------------
10.0
10.0
11.1
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 216      |
| explained_variance | -6.24    |
| fps                | 417      |
| nupdates           | 32400    |
| policy_entropy     | 0.0741   |
| total_timesteps    | 162000   |
| value_loss         | 719      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 210      |
| explained_variance | -2.96    |
| fps                | 417      |
| nupdates           | 32500    |
| policy_entropy     | 0.0679   |
| total_timesteps    | 162500   |
| value_loss         | 155      |
---------------------------------
9.0
9.0
13.16
9.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.981    |
| fps                | 417      |
| nupdates           | 32600    |
| policy_entropy     | 0.0428   |
| total_timesteps    | 163000   |
| value_loss         | 2.47     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.994    |
| fps                | 417      |
| nupdates           | 32700    |
| policy_entropy     | 0.00466  |
| total_timesteps    | 163500   |
| value_loss         | 0.824    |
---------------------------------
9.0
9.0
11.68
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.988    |
| fps                | 417      |
| nupdates           | 32800    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 164000   |
| value_loss         | 2.11     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.988    |
| fps                | 417      |
| nupdates           | 32900    |
| policy_entropy     | 0.00317  |
| total_timesteps    | 164500   |
| value_loss         | 2.11     |
---------------------------------
11.0
11.0
12.27
11.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.994    |
| fps                | 417      |
| nupdates           | 33000    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 165000   |
| value_loss         | 1.28     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.975    |
| fps                | 417      |
| nupdates           | 33100    |
| policy_entropy     | 0.00564  |
| total_timesteps    | 165500   |
| value_loss         | 8.65     |
---------------------------------
23.0
23.0
12.81
10.5
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.823    |
| fps                | 417      |
| nupdates           | 33200    |
| policy_entropy     | 0.0955   |
| total_timesteps    | 166000   |
| value_loss         | 36.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.987    |
| fps                | 417      |
| nupdates           | 33300    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 166500   |
| value_loss         | 2.19     |
---------------------------------
10.0
10.0
12.4
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.991    |
| fps                | 417      |
| nupdates           | 33400    |
| policy_entropy     | 0.00884  |
| total_timesteps    | 167000   |
| value_loss         | 5.86     |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 210      |
| explained_variance | 0.73     |
| fps                | 417      |
| nupdates           | 33500    |
| policy_entropy     | 0.00262  |
| total_timesteps    | 167500   |
| value_loss         | 54.1     |
---------------------------------
10.0
10.0
13.61
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.509    |
| fps                | 417      |
| nupdates           | 33600    |
| policy_entropy     | 0.155    |
| total_timesteps    | 168000   |
| value_loss         | 17.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.968    |
| fps                | 416      |
| nupdates           | 33700    |
| policy_entropy     | 0.00431  |
| total_timesteps    | 168500   |
| value_loss         | 4.07     |
---------------------------------
10.0
10.0
12.65
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.768    |
| fps                | 416      |
| nupdates           | 33800    |
| policy_entropy     | 0.00468  |
| total_timesteps    | 169000   |
| value_loss         | 78.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 214      |
| explained_variance | 0.939    |
| fps                | 416      |
| nupdates           | 33900    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 169500   |
| value_loss         | 3.55     |
---------------------------------
10.0
10.0
11.81
11.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.981    |
| fps                | 416      |
| nupdates           | 34000    |
| policy_entropy     | 0.00948  |
| total_timesteps    | 170000   |
| value_loss         | 4.38     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.991    |
| fps                | 416      |
| nupdates           | 34100    |
| policy_entropy     | 0.06     |
| total_timesteps    | 170500   |
| value_loss         | 0.249    |
---------------------------------
9.0
9.0
12.1
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | -2.64    |
| fps                | 416      |
| nupdates           | 34200    |
| policy_entropy     | 0.233    |
| total_timesteps    | 171000   |
| value_loss         | 278      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 212      |
| explained_variance | -2.68    |
| fps                | 416      |
| nupdates           | 34300    |
| policy_entropy     | 0.334    |
| total_timesteps    | 171500   |
| value_loss         | 530      |
---------------------------------
10.0
10.0
12.56
15.5
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.983    |
| fps                | 416      |
| nupdates           | 34400    |
| policy_entropy     | 0.00955  |
| total_timesteps    | 172000   |
| value_loss         | 0.654    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.727    |
| fps                | 416      |
| nupdates           | 34500    |
| policy_entropy     | 0.0251   |
| total_timesteps    | 172500   |
| value_loss         | 19.4     |
---------------------------------
9.0
9.0
13.88
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 209      |
| explained_variance | -7.69    |
| fps                | 416      |
| nupdates           | 34600    |
| policy_entropy     | 0.0484   |
| total_timesteps    | 173000   |
| value_loss         | 1.12e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.947    |
| fps                | 416      |
| nupdates           | 34700    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 173500   |
| value_loss         | 7.33     |
---------------------------------
10.0
10.0
12.72
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.95     |
| fps                | 416      |
| nupdates           | 34800    |
| policy_entropy     | 0.0398   |
| total_timesteps    | 174000   |
| value_loss         | 4.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.992    |
| fps                | 416      |
| nupdates           | 34900    |
| policy_entropy     | 0.00289  |
| total_timesteps    | 174500   |
| value_loss         | 1.86     |
---------------------------------
11.0
11.0
12.13
11.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.978    |
| fps                | 416      |
| nupdates           | 35000    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 175000   |
| value_loss         | 2.81     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.525    |
| fps                | 416      |
| nupdates           | 35100    |
| policy_entropy     | 0.0485   |
| total_timesteps    | 175500   |
| value_loss         | 15.2     |
---------------------------------
10.0
10.0
12.81
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.995    |
| fps                | 416      |
| nupdates           | 35200    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 176000   |
| value_loss         | 0.414    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.962    |
| fps                | 416      |
| nupdates           | 35300    |
| policy_entropy     | 0.00338  |
| total_timesteps    | 176500   |
| value_loss         | 3.02     |
---------------------------------
10.0
10.0
12.95
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.954    |
| fps                | 415      |
| nupdates           | 35400    |
| policy_entropy     | 0.00311  |
| total_timesteps    | 177000   |
| value_loss         | 7.76     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 216      |
| explained_variance | -0.837   |
| fps                | 415      |
| nupdates           | 35500    |
| policy_entropy     | 0.329    |
| total_timesteps    | 177500   |
| value_loss         | 714      |
---------------------------------
20.0
20.0
11.71
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.934    |
| fps                | 415      |
| nupdates           | 35600    |
| policy_entropy     | 0.00196  |
| total_timesteps    | 178000   |
| value_loss         | 4.24     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.984    |
| fps                | 415      |
| nupdates           | 35700    |
| policy_entropy     | 0.00292  |
| total_timesteps    | 178500   |
| value_loss         | 5.36     |
---------------------------------
10.0
10.0
13.27
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.96     |
| fps                | 415      |
| nupdates           | 35800    |
| policy_entropy     | 0.0422   |
| total_timesteps    | 179000   |
| value_loss         | 4.98     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 209      |
| explained_variance | -1.53    |
| fps                | 415      |
| nupdates           | 35900    |
| policy_entropy     | 0.339    |
| total_timesteps    | 179500   |
| value_loss         | 246      |
---------------------------------
11.0
11.0
12.19
10.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 212      |
| explained_variance | -2.12    |
| fps                | 415      |
| nupdates           | 36000    |
| policy_entropy     | 0.303    |
| total_timesteps    | 180000   |
| value_loss         | 663      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.792    |
| fps                | 415      |
| nupdates           | 36100    |
| policy_entropy     | 0.00561  |
| total_timesteps    | 180500   |
| value_loss         | 24.5     |
---------------------------------
10.0
10.0
12.89
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 210      |
| explained_variance | 0.996    |
| fps                | 415      |
| nupdates           | 36200    |
| policy_entropy     | 0.0662   |
| total_timesteps    | 181000   |
| value_loss         | 0.101    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.997    |
| fps                | 415      |
| nupdates           | 36300    |
| policy_entropy     | 0.00999  |
| total_timesteps    | 181500   |
| value_loss         | 0.568    |
---------------------------------
10.0
10.0
12.48
15.5
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 211      |
| explained_variance | 5.96e-08 |
| fps                | 415      |
| nupdates           | 36400    |
| policy_entropy     | 0.0791   |
| total_timesteps    | 182000   |
| value_loss         | 128      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.769    |
| fps                | 415      |
| nupdates           | 36500    |
| policy_entropy     | 0.0573   |
| total_timesteps    | 182500   |
| value_loss         | 32.8     |
---------------------------------
11.0
11.0
13.79
11.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.981    |
| fps                | 415      |
| nupdates           | 36600    |
| policy_entropy     | 0.00799  |
| total_timesteps    | 183000   |
| value_loss         | 0.777    |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 207      |
| explained_variance | 0.98     |
| fps                | 414      |
| nupdates           | 36700    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 183500   |
| value_loss         | 3.88     |
---------------------------------
11.0
11.0
14.59
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0.958    |
| fps                | 414      |
| nupdates           | 36800    |
| policy_entropy     | 0.00703  |
| total_timesteps    | 184000   |
| value_loss         | 3.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.967    |
| fps                | 414      |
| nupdates           | 36900    |
| policy_entropy     | 0.00186  |
| total_timesteps    | 184500   |
| value_loss         | 8.09     |
---------------------------------
11.0
11.0
13.58
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.982    |
| fps                | 414      |
| nupdates           | 37000    |
| policy_entropy     | 0.00282  |
| total_timesteps    | 185000   |
| value_loss         | 1.83     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.969    |
| fps                | 414      |
| nupdates           | 37100    |
| policy_entropy     | 0.0206   |
| total_timesteps    | 185500   |
| value_loss         | 3.2      |
---------------------------------
11.0
11.0
11.94
11.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.998    |
| fps                | 414      |
| nupdates           | 37200    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 186000   |
| value_loss         | 0.708    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.893    |
| fps                | 414      |
| nupdates           | 37300    |
| policy_entropy     | 0.00815  |
| total_timesteps    | 186500   |
| value_loss         | 7.86     |
---------------------------------
11.0
11.0
13.63
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 208      |
| explained_variance | -3       |
| fps                | 414      |
| nupdates           | 37400    |
| policy_entropy     | 0.174    |
| total_timesteps    | 187000   |
| value_loss         | 191      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 208      |
| explained_variance | -2.39    |
| fps                | 414      |
| nupdates           | 37500    |
| policy_entropy     | 0.134    |
| total_timesteps    | 187500   |
| value_loss         | 771      |
---------------------------------
10.0
10.0
14.12
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 208      |
| explained_variance | 0.999    |
| fps                | 414      |
| nupdates           | 37600    |
| policy_entropy     | 0.102    |
| total_timesteps    | 188000   |
| value_loss         | 0.0435   |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.993    |
| fps                | 414      |
| nupdates           | 37700    |
| policy_entropy     | 0.00169  |
| total_timesteps    | 188500   |
| value_loss         | 1.64     |
---------------------------------
10.0
10.0
11.6
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.94     |
| fps                | 414      |
| nupdates           | 37800    |
| policy_entropy     | 0.0815   |
| total_timesteps    | 189000   |
| value_loss         | 7.56     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 211      |
| explained_variance | 0.932    |
| fps                | 414      |
| nupdates           | 37900    |
| policy_entropy     | 0.0848   |
| total_timesteps    | 189500   |
| value_loss         | 12.6     |
---------------------------------
10.0
10.0
11.44
10.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.983    |
| fps                | 413      |
| nupdates           | 38000    |
| policy_entropy     | 0.00337  |
| total_timesteps    | 190000   |
| value_loss         | 1.23     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 213      |
| explained_variance | 0.469    |
| fps                | 413      |
| nupdates           | 38100    |
| policy_entropy     | 0.19     |
| total_timesteps    | 190500   |
| value_loss         | 544      |
---------------------------------
9.0
9.0
12.81
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.984    |
| fps                | 413      |
| nupdates           | 38200    |
| policy_entropy     | 0.00194  |
| total_timesteps    | 191000   |
| value_loss         | 4.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.986    |
| fps                | 413      |
| nupdates           | 38300    |
| policy_entropy     | 0.00706  |
| total_timesteps    | 191500   |
| value_loss         | 1.57     |
---------------------------------
31.0
31.0
14.32
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 205      |
| explained_variance | -157     |
| fps                | 413      |
| nupdates           | 38400    |
| policy_entropy     | 0.165    |
| total_timesteps    | 192000   |
| value_loss         | 1.73e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 203      |
| explained_variance | -0.179   |
| fps                | 413      |
| nupdates           | 38500    |
| policy_entropy     | 0.197    |
| total_timesteps    | 192500   |
| value_loss         | 349      |
---------------------------------
22.0
22.0
15.08
16.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 202      |
| explained_variance | -8.66    |
| fps                | 413      |
| nupdates           | 38600    |
| policy_entropy     | 0.237    |
| total_timesteps    | 193000   |
| value_loss         | 764      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.177    |
| fps                | 413      |
| nupdates           | 38700    |
| policy_entropy     | 0.296    |
| total_timesteps    | 193500   |
| value_loss         | 30.3     |
---------------------------------
19.0
19.0
12.76
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.781    |
| fps                | 413      |
| nupdates           | 38800    |
| policy_entropy     | 0.071    |
| total_timesteps    | 194000   |
| value_loss         | 27.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.725    |
| fps                | 413      |
| nupdates           | 38900    |
| policy_entropy     | 0.0798   |
| total_timesteps    | 194500   |
| value_loss         | 53.3     |
---------------------------------
10.0
10.0
12.28
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.726    |
| fps                | 413      |
| nupdates           | 39000    |
| policy_entropy     | 0.216    |
| total_timesteps    | 195000   |
| value_loss         | 70.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.981    |
| fps                | 413      |
| nupdates           | 39100    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 195500   |
| value_loss         | 4.6      |
---------------------------------
10.0
10.0
12.49
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.996    |
| fps                | 413      |
| nupdates           | 39200    |
| policy_entropy     | 0.00859  |
| total_timesteps    | 196000   |
| value_loss         | 0.3      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.959    |
| fps                | 413      |
| nupdates           | 39300    |
| policy_entropy     | 0.00933  |
| total_timesteps    | 196500   |
| value_loss         | 9.87     |
---------------------------------
9.0
9.0
12.58
9.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.997    |
| fps                | 412      |
| nupdates           | 39400    |
| policy_entropy     | 0.00723  |
| total_timesteps    | 197000   |
| value_loss         | 0.256    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.328    |
| fps                | 412      |
| nupdates           | 39500    |
| policy_entropy     | 0.0259   |
| total_timesteps    | 197500   |
| value_loss         | 114      |
---------------------------------
10.0
10.0
13.07
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.995    |
| fps                | 412      |
| nupdates           | 39600    |
| policy_entropy     | 0.0336   |
| total_timesteps    | 198000   |
| value_loss         | 0.995    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.975    |
| fps                | 412      |
| nupdates           | 39700    |
| policy_entropy     | 0.00324  |
| total_timesteps    | 198500   |
| value_loss         | 4.45     |
---------------------------------
10.0
10.0
11.76
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.971    |
| fps                | 412      |
| nupdates           | 39800    |
| policy_entropy     | 0.00341  |
| total_timesteps    | 199000   |
| value_loss         | 7.83     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.957    |
| fps                | 412      |
| nupdates           | 39900    |
| policy_entropy     | 0.00791  |
| total_timesteps    | 199500   |
| value_loss         | 6.17     |
---------------------------------
11.0
11.0
11.48
10.5
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 213      |
| explained_variance | 0.991    |
| fps                | 412      |
| nupdates           | 40000    |
| policy_entropy     | 0.00352  |
| total_timesteps    | 200000   |
| value_loss         | 3.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.811    |
| fps                | 412      |
| nupdates           | 40100    |
| policy_entropy     | 0.00174  |
| total_timesteps    | 200500   |
| value_loss         | 29.4     |
---------------------------------
9.0
9.0
12.04
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 213      |
| explained_variance | 0.956    |
| fps                | 412      |
| nupdates           | 40200    |
| policy_entropy     | 0.00396  |
| total_timesteps    | 201000   |
| value_loss         | 3.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.963    |
| fps                | 412      |
| nupdates           | 40300    |
| policy_entropy     | 0.00502  |
| total_timesteps    | 201500   |
| value_loss         | 16.4     |
---------------------------------
9.0
9.0
13.12
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0.998    |
| fps                | 412      |
| nupdates           | 40400    |
| policy_entropy     | 0.00727  |
| total_timesteps    | 202000   |
| value_loss         | 0.282    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.995    |
| fps                | 412      |
| nupdates           | 40500    |
| policy_entropy     | 0.00468  |
| total_timesteps    | 202500   |
| value_loss         | 0.572    |
---------------------------------
21.0
21.0
11.86
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.956    |
| fps                | 412      |
| nupdates           | 40600    |
| policy_entropy     | 0.0356   |
| total_timesteps    | 203000   |
| value_loss         | 8.42     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.994    |
| fps                | 412      |
| nupdates           | 40700    |
| policy_entropy     | 0.00393  |
| total_timesteps    | 203500   |
| value_loss         | 0.343    |
---------------------------------
9.0
9.0
13.0
10.0
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 209      |
| explained_variance | 0.993    |
| fps                | 412      |
| nupdates           | 40800    |
| policy_entropy     | 0.0222   |
| total_timesteps    | 204000   |
| value_loss         | 1.38     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 206      |
| explained_variance | 0.96     |
| fps                | 412      |
| nupdates           | 40900    |
| policy_entropy     | 0.0353   |
| total_timesteps    | 204500   |
| value_loss         | 12       |
---------------------------------
11.0
11.0
13.15
10.5
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.986    |
| fps                | 412      |
| nupdates           | 41000    |
| policy_entropy     | 0.00566  |
| total_timesteps    | 205000   |
| value_loss         | 1.34     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.887    |
| fps                | 411      |
| nupdates           | 41100    |
| policy_entropy     | 0.00252  |
| total_timesteps    | 205500   |
| value_loss         | 46.2     |
---------------------------------
12.0
12.0
11.88
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.996    |
| fps                | 411      |
| nupdates           | 41200    |
| policy_entropy     | 0.00151  |
| total_timesteps    | 206000   |
| value_loss         | 1.36     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 215      |
| explained_variance | -0.632   |
| fps                | 411      |
| nupdates           | 41300    |
| policy_entropy     | 0.185    |
| total_timesteps    | 206500   |
| value_loss         | 34.8     |
---------------------------------
9.0
9.0
11.91
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.988    |
| fps                | 411      |
| nupdates           | 41400    |
| policy_entropy     | 0.00606  |
| total_timesteps    | 207000   |
| value_loss         | 0.735    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.939    |
| fps                | 411      |
| nupdates           | 41500    |
| policy_entropy     | 0.00702  |
| total_timesteps    | 207500   |
| value_loss         | 3.9      |
---------------------------------
9.0
9.0
11.52
10.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.994    |
| fps                | 411      |
| nupdates           | 41600    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 208000   |
| value_loss         | 1.68     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.996    |
| fps                | 411      |
| nupdates           | 41700    |
| policy_entropy     | 0.00267  |
| total_timesteps    | 208500   |
| value_loss         | 0.294    |
---------------------------------
9.0
9.0
12.39
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.985    |
| fps                | 411      |
| nupdates           | 41800    |
| policy_entropy     | 0.00315  |
| total_timesteps    | 209000   |
| value_loss         | 1.28     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 213      |
| explained_variance | -1.57    |
| fps                | 411      |
| nupdates           | 41900    |
| policy_entropy     | 0.172    |
| total_timesteps    | 209500   |
| value_loss         | 202      |
---------------------------------
19.0
19.0
12.7
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.984    |
| fps                | 411      |
| nupdates           | 42000    |
| policy_entropy     | 0.00326  |
| total_timesteps    | 210000   |
| value_loss         | 1.69     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.621    |
| fps                | 411      |
| nupdates           | 42100    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 210500   |
| value_loss         | 16.6     |
---------------------------------
11.0
11.0
11.25
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.176    |
| fps                | 411      |
| nupdates           | 42200    |
| policy_entropy     | 0.126    |
| total_timesteps    | 211000   |
| value_loss         | 22.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.997    |
| fps                | 411      |
| nupdates           | 42300    |
| policy_entropy     | 0.0264   |
| total_timesteps    | 211500   |
| value_loss         | 0.232    |
---------------------------------
9.0
9.0
13.38
10.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.771    |
| fps                | 411      |
| nupdates           | 42400    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 212000   |
| value_loss         | 10.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.996    |
| fps                | 411      |
| nupdates           | 42500    |
| policy_entropy     | 0.0263   |
| total_timesteps    | 212500   |
| value_loss         | 0.668    |
---------------------------------
10.0
10.0
12.33
10.5
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.722    |
| fps                | 410      |
| nupdates           | 42600    |
| policy_entropy     | 0.0986   |
| total_timesteps    | 213000   |
| value_loss         | 92.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.998    |
| fps                | 410      |
| nupdates           | 42700    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 213500   |
| value_loss         | 1.79     |
---------------------------------
10.0
10.0
11.86
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.994    |
| fps                | 410      |
| nupdates           | 42800    |
| policy_entropy     | 0.00673  |
| total_timesteps    | 214000   |
| value_loss         | 4.44     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 213      |
| explained_variance | -1.9     |
| fps                | 410      |
| nupdates           | 42900    |
| policy_entropy     | 0.0809   |
| total_timesteps    | 214500   |
| value_loss         | 430      |
---------------------------------
21.0
21.0
12.02
10.5
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 211      |
| explained_variance | 0.987    |
| fps                | 410      |
| nupdates           | 43000    |
| policy_entropy     | 0.00558  |
| total_timesteps    | 215000   |
| value_loss         | 2.26     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.992    |
| fps                | 410      |
| nupdates           | 43100    |
| policy_entropy     | 0.00327  |
| total_timesteps    | 215500   |
| value_loss         | 0.773    |
---------------------------------
9.0
9.0
11.99
14.5
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 213      |
| explained_variance | 0.823    |
| fps                | 410      |
| nupdates           | 43200    |
| policy_entropy     | 0.00994  |
| total_timesteps    | 216000   |
| value_loss         | 12.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.988    |
| fps                | 410      |
| nupdates           | 43300    |
| policy_entropy     | 0.00738  |
| total_timesteps    | 216500   |
| value_loss         | 1.6      |
---------------------------------
31.0
31.0
12.7
10.5
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.996    |
| fps                | 410      |
| nupdates           | 43400    |
| policy_entropy     | 0.00192  |
| total_timesteps    | 217000   |
| value_loss         | 0.55     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.976    |
| fps                | 410      |
| nupdates           | 43500    |
| policy_entropy     | 0.00562  |
| total_timesteps    | 217500   |
| value_loss         | 2.15     |
---------------------------------
11.0
11.0
12.07
11.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.995    |
| fps                | 410      |
| nupdates           | 43600    |
| policy_entropy     | 0.017    |
| total_timesteps    | 218000   |
| value_loss         | 0.548    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 214      |
| explained_variance | -2.83    |
| fps                | 410      |
| nupdates           | 43700    |
| policy_entropy     | 0.397    |
| total_timesteps    | 218500   |
| value_loss         | 432      |
---------------------------------
10.0
10.0
13.13
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.962    |
| fps                | 410      |
| nupdates           | 43800    |
| policy_entropy     | 0.00905  |
| total_timesteps    | 219000   |
| value_loss         | 0.544    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.994    |
| fps                | 410      |
| nupdates           | 43900    |
| policy_entropy     | 0.011    |
| total_timesteps    | 219500   |
| value_loss         | 0.817    |
---------------------------------
11.0
11.0
12.59
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.983    |
| fps                | 410      |
| nupdates           | 44000    |
| policy_entropy     | 0.00642  |
| total_timesteps    | 220000   |
| value_loss         | 0.83     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.959    |
| fps                | 410      |
| nupdates           | 44100    |
| policy_entropy     | 0.00453  |
| total_timesteps    | 220500   |
| value_loss         | 5.29     |
---------------------------------
10.0
10.0
12.08
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.998    |
| fps                | 410      |
| nupdates           | 44200    |
| policy_entropy     | 0.00762  |
| total_timesteps    | 221000   |
| value_loss         | 0.504    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.998    |
| fps                | 410      |
| nupdates           | 44300    |
| policy_entropy     | 0.00396  |
| total_timesteps    | 221500   |
| value_loss         | 0.22     |
---------------------------------
10.0
10.0
11.21
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.998    |
| fps                | 410      |
| nupdates           | 44400    |
| policy_entropy     | 0.0403   |
| total_timesteps    | 222000   |
| value_loss         | 0.645    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.997    |
| fps                | 410      |
| nupdates           | 44500    |
| policy_entropy     | 0.00467  |
| total_timesteps    | 222500   |
| value_loss         | 4.13     |
---------------------------------
19.0
19.0
12.66
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.821    |
| fps                | 410      |
| nupdates           | 44600    |
| policy_entropy     | 0.0636   |
| total_timesteps    | 223000   |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.916    |
| fps                | 410      |
| nupdates           | 44700    |
| policy_entropy     | 0.0242   |
| total_timesteps    | 223500   |
| value_loss         | 11.2     |
---------------------------------
10.0
10.0
13.35
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.987    |
| fps                | 409      |
| nupdates           | 44800    |
| policy_entropy     | 0.00733  |
| total_timesteps    | 224000   |
| value_loss         | 1.51     |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 211      |
| explained_variance | 0.894    |
| fps                | 409      |
| nupdates           | 44900    |
| policy_entropy     | 0.00185  |
| total_timesteps    | 224500   |
| value_loss         | 12.5     |
---------------------------------
20.0
20.0
13.04
10.0
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 209      |
| explained_variance | 0.954    |
| fps                | 409      |
| nupdates           | 45000    |
| policy_entropy     | 0.111    |
| total_timesteps    | 225000   |
| value_loss         | 3.94     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 211      |
| explained_variance | -2.55    |
| fps                | 409      |
| nupdates           | 45100    |
| policy_entropy     | 0.391    |
| total_timesteps    | 225500   |
| value_loss         | 349      |
---------------------------------
10.0
10.0
12.01
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 214      |
| explained_variance | -5.96    |
| fps                | 409      |
| nupdates           | 45200    |
| policy_entropy     | 0.357    |
| total_timesteps    | 226000   |
| value_loss         | 759      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.998    |
| fps                | 409      |
| nupdates           | 45300    |
| policy_entropy     | 0.0106   |
| total_timesteps    | 226500   |
| value_loss         | 1        |
---------------------------------
10.0
10.0
11.65
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.977    |
| fps                | 409      |
| nupdates           | 45400    |
| policy_entropy     | 0.00755  |
| total_timesteps    | 227000   |
| value_loss         | 3.96     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.994    |
| fps                | 409      |
| nupdates           | 45500    |
| policy_entropy     | 0.0079   |
| total_timesteps    | 227500   |
| value_loss         | 1.03     |
---------------------------------
11.0
11.0
11.73
11.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.997    |
| fps                | 409      |
| nupdates           | 45600    |
| policy_entropy     | 0.106    |
| total_timesteps    | 228000   |
| value_loss         | 0.373    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.99     |
| fps                | 409      |
| nupdates           | 45700    |
| policy_entropy     | 0.00113  |
| total_timesteps    | 228500   |
| value_loss         | 1.73     |
---------------------------------
10.0
10.0
12.81
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.995    |
| fps                | 409      |
| nupdates           | 45800    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 229000   |
| value_loss         | 0.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.986    |
| fps                | 409      |
| nupdates           | 45900    |
| policy_entropy     | 0.00142  |
| total_timesteps    | 229500   |
| value_loss         | 2.92     |
---------------------------------
20.0
20.0
12.63
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 213      |
| explained_variance | -231     |
| fps                | 409      |
| nupdates           | 46000    |
| policy_entropy     | 0.225    |
| total_timesteps    | 230000   |
| value_loss         | 1.22e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 183      |
| explained_variance | -3.14    |
| fps                | 409      |
| nupdates           | 46100    |
| policy_entropy     | 0.262    |
| total_timesteps    | 230500   |
| value_loss         | 2.03e+03 |
---------------------------------
9.0
9.0
19.87
9.5
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 182      |
| explained_variance | 0.993    |
| fps                | 409      |
| nupdates           | 46200    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 231000   |
| value_loss         | 30.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 184      |
| explained_variance | 0.978    |
| fps                | 409      |
| nupdates           | 46300    |
| policy_entropy     | 0.0744   |
| total_timesteps    | 231500   |
| value_loss         | 6.74     |
---------------------------------
23.0
23.0
11.94
10.5
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | -3.79    |
| fps                | 409      |
| nupdates           | 46400    |
| policy_entropy     | 0.0313   |
| total_timesteps    | 232000   |
| value_loss         | 158      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 214      |
| explained_variance | 0.945    |
| fps                | 409      |
| nupdates           | 46500    |
| policy_entropy     | 0.00617  |
| total_timesteps    | 232500   |
| value_loss         | 5.26     |
---------------------------------
9.0
9.0
11.64
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.22     |
| fps                | 409      |
| nupdates           | 46600    |
| policy_entropy     | 0.298    |
| total_timesteps    | 233000   |
| value_loss         | 123      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.979    |
| fps                | 409      |
| nupdates           | 46700    |
| policy_entropy     | 0.00126  |
| total_timesteps    | 233500   |
| value_loss         | 3.8      |
---------------------------------
9.0
9.0
11.7
9.5
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.951    |
| fps                | 409      |
| nupdates           | 46800    |
| policy_entropy     | 0.0104   |
| total_timesteps    | 234000   |
| value_loss         | 0.682    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.972    |
| fps                | 409      |
| nupdates           | 46900    |
| policy_entropy     | 0.0308   |
| total_timesteps    | 234500   |
| value_loss         | 3.75     |
---------------------------------
11.0
11.0
12.06
10.5
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 213      |
| explained_variance | -3.13    |
| fps                | 409      |
| nupdates           | 47000    |
| policy_entropy     | 0.0328   |
| total_timesteps    | 235000   |
| value_loss         | 418      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.998    |
| fps                | 408      |
| nupdates           | 47100    |
| policy_entropy     | 0.00118  |
| total_timesteps    | 235500   |
| value_loss         | 0.811    |
---------------------------------
9.0
9.0
12.19
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.95     |
| fps                | 408      |
| nupdates           | 47200    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 236000   |
| value_loss         | 8.46     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.973    |
| fps                | 408      |
| nupdates           | 47300    |
| policy_entropy     | 0.0297   |
| total_timesteps    | 236500   |
| value_loss         | 2.42     |
---------------------------------
10.0
10.0
12.01
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 213      |
| explained_variance | 0.99     |
| fps                | 408      |
| nupdates           | 47400    |
| policy_entropy     | 0.00523  |
| total_timesteps    | 237000   |
| value_loss         | 2.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.963    |
| fps                | 408      |
| nupdates           | 47500    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 237500   |
| value_loss         | 17.9     |
---------------------------------
10.0
10.0
11.15
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.983    |
| fps                | 408      |
| nupdates           | 47600    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 238000   |
| value_loss         | 2.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 11       |
| ep_reward_mean     | 216      |
| explained_variance | -0.195   |
| fps                | 408      |
| nupdates           | 47700    |
| policy_entropy     | 0.129    |
| total_timesteps    | 238500   |
| value_loss         | 31.5     |
---------------------------------
9.0
9.0
11.69
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.991    |
| fps                | 408      |
| nupdates           | 47800    |
| policy_entropy     | 0.00615  |
| total_timesteps    | 239000   |
| value_loss         | 0.646    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.964    |
| fps                | 408      |
| nupdates           | 47900    |
| policy_entropy     | 0.00192  |
| total_timesteps    | 239500   |
| value_loss         | 1.11e+03 |
---------------------------------
10.0
10.0
12.35
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.993    |
| fps                | 408      |
| nupdates           | 48000    |
| policy_entropy     | 0.006    |
| total_timesteps    | 240000   |
| value_loss         | 3.28     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.947    |
| fps                | 408      |
| nupdates           | 48100    |
| policy_entropy     | 0.0224   |
| total_timesteps    | 240500   |
| value_loss         | 1.47     |
---------------------------------
10.0
10.0
11.13
10.0
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.992    |
| fps                | 408      |
| nupdates           | 48200    |
| policy_entropy     | 0.0082   |
| total_timesteps    | 241000   |
| value_loss         | 0.681    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.999    |
| fps                | 408      |
| nupdates           | 48300    |
| policy_entropy     | 0.0199   |
| total_timesteps    | 241500   |
| value_loss         | 0.209    |
---------------------------------
9.0
9.0
12.18
9.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 213      |
| explained_variance | -0.578   |
| fps                | 408      |
| nupdates           | 48400    |
| policy_entropy     | 0.165    |
| total_timesteps    | 242000   |
| value_loss         | 45.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.688    |
| fps                | 408      |
| nupdates           | 48500    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 242500   |
| value_loss         | 75       |
---------------------------------
11.0
11.0
12.65
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.964    |
| fps                | 408      |
| nupdates           | 48600    |
| policy_entropy     | 0.00163  |
| total_timesteps    | 243000   |
| value_loss         | 1.22e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.992    |
| fps                | 408      |
| nupdates           | 48700    |
| policy_entropy     | 0.00642  |
| total_timesteps    | 243500   |
| value_loss         | 2.15     |
---------------------------------
10.0
10.0
11.86
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.532    |
| fps                | 408      |
| nupdates           | 48800    |
| policy_entropy     | 0.107    |
| total_timesteps    | 244000   |
| value_loss         | 153      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.984    |
| fps                | 408      |
| nupdates           | 48900    |
| policy_entropy     | 0.00542  |
| total_timesteps    | 244500   |
| value_loss         | 1.47     |
---------------------------------
9.0
9.0
12.22
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 214      |
| explained_variance | -2.57    |
| fps                | 408      |
| nupdates           | 49000    |
| policy_entropy     | 0.0283   |
| total_timesteps    | 245000   |
| value_loss         | 467      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.981    |
| fps                | 408      |
| nupdates           | 49100    |
| policy_entropy     | 0.0687   |
| total_timesteps    | 245500   |
| value_loss         | 0.983    |
---------------------------------
10.0
10.0
11.81
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.988    |
| fps                | 408      |
| nupdates           | 49200    |
| policy_entropy     | 0.00373  |
| total_timesteps    | 246000   |
| value_loss         | 0.345    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.998    |
| fps                | 408      |
| nupdates           | 49300    |
| policy_entropy     | 0.00858  |
| total_timesteps    | 246500   |
| value_loss         | 0.786    |
---------------------------------
10.0
10.0
13.82
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 205      |
| explained_variance | -3.43    |
| fps                | 407      |
| nupdates           | 49400    |
| policy_entropy     | 0.00123  |
| total_timesteps    | 247000   |
| value_loss         | 178      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 206      |
| explained_variance | 0.959    |
| fps                | 407      |
| nupdates           | 49500    |
| policy_entropy     | 0.00471  |
| total_timesteps    | 247500   |
| value_loss         | 13.1     |
---------------------------------
11.0
11.0
13.55
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.979    |
| fps                | 407      |
| nupdates           | 49600    |
| policy_entropy     | 0.0311   |
| total_timesteps    | 248000   |
| value_loss         | 2.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.995    |
| fps                | 407      |
| nupdates           | 49700    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 248500   |
| value_loss         | 5.15     |
---------------------------------
9.0
9.0
11.31
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.997    |
| fps                | 407      |
| nupdates           | 49800    |
| policy_entropy     | 0.013    |
| total_timesteps    | 249000   |
| value_loss         | 1.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.992    |
| fps                | 407      |
| nupdates           | 49900    |
| policy_entropy     | 0.00442  |
| total_timesteps    | 249500   |
| value_loss         | 0.808    |
---------------------------------
9.0
9.0
12.35
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.988    |
| fps                | 407      |
| nupdates           | 50000    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 250000   |
| value_loss         | 3.7      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | -0.71    |
| fps                | 407      |
| nupdates           | 50100    |
| policy_entropy     | 0.135    |
| total_timesteps    | 250500   |
| value_loss         | 154      |
---------------------------------
10.0
10.0
11.82
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | 1.19e-07 |
| fps                | 407      |
| nupdates           | 50200    |
| policy_entropy     | 0.176    |
| total_timesteps    | 251000   |
| value_loss         | 46       |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.996    |
| fps                | 407      |
| nupdates           | 50300    |
| policy_entropy     | 0.0109   |
| total_timesteps    | 251500   |
| value_loss         | 3.02     |
---------------------------------
9.0
9.0
12.15
9.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.965    |
| fps                | 407      |
| nupdates           | 50400    |
| policy_entropy     | 0.00283  |
| total_timesteps    | 252000   |
| value_loss         | 14       |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.993    |
| fps                | 407      |
| nupdates           | 50500    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 252500   |
| value_loss         | 0.557    |
---------------------------------
10.0
10.0
13.51
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 209      |
| explained_variance | -0.755   |
| fps                | 407      |
| nupdates           | 50600    |
| policy_entropy     | 0.0688   |
| total_timesteps    | 253000   |
| value_loss         | 586      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.974    |
| fps                | 407      |
| nupdates           | 50700    |
| policy_entropy     | 0.00116  |
| total_timesteps    | 253500   |
| value_loss         | 615      |
---------------------------------
13.0
13.0
13.74
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.996    |
| fps                | 407      |
| nupdates           | 50800    |
| policy_entropy     | 0.00393  |
| total_timesteps    | 254000   |
| value_loss         | 0.89     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.984    |
| fps                | 407      |
| nupdates           | 50900    |
| policy_entropy     | 0.00435  |
| total_timesteps    | 254500   |
| value_loss         | 4.93     |
---------------------------------
9.0
9.0
11.6
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.991    |
| fps                | 407      |
| nupdates           | 51000    |
| policy_entropy     | 0.00423  |
| total_timesteps    | 255000   |
| value_loss         | 0.495    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.978    |
| fps                | 407      |
| nupdates           | 51100    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 255500   |
| value_loss         | 0.799    |
---------------------------------
10.0
10.0
11.21
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.956    |
| fps                | 407      |
| nupdates           | 51200    |
| policy_entropy     | 0.00477  |
| total_timesteps    | 256000   |
| value_loss         | 2.02     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | -0.216   |
| fps                | 407      |
| nupdates           | 51300    |
| policy_entropy     | 0.168    |
| total_timesteps    | 256500   |
| value_loss         | 121      |
---------------------------------
11.0
11.0
12.69
10.5
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.978    |
| fps                | 407      |
| nupdates           | 51400    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 257000   |
| value_loss         | 1.3      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.971    |
| fps                | 407      |
| nupdates           | 51500    |
| policy_entropy     | 0.00291  |
| total_timesteps    | 257500   |
| value_loss         | 5.02     |
---------------------------------
9.0
9.0
13.04
10.0
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 210      |
| explained_variance | 0.636    |
| fps                | 407      |
| nupdates           | 51600    |
| policy_entropy     | 0.149    |
| total_timesteps    | 258000   |
| value_loss         | 59.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.986    |
| fps                | 407      |
| nupdates           | 51700    |
| policy_entropy     | 0.0011   |
| total_timesteps    | 258500   |
| value_loss         | 0.765    |
---------------------------------
10.0
10.0
11.62
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.958    |
| fps                | 406      |
| nupdates           | 51800    |
| policy_entropy     | 0.00109  |
| total_timesteps    | 259000   |
| value_loss         | 3.37     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0        |
| fps                | 406      |
| nupdates           | 51900    |
| policy_entropy     | 0.384    |
| total_timesteps    | 259500   |
| value_loss         | 80.1     |
---------------------------------
10.0
10.0
12.21
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.994    |
| fps                | 406      |
| nupdates           | 52000    |
| policy_entropy     | 0.00816  |
| total_timesteps    | 260000   |
| value_loss         | 12.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.591    |
| fps                | 406      |
| nupdates           | 52100    |
| policy_entropy     | 0.0276   |
| total_timesteps    | 260500   |
| value_loss         | 21.9     |
---------------------------------
21.0
21.0
11.38
11.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.864    |
| fps                | 406      |
| nupdates           | 52200    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 261000   |
| value_loss         | 34.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.955    |
| fps                | 406      |
| nupdates           | 52300    |
| policy_entropy     | 0.00931  |
| total_timesteps    | 261500   |
| value_loss         | 1.11     |
---------------------------------
19.0
19.0
11.86
11.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.98     |
| fps                | 406      |
| nupdates           | 52400    |
| policy_entropy     | 0.233    |
| total_timesteps    | 262000   |
| value_loss         | 3.95     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.996    |
| fps                | 406      |
| nupdates           | 52500    |
| policy_entropy     | 0.116    |
| total_timesteps    | 262500   |
| value_loss         | 0.647    |
---------------------------------
11.0
11.0
12.86
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.956    |
| fps                | 406      |
| nupdates           | 52600    |
| policy_entropy     | 0.00468  |
| total_timesteps    | 263000   |
| value_loss         | 12.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.998    |
| fps                | 406      |
| nupdates           | 52700    |
| policy_entropy     | 0.0214   |
| total_timesteps    | 263500   |
| value_loss         | 0.395    |
---------------------------------
20.0
20.0
12.35
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 214      |
| explained_variance | -650     |
| fps                | 406      |
| nupdates           | 52800    |
| policy_entropy     | 0.209    |
| total_timesteps    | 264000   |
| value_loss         | 1.49e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 211      |
| explained_variance | -0.573   |
| fps                | 406      |
| nupdates           | 52900    |
| policy_entropy     | 0.0175   |
| total_timesteps    | 264500   |
| value_loss         | 647      |
---------------------------------
10.0
10.0
12.87
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 210      |
| explained_variance | 0.999    |
| fps                | 406      |
| nupdates           | 53000    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 265000   |
| value_loss         | 0.821    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 214      |
| explained_variance | -2.7     |
| fps                | 406      |
| nupdates           | 53100    |
| policy_entropy     | 0.0383   |
| total_timesteps    | 265500   |
| value_loss         | 145      |
---------------------------------
11.0
11.0
12.22
11.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.966    |
| fps                | 406      |
| nupdates           | 53200    |
| policy_entropy     | 0.0299   |
| total_timesteps    | 266000   |
| value_loss         | 1.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.261    |
| fps                | 406      |
| nupdates           | 53300    |
| policy_entropy     | 0.196    |
| total_timesteps    | 266500   |
| value_loss         | 196      |
---------------------------------
10.0
10.0
12.57
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 406      |
| nupdates           | 53400    |
| policy_entropy     | 0.0936   |
| total_timesteps    | 267000   |
| value_loss         | 3.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 208      |
| explained_variance | -2.22    |
| fps                | 406      |
| nupdates           | 53500    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 267500   |
| value_loss         | 363      |
---------------------------------
11.0
11.0
13.98
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 208      |
| explained_variance | 0.979    |
| fps                | 406      |
| nupdates           | 53600    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 268000   |
| value_loss         | 6.86     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 211      |
| explained_variance | -2.68    |
| fps                | 406      |
| nupdates           | 53700    |
| policy_entropy     | 0.0206   |
| total_timesteps    | 268500   |
| value_loss         | 465      |
---------------------------------
19.0
19.0
12.03
11.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 212      |
| explained_variance | 0.995    |
| fps                | 406      |
| nupdates           | 53800    |
| policy_entropy     | 0.0274   |
| total_timesteps    | 269000   |
| value_loss         | 9.24     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.995    |
| fps                | 406      |
| nupdates           | 53900    |
| policy_entropy     | 0.0942   |
| total_timesteps    | 269500   |
| value_loss         | 0.532    |
---------------------------------
10.0
10.0
11.55
9.5
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.994    |
| fps                | 406      |
| nupdates           | 54000    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 270000   |
| value_loss         | 1.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.976    |
| fps                | 406      |
| nupdates           | 54100    |
| policy_entropy     | 0.0293   |
| total_timesteps    | 270500   |
| value_loss         | 5.97     |
---------------------------------
10.0
10.0
11.61
10.5
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.938    |
| fps                | 406      |
| nupdates           | 54200    |
| policy_entropy     | 0.1      |
| total_timesteps    | 271000   |
| value_loss         | 6        |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.99     |
| fps                | 406      |
| nupdates           | 54300    |
| policy_entropy     | 0.00304  |
| total_timesteps    | 271500   |
| value_loss         | 0.786    |
---------------------------------
10.0
10.0
13.71
12.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.771    |
| fps                | 406      |
| nupdates           | 54400    |
| policy_entropy     | 0.0543   |
| total_timesteps    | 272000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.964    |
| fps                | 406      |
| nupdates           | 54500    |
| policy_entropy     | 0.175    |
| total_timesteps    | 272500   |
| value_loss         | 3.16     |
---------------------------------
11.0
11.0
15.36
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 205      |
| explained_variance | 0        |
| fps                | 406      |
| nupdates           | 54600    |
| policy_entropy     | 0.13     |
| total_timesteps    | 273000   |
| value_loss         | 83.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 203      |
| explained_variance | -1.74    |
| fps                | 406      |
| nupdates           | 54700    |
| policy_entropy     | 0.15     |
| total_timesteps    | 273500   |
| value_loss         | 128      |
---------------------------------
9.0
9.0
15.93
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 201      |
| explained_variance | 0.988    |
| fps                | 406      |
| nupdates           | 54800    |
| policy_entropy     | 0.00247  |
| total_timesteps    | 274000   |
| value_loss         | 1.07     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.976    |
| fps                | 406      |
| nupdates           | 54900    |
| policy_entropy     | 0.00139  |
| total_timesteps    | 274500   |
| value_loss         | 5.37     |
---------------------------------
10.0
10.0
12.49
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 212      |
| explained_variance | -71.4    |
| fps                | 406      |
| nupdates           | 55000    |
| policy_entropy     | 0.242    |
| total_timesteps    | 275000   |
| value_loss         | 1.18e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.992    |
| fps                | 406      |
| nupdates           | 55100    |
| policy_entropy     | 0.0834   |
| total_timesteps    | 275500   |
| value_loss         | 2.61     |
---------------------------------
10.0
10.0
14.29
14.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 206      |
| explained_variance | -4.99    |
| fps                | 406      |
| nupdates           | 55200    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 276000   |
| value_loss         | 469      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 202      |
| explained_variance | 0.668    |
| fps                | 405      |
| nupdates           | 55300    |
| policy_entropy     | 0.016    |
| total_timesteps    | 276500   |
| value_loss         | 171      |
---------------------------------
9.0
9.0
16.92
15.5
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 200      |
| explained_variance | 0.351    |
| fps                | 405      |
| nupdates           | 55400    |
| policy_entropy     | 0.00507  |
| total_timesteps    | 277000   |
| value_loss         | 125      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 195      |
| explained_variance | -18.9    |
| fps                | 405      |
| nupdates           | 55500    |
| policy_entropy     | 0.155    |
| total_timesteps    | 277500   |
| value_loss         | 4.67e+03 |
---------------------------------
47.0
47.0
20.11
21.5
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 194      |
| explained_variance | 0.35     |
| fps                | 405      |
| nupdates           | 55600    |
| policy_entropy     | 0.145    |
| total_timesteps    | 278000   |
| value_loss         | 181      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 196      |
| explained_variance | -0.243   |
| fps                | 405      |
| nupdates           | 55700    |
| policy_entropy     | 0.23     |
| total_timesteps    | 278500   |
| value_loss         | 39.7     |
---------------------------------
22.0
22.0
18.35
11.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 197      |
| explained_variance | 0.669    |
| fps                | 405      |
| nupdates           | 55800    |
| policy_entropy     | 0.0187   |
| total_timesteps    | 279000   |
| value_loss         | 42       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0158   |
| fps                | 405      |
| nupdates           | 55900    |
| policy_entropy     | 0.0304   |
| total_timesteps    | 279500   |
| value_loss         | 37.6     |
---------------------------------
11.0
11.0
16.64
24.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0.54     |
| fps                | 405      |
| nupdates           | 56000    |
| policy_entropy     | 0.123    |
| total_timesteps    | 280000   |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 200      |
| explained_variance | -1.02    |
| fps                | 405      |
| nupdates           | 56100    |
| policy_entropy     | 0.0828   |
| total_timesteps    | 280500   |
| value_loss         | 49.4     |
---------------------------------
20.0
20.0
19.81
20.0
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 196      |
| explained_variance | 0.933    |
| fps                | 405      |
| nupdates           | 56200    |
| policy_entropy     | 0.136    |
| total_timesteps    | 281000   |
| value_loss         | 21       |
---------------------------------
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 193      |
| explained_variance | -1.39    |
| fps                | 405      |
| nupdates           | 56300    |
| policy_entropy     | 0.28     |
| total_timesteps    | 281500   |
| value_loss         | 354      |
---------------------------------
9.0
9.0
21.34
15.0
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 193      |
| explained_variance | 0.765    |
| fps                | 405      |
| nupdates           | 56400    |
| policy_entropy     | 0.236    |
| total_timesteps    | 282000   |
| value_loss         | 51.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 189      |
| explained_variance | 0        |
| fps                | 405      |
| nupdates           | 56500    |
| policy_entropy     | 0.0535   |
| total_timesteps    | 282500   |
| value_loss         | 19       |
---------------------------------
15.0
15.0
22.19
26.0
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 189      |
| explained_variance | -11.2    |
| fps                | 405      |
| nupdates           | 56600    |
| policy_entropy     | 0.0855   |
| total_timesteps    | 283000   |
| value_loss         | 67.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 189      |
| explained_variance | -1.81    |
| fps                | 405      |
| nupdates           | 56700    |
| policy_entropy     | 0.156    |
| total_timesteps    | 283500   |
| value_loss         | 726      |
---------------------------------
9.0
9.0
31.24
10.0
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 159      |
| explained_variance | 0.585    |
| fps                | 405      |
| nupdates           | 56800    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 284000   |
| value_loss         | 2.26e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 30       |
| ep_reward_mean     | 162      |
| explained_variance | 0        |
| fps                | 405      |
| nupdates           | 56900    |
| policy_entropy     | 0.762    |
| total_timesteps    | 284500   |
| value_loss         | 0.651    |
---------------------------------
144.0
144.0
33.08
21.0
---------------------------------
| ep_len_mean        | 33.1     |
| ep_reward_mean     | 152      |
| explained_variance | 5.96e-08 |
| fps                | 405      |
| nupdates           | 57000    |
| policy_entropy     | 0.138    |
| total_timesteps    | 285000   |
| value_loss         | 0.00527  |
---------------------------------
---------------------------------
| ep_len_mean        | 34.8     |
| ep_reward_mean     | 146      |
| explained_variance | -0.0488  |
| fps                | 405      |
| nupdates           | 57100    |
| policy_entropy     | 0.171    |
| total_timesteps    | 285500   |
| value_loss         | 31.9     |
---------------------------------
10.0
10.0
22.66
11.0
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 180      |
| explained_variance | -2.48    |
| fps                | 405      |
| nupdates           | 57200    |
| policy_entropy     | 0.391    |
| total_timesteps    | 286000   |
| value_loss         | 55.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.9     |
| ep_reward_mean     | 179      |
| explained_variance | -20.9    |
| fps                | 405      |
| nupdates           | 57300    |
| policy_entropy     | 0.428    |
| total_timesteps    | 286500   |
| value_loss         | 73.4     |
---------------------------------
12.0
12.0
17.89
10.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 193      |
| explained_variance | -2.2     |
| fps                | 405      |
| nupdates           | 57400    |
| policy_entropy     | 0.0916   |
| total_timesteps    | 287000   |
| value_loss         | 316      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 205      |
| explained_variance | -5.02    |
| fps                | 405      |
| nupdates           | 57500    |
| policy_entropy     | 0.0065   |
| total_timesteps    | 287500   |
| value_loss         | 6.14e+03 |
---------------------------------
23.0
23.0
13.81
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 207      |
| explained_variance | 0.566    |
| fps                | 405      |
| nupdates           | 57600    |
| policy_entropy     | 0.015    |
| total_timesteps    | 288000   |
| value_loss         | 33.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 405      |
| nupdates           | 57700    |
| policy_entropy     | 0.0479   |
| total_timesteps    | 288500   |
| value_loss         | 123      |
---------------------------------
19.0
19.0
14.28
12.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.748    |
| fps                | 405      |
| nupdates           | 57800    |
| policy_entropy     | 0.00696  |
| total_timesteps    | 289000   |
| value_loss         | 21.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 210      |
| explained_variance | -3.72    |
| fps                | 405      |
| nupdates           | 57900    |
| policy_entropy     | 0.239    |
| total_timesteps    | 289500   |
| value_loss         | 539      |
---------------------------------
10.0
10.0
12.26
10.5
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.892    |
| fps                | 405      |
| nupdates           | 58000    |
| policy_entropy     | 0.0388   |
| total_timesteps    | 290000   |
| value_loss         | 18.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 213      |
| explained_variance | -0.627   |
| fps                | 405      |
| nupdates           | 58100    |
| policy_entropy     | 0.151    |
| total_timesteps    | 290500   |
| value_loss         | 724      |
---------------------------------
10.0
10.0
11.74
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.424    |
| fps                | 405      |
| nupdates           | 58200    |
| policy_entropy     | 0.269    |
| total_timesteps    | 291000   |
| value_loss         | 228      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.816    |
| fps                | 405      |
| nupdates           | 58300    |
| policy_entropy     | 0.00615  |
| total_timesteps    | 291500   |
| value_loss         | 17       |
---------------------------------
9.0
9.0
12.42
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.968    |
| fps                | 405      |
| nupdates           | 58400    |
| policy_entropy     | 0.117    |
| total_timesteps    | 292000   |
| value_loss         | 8.09     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 208      |
| explained_variance | 0.989    |
| fps                | 405      |
| nupdates           | 58500    |
| policy_entropy     | 0.182    |
| total_timesteps    | 292500   |
| value_loss         | 1.16     |
---------------------------------
9.0
9.0
13.98
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 207      |
| explained_variance | 0.898    |
| fps                | 404      |
| nupdates           | 58600    |
| policy_entropy     | 0.178    |
| total_timesteps    | 293000   |
| value_loss         | 15.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 205      |
| explained_variance | -6.61    |
| fps                | 404      |
| nupdates           | 58700    |
| policy_entropy     | 0.517    |
| total_timesteps    | 293500   |
| value_loss         | 1.02e+03 |
---------------------------------
9.0
9.0
14.41
12.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 205      |
| explained_variance | 0.995    |
| fps                | 404      |
| nupdates           | 58800    |
| policy_entropy     | 0.141    |
| total_timesteps    | 294000   |
| value_loss         | 20.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 205      |
| explained_variance | 0.989    |
| fps                | 404      |
| nupdates           | 58900    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 294500   |
| value_loss         | 3.91     |
---------------------------------
11.0
11.0
16.29
15.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 204      |
| explained_variance | -0.545   |
| fps                | 404      |
| nupdates           | 59000    |
| policy_entropy     | 0.00341  |
| total_timesteps    | 295000   |
| value_loss         | 329      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 208      |
| explained_variance | -11.6    |
| fps                | 404      |
| nupdates           | 59100    |
| policy_entropy     | 0.254    |
| total_timesteps    | 295500   |
| value_loss         | 748      |
---------------------------------
9.0
9.0
13.65
9.5
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.983    |
| fps                | 404      |
| nupdates           | 59200    |
| policy_entropy     | 0.027    |
| total_timesteps    | 296000   |
| value_loss         | 4.27     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.916    |
| fps                | 404      |
| nupdates           | 59300    |
| policy_entropy     | 0.00388  |
| total_timesteps    | 296500   |
| value_loss         | 11.5     |
---------------------------------
20.0
20.0
13.32
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.0371   |
| fps                | 404      |
| nupdates           | 59400    |
| policy_entropy     | 0.0187   |
| total_timesteps    | 297000   |
| value_loss         | 823      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.957    |
| fps                | 404      |
| nupdates           | 59500    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 297500   |
| value_loss         | 7.84     |
---------------------------------
9.0
9.0
13.3
10.0
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.929    |
| fps                | 404      |
| nupdates           | 59600    |
| policy_entropy     | 0.00378  |
| total_timesteps    | 298000   |
| value_loss         | 61.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 211      |
| explained_variance | 0.925    |
| fps                | 404      |
| nupdates           | 59700    |
| policy_entropy     | 0.164    |
| total_timesteps    | 298500   |
| value_loss         | 403      |
---------------------------------
10.0
10.0
12.02
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 212      |
| explained_variance | 0.981    |
| fps                | 404      |
| nupdates           | 59800    |
| policy_entropy     | 0.137    |
| total_timesteps    | 299000   |
| value_loss         | 3.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 209      |
| explained_variance | -59.8    |
| fps                | 404      |
| nupdates           | 59900    |
| policy_entropy     | 0.185    |
| total_timesteps    | 299500   |
| value_loss         | 9.04e+03 |
---------------------------------
10.0
10.0
14.38
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.995    |
| fps                | 404      |
| nupdates           | 60000    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 300000   |
| value_loss         | 4.03     |
---------------------------------