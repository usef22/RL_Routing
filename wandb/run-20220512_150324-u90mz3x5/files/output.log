___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 5}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | -0.00123 |
| fps                | 33       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 986      |
---------------------------------
---------------------------------
| ep_len_mean        | 83.7     |
| ep_reward_mean     | -37.7    |
| explained_variance | -0.0527  |
| fps                | 441      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 173      |
---------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026F58996FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026F58996FD0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026F61179F98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026F61179F98>>: AttributeError: module 'gast' has no attribute 'Index'
375.0
375.0
156.5
88.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 156      |
| ep_reward_mean     | -295     |
| explained_variance | 0.0272   |
| fps                | 464      |
| nupdates           | 200      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1000     |
| value_loss         | 50.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 249      |
| ep_reward_mean     | -688     |
| explained_variance | -0.0268  |
| fps                | 477      |
| nupdates           | 300      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1500     |
| value_loss         | 231      |
---------------------------------
452.0
452.0
249.16666666666666
239.0
---------------------------------
| ep_len_mean        | 249      |
| ep_reward_mean     | -688     |
| explained_variance | 0.00372  |
| fps                | 484      |
| nupdates           | 400      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2000     |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 300      |
| ep_reward_mean     | -864     |
| explained_variance | 0.0363   |
| fps                | 481      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 224      |
---------------------------------
109.0
109.0
276.4
225.5
---------------------------------
| ep_len_mean        | 276      |
| ep_reward_mean     | -768     |
| explained_variance | 0.00728  |
| fps                | 485      |
| nupdates           | 600      |
| policy_entropy     | 1.09     |
| total_timesteps    | 3000     |
| value_loss         | 39       |
---------------------------------
---------------------------------
| ep_len_mean        | 281      |
| ep_reward_mean     | -774     |
| explained_variance | 0.0381   |
| fps                | 488      |
| nupdates           | 700      |
| policy_entropy     | 1.08     |
| total_timesteps    | 3500     |
| value_loss         | 135      |
---------------------------------
369.0
369.0
287.9230769230769
372.0
---------------------------------
| ep_len_mean        | 288      |
| ep_reward_mean     | -806     |
| explained_variance | -0.0479  |
| fps                | 491      |
| nupdates           | 800      |
| policy_entropy     | 1.05     |
| total_timesteps    | 4000     |
| value_loss         | 34.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 296      |
| ep_reward_mean     | -827     |
| explained_variance | -0.27    |
| fps                | 493      |
| nupdates           | 900      |
| policy_entropy     | 1.04     |
| total_timesteps    | 4500     |
| value_loss         | 66.8     |
---------------------------------
298.0
298.0
287.0
255.0
---------------------------------
| ep_len_mean        | 287      |
| ep_reward_mean     | -803     |
| explained_variance | 0.0133   |
| fps                | 494      |
| nupdates           | 1000     |
| policy_entropy     | 1.02     |
| total_timesteps    | 5000     |
| value_loss         | 86       |
---------------------------------
---------------------------------
| ep_len_mean        | 274      |
| ep_reward_mean     | -756     |
| explained_variance | 0.0023   |
| fps                | 495      |
| nupdates           | 1100     |
| policy_entropy     | 1.06     |
| total_timesteps    | 5500     |
| value_loss         | 80.1     |
---------------------------------
24.0
24.0
246.33333333333334
134.5
---------------------------------
| ep_len_mean        | 246      |
| ep_reward_mean     | -658     |
| explained_variance | 1.41e-05 |
| fps                | 496      |
| nupdates           | 1200     |
| policy_entropy     | 1.05     |
| total_timesteps    | 6000     |
| value_loss         | 586      |
---------------------------------
---------------------------------
| ep_len_mean        | 259      |
| ep_reward_mean     | -705     |
| explained_variance | 0.000177 |
| fps                | 496      |
| nupdates           | 1300     |
| policy_entropy     | 1.02     |
| total_timesteps    | 6500     |
| value_loss         | 89.9     |
---------------------------------
100.0
100.0
245.35714285714286
103.5
---------------------------------
| ep_len_mean        | 245      |
| ep_reward_mean     | -654     |
| explained_variance | 0        |
| fps                | 497      |
| nupdates           | 1400     |
| policy_entropy     | 0.766    |
| total_timesteps    | 7000     |
| value_loss         | 71.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 226      |
| ep_reward_mean     | -589     |
| explained_variance | 0.00162  |
| fps                | 497      |
| nupdates           | 1500     |
| policy_entropy     | 0.945    |
| total_timesteps    | 7500     |
| value_loss         | 309      |
---------------------------------
94.0
94.0
206.78947368421052
102.0
----------------------------------
| ep_len_mean        | 207       |
| ep_reward_mean     | -520      |
| explained_variance | -1.69e-05 |
| fps                | 498       |
| nupdates           | 1600      |
| policy_entropy     | 0.997     |
| total_timesteps    | 8000      |
| value_loss         | 153       |
----------------------------------
---------------------------------
| ep_len_mean        | 195      |
| ep_reward_mean     | -478     |
| explained_variance | 2.5e-05  |
| fps                | 499      |
| nupdates           | 1700     |
| policy_entropy     | 1        |
| total_timesteps    | 8500     |
| value_loss         | 98.4     |
---------------------------------
21.0
21.0
172.94230769230768
49.0
---------------------------------
| ep_len_mean        | 173      |
| ep_reward_mean     | -397     |
| explained_variance | 0.00306  |
| fps                | 499      |
| nupdates           | 1800     |
| policy_entropy     | 0.822    |
| total_timesteps    | 9000     |
| value_loss         | 649      |
---------------------------------
---------------------------------
| ep_len_mean        | 148      |
| ep_reward_mean     | -306     |
| explained_variance | 1.4e-05  |
| fps                | 499      |
| nupdates           | 1900     |
| policy_entropy     | 0.822    |
| total_timesteps    | 9500     |
| value_loss         | 4.98e+04 |
---------------------------------
78.0
78.0
134.6216216216216
38.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 135       |
| ep_reward_mean     | -251      |
| explained_variance | -6.32e-06 |
| fps                | 498       |
| nupdates           | 2000      |
| policy_entropy     | 0.938     |
| total_timesteps    | 10000     |
| value_loss         | 129       |
----------------------------------
---------------------------------
| ep_len_mean        | 119      |
| ep_reward_mean     | -191     |
| explained_variance | -0.0111  |
| fps                | 498      |
| nupdates           | 2100     |
| policy_entropy     | 0.417    |
| total_timesteps    | 10500    |
| value_loss         | 51.2     |
---------------------------------
18.0
18.0
99.42
17.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 99.4     |
| ep_reward_mean     | -110     |
| explained_variance | -0.00302 |
| fps                | 498      |
| nupdates           | 2200     |
| policy_entropy     | 0.599    |
| total_timesteps    | 11000    |
| value_loss         | 1.34e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 70.6     |
| ep_reward_mean     | -5.12    |
| explained_variance | -0.0012  |
| fps                | 498      |
| nupdates           | 2300     |
| policy_entropy     | 0.34     |
| total_timesteps    | 11500    |
| value_loss         | 307      |
---------------------------------
10.0
10.0
43.53
14.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 43.5      |
| ep_reward_mean     | 102       |
| explained_variance | -4.92e-05 |
| fps                | 498       |
| nupdates           | 2400      |
| policy_entropy     | 0.662     |
| total_timesteps    | 12000     |
| value_loss         | 35.3      |
----------------------------------
---------------------------------
| ep_len_mean        | 35.1     |
| ep_reward_mean     | 137      |
| explained_variance | 0        |
| fps                | 498      |
| nupdates           | 2500     |
| policy_entropy     | 0.116    |
| total_timesteps    | 12500    |
| value_loss         | 117      |
---------------------------------
9.0
9.0
38.54
18.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 38.5      |
| ep_reward_mean     | 125       |
| explained_variance | -0.000677 |
| fps                | 498       |
| nupdates           | 2600      |
| policy_entropy     | 0.537     |
| total_timesteps    | 13000     |
| value_loss         | 2.92e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 32.5     |
| ep_reward_mean     | 144      |
| explained_variance | 0        |
| fps                | 498      |
| nupdates           | 2700     |
| policy_entropy     | 0.237    |
| total_timesteps    | 13500    |
| value_loss         | 17.2     |
---------------------------------
13.0
13.0
32.78
18.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 32.8     |
| ep_reward_mean     | 146      |
| explained_variance | -0.012   |
| fps                | 497      |
| nupdates           | 2800     |
| policy_entropy     | 0.211    |
| total_timesteps    | 14000    |
| value_loss         | 108      |
---------------------------------
---------------------------------
| ep_len_mean        | 30.8     |
| ep_reward_mean     | 150      |
| explained_variance | -0.0196  |
| fps                | 498      |
| nupdates           | 2900     |
| policy_entropy     | 0.093    |
| total_timesteps    | 14500    |
| value_loss         | 113      |
---------------------------------
24.0
24.0
30.65
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 30.6     |
| ep_reward_mean     | 153      |
| explained_variance | 0        |
| fps                | 497      |
| nupdates           | 3000     |
| policy_entropy     | 0.498    |
| total_timesteps    | 15000    |
| value_loss         | 16       |
---------------------------------
---------------------------------
| ep_len_mean        | 28.3     |
| ep_reward_mean     | 164      |
| explained_variance | -0.00474 |
| fps                | 497      |
| nupdates           | 3100     |
| policy_entropy     | 0.749    |
| total_timesteps    | 15500    |
| value_loss         | 15.6     |
---------------------------------
24.0
24.0
25.8
16.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.8     |
| ep_reward_mean     | 179      |
| explained_variance | -3.15    |
| fps                | 497      |
| nupdates           | 3200     |
| policy_entropy     | 0.346    |
| total_timesteps    | 16000    |
| value_loss         | 108      |
---------------------------------
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 196      |
| explained_variance | 0.538    |
| fps                | 497      |
| nupdates           | 3300     |
| policy_entropy     | 0.647    |
| total_timesteps    | 16500    |
| value_loss         | 82.1     |
---------------------------------
10.0
10.0
20.52
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 195      |
| explained_variance | -0.305   |
| fps                | 497      |
| nupdates           | 3400     |
| policy_entropy     | 0.137    |
| total_timesteps    | 17000    |
| value_loss         | 7.27e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 199      |
| explained_variance | -0.00464 |
| fps                | 496      |
| nupdates           | 3500     |
| policy_entropy     | 0.844    |
| total_timesteps    | 17500    |
| value_loss         | 105      |
---------------------------------
9.0
9.0
23.68
17.0
----------------------------------
| ep_len_mean        | 23.7      |
| ep_reward_mean     | 181       |
| explained_variance | -1.19e-07 |
| fps                | 496       |
| nupdates           | 3600      |
| policy_entropy     | 0.181     |
| total_timesteps    | 18000     |
| value_loss         | 104       |
----------------------------------
---------------------------------
| ep_len_mean        | 23.6     |
| ep_reward_mean     | 180      |
| explained_variance | -0.0622  |
| fps                | 496      |
| nupdates           | 3700     |
| policy_entropy     | 0.147    |
| total_timesteps    | 18500    |
| value_loss         | 3.29e+04 |
---------------------------------
9.0
9.0
22.74
9.5
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 182      |
| explained_variance | 0        |
| fps                | 495      |
| nupdates           | 3800     |
| policy_entropy     | 0.595    |
| total_timesteps    | 19000    |
| value_loss         | 13.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.3     |
| ep_reward_mean     | 186      |
| explained_variance | 0        |
| fps                | 495      |
| nupdates           | 3900     |
| policy_entropy     | 0.0486   |
| total_timesteps    | 19500    |
| value_loss         | 102      |
---------------------------------
311.0
311.0
23.97
17.0
---------------------------------
| ep_len_mean        | 24       |
| ep_reward_mean     | 179      |
| explained_variance | 0        |
| fps                | 496      |
| nupdates           | 4000     |
| policy_entropy     | 0.032    |
| total_timesteps    | 20000    |
| value_loss         | 98.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.2     |
| ep_reward_mean     | 178      |
| explained_variance | -0.00889 |
| fps                | 496      |
| nupdates           | 4100     |
| policy_entropy     | 0.405    |
| total_timesteps    | 20500    |
| value_loss         | 1.8e+04  |
---------------------------------
18.0
18.0
25.69
11.0
---------------------------------
| ep_len_mean        | 25.7     |
| ep_reward_mean     | 175      |
| explained_variance | 0        |
| fps                | 496      |
| nupdates           | 4200     |
| policy_entropy     | 0.494    |
| total_timesteps    | 21000    |
| value_loss         | 10.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 28       |
| ep_reward_mean     | 170      |
| explained_variance | 0        |
| fps                | 496      |
| nupdates           | 4300     |
| policy_entropy     | 0.0475   |
| total_timesteps    | 21500    |
| value_loss         | 95.3     |
---------------------------------
9.0
9.0
31.39
18.5
---------------------------------
| ep_len_mean        | 31.4     |
| ep_reward_mean     | 157      |
| explained_variance | 0        |
| fps                | 496      |
| nupdates           | 4400     |
| policy_entropy     | 0.343    |
| total_timesteps    | 22000    |
| value_loss         | 9.57     |
---------------------------------
----------------------------------
| ep_len_mean        | 35.1      |
| ep_reward_mean     | 150       |
| explained_variance | -0.000651 |
| fps                | 496       |
| nupdates           | 4500      |
| policy_entropy     | 0.51      |
| total_timesteps    | 22500     |
| value_loss         | 146       |
----------------------------------
9.0
9.0
36.9
9.0
----------------------------------
| ep_len_mean        | 36.9      |
| ep_reward_mean     | 144       |
| explained_variance | -0.000785 |
| fps                | 496       |
| nupdates           | 4600      |
| policy_entropy     | 0.754     |
| total_timesteps    | 23000     |
| value_loss         | 8.67      |
----------------------------------
----------------------------------
| ep_len_mean        | 32.1      |
| ep_reward_mean     | 169       |
| explained_variance | -1.19e-07 |
| fps                | 496       |
| nupdates           | 4700      |
| policy_entropy     | 0.103     |
| total_timesteps    | 23500     |
| value_loss         | 87.6      |
----------------------------------
10.0
10.0
31.01
10.0
---------------------------------
| ep_len_mean        | 31       |
| ep_reward_mean     | 165      |
| explained_variance | 0.641    |
| fps                | 496      |
| nupdates           | 4800     |
| policy_entropy     | 0.238    |
| total_timesteps    | 24000    |
| value_loss         | 151      |
---------------------------------
---------------------------------
| ep_len_mean        | 26.9     |
| ep_reward_mean     | 179      |
| explained_variance | 0.689    |
| fps                | 496      |
| nupdates           | 4900     |
| policy_entropy     | 0.117    |
| total_timesteps    | 24500    |
| value_loss         | 1.11e+03 |
---------------------------------
15.0
15.0
20.24
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 195      |
| explained_variance | 0.236    |
| fps                | 495      |
| nupdates           | 5000     |
| policy_entropy     | 0.129    |
| total_timesteps    | 25000    |
| value_loss         | 120      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 210      |
| explained_variance | -2.79    |
| fps                | 495      |
| nupdates           | 5100     |
| policy_entropy     | 0.0977   |
| total_timesteps    | 25500    |
| value_loss         | 249      |
---------------------------------
10.0
10.0
13.92
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.0727   |
| fps                | 494      |
| nupdates           | 5200     |
| policy_entropy     | 0.113    |
| total_timesteps    | 26000    |
| value_loss         | 62.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 211      |
| explained_variance | -0.22    |
| fps                | 494      |
| nupdates           | 5300     |
| policy_entropy     | 0.145    |
| total_timesteps    | 26500    |
| value_loss         | 5.54e+04 |
---------------------------------
20.0
20.0
18.36
19.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 200      |
| explained_variance | 0.00125  |
| fps                | 494      |
| nupdates           | 5400     |
| policy_entropy     | 0.67     |
| total_timesteps    | 27000    |
| value_loss         | 3.94e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 197      |
| explained_variance | 0.145    |
| fps                | 494      |
| nupdates           | 5500     |
| policy_entropy     | 0.195    |
| total_timesteps    | 27500    |
| value_loss         | 296      |
---------------------------------
21.0
21.0
19.27
10.0
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 197      |
| explained_variance | 0.749    |
| fps                | 494      |
| nupdates           | 5600     |
| policy_entropy     | 0.114    |
| total_timesteps    | 28000    |
| value_loss         | 184      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 213      |
| explained_variance | -0.547   |
| fps                | 494      |
| nupdates           | 5700     |
| policy_entropy     | 0.167    |
| total_timesteps    | 28500    |
| value_loss         | 6.19e+04 |
---------------------------------
8.0
8.0
13.74
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0071  |
| fps                | 493      |
| nupdates           | 5800     |
| policy_entropy     | 0.0983   |
| total_timesteps    | 29000    |
| value_loss         | 1.22e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 212      |
| explained_variance | -0.0406  |
| fps                | 493      |
| nupdates           | 5900     |
| policy_entropy     | 0.104    |
| total_timesteps    | 29500    |
| value_loss         | 2.43e+04 |
---------------------------------
9.0
9.0
14.73
12.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | -0.298   |
| fps                | 493      |
| nupdates           | 6000     |
| policy_entropy     | 0.0471   |
| total_timesteps    | 30000    |
| value_loss         | 4.29e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 214      |
| explained_variance | -0.277   |
| fps                | 493      |
| nupdates           | 6100     |
| policy_entropy     | 0.0475   |
| total_timesteps    | 30500    |
| value_loss         | 193      |
---------------------------------
20.0
20.0
15.29
15.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | -1.71    |
| fps                | 493      |
| nupdates           | 6200     |
| policy_entropy     | 0.133    |
| total_timesteps    | 31000    |
| value_loss         | 53.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | 0.493    |
| fps                | 493      |
| nupdates           | 6300     |
| policy_entropy     | 0.712    |
| total_timesteps    | 31500    |
| value_loss         | 128      |
---------------------------------
17.0
17.0
17.31
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 206      |
| explained_variance | -0.616   |
| fps                | 493      |
| nupdates           | 6400     |
| policy_entropy     | 0.255    |
| total_timesteps    | 32000    |
| value_loss         | 1.32e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | 0.225    |
| fps                | 493      |
| nupdates           | 6500     |
| policy_entropy     | 0.323    |
| total_timesteps    | 32500    |
| value_loss         | 10.1     |
---------------------------------
9.0
9.0
14.39
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.15     |
| fps                | 492      |
| nupdates           | 6600     |
| policy_entropy     | 0.0374   |
| total_timesteps    | 33000    |
| value_loss         | 628      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 219      |
| explained_variance | -0.0258  |
| fps                | 492      |
| nupdates           | 6700     |
| policy_entropy     | 0.185    |
| total_timesteps    | 33500    |
| value_loss         | 4.94e+03 |
---------------------------------
17.0
17.0
16.53
14.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 209      |
| explained_variance | -1.53    |
| fps                | 492      |
| nupdates           | 6800     |
| policy_entropy     | 0.179    |
| total_timesteps    | 34000    |
| value_loss         | 6.01e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 208      |
| explained_variance | -0.0838  |
| fps                | 492      |
| nupdates           | 6900     |
| policy_entropy     | 0.039    |
| total_timesteps    | 34500    |
| value_loss         | 36.5     |
---------------------------------
18.0
18.0
12.08
9.5
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.613    |
| fps                | 492      |
| nupdates           | 7000     |
| policy_entropy     | 0.269    |
| total_timesteps    | 35000    |
| value_loss         | 89.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0        |
| fps                | 492      |
| nupdates           | 7100     |
| policy_entropy     | 0.175    |
| total_timesteps    | 35500    |
| value_loss         | 60.5     |
---------------------------------
316.0
316.0
15.81
15.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 207      |
| explained_variance | 0        |
| fps                | 492      |
| nupdates           | 7200     |
| policy_entropy     | 0.36     |
| total_timesteps    | 36000    |
| value_loss         | 7.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 198      |
| explained_variance | -12.1    |
| fps                | 492      |
| nupdates           | 7300     |
| policy_entropy     | 0.0979   |
| total_timesteps    | 36500    |
| value_loss         | 93.3     |
---------------------------------
9.0
9.0
20.45
9.5
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 198      |
| explained_variance | -34.6    |
| fps                | 492      |
| nupdates           | 7400     |
| policy_entropy     | 0.361    |
| total_timesteps    | 37000    |
| value_loss         | 304      |
---------------------------------
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 196      |
| explained_variance | 0.665    |
| fps                | 492      |
| nupdates           | 7500     |
| policy_entropy     | 0.0272   |
| total_timesteps    | 37500    |
| value_loss         | 63.2     |
---------------------------------
10.0
10.0
13.81
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.106    |
| fps                | 492      |
| nupdates           | 7600     |
| policy_entropy     | 0.114    |
| total_timesteps    | 38000    |
| value_loss         | 1.64e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | -0.0642  |
| fps                | 492      |
| nupdates           | 7700     |
| policy_entropy     | 0.0418   |
| total_timesteps    | 38500    |
| value_loss         | 429      |
---------------------------------
27.0
27.0
13.12
10.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 216      |
| explained_variance | 1.19e-07 |
| fps                | 492      |
| nupdates           | 7800     |
| policy_entropy     | 0.0905   |
| total_timesteps    | 39000    |
| value_loss         | 167      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 492      |
| nupdates           | 7900     |
| policy_entropy     | 0.194    |
| total_timesteps    | 39500    |
| value_loss         | 151      |
---------------------------------
8.0
8.0
16.29
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0103   |
| fps                | 491      |
| nupdates           | 8000     |
| policy_entropy     | 0.203    |
| total_timesteps    | 40000    |
| value_loss         | 5.57e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | -0.0365  |
| fps                | 491      |
| nupdates           | 8100     |
| policy_entropy     | 0.772    |
| total_timesteps    | 40500    |
| value_loss         | 78.7     |
---------------------------------
10.0
10.0
13.36
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 221      |
| explained_variance | -0.0116  |
| fps                | 491      |
| nupdates           | 8200     |
| policy_entropy     | 0.159    |
| total_timesteps    | 41000    |
| value_loss         | 1.75e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 207      |
| explained_variance | -8.11    |
| fps                | 492      |
| nupdates           | 8300     |
| policy_entropy     | 0.265    |
| total_timesteps    | 41500    |
| value_loss         | 435      |
---------------------------------
10.0
10.0
17.14
13.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 202      |
| explained_variance | 0.00715  |
| fps                | 491      |
| nupdates           | 8400     |
| policy_entropy     | 0.113    |
| total_timesteps    | 42000    |
| value_loss         | 5.99e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 198      |
| explained_variance | -1.65    |
| fps                | 491      |
| nupdates           | 8500     |
| policy_entropy     | 0.146    |
| total_timesteps    | 42500    |
| value_loss         | 9.1e+03  |
---------------------------------
9.0
9.0
13.45
9.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.0181   |
| fps                | 491      |
| nupdates           | 8600     |
| policy_entropy     | 0.0362   |
| total_timesteps    | 43000    |
| value_loss         | 132      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.0437   |
| fps                | 491      |
| nupdates           | 8700     |
| policy_entropy     | 0.207    |
| total_timesteps    | 43500    |
| value_loss         | 2.6e+03  |
---------------------------------
10.0
10.0
14.3
13.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | -0.0518  |
| fps                | 491      |
| nupdates           | 8800     |
| policy_entropy     | 0.0481   |
| total_timesteps    | 44000    |
| value_loss         | 4.24e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.0325   |
| fps                | 491      |
| nupdates           | 8900     |
| policy_entropy     | 0.0709   |
| total_timesteps    | 44500    |
| value_loss         | 1.14e+03 |
---------------------------------
9.0
9.0
15.48
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 209      |
| explained_variance | -1.27    |
| fps                | 491      |
| nupdates           | 9000     |
| policy_entropy     | 0.0605   |
| total_timesteps    | 45000    |
| value_loss         | 227      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 202      |
| explained_variance | -0.0227  |
| fps                | 491      |
| nupdates           | 9100     |
| policy_entropy     | 0.18     |
| total_timesteps    | 45500    |
| value_loss         | 8.86e+03 |
---------------------------------
15.0
15.0
16.16
12.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 203      |
| explained_variance | 0.222    |
| fps                | 491      |
| nupdates           | 9200     |
| policy_entropy     | 0.0549   |
| total_timesteps    | 46000    |
| value_loss         | 5.24e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | -0.0451  |
| fps                | 491      |
| nupdates           | 9300     |
| policy_entropy     | 0.116    |
| total_timesteps    | 46500    |
| value_loss         | 2.03e+03 |
---------------------------------
10.0
10.0
11.87
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.0341   |
| fps                | 490      |
| nupdates           | 9400     |
| policy_entropy     | 0.0178   |
| total_timesteps    | 47000    |
| value_loss         | 2.85e+03 |
---------------------------------
----------------------------------
| ep_len_mean        | 12.1      |
| ep_reward_mean     | 222       |
| explained_variance | -1.19e-07 |
| fps                | 490       |
| nupdates           | 9500      |
| policy_entropy     | 0.0478    |
| total_timesteps    | 47500     |
| value_loss         | 307       |
----------------------------------
16.0
16.0
15.63
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 206      |
| explained_variance | -7.69    |
| fps                | 490      |
| nupdates           | 9600     |
| policy_entropy     | 0.029    |
| total_timesteps    | 48000    |
| value_loss         | 1.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 207      |
| explained_variance | -7.58    |
| fps                | 490      |
| nupdates           | 9700     |
| policy_entropy     | 0.288    |
| total_timesteps    | 48500    |
| value_loss         | 2.45e+03 |
---------------------------------
9.0
9.0
15.94
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 207      |
| explained_variance | -0.18    |
| fps                | 490      |
| nupdates           | 9800     |
| policy_entropy     | 0.0336   |
| total_timesteps    | 49000    |
| value_loss         | 2.14e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.427    |
| fps                | 490      |
| nupdates           | 9900     |
| policy_entropy     | 0.154    |
| total_timesteps    | 49500    |
| value_loss         | 59.4     |
---------------------------------
16.0
16.0
12.33
9.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.118    |
| fps                | 490      |
| nupdates           | 10000    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 50000    |
| value_loss         | 1.81e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 216      |
| explained_variance | -0.313   |
| fps                | 490      |
| nupdates           | 10100    |
| policy_entropy     | 0.438    |
| total_timesteps    | 50500    |
| value_loss         | 2.31e+03 |
---------------------------------
9.0
9.0
13.44
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 216      |
| explained_variance | -0.112   |
| fps                | 490      |
| nupdates           | 10200    |
| policy_entropy     | 0.0221   |
| total_timesteps    | 51000    |
| value_loss         | 144      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.316    |
| fps                | 490      |
| nupdates           | 10300    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 51500    |
| value_loss         | 1.57e+03 |
---------------------------------
16.0
16.0
12.16
9.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.42     |
| fps                | 490      |
| nupdates           | 10400    |
| policy_entropy     | 0.0396   |
| total_timesteps    | 52000    |
| value_loss         | 49.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.58     |
| fps                | 490      |
| nupdates           | 10500    |
| policy_entropy     | 0.13     |
| total_timesteps    | 52500    |
| value_loss         | 231      |
---------------------------------
16.0
16.0
12.11
9.5
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.126    |
| fps                | 490      |
| nupdates           | 10600    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 53000    |
| value_loss         | 1.01e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0        |
| fps                | 490      |
| nupdates           | 10700    |
| policy_entropy     | 0.104    |
| total_timesteps    | 53500    |
| value_loss         | 98       |
---------------------------------
10.0
10.0
16.42
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | -11.5    |
| fps                | 490      |
| nupdates           | 10800    |
| policy_entropy     | 0.123    |
| total_timesteps    | 54000    |
| value_loss         | 2.24e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.378    |
| fps                | 489      |
| nupdates           | 10900    |
| policy_entropy     | 0.0325   |
| total_timesteps    | 54500    |
| value_loss         | 832      |
---------------------------------
23.0
23.0
12.11
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 217      |
| explained_variance | -0.0844  |
| fps                | 489      |
| nupdates           | 11000    |
| policy_entropy     | 0.15     |
| total_timesteps    | 55000    |
| value_loss         | 652      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.304    |
| fps                | 489      |
| nupdates           | 11100    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 55500    |
| value_loss         | 65.3     |
---------------------------------
15.0
15.0
11.92
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 223      |
| explained_variance | 0.0289   |
| fps                | 489      |
| nupdates           | 11200    |
| policy_entropy     | 0.0408   |
| total_timesteps    | 56000    |
| value_loss         | 530      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 220      |
| explained_variance | -0.0518  |
| fps                | 489      |
| nupdates           | 11300    |
| policy_entropy     | 0.0232   |
| total_timesteps    | 56500    |
| value_loss         | 256      |
---------------------------------
21.0
21.0
11.36
10.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 220      |
| explained_variance | -0.0127  |
| fps                | 489      |
| nupdates           | 11400    |
| policy_entropy     | 0.607    |
| total_timesteps    | 57000    |
| value_loss         | 76.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.00731  |
| fps                | 489      |
| nupdates           | 11500    |
| policy_entropy     | 0.448    |
| total_timesteps    | 57500    |
| value_loss         | 52.5     |
---------------------------------
10.0
10.0
21.43
9.5
---------------------------------
| ep_len_mean        | 21.4     |
| ep_reward_mean     | 179      |
| explained_variance | -0.00638 |
| fps                | 489      |
| nupdates           | 11600    |
| policy_entropy     | 0.0323   |
| total_timesteps    | 58000    |
| value_loss         | 5.39e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 176      |
| explained_variance | 0.193    |
| fps                | 489      |
| nupdates           | 11700    |
| policy_entropy     | 0.02     |
| total_timesteps    | 58500    |
| value_loss         | 681      |
---------------------------------
12.0
12.0
24.69
11.0
---------------------------------
| ep_len_mean        | 24.7     |
| ep_reward_mean     | 172      |
| explained_variance | -0.14    |
| fps                | 489      |
| nupdates           | 11800    |
| policy_entropy     | 0.111    |
| total_timesteps    | 59000    |
| value_loss         | 4.43e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 208      |
| explained_variance | 0.047    |
| fps                | 489      |
| nupdates           | 11900    |
| policy_entropy     | 0.208    |
| total_timesteps    | 59500    |
| value_loss         | 51.4     |
---------------------------------
13.0
13.0
22.18
12.0
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 183      |
| explained_variance | 0.01     |
| fps                | 489      |
| nupdates           | 12000    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 60000    |
| value_loss         | 1.14e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 186      |
| explained_variance | -0.442   |
| fps                | 489      |
| nupdates           | 12100    |
| policy_entropy     | 0.0327   |
| total_timesteps    | 60500    |
| value_loss         | 5.86e+04 |
---------------------------------
71.0
71.0
19.71
9.5
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 188      |
| explained_variance | -13.9    |
| fps                | 489      |
| nupdates           | 12200    |
| policy_entropy     | 0.169    |
| total_timesteps    | 61000    |
| value_loss         | 3.79e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.979   |
| fps                | 489      |
| nupdates           | 12300    |
| policy_entropy     | 0.0698   |
| total_timesteps    | 61500    |
| value_loss         | 278      |
---------------------------------
10.0
10.0
12.51
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0        |
| fps                | 489      |
| nupdates           | 12400    |
| policy_entropy     | 0.0826   |
| total_timesteps    | 62000    |
| value_loss         | 157      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 195      |
| explained_variance | 0.207    |
| fps                | 489      |
| nupdates           | 12500    |
| policy_entropy     | 0.457    |
| total_timesteps    | 62500    |
| value_loss         | 0.0648   |
---------------------------------
16.0
16.0
19.85
17.0
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 193      |
| explained_variance | -0.703   |
| fps                | 489      |
| nupdates           | 12600    |
| policy_entropy     | 0.0366   |
| total_timesteps    | 63000    |
| value_loss         | 365      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 189      |
| explained_variance | -50.6    |
| fps                | 489      |
| nupdates           | 12700    |
| policy_entropy     | 0.0176   |
| total_timesteps    | 63500    |
| value_loss         | 744      |
---------------------------------
10.0
10.0
12.81
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 215      |
| explained_variance | -1.11    |
| fps                | 489      |
| nupdates           | 12800    |
| policy_entropy     | 0.027    |
| total_timesteps    | 64000    |
| value_loss         | 255      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.5      |
| fps                | 489      |
| nupdates           | 12900    |
| policy_entropy     | 0.0605   |
| total_timesteps    | 64500    |
| value_loss         | 473      |
---------------------------------
9.0
9.0
11.75
9.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 220      |
| explained_variance | -20.9    |
| fps                | 489      |
| nupdates           | 13000    |
| policy_entropy     | 0.459    |
| total_timesteps    | 65000    |
| value_loss         | 4.04e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 210      |
| explained_variance | -0.131   |
| fps                | 489      |
| nupdates           | 13100    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 65500    |
| value_loss         | 153      |
---------------------------------
10.0
10.0
14.52
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.427    |
| fps                | 489      |
| nupdates           | 13200    |
| policy_entropy     | 0.0438   |
| total_timesteps    | 66000    |
| value_loss         | 60.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.303    |
| fps                | 489      |
| nupdates           | 13300    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 66500    |
| value_loss         | 161      |
---------------------------------
9.0
9.0
12.18
9.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 222      |
| explained_variance | -0.263   |
| fps                | 488      |
| nupdates           | 13400    |
| policy_entropy     | 0.0311   |
| total_timesteps    | 67000    |
| value_loss         | 149      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 223      |
| explained_variance | 0.235    |
| fps                | 488      |
| nupdates           | 13500    |
| policy_entropy     | 0.00973  |
| total_timesteps    | 67500    |
| value_loss         | 468      |
---------------------------------
10.0
10.0
11.32
9.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 222      |
| explained_variance | -0.315   |
| fps                | 488      |
| nupdates           | 13600    |
| policy_entropy     | 0.636    |
| total_timesteps    | 68000    |
| value_loss         | 190      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 206      |
| explained_variance | -4.3     |
| fps                | 488      |
| nupdates           | 13700    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 68500    |
| value_loss         | 3.41e+03 |
---------------------------------
10.0
10.0
16.73
10.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 207      |
| explained_variance | -0.273   |
| fps                | 488      |
| nupdates           | 13800    |
| policy_entropy     | 0.0294   |
| total_timesteps    | 69000    |
| value_loss         | 602      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.111    |
| fps                | 488      |
| nupdates           | 13900    |
| policy_entropy     | 0.00969  |
| total_timesteps    | 69500    |
| value_loss         | 379      |
---------------------------------
9.0
9.0
12.2
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.143    |
| fps                | 488      |
| nupdates           | 14000    |
| policy_entropy     | 0.53     |
| total_timesteps    | 70000    |
| value_loss         | 98.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 222      |
| explained_variance | -1.27    |
| fps                | 488      |
| nupdates           | 14100    |
| policy_entropy     | 0.648    |
| total_timesteps    | 70500    |
| value_loss         | 376      |
---------------------------------
8.0
8.0
12.8
9.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 219      |
| explained_variance | -0.305   |
| fps                | 488      |
| nupdates           | 14200    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 71000    |
| value_loss         | 50.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | -0.152   |
| fps                | 488      |
| nupdates           | 14300    |
| policy_entropy     | 0.281    |
| total_timesteps    | 71500    |
| value_loss         | 93.7     |
---------------------------------
22.0
22.0
12.67
13.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.169    |
| fps                | 488      |
| nupdates           | 14400    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 72000    |
| value_loss         | 361      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 225      |
| explained_variance | -0.424   |
| fps                | 488      |
| nupdates           | 14500    |
| policy_entropy     | 0.0141   |
| total_timesteps    | 72500    |
| value_loss         | 138      |
---------------------------------
17.0
17.0
12.18
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 225      |
| explained_variance | 0.379    |
| fps                | 488      |
| nupdates           | 14600    |
| policy_entropy     | 0.0378   |
| total_timesteps    | 73000    |
| value_loss         | 182      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 221      |
| explained_variance | -0.268   |
| fps                | 487      |
| nupdates           | 14700    |
| policy_entropy     | 0.016    |
| total_timesteps    | 73500    |
| value_loss         | 78.3     |
---------------------------------
10.0
10.0
11.48
10.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 221      |
| explained_variance | -0.21    |
| fps                | 487      |
| nupdates           | 14800    |
| policy_entropy     | 0.0317   |
| total_timesteps    | 74000    |
| value_loss         | 162      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.114    |
| fps                | 487      |
| nupdates           | 14900    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 74500    |
| value_loss         | 479      |
---------------------------------
15.0
15.0
12.35
9.5
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.439    |
| fps                | 487      |
| nupdates           | 15000    |
| policy_entropy     | 0.0212   |
| total_timesteps    | 75000    |
| value_loss         | 44.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 223      |
| explained_variance | 0.494    |
| fps                | 487      |
| nupdates           | 15100    |
| policy_entropy     | 0.29     |
| total_timesteps    | 75500    |
| value_loss         | 19.3     |
---------------------------------
16.0
16.0
12.01
13.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 221      |
| explained_variance | 0.585    |
| fps                | 487      |
| nupdates           | 15200    |
| policy_entropy     | 0.0218   |
| total_timesteps    | 76000    |
| value_loss         | 29.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.091    |
| fps                | 487      |
| nupdates           | 15300    |
| policy_entropy     | 0.00783  |
| total_timesteps    | 76500    |
| value_loss         | 43.4     |
---------------------------------
15.0
15.0
12.12
12.5
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.457    |
| fps                | 487      |
| nupdates           | 15400    |
| policy_entropy     | 0.00917  |
| total_timesteps    | 77000    |
| value_loss         | 319      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 223      |
| explained_variance | -0.219   |
| fps                | 487      |
| nupdates           | 15500    |
| policy_entropy     | 0.0585   |
| total_timesteps    | 77500    |
| value_loss         | 149      |
---------------------------------
17.0
17.0
12.19
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.866    |
| fps                | 487      |
| nupdates           | 15600    |
| policy_entropy     | 0.0317   |
| total_timesteps    | 78000    |
| value_loss         | 44.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.725    |
| fps                | 487      |
| nupdates           | 15700    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 78500    |
| value_loss         | 437      |
---------------------------------
16.0
16.0
12.74
9.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.731    |
| fps                | 487      |
| nupdates           | 15800    |
| policy_entropy     | 0.0347   |
| total_timesteps    | 79000    |
| value_loss         | 27.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.09     |
| fps                | 487      |
| nupdates           | 15900    |
| policy_entropy     | 0.0515   |
| total_timesteps    | 79500    |
| value_loss         | 128      |
---------------------------------
16.0
16.0
13.36
9.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.745    |
| fps                | 487      |
| nupdates           | 16000    |
| policy_entropy     | 0.0284   |
| total_timesteps    | 80000    |
| value_loss         | 27.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.756    |
| fps                | 487      |
| nupdates           | 16100    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 80500    |
| value_loss         | 370      |
---------------------------------
8.0
8.0
10.87
10.0
---------------------------------
| ep_len_mean        | 10.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.427    |
| fps                | 487      |
| nupdates           | 16200    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 81000    |
| value_loss         | 612      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.00165  |
| fps                | 487      |
| nupdates           | 16300    |
| policy_entropy     | 0.493    |
| total_timesteps    | 81500    |
| value_loss         | 51.2     |
---------------------------------
8.0
8.0
11.64
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 221      |
| explained_variance | -0.403   |
| fps                | 487      |
| nupdates           | 16400    |
| policy_entropy     | 0.138    |
| total_timesteps    | 82000    |
| value_loss         | 285      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 224      |
| explained_variance | 0.727    |
| fps                | 487      |
| nupdates           | 16500    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 82500    |
| value_loss         | 48.7     |
---------------------------------
17.0
17.0
11.73
13.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | -0.273   |
| fps                | 487      |
| nupdates           | 16600    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 83000    |
| value_loss         | 52.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | 0.0112   |
| fps                | 487      |
| nupdates           | 16700    |
| policy_entropy     | 0.01     |
| total_timesteps    | 83500    |
| value_loss         | 272      |
---------------------------------
16.0
16.0
11.49
10.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 222      |
| explained_variance | -0.185   |
| fps                | 487      |
| nupdates           | 16800    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 84000    |
| value_loss         | 159      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.38     |
| fps                | 487      |
| nupdates           | 16900    |
| policy_entropy     | 0.06     |
| total_timesteps    | 84500    |
| value_loss         | 284      |
---------------------------------
9.0
9.0
11.43
9.5
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.932    |
| fps                | 487      |
| nupdates           | 17000    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 85000    |
| value_loss         | 14.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.873    |
| fps                | 487      |
| nupdates           | 17100    |
| policy_entropy     | 0.0154   |
| total_timesteps    | 85500    |
| value_loss         | 16.5     |
---------------------------------
17.0
17.0
11.92
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.411    |
| fps                | 486      |
| nupdates           | 17200    |
| policy_entropy     | 0.00863  |
| total_timesteps    | 86000    |
| value_loss         | 323      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | -1.44    |
| fps                | 487      |
| nupdates           | 17300    |
| policy_entropy     | 0.0972   |
| total_timesteps    | 86500    |
| value_loss         | 217      |
---------------------------------
9.0
9.0
11.99
9.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.853    |
| fps                | 486      |
| nupdates           | 17400    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 87000    |
| value_loss         | 71.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | -0.253   |
| fps                | 486      |
| nupdates           | 17500    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 87500    |
| value_loss         | 57.8     |
---------------------------------
9.0
9.0
11.47
12.5
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.428    |
| fps                | 486      |
| nupdates           | 17600    |
| policy_entropy     | 0.00891  |
| total_timesteps    | 88000    |
| value_loss         | 356      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 225      |
| explained_variance | 0.227    |
| fps                | 486      |
| nupdates           | 17700    |
| policy_entropy     | 0.032    |
| total_timesteps    | 88500    |
| value_loss         | 67.6     |
---------------------------------
16.0
16.0
11.95
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | -2.75    |
| fps                | 486      |
| nupdates           | 17800    |
| policy_entropy     | 0.592    |
| total_timesteps    | 89000    |
| value_loss         | 294      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | -0.212   |
| fps                | 486      |
| nupdates           | 17900    |
| policy_entropy     | 0.115    |
| total_timesteps    | 89500    |
| value_loss         | 438      |
---------------------------------
9.0
9.0
11.59
9.5
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.772    |
| fps                | 486      |
| nupdates           | 18000    |
| policy_entropy     | 0.00794  |
| total_timesteps    | 90000    |
| value_loss         | 372      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 222      |
| explained_variance | -1.33    |
| fps                | 486      |
| nupdates           | 18100    |
| policy_entropy     | 0.138    |
| total_timesteps    | 90500    |
| value_loss         | 240      |
---------------------------------
10.0
10.0
11.33
9.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.735    |
| fps                | 486      |
| nupdates           | 18200    |
| policy_entropy     | 0.00715  |
| total_timesteps    | 91000    |
| value_loss         | 16.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.916    |
| fps                | 486      |
| nupdates           | 18300    |
| policy_entropy     | 0.0257   |
| total_timesteps    | 91500    |
| value_loss         | 3.93     |
---------------------------------
10.0
10.0
11.93
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 223      |
| explained_variance | 0.642    |
| fps                | 486      |
| nupdates           | 18400    |
| policy_entropy     | 0.00928  |
| total_timesteps    | 92000    |
| value_loss         | 145      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.247    |
| fps                | 486      |
| nupdates           | 18500    |
| policy_entropy     | 0.00889  |
| total_timesteps    | 92500    |
| value_loss         | 544      |
---------------------------------
17.0
17.0
11.34
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.693    |
| fps                | 486      |
| nupdates           | 18600    |
| policy_entropy     | 0.015    |
| total_timesteps    | 93000    |
| value_loss         | 178      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.886    |
| fps                | 486      |
| nupdates           | 18700    |
| policy_entropy     | 0.0371   |
| total_timesteps    | 93500    |
| value_loss         | 12.1     |
---------------------------------
9.0
9.0
11.92
13.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | -0.232   |
| fps                | 486      |
| nupdates           | 18800    |
| policy_entropy     | 0.00581  |
| total_timesteps    | 94000    |
| value_loss         | 67       |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 224      |
| explained_variance | 0.0773   |
| fps                | 486      |
| nupdates           | 18900    |
| policy_entropy     | 0.0224   |
| total_timesteps    | 94500    |
| value_loss         | 178      |
---------------------------------
17.0
17.0
12.87
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 226      |
| explained_variance | 0.883    |
| fps                | 486      |
| nupdates           | 19000    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 95000    |
| value_loss         | 369      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 225      |
| explained_variance | 0.728    |
| fps                | 486      |
| nupdates           | 19100    |
| policy_entropy     | 0.00792  |
| total_timesteps    | 95500    |
| value_loss         | 16.8     |
---------------------------------
9.0
9.0
11.71
9.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | -0.92    |
| fps                | 486      |
| nupdates           | 19200    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 96000    |
| value_loss         | 111      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.176    |
| fps                | 486      |
| nupdates           | 19300    |
| policy_entropy     | 0.0258   |
| total_timesteps    | 96500    |
| value_loss         | 98.1     |
---------------------------------
9.0
9.0
11.98
9.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.92     |
| fps                | 486      |
| nupdates           | 19400    |
| policy_entropy     | 0.0386   |
| total_timesteps    | 97000    |
| value_loss         | 16.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 224      |
| explained_variance | -0.36    |
| fps                | 486      |
| nupdates           | 19500    |
| policy_entropy     | 0.0709   |
| total_timesteps    | 97500    |
| value_loss         | 135      |
---------------------------------
10.0
10.0
11.03
10.0
---------------------------------
| ep_len_mean        | 11       |
| ep_reward_mean     | 222      |
| explained_variance | 0.616    |
| fps                | 486      |
| nupdates           | 19600    |
| policy_entropy     | 0.0283   |
| total_timesteps    | 98000    |
| value_loss         | 66.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.774    |
| fps                | 486      |
| nupdates           | 19700    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 98500    |
| value_loss         | 25.6     |
---------------------------------
9.0
9.0
11.36
9.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.46     |
| fps                | 486      |
| nupdates           | 19800    |
| policy_entropy     | 0.0068   |
| total_timesteps    | 99000    |
| value_loss         | 565      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.938    |
| fps                | 486      |
| nupdates           | 19900    |
| policy_entropy     | 0.0215   |
| total_timesteps    | 99500    |
| value_loss         | 5.34     |
---------------------------------
16.0
16.0
11.69
9.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.331    |
| fps                | 486      |
| nupdates           | 20000    |
| policy_entropy     | 0.0194   |
| total_timesteps    | 100000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 225      |
| explained_variance | 0.415    |
| fps                | 486      |
| nupdates           | 20100    |
| policy_entropy     | 0.00843  |
| total_timesteps    | 100500   |
| value_loss         | 400      |
---------------------------------
15.0
15.0
11.82
9.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 223      |
| explained_variance | 0.908    |
| fps                | 486      |
| nupdates           | 20200    |
| policy_entropy     | 0.381    |
| total_timesteps    | 101000   |
| value_loss         | 29.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 224      |
| explained_variance | 0.982    |
| fps                | 486      |
| nupdates           | 20300    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 101500   |
| value_loss         | 1.14     |
---------------------------------
9.0
9.0
11.39
9.5
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.67     |
| fps                | 486      |
| nupdates           | 20400    |
| policy_entropy     | 0.00888  |
| total_timesteps    | 102000   |
| value_loss         | 291      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.612    |
| fps                | 486      |
| nupdates           | 20500    |
| policy_entropy     | 0.014    |
| total_timesteps    | 102500   |
| value_loss         | 44.5     |
---------------------------------
10.0
10.0
11.4
9.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.953    |
| fps                | 486      |
| nupdates           | 20600    |
| policy_entropy     | 0.044    |
| total_timesteps    | 103000   |
| value_loss         | 2.08     |
---------------------------------
---------------------------------
| ep_len_mean        | 10.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.826    |
| fps                | 486      |
| nupdates           | 20700    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 103500   |
| value_loss         | 16.5     |
---------------------------------
17.0
17.0
11.34
13.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.0791   |
| fps                | 485      |
| nupdates           | 20800    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 104000   |
| value_loss         | 119      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 224      |
| explained_variance | 0.92     |
| fps                | 485      |
| nupdates           | 20900    |
| policy_entropy     | 0.0727   |
| total_timesteps    | 104500   |
| value_loss         | 4.13     |
---------------------------------
10.0
10.0
12.48
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.62     |
| fps                | 485      |
| nupdates           | 21000    |
| policy_entropy     | 0.0166   |
| total_timesteps    | 105000   |
| value_loss         | 44.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.992    |
| fps                | 485      |
| nupdates           | 21100    |
| policy_entropy     | 0.0183   |
| total_timesteps    | 105500   |
| value_loss         | 0.974    |
---------------------------------
15.0
15.0
11.16
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.818    |
| fps                | 485      |
| nupdates           | 21200    |
| policy_entropy     | 0.00793  |
| total_timesteps    | 106000   |
| value_loss         | 329      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0.495    |
| fps                | 485      |
| nupdates           | 21300    |
| policy_entropy     | 0.0236   |
| total_timesteps    | 106500   |
| value_loss         | 35.2     |
---------------------------------
9.0
9.0
11.34
9.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | -0.558   |
| fps                | 485      |
| nupdates           | 21400    |
| policy_entropy     | 0.00859  |
| total_timesteps    | 107000   |
| value_loss         | 79.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | -0.0279  |
| fps                | 485      |
| nupdates           | 21500    |
| policy_entropy     | 0.00971  |
| total_timesteps    | 107500   |
| value_loss         | 161      |
---------------------------------
9.0
9.0
11.66
13.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.815    |
| fps                | 485      |
| nupdates           | 21600    |
| policy_entropy     | 0.334    |
| total_timesteps    | 108000   |
| value_loss         | 6.3      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 224      |
| explained_variance | -2.03    |
| fps                | 485      |
| nupdates           | 21700    |
| policy_entropy     | 0.00902  |
| total_timesteps    | 108500   |
| value_loss         | 170      |
---------------------------------
15.0
15.0
11.8
9.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 223      |
| explained_variance | -0.194   |
| fps                | 485      |
| nupdates           | 21800    |
| policy_entropy     | 0.00709  |
| total_timesteps    | 109000   |
| value_loss         | 138      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | 0.629    |
| fps                | 485      |
| nupdates           | 21900    |
| policy_entropy     | 0.00448  |
| total_timesteps    | 109500   |
| value_loss         | 265      |
---------------------------------
9.0
9.0
11.7
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.346    |
| fps                | 485      |
| nupdates           | 22000    |
| policy_entropy     | 0.00696  |
| total_timesteps    | 110000   |
| value_loss         | 382      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 224      |
| explained_variance | 0.953    |
| fps                | 485      |
| nupdates           | 22100    |
| policy_entropy     | 0.024    |
| total_timesteps    | 110500   |
| value_loss         | 12.4     |
---------------------------------
9.0
9.0
11.09
9.5
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 222      |
| explained_variance | -0.596   |
| fps                | 485      |
| nupdates           | 22200    |
| policy_entropy     | 0.151    |
| total_timesteps    | 111000   |
| value_loss         | 254      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 222      |
| explained_variance | -0.0019  |
| fps                | 485      |
| nupdates           | 22300    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 111500   |
| value_loss         | 91.8     |
---------------------------------
9.0
9.0
11.57
9.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0.854    |
| fps                | 485      |
| nupdates           | 22400    |
| policy_entropy     | 0.199    |
| total_timesteps    | 112000   |
| value_loss         | 11       |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.87     |
| fps                | 485      |
| nupdates           | 22500    |
| policy_entropy     | 0.0142   |
| total_timesteps    | 112500   |
| value_loss         | 12.3     |
---------------------------------
9.0
9.0
11.27
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 222      |
| explained_variance | -0.379   |
| fps                | 485      |
| nupdates           | 22600    |
| policy_entropy     | 0.133    |
| total_timesteps    | 113000   |
| value_loss         | 669      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.363    |
| fps                | 485      |
| nupdates           | 22700    |
| policy_entropy     | 0.00597  |
| total_timesteps    | 113500   |
| value_loss         | 392      |
---------------------------------
9.0
9.0
11.84
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | 0.685    |
| fps                | 485      |
| nupdates           | 22800    |
| policy_entropy     | 0.191    |
| total_timesteps    | 114000   |
| value_loss         | 11.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.654    |
| fps                | 485      |
| nupdates           | 22900    |
| policy_entropy     | 0.0512   |
| total_timesteps    | 114500   |
| value_loss         | 21.1     |
---------------------------------
17.0
17.0
11.93
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.92     |
| fps                | 485      |
| nupdates           | 23000    |
| policy_entropy     | 0.0106   |
| total_timesteps    | 115000   |
| value_loss         | 45.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.669    |
| fps                | 485      |
| nupdates           | 23100    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 115500   |
| value_loss         | 34.5     |
---------------------------------
9.0
9.0
12.15
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 219      |
| explained_variance | -0.17    |
| fps                | 485      |
| nupdates           | 23200    |
| policy_entropy     | 0.648    |
| total_timesteps    | 116000   |
| value_loss         | 322      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 217      |
| explained_variance | -0.745   |
| fps                | 485      |
| nupdates           | 23300    |
| policy_entropy     | 0.0884   |
| total_timesteps    | 116500   |
| value_loss         | 488      |
---------------------------------
9.0
9.0
12.07
9.5
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.584    |
| fps                | 485      |
| nupdates           | 23400    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 117000   |
| value_loss         | 317      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | -0.185   |
| fps                | 485      |
| nupdates           | 23500    |
| policy_entropy     | 0.00875  |
| total_timesteps    | 117500   |
| value_loss         | 143      |
---------------------------------
9.0
9.0
11.82
12.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.386    |
| fps                | 485      |
| nupdates           | 23600    |
| policy_entropy     | 0.00585  |
| total_timesteps    | 118000   |
| value_loss         | 410      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.336    |
| fps                | 485      |
| nupdates           | 23700    |
| policy_entropy     | 0.00645  |
| total_timesteps    | 118500   |
| value_loss         | 406      |
---------------------------------
17.0
17.0
11.77
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.759    |
| fps                | 485      |
| nupdates           | 23800    |
| policy_entropy     | 0.244    |
| total_timesteps    | 119000   |
| value_loss         | 17.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 227      |
| explained_variance | -0.489   |
| fps                | 485      |
| nupdates           | 23900    |
| policy_entropy     | 0.126    |
| total_timesteps    | 119500   |
| value_loss         | 452      |
---------------------------------
9.0
9.0
15.16
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | -1.28    |
| fps                | 485      |
| nupdates           | 24000    |
| policy_entropy     | 0.00766  |
| total_timesteps    | 120000   |
| value_loss         | 332      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 218      |
| explained_variance | -0.263   |
| fps                | 485      |
| nupdates           | 24100    |
| policy_entropy     | 0.00666  |
| total_timesteps    | 120500   |
| value_loss         | 81.4     |
---------------------------------
15.0
15.0
12.15
12.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 226      |
| explained_variance | 0.325    |
| fps                | 485      |
| nupdates           | 24200    |
| policy_entropy     | 0.0178   |
| total_timesteps    | 121000   |
| value_loss         | 94.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 223      |
| explained_variance | 0.619    |
| fps                | 485      |
| nupdates           | 24300    |
| policy_entropy     | 0.0052   |
| total_timesteps    | 121500   |
| value_loss         | 244      |
---------------------------------
15.0
15.0
11.53
12.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | -1.89    |
| fps                | 485      |
| nupdates           | 24400    |
| policy_entropy     | 0.232    |
| total_timesteps    | 122000   |
| value_loss         | 317      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.919    |
| fps                | 485      |
| nupdates           | 24500    |
| policy_entropy     | 0.0202   |
| total_timesteps    | 122500   |
| value_loss         | 7.8      |
---------------------------------
10.0
10.0
11.33
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.002    |
| fps                | 485      |
| nupdates           | 24600    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 123000   |
| value_loss         | 45.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | -1.39    |
| fps                | 485      |
| nupdates           | 24700    |
| policy_entropy     | 0.00982  |
| total_timesteps    | 123500   |
| value_loss         | 124      |
---------------------------------
15.0
15.0
11.8
9.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.979    |
| fps                | 485      |
| nupdates           | 24800    |
| policy_entropy     | 0.0737   |
| total_timesteps    | 124000   |
| value_loss         | 0.932    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.993    |
| fps                | 485      |
| nupdates           | 24900    |
| policy_entropy     | 0.0329   |
| total_timesteps    | 124500   |
| value_loss         | 0.68     |
---------------------------------
16.0
16.0
12.09
13.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.781    |
| fps                | 485      |
| nupdates           | 25000    |
| policy_entropy     | 0.0193   |
| total_timesteps    | 125000   |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 226      |
| explained_variance | -0.174   |
| fps                | 485      |
| nupdates           | 25100    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 125500   |
| value_loss         | 103      |
---------------------------------
16.0
16.0
11.91
12.5
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.408    |
| fps                | 484      |
| nupdates           | 25200    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 126000   |
| value_loss         | 396      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | 0.912    |
| fps                | 485      |
| nupdates           | 25300    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 126500   |
| value_loss         | 6.6      |
---------------------------------
10.0
10.0
12.09
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | -0.301   |
| fps                | 484      |
| nupdates           | 25400    |
| policy_entropy     | 0.0124   |
| total_timesteps    | 127000   |
| value_loss         | 353      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.852    |
| fps                | 485      |
| nupdates           | 25500    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 127500   |
| value_loss         | 12.2     |
---------------------------------
9.0
9.0
11.77
9.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 227      |
| explained_variance | 0.651    |
| fps                | 484      |
| nupdates           | 25600    |
| policy_entropy     | 0.00935  |
| total_timesteps    | 128000   |
| value_loss         | 28.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 223      |
| explained_variance | 0.873    |
| fps                | 484      |
| nupdates           | 25700    |
| policy_entropy     | 0.00689  |
| total_timesteps    | 128500   |
| value_loss         | 683      |
---------------------------------
9.0
9.0
11.96
9.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 223      |
| explained_variance | 0.932    |
| fps                | 484      |
| nupdates           | 25800    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 129000   |
| value_loss         | 6.29     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | 0.596    |
| fps                | 484      |
| nupdates           | 25900    |
| policy_entropy     | 0.145    |
| total_timesteps    | 129500   |
| value_loss         | 17       |
---------------------------------
16.0
16.0
11.55
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.165    |
| fps                | 484      |
| nupdates           | 26000    |
| policy_entropy     | 0.0284   |
| total_timesteps    | 130000   |
| value_loss         | 529      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | -1.3     |
| fps                | 484      |
| nupdates           | 26100    |
| policy_entropy     | 0.15     |
| total_timesteps    | 130500   |
| value_loss         | 520      |
---------------------------------
10.0
10.0
11.63
9.5
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 224      |
| explained_variance | 0.942    |
| fps                | 484      |
| nupdates           | 26200    |
| policy_entropy     | 0.0729   |
| total_timesteps    | 131000   |
| value_loss         | 2.49     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.38     |
| fps                | 484      |
| nupdates           | 26300    |
| policy_entropy     | 0.0045   |
| total_timesteps    | 131500   |
| value_loss         | 381      |
---------------------------------
9.0
9.0
11.73
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 222      |
| explained_variance | -0.245   |
| fps                | 484      |
| nupdates           | 26400    |
| policy_entropy     | 0.00465  |
| total_timesteps    | 132000   |
| value_loss         | 57.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 2.38e-07 |
| fps                | 484      |
| nupdates           | 26500    |
| policy_entropy     | 0.0806   |
| total_timesteps    | 132500   |
| value_loss         | 184      |
---------------------------------
43.0
43.0
15.61
13.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 210      |
| explained_variance | -3.25    |
| fps                | 484      |
| nupdates           | 26600    |
| policy_entropy     | 0.122    |
| total_timesteps    | 133000   |
| value_loss         | 2.23e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 207      |
| explained_variance | -5.53    |
| fps                | 484      |
| nupdates           | 26700    |
| policy_entropy     | 0.18     |
| total_timesteps    | 133500   |
| value_loss         | 777      |
---------------------------------
15.0
15.0
17.02
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | 0.9      |
| fps                | 484      |
| nupdates           | 26800    |
| policy_entropy     | 0.133    |
| total_timesteps    | 134000   |
| value_loss         | 3.98     |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 222      |
| explained_variance | 0.364    |
| fps                | 484      |
| nupdates           | 26900    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 134500   |
| value_loss         | 460      |
---------------------------------
8.0
8.0
12.23
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.753    |
| fps                | 484      |
| nupdates           | 27000    |
| policy_entropy     | 0.235    |
| total_timesteps    | 135000   |
| value_loss         | 18.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 223      |
| explained_variance | -0.735   |
| fps                | 484      |
| nupdates           | 27100    |
| policy_entropy     | 0.0068   |
| total_timesteps    | 135500   |
| value_loss         | 220      |
---------------------------------
16.0
16.0
12.08
15.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | -1.34    |
| fps                | 484      |
| nupdates           | 27200    |
| policy_entropy     | 0.169    |
| total_timesteps    | 136000   |
| value_loss         | 221      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 225      |
| explained_variance | -2.18    |
| fps                | 484      |
| nupdates           | 27300    |
| policy_entropy     | 0.174    |
| total_timesteps    | 136500   |
| value_loss         | 282      |
---------------------------------
10.0
10.0
12.01
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 225      |
| explained_variance | 0.0674   |
| fps                | 484      |
| nupdates           | 27400    |
| policy_entropy     | 0.012    |
| total_timesteps    | 137000   |
| value_loss         | 155      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | -0.133   |
| fps                | 484      |
| nupdates           | 27500    |
| policy_entropy     | 0.00456  |
| total_timesteps    | 137500   |
| value_loss         | 57.5     |
---------------------------------
9.0
9.0
11.8
9.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.819    |
| fps                | 484      |
| nupdates           | 27600    |
| policy_entropy     | 0.011    |
| total_timesteps    | 138000   |
| value_loss         | 14.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.49     |
| fps                | 484      |
| nupdates           | 27700    |
| policy_entropy     | 0.0136   |
| total_timesteps    | 138500   |
| value_loss         | 299      |
---------------------------------
9.0
9.0
11.33
9.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.736    |
| fps                | 484      |
| nupdates           | 27800    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 139000   |
| value_loss         | 24.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | -0.158   |
| fps                | 484      |
| nupdates           | 27900    |
| policy_entropy     | 0.00772  |
| total_timesteps    | 139500   |
| value_loss         | 139      |
---------------------------------
10.0
10.0
12.52
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 225      |
| explained_variance | -0.0942  |
| fps                | 484      |
| nupdates           | 28000    |
| policy_entropy     | 0.00448  |
| total_timesteps    | 140000   |
| value_loss         | 45.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | -0.0903  |
| fps                | 484      |
| nupdates           | 28100    |
| policy_entropy     | 0.00615  |
| total_timesteps    | 140500   |
| value_loss         | 56.2     |
---------------------------------
23.0
23.0
11.82
9.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.702    |
| fps                | 484      |
| nupdates           | 28200    |
| policy_entropy     | 0.0371   |
| total_timesteps    | 141000   |
| value_loss         | 33.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | -0.717   |
| fps                | 484      |
| nupdates           | 28300    |
| policy_entropy     | 0.00671  |
| total_timesteps    | 141500   |
| value_loss         | 117      |
---------------------------------
15.0
15.0
11.99
15.5
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 223      |
| explained_variance | 0.981    |
| fps                | 484      |
| nupdates           | 28400    |
| policy_entropy     | 0.0258   |
| total_timesteps    | 142000   |
| value_loss         | 1.64     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 225      |
| explained_variance | -0.304   |
| fps                | 484      |
| nupdates           | 28500    |
| policy_entropy     | 0.0553   |
| total_timesteps    | 142500   |
| value_loss         | 35       |
---------------------------------
16.0
16.0
11.76
12.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | -1.26    |
| fps                | 484      |
| nupdates           | 28600    |
| policy_entropy     | 0.121    |
| total_timesteps    | 143000   |
| value_loss         | 358      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.889    |
| fps                | 484      |
| nupdates           | 28700    |
| policy_entropy     | 0.0271   |
| total_timesteps    | 143500   |
| value_loss         | 10.5     |
---------------------------------
16.0
16.0
11.67
12.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 225      |
| explained_variance | 0.129    |
| fps                | 484      |
| nupdates           | 28800    |
| policy_entropy     | 0.266    |
| total_timesteps    | 144000   |
| value_loss         | 36.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 228      |
| explained_variance | -1.52    |
| fps                | 484      |
| nupdates           | 28900    |
| policy_entropy     | 0.162    |
| total_timesteps    | 144500   |
| value_loss         | 309      |
---------------------------------
9.0
9.0
12.22
9.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 228      |
| explained_variance | 0        |
| fps                | 484      |
| nupdates           | 29000    |
| policy_entropy     | 0.0932   |
| total_timesteps    | 145000   |
| value_loss         | 200      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | -3.28    |
| fps                | 484      |
| nupdates           | 29100    |
| policy_entropy     | 0.0528   |
| total_timesteps    | 145500   |
| value_loss         | 6.92e+03 |
---------------------------------
8.0
8.0
15.65
9.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 215      |
| explained_variance | -0.146   |
| fps                | 484      |
| nupdates           | 29200    |
| policy_entropy     | 0.00795  |
| total_timesteps    | 146000   |
| value_loss         | 51.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.688    |
| fps                | 484      |
| nupdates           | 29300    |
| policy_entropy     | 0.0584   |
| total_timesteps    | 146500   |
| value_loss         | 23.7     |
---------------------------------
17.0
17.0
11.78
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | -0.413   |
| fps                | 484      |
| nupdates           | 29400    |
| policy_entropy     | 0.011    |
| total_timesteps    | 147000   |
| value_loss         | 199      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.971    |
| fps                | 484      |
| nupdates           | 29500    |
| policy_entropy     | 0.0538   |
| total_timesteps    | 147500   |
| value_loss         | 4.57     |
---------------------------------
8.0
8.0
12.41
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.78     |
| fps                | 484      |
| nupdates           | 29600    |
| policy_entropy     | 0.00604  |
| total_timesteps    | 148000   |
| value_loss         | 22.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 224      |
| explained_variance | 0.945    |
| fps                | 484      |
| nupdates           | 29700    |
| policy_entropy     | 0.00789  |
| total_timesteps    | 148500   |
| value_loss         | 9.31     |
---------------------------------
8.0
8.0
11.38
12.5
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.856    |
| fps                | 484      |
| nupdates           | 29800    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 149000   |
| value_loss         | 15.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 11       |
| ep_reward_mean     | 221      |
| explained_variance | 0.587    |
| fps                | 484      |
| nupdates           | 29900    |
| policy_entropy     | 0.0151   |
| total_timesteps    | 149500   |
| value_loss         | 50.4     |
---------------------------------
10.0
10.0
11.35
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | -3.02    |
| fps                | 484      |
| nupdates           | 30000    |
| policy_entropy     | 0.21     |
| total_timesteps    | 150000   |
| value_loss         | 166      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 223      |
| explained_variance | 0.974    |
| fps                | 484      |
| nupdates           | 30100    |
| policy_entropy     | 0.0396   |
| total_timesteps    | 150500   |
| value_loss         | 6.46     |
---------------------------------
8.0
8.0
11.5
9.5
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 225      |
| explained_variance | -1.16    |
| fps                | 484      |
| nupdates           | 30200    |
| policy_entropy     | 0.00822  |
| total_timesteps    | 151000   |
| value_loss         | 57.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | -0.416   |
| fps                | 484      |
| nupdates           | 30300    |
| policy_entropy     | 0.0753   |
| total_timesteps    | 151500   |
| value_loss         | 387      |
---------------------------------
16.0
16.0
12.64
15.5
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.917    |
| fps                | 484      |
| nupdates           | 30400    |
| policy_entropy     | 0.00722  |
| total_timesteps    | 152000   |
| value_loss         | 16.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 224      |
| explained_variance | 0.522    |
| fps                | 484      |
| nupdates           | 30500    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 152500   |
| value_loss         | 68       |
---------------------------------
16.0
16.0
12.65
16.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.465    |
| fps                | 484      |
| nupdates           | 30600    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 153000   |
| value_loss         | 412      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.532    |
| fps                | 484      |
| nupdates           | 30700    |
| policy_entropy     | 0.00258  |
| total_timesteps    | 153500   |
| value_loss         | 296      |
---------------------------------
17.0
17.0
13.37
16.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.731    |
| fps                | 484      |
| nupdates           | 30800    |
| policy_entropy     | 0.00623  |
| total_timesteps    | 154000   |
| value_loss         | 339      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 224      |
| explained_variance | -0.633   |
| fps                | 484      |
| nupdates           | 30900    |
| policy_entropy     | 0.00502  |
| total_timesteps    | 154500   |
| value_loss         | 195      |
---------------------------------
10.0
10.0
11.84
9.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.879    |
| fps                | 484      |
| nupdates           | 31000    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 155000   |
| value_loss         | 9.68     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.749    |
| fps                | 484      |
| nupdates           | 31100    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 155500   |
| value_loss         | 33.9     |
---------------------------------
15.0
15.0
12.59
9.5
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.97     |
| fps                | 484      |
| nupdates           | 31200    |
| policy_entropy     | 0.0256   |
| total_timesteps    | 156000   |
| value_loss         | 5.23     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 225      |
| explained_variance | 0.8      |
| fps                | 484      |
| nupdates           | 31300    |
| policy_entropy     | 0.00869  |
| total_timesteps    | 156500   |
| value_loss         | 21.1     |
---------------------------------
8.0
8.0
11.64
9.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.775    |
| fps                | 484      |
| nupdates           | 31400    |
| policy_entropy     | 0.0222   |
| total_timesteps    | 157000   |
| value_loss         | 27.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 222      |
| explained_variance | -0.592   |
| fps                | 484      |
| nupdates           | 31500    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 157500   |
| value_loss         | 126      |
---------------------------------
11.0
11.0
11.29
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0.731    |
| fps                | 484      |
| nupdates           | 31600    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 158000   |
| value_loss         | 27.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 221      |
| explained_variance | -0.814   |
| fps                | 484      |
| nupdates           | 31700    |
| policy_entropy     | 0.00885  |
| total_timesteps    | 158500   |
| value_loss         | 97.6     |
---------------------------------
9.0
9.0
12.25
9.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.979    |
| fps                | 484      |
| nupdates           | 31800    |
| policy_entropy     | 0.011    |
| total_timesteps    | 159000   |
| value_loss         | 7.06     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.814    |
| fps                | 484      |
| nupdates           | 31900    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 159500   |
| value_loss         | 390      |
---------------------------------
10.0
10.0
10.9
9.0
---------------------------------
| ep_len_mean        | 10.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.475    |
| fps                | 484      |
| nupdates           | 32000    |
| policy_entropy     | 0.00936  |
| total_timesteps    | 160000   |
| value_loss         | 55       |
---------------------------------
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.802    |
| fps                | 484      |
| nupdates           | 32100    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 160500   |
| value_loss         | 344      |
---------------------------------
9.0
9.0
11.34
9.5
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0.959    |
| fps                | 484      |
| nupdates           | 32200    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 161000   |
| value_loss         | 1.98     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.993    |
| fps                | 484      |
| nupdates           | 32300    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 161500   |
| value_loss         | 4.73     |
---------------------------------
15.0
15.0
11.82
9.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.785    |
| fps                | 484      |
| nupdates           | 32400    |
| policy_entropy     | 0.00579  |
| total_timesteps    | 162000   |
| value_loss         | 37.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | -1.87    |
| fps                | 484      |
| nupdates           | 32500    |
| policy_entropy     | 0.123    |
| total_timesteps    | 162500   |
| value_loss         | 352      |
---------------------------------
9.0
9.0
13.14
9.5
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 223      |
| explained_variance | 0.454    |
| fps                | 484      |
| nupdates           | 32600    |
| policy_entropy     | 0.00652  |
| total_timesteps    | 163000   |
| value_loss         | 44.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.968    |
| fps                | 484      |
| nupdates           | 32700    |
| policy_entropy     | 0.0225   |
| total_timesteps    | 163500   |
| value_loss         | 1.88     |
---------------------------------
10.0
10.0
12.53
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.347    |
| fps                | 484      |
| nupdates           | 32800    |
| policy_entropy     | 0.00564  |
| total_timesteps    | 164000   |
| value_loss         | 411      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.479    |
| fps                | 484      |
| nupdates           | 32900    |
| policy_entropy     | 0.00669  |
| total_timesteps    | 164500   |
| value_loss         | 564      |
---------------------------------
16.0
16.0
12.02
13.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.806    |
| fps                | 484      |
| nupdates           | 33000    |
| policy_entropy     | 0.00912  |
| total_timesteps    | 165000   |
| value_loss         | 27.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 228      |
| explained_variance | 0.63     |
| fps                | 484      |
| nupdates           | 33100    |
| policy_entropy     | 0.011    |
| total_timesteps    | 165500   |
| value_loss         | 384      |
---------------------------------
10.0
10.0
11.91
9.5
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | -0.0435  |
| fps                | 484      |
| nupdates           | 33200    |
| policy_entropy     | 0.0324   |
| total_timesteps    | 166000   |
| value_loss         | 89.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 221      |
| explained_variance | 0.522    |
| fps                | 484      |
| nupdates           | 33300    |
| policy_entropy     | 0.00546  |
| total_timesteps    | 166500   |
| value_loss         | 212      |
---------------------------------
16.0
16.0
12.01
9.5
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 222      |
| explained_variance | 0.749    |
| fps                | 484      |
| nupdates           | 33400    |
| policy_entropy     | 0.0245   |
| total_timesteps    | 167000   |
| value_loss         | 22.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 223      |
| explained_variance | 0.852    |
| fps                | 483      |
| nupdates           | 33500    |
| policy_entropy     | 0.00744  |
| total_timesteps    | 167500   |
| value_loss         | 31.6     |
---------------------------------
17.0
17.0
11.37
12.5
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 225      |
| explained_variance | -2       |
| fps                | 483      |
| nupdates           | 33600    |
| policy_entropy     | 0.0054   |
| total_timesteps    | 168000   |
| value_loss         | 245      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.796    |
| fps                | 483      |
| nupdates           | 33700    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 168500   |
| value_loss         | 290      |
---------------------------------
9.0
9.0
11.7
9.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.725    |
| fps                | 483      |
| nupdates           | 33800    |
| policy_entropy     | 0.00785  |
| total_timesteps    | 169000   |
| value_loss         | 180      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.999    |
| fps                | 483      |
| nupdates           | 33900    |
| policy_entropy     | 0.0216   |
| total_timesteps    | 169500   |
| value_loss         | 0.0641   |
---------------------------------
15.0
15.0
12.31
12.5
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 226      |
| explained_variance | 0.775    |
| fps                | 483      |
| nupdates           | 34000    |
| policy_entropy     | 0.0312   |
| total_timesteps    | 170000   |
| value_loss         | 22.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 225      |
| explained_variance | 0.976    |
| fps                | 483      |
| nupdates           | 34100    |
| policy_entropy     | 0.121    |
| total_timesteps    | 170500   |
| value_loss         | 0.947    |
---------------------------------
10.0
10.0
12.18
12.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 225      |
| explained_variance | 0.911    |
| fps                | 483      |
| nupdates           | 34200    |
| policy_entropy     | 0.114    |
| total_timesteps    | 171000   |
| value_loss         | 3.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 223      |
| explained_variance | 0.928    |
| fps                | 483      |
| nupdates           | 34300    |
| policy_entropy     | 0.17     |
| total_timesteps    | 171500   |
| value_loss         | 2.91     |
---------------------------------
11.0
11.0
12.5
13.5
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.941    |
| fps                | 483      |
| nupdates           | 34400    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 172000   |
| value_loss         | 4.6      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.931    |
| fps                | 483      |
| nupdates           | 34500    |
| policy_entropy     | 0.0903   |
| total_timesteps    | 172500   |
| value_loss         | 4.05     |
---------------------------------
15.0
15.0
11.05
10.0
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.989    |
| fps                | 483      |
| nupdates           | 34600    |
| policy_entropy     | 0.0238   |
| total_timesteps    | 173000   |
| value_loss         | 2.94     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 221      |
| explained_variance | -5.76    |
| fps                | 483      |
| nupdates           | 34700    |
| policy_entropy     | 0.186    |
| total_timesteps    | 173500   |
| value_loss         | 695      |
---------------------------------
10.0
10.0
12.51
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 222      |
| explained_variance | -0.088   |
| fps                | 483      |
| nupdates           | 34800    |
| policy_entropy     | 0.004    |
| total_timesteps    | 174000   |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.976    |
| fps                | 483      |
| nupdates           | 34900    |
| policy_entropy     | 0.0478   |
| total_timesteps    | 174500   |
| value_loss         | 0.96     |
---------------------------------
10.0
10.0
11.81
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.484    |
| fps                | 483      |
| nupdates           | 35000    |
| policy_entropy     | 0.018    |
| total_timesteps    | 175000   |
| value_loss         | 43.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | 0.213    |
| fps                | 483      |
| nupdates           | 35100    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 175500   |
| value_loss         | 74.8     |
---------------------------------
10.0
10.0
11.33
9.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 224      |
| explained_variance | -1.9     |
| fps                | 483      |
| nupdates           | 35200    |
| policy_entropy     | 0.148    |
| total_timesteps    | 176000   |
| value_loss         | 220      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.266    |
| fps                | 483      |
| nupdates           | 35300    |
| policy_entropy     | 0.128    |
| total_timesteps    | 176500   |
| value_loss         | 215      |
---------------------------------
8.0
8.0
11.7
9.5
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | -0.805   |
| fps                | 483      |
| nupdates           | 35400    |
| policy_entropy     | 0.106    |
| total_timesteps    | 177000   |
| value_loss         | 502      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | 0.345    |
| fps                | 483      |
| nupdates           | 35500    |
| policy_entropy     | 0.0271   |
| total_timesteps    | 177500   |
| value_loss         | 91.5     |
---------------------------------
15.0
15.0
12.02
11.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.712    |
| fps                | 483      |
| nupdates           | 35600    |
| policy_entropy     | 0.0262   |
| total_timesteps    | 178000   |
| value_loss         | 271      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 225      |
| explained_variance | 0.497    |
| fps                | 483      |
| nupdates           | 35700    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 178500   |
| value_loss         | 485      |
---------------------------------
11.0
11.0
12.73
10.5
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.168    |
| fps                | 483      |
| nupdates           | 35800    |
| policy_entropy     | 0.102    |
| total_timesteps    | 179000   |
| value_loss         | 106      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0.943    |
| fps                | 483      |
| nupdates           | 35900    |
| policy_entropy     | 0.0677   |
| total_timesteps    | 179500   |
| value_loss         | 2.61     |
---------------------------------
16.0
16.0
12.28
16.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 226      |
| explained_variance | 0.0136   |
| fps                | 483      |
| nupdates           | 36000    |
| policy_entropy     | 0.0837   |
| total_timesteps    | 180000   |
| value_loss         | 441      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 227      |
| explained_variance | 0.83     |
| fps                | 483      |
| nupdates           | 36100    |
| policy_entropy     | 0.0287   |
| total_timesteps    | 180500   |
| value_loss         | 4.59     |
---------------------------------
10.0
10.0
12.15
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 226      |
| explained_variance | -4.7     |
| fps                | 483      |
| nupdates           | 36200    |
| policy_entropy     | 0.0277   |
| total_timesteps    | 181000   |
| value_loss         | 252      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | -0.91    |
| fps                | 483      |
| nupdates           | 36300    |
| policy_entropy     | 0.124    |
| total_timesteps    | 181500   |
| value_loss         | 510      |
---------------------------------
10.0
10.0
11.44
10.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.503    |
| fps                | 483      |
| nupdates           | 36400    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 182000   |
| value_loss         | 540      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 225      |
| explained_variance | -1.01    |
| fps                | 483      |
| nupdates           | 36500    |
| policy_entropy     | 0.0353   |
| total_timesteps    | 182500   |
| value_loss         | 439      |
---------------------------------
10.0
10.0
12.1
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | 0.992    |
| fps                | 483      |
| nupdates           | 36600    |
| policy_entropy     | 0.0194   |
| total_timesteps    | 183000   |
| value_loss         | 1.41     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 224      |
| explained_variance | -1.82    |
| fps                | 483      |
| nupdates           | 36700    |
| policy_entropy     | 0.00949  |
| total_timesteps    | 183500   |
| value_loss         | 171      |
---------------------------------
11.0
11.0
12.37
13.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 224      |
| explained_variance | 0.956    |
| fps                | 483      |
| nupdates           | 36800    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 184000   |
| value_loss         | 3.05     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | -3.78    |
| fps                | 483      |
| nupdates           | 36900    |
| policy_entropy     | 0.0422   |
| total_timesteps    | 184500   |
| value_loss         | 341      |
---------------------------------
10.0
10.0
13.09
10.5
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 225      |
| explained_variance | 0.648    |
| fps                | 483      |
| nupdates           | 37000    |
| policy_entropy     | 0.062    |
| total_timesteps    | 185000   |
| value_loss         | 66.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 214      |
| explained_variance | -1.1     |
| fps                | 483      |
| nupdates           | 37100    |
| policy_entropy     | 0.0516   |
| total_timesteps    | 185500   |
| value_loss         | 7.45e+04 |
---------------------------------
9.0
9.0
15.25
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | -0.63    |
| fps                | 483      |
| nupdates           | 37200    |
| policy_entropy     | 0.0267   |
| total_timesteps    | 186000   |
| value_loss         | 4.72e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 223      |
| explained_variance | 0.679    |
| fps                | 483      |
| nupdates           | 37300    |
| policy_entropy     | 0.0602   |
| total_timesteps    | 186500   |
| value_loss         | 46       |
---------------------------------
10.0
10.0
12.49
15.5
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 221      |
| explained_variance | 0.974    |
| fps                | 483      |
| nupdates           | 37400    |
| policy_entropy     | 0.0233   |
| total_timesteps    | 187000   |
| value_loss         | 3.03     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 219      |
| explained_variance | -2.25    |
| fps                | 483      |
| nupdates           | 37500    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 187500   |
| value_loss         | 166      |
---------------------------------
11.0
11.0
12.03
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 223      |
| explained_variance | 0.816    |
| fps                | 483      |
| nupdates           | 37600    |
| policy_entropy     | 0.0216   |
| total_timesteps    | 188000   |
| value_loss         | 10.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.205    |
| fps                | 483      |
| nupdates           | 37700    |
| policy_entropy     | 0.0538   |
| total_timesteps    | 188500   |
| value_loss         | 828      |
---------------------------------
11.0
11.0
12.15
11.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | 0.994    |
| fps                | 483      |
| nupdates           | 37800    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 189000   |
| value_loss         | 2.09     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 226      |
| explained_variance | 0.593    |
| fps                | 483      |
| nupdates           | 37900    |
| policy_entropy     | 0.0347   |
| total_timesteps    | 189500   |
| value_loss         | 186      |
---------------------------------
10.0
10.0
12.15
13.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 225      |
| explained_variance | 0.817    |
| fps                | 483      |
| nupdates           | 38000    |
| policy_entropy     | 0.0215   |
| total_timesteps    | 190000   |
| value_loss         | 9.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 226      |
| explained_variance | 0.984    |
| fps                | 483      |
| nupdates           | 38100    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 190500   |
| value_loss         | 1.66     |
---------------------------------
17.0
17.0
12.22
10.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | 0.997    |
| fps                | 483      |
| nupdates           | 38200    |
| policy_entropy     | 0.026    |
| total_timesteps    | 191000   |
| value_loss         | 0.273    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 228      |
| explained_variance | 0.984    |
| fps                | 483      |
| nupdates           | 38300    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 191500   |
| value_loss         | 4.28     |
---------------------------------
10.0
10.0
12.41
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 227      |
| explained_variance | -0.00531 |
| fps                | 483      |
| nupdates           | 38400    |
| policy_entropy     | 0.0867   |
| total_timesteps    | 192000   |
| value_loss         | 235      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 222      |
| explained_variance | -0.397   |
| fps                | 483      |
| nupdates           | 38500    |
| policy_entropy     | 0.108    |
| total_timesteps    | 192500   |
| value_loss         | 348      |
---------------------------------
9.0
9.0
12.66
10.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.553    |
| fps                | 483      |
| nupdates           | 38600    |
| policy_entropy     | 0.0799   |
| total_timesteps    | 193000   |
| value_loss         | 49.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.926    |
| fps                | 483      |
| nupdates           | 38700    |
| policy_entropy     | 0.111    |
| total_timesteps    | 193500   |
| value_loss         | 15.8     |
---------------------------------
9.0
9.0
11.87
11.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | 0.877    |
| fps                | 483      |
| nupdates           | 38800    |
| policy_entropy     | 0.0378   |
| total_timesteps    | 194000   |
| value_loss         | 6.98     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | 0.249    |
| fps                | 483      |
| nupdates           | 38900    |
| policy_entropy     | 0.145    |
| total_timesteps    | 194500   |
| value_loss         | 967      |
---------------------------------
15.0
15.0
12.83
15.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 224      |
| explained_variance | -2.06    |
| fps                | 483      |
| nupdates           | 39000    |
| policy_entropy     | 0.068    |
| total_timesteps    | 195000   |
| value_loss         | 235      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | -0.847   |
| fps                | 483      |
| nupdates           | 39100    |
| policy_entropy     | 0.00653  |
| total_timesteps    | 195500   |
| value_loss         | 200      |
---------------------------------
10.0
10.0
11.75
13.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 227      |
| explained_variance | 0.973    |
| fps                | 483      |
| nupdates           | 39200    |
| policy_entropy     | 0.0596   |
| total_timesteps    | 196000   |
| value_loss         | 3.89     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 229      |
| explained_variance | 0.958    |
| fps                | 483      |
| nupdates           | 39300    |
| policy_entropy     | 0.0123   |
| total_timesteps    | 196500   |
| value_loss         | 6.84     |
---------------------------------
10.0
10.0
12.4
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 228      |
| explained_variance | 0.996    |
| fps                | 483      |
| nupdates           | 39400    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 197000   |
| value_loss         | 0.322    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.992    |
| fps                | 483      |
| nupdates           | 39500    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 197500   |
| value_loss         | 1.6      |
---------------------------------
17.0
17.0
11.34
10.5
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.794    |
| fps                | 483      |
| nupdates           | 39600    |
| policy_entropy     | 0.0281   |
| total_timesteps    | 198000   |
| value_loss         | 3.76     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 223      |
| explained_variance | -2.59    |
| fps                | 483      |
| nupdates           | 39700    |
| policy_entropy     | 0.125    |
| total_timesteps    | 198500   |
| value_loss         | 178      |
---------------------------------
9.0
9.0
12.73
13.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 225      |
| explained_variance | 0.207    |
| fps                | 483      |
| nupdates           | 39800    |
| policy_entropy     | 0.0217   |
| total_timesteps    | 199000   |
| value_loss         | 21.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.368    |
| fps                | 483      |
| nupdates           | 39900    |
| policy_entropy     | 0.0446   |
| total_timesteps    | 199500   |
| value_loss         | 59.9     |
---------------------------------
16.0
16.0
12.02
11.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 224      |
| explained_variance | -2.78    |
| fps                | 483      |
| nupdates           | 40000    |
| policy_entropy     | 0.151    |
| total_timesteps    | 200000   |
| value_loss         | 157      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | 0.996    |
| fps                | 483      |
| nupdates           | 40100    |
| policy_entropy     | 0.019    |
| total_timesteps    | 200500   |
| value_loss         | 2.11     |
---------------------------------
17.0
17.0
12.59
15.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 228      |
| explained_variance | 0        |
| fps                | 483      |
| nupdates           | 40200    |
| policy_entropy     | 0.0617   |
| total_timesteps    | 201000   |
| value_loss         | 365      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.399    |
| fps                | 483      |
| nupdates           | 40300    |
| policy_entropy     | 0.0515   |
| total_timesteps    | 201500   |
| value_loss         | 97.1     |
---------------------------------
16.0
16.0
13.73
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.858    |
| fps                | 483      |
| nupdates           | 40400    |
| policy_entropy     | 0.00431  |
| total_timesteps    | 202000   |
| value_loss         | 667      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 227      |
| explained_variance | 0.995    |
| fps                | 483      |
| nupdates           | 40500    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 202500   |
| value_loss         | 1.07     |
---------------------------------
9.0
9.0
12.89
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 227      |
| explained_variance | -0.94    |
| fps                | 483      |
| nupdates           | 40600    |
| policy_entropy     | 0.114    |
| total_timesteps    | 203000   |
| value_loss         | 359      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 228      |
| explained_variance | 0.691    |
| fps                | 483      |
| nupdates           | 40700    |
| policy_entropy     | 0.00847  |
| total_timesteps    | 203500   |
| value_loss         | 241      |
---------------------------------
17.0
17.0
12.54
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 228      |
| explained_variance | -0.776   |
| fps                | 483      |
| nupdates           | 40800    |
| policy_entropy     | 0.00433  |
| total_timesteps    | 204000   |
| value_loss         | 197      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 226      |
| explained_variance | 0.39     |
| fps                | 483      |
| nupdates           | 40900    |
| policy_entropy     | 0.00488  |
| total_timesteps    | 204500   |
| value_loss         | 447      |
---------------------------------
15.0
15.0
12.56
10.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 226      |
| explained_variance | 0.388    |
| fps                | 483      |
| nupdates           | 41000    |
| policy_entropy     | 0.0051   |
| total_timesteps    | 205000   |
| value_loss         | 425      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 228      |
| explained_variance | 0.257    |
| fps                | 483      |
| nupdates           | 41100    |
| policy_entropy     | 0.0249   |
| total_timesteps    | 205500   |
| value_loss         | 8.88     |
---------------------------------
10.0
10.0
12.32
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 227      |
| explained_variance | 0.983    |
| fps                | 483      |
| nupdates           | 41200    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 206000   |
| value_loss         | 2.71     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | -0.644   |
| fps                | 483      |
| nupdates           | 41300    |
| policy_entropy     | 0.00379  |
| total_timesteps    | 206500   |
| value_loss         | 195      |
---------------------------------
16.0
16.0
12.69
11.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 228      |
| explained_variance | 0.924    |
| fps                | 483      |
| nupdates           | 41400    |
| policy_entropy     | 0.127    |
| total_timesteps    | 207000   |
| value_loss         | 30.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 226      |
| explained_variance | 0.643    |
| fps                | 483      |
| nupdates           | 41500    |
| policy_entropy     | 0.0195   |
| total_timesteps    | 207500   |
| value_loss         | 327      |
---------------------------------
11.0
11.0
13.77
13.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.549    |
| fps                | 483      |
| nupdates           | 41600    |
| policy_entropy     | 0.00464  |
| total_timesteps    | 208000   |
| value_loss         | 629      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 222      |
| explained_variance | -0.416   |
| fps                | 483      |
| nupdates           | 41700    |
| policy_entropy     | 0.28     |
| total_timesteps    | 208500   |
| value_loss         | 80.1     |
---------------------------------
16.0
16.0
12.74
13.0
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 226      |
| explained_variance | 0.678    |
| fps                | 483      |
| nupdates           | 41800    |
| policy_entropy     | 0.0584   |
| total_timesteps    | 209000   |
| value_loss         | 26.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 226      |
| explained_variance | 0.548    |
| fps                | 483      |
| nupdates           | 41900    |
| policy_entropy     | 0.00617  |
| total_timesteps    | 209500   |
| value_loss         | 237      |
---------------------------------
17.0
17.0
12.42
13.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 228      |
| explained_variance | 0.996    |
| fps                | 482      |
| nupdates           | 42000    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 210000   |
| value_loss         | 6.59     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 229      |
| explained_variance | 0.907    |
| fps                | 483      |
| nupdates           | 42100    |
| policy_entropy     | 0.00557  |
| total_timesteps    | 210500   |
| value_loss         | 6.79     |
---------------------------------
11.0
11.0
12.75
10.5
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 228      |
| explained_variance | 0.992    |
| fps                | 482      |
| nupdates           | 42200    |
| policy_entropy     | 0.0213   |
| total_timesteps    | 211000   |
| value_loss         | 9.25     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 229      |
| explained_variance | 0.988    |
| fps                | 482      |
| nupdates           | 42300    |
| policy_entropy     | 0.00588  |
| total_timesteps    | 211500   |
| value_loss         | 2.09     |
---------------------------------
10.0
10.0
12.47
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 230      |
| explained_variance | -2.75    |
| fps                | 482      |
| nupdates           | 42400    |
| policy_entropy     | 0.0785   |
| total_timesteps    | 212000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 227      |
| explained_variance | 0.468    |
| fps                | 482      |
| nupdates           | 42500    |
| policy_entropy     | 0.0293   |
| total_timesteps    | 212500   |
| value_loss         | 90.8     |
---------------------------------
10.0
10.0
12.75
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.456    |
| fps                | 482      |
| nupdates           | 42600    |
| policy_entropy     | 0.0048   |
| total_timesteps    | 213000   |
| value_loss         | 409      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | -1.78    |
| fps                | 482      |
| nupdates           | 42700    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 213500   |
| value_loss         | 405      |
---------------------------------
15.0
15.0
13.62
13.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 42800    |
| policy_entropy     | 0.112    |
| total_timesteps    | 214000   |
| value_loss         | 228      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 216      |
| explained_variance | -2.57    |
| fps                | 482      |
| nupdates           | 42900    |
| policy_entropy     | 0.112    |
| total_timesteps    | 214500   |
| value_loss         | 307      |
---------------------------------
10.0
10.0
15.17
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.751    |
| fps                | 482      |
| nupdates           | 43000    |
| policy_entropy     | 0.0409   |
| total_timesteps    | 215000   |
| value_loss         | 24.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.829    |
| fps                | 482      |
| nupdates           | 43100    |
| policy_entropy     | 0.0963   |
| total_timesteps    | 215500   |
| value_loss         | 18       |
---------------------------------
10.0
10.0
11.65
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.768    |
| fps                | 482      |
| nupdates           | 43200    |
| policy_entropy     | 0.116    |
| total_timesteps    | 216000   |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 226      |
| explained_variance | -1.6     |
| fps                | 482      |
| nupdates           | 43300    |
| policy_entropy     | 0.168    |
| total_timesteps    | 216500   |
| value_loss         | 287      |
---------------------------------
16.0
16.0
11.43
10.5
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | -2.13    |
| fps                | 482      |
| nupdates           | 43400    |
| policy_entropy     | 0.213    |
| total_timesteps    | 217000   |
| value_loss         | 131      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 226      |
| explained_variance | -0.0767  |
| fps                | 482      |
| nupdates           | 43500    |
| policy_entropy     | 0.0835   |
| total_timesteps    | 217500   |
| value_loss         | 127      |
---------------------------------
16.0
16.0
12.27
13.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 228      |
| explained_variance | 0.428    |
| fps                | 482      |
| nupdates           | 43600    |
| policy_entropy     | 0.00404  |
| total_timesteps    | 218000   |
| value_loss         | 445      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.43     |
| fps                | 482      |
| nupdates           | 43700    |
| policy_entropy     | 0.0587   |
| total_timesteps    | 218500   |
| value_loss         | 153      |
---------------------------------
15.0
15.0
13.45
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 222      |
| explained_variance | 0.987    |
| fps                | 482      |
| nupdates           | 43800    |
| policy_entropy     | 0.088    |
| total_timesteps    | 219000   |
| value_loss         | 0.821    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 220      |
| explained_variance | -1.63    |
| fps                | 482      |
| nupdates           | 43900    |
| policy_entropy     | 0.237    |
| total_timesteps    | 219500   |
| value_loss         | 1.77e+03 |
---------------------------------
9.0
9.0
12.15
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 224      |
| explained_variance | -1.57    |
| fps                | 482      |
| nupdates           | 44000    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 220000   |
| value_loss         | 63.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.905    |
| fps                | 482      |
| nupdates           | 44100    |
| policy_entropy     | 0.0022   |
| total_timesteps    | 220500   |
| value_loss         | 445      |
---------------------------------
9.0
9.0
11.71
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.912    |
| fps                | 482      |
| nupdates           | 44200    |
| policy_entropy     | 0.00336  |
| total_timesteps    | 221000   |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.458    |
| fps                | 482      |
| nupdates           | 44300    |
| policy_entropy     | 0.109    |
| total_timesteps    | 221500   |
| value_loss         | 103      |
---------------------------------
15.0
15.0
11.74
15.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | 0.985    |
| fps                | 482      |
| nupdates           | 44400    |
| policy_entropy     | 0.0799   |
| total_timesteps    | 222000   |
| value_loss         | 1.78     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.0713   |
| fps                | 482      |
| nupdates           | 44500    |
| policy_entropy     | 0.00359  |
| total_timesteps    | 222500   |
| value_loss         | 73.2     |
---------------------------------
10.0
10.0
11.95
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 226      |
| explained_variance | 0.996    |
| fps                | 482      |
| nupdates           | 44600    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 223000   |
| value_loss         | 1.48     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 225      |
| explained_variance | 0.99     |
| fps                | 482      |
| nupdates           | 44700    |
| policy_entropy     | 0.0945   |
| total_timesteps    | 223500   |
| value_loss         | 0.403    |
---------------------------------
10.0
10.0
12.08
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.992    |
| fps                | 482      |
| nupdates           | 44800    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 224000   |
| value_loss         | 2.55     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 226      |
| explained_variance | -0.596   |
| fps                | 482      |
| nupdates           | 44900    |
| policy_entropy     | 0.0859   |
| total_timesteps    | 224500   |
| value_loss         | 68.9     |
---------------------------------
16.0
16.0
12.59
16.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 228      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 45000    |
| policy_entropy     | 0.0535   |
| total_timesteps    | 225000   |
| value_loss         | 312      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.993    |
| fps                | 482      |
| nupdates           | 45100    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 225500   |
| value_loss         | 1.01     |
---------------------------------
16.0
16.0
13.97
13.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 227      |
| explained_variance | 0.983    |
| fps                | 482      |
| nupdates           | 45200    |
| policy_entropy     | 0.00441  |
| total_timesteps    | 226000   |
| value_loss         | 2.1      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 229      |
| explained_variance | -0.603   |
| fps                | 482      |
| nupdates           | 45300    |
| policy_entropy     | 0.392    |
| total_timesteps    | 226500   |
| value_loss         | 762      |
---------------------------------
11.0
11.0
13.54
10.5
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 227      |
| explained_variance | -0.737   |
| fps                | 482      |
| nupdates           | 45400    |
| policy_entropy     | 0.00339  |
| total_timesteps    | 227000   |
| value_loss         | 202      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 226      |
| explained_variance | 0.988    |
| fps                | 482      |
| nupdates           | 45500    |
| policy_entropy     | 0.0715   |
| total_timesteps    | 227500   |
| value_loss         | 1.02     |
---------------------------------
16.0
16.0
12.01
15.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.998    |
| fps                | 482      |
| nupdates           | 45600    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 228000   |
| value_loss         | 0.364    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | -0.404   |
| fps                | 482      |
| nupdates           | 45700    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 228500   |
| value_loss         | 415      |
---------------------------------
16.0
16.0
12.3
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 226      |
| explained_variance | 0.995    |
| fps                | 482      |
| nupdates           | 45800    |
| policy_entropy     | 0.0656   |
| total_timesteps    | 229000   |
| value_loss         | 0.946    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 227      |
| explained_variance | 0.915    |
| fps                | 482      |
| nupdates           | 45900    |
| policy_entropy     | 0.133    |
| total_timesteps    | 229500   |
| value_loss         | 2.87     |
---------------------------------
10.0
10.0
11.69
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 227      |
| explained_variance | -1.89    |
| fps                | 482      |
| nupdates           | 46000    |
| policy_entropy     | 0.0669   |
| total_timesteps    | 230000   |
| value_loss         | 355      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 226      |
| explained_variance | 0.97     |
| fps                | 482      |
| nupdates           | 46100    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 230500   |
| value_loss         | 20.7     |
---------------------------------
11.0
11.0
11.58
10.5
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | -0.725   |
| fps                | 482      |
| nupdates           | 46200    |
| policy_entropy     | 0.0515   |
| total_timesteps    | 231000   |
| value_loss         | 253      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 217      |
| explained_variance | -0.715   |
| fps                | 482      |
| nupdates           | 46300    |
| policy_entropy     | 0.00506  |
| total_timesteps    | 231500   |
| value_loss         | 196      |
---------------------------------
15.0
15.0
13.36
11.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.596    |
| fps                | 482      |
| nupdates           | 46400    |
| policy_entropy     | 0.0171   |
| total_timesteps    | 232000   |
| value_loss         | 256      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.98     |
| fps                | 482      |
| nupdates           | 46500    |
| policy_entropy     | 0.0199   |
| total_timesteps    | 232500   |
| value_loss         | 1.1      |
---------------------------------
15.0
15.0
12.53
13.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 229      |
| explained_variance | 0.916    |
| fps                | 482      |
| nupdates           | 46600    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 233000   |
| value_loss         | 5.44     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 229      |
| explained_variance | 0.742    |
| fps                | 482      |
| nupdates           | 46700    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 233500   |
| value_loss         | 44.6     |
---------------------------------
9.0
9.0
12.06
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 230      |
| explained_variance | -0.606   |
| fps                | 482      |
| nupdates           | 46800    |
| policy_entropy     | 0.0578   |
| total_timesteps    | 234000   |
| value_loss         | 516      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 227      |
| explained_variance | 0.987    |
| fps                | 482      |
| nupdates           | 46900    |
| policy_entropy     | 0.0241   |
| total_timesteps    | 234500   |
| value_loss         | 1.33     |
---------------------------------
11.0
11.0
11.69
11.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 225      |
| explained_variance | 0.978    |
| fps                | 482      |
| nupdates           | 47000    |
| policy_entropy     | 0.0438   |
| total_timesteps    | 235000   |
| value_loss         | 2.32     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 226      |
| explained_variance | 0.847    |
| fps                | 482      |
| nupdates           | 47100    |
| policy_entropy     | 0.00519  |
| total_timesteps    | 235500   |
| value_loss         | 535      |
---------------------------------
17.0
17.0
12.87
13.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 228      |
| explained_variance | -1.7     |
| fps                | 482      |
| nupdates           | 47200    |
| policy_entropy     | 0.181    |
| total_timesteps    | 236000   |
| value_loss         | 254      |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 224      |
| explained_variance | 0.966    |
| fps                | 482      |
| nupdates           | 47300    |
| policy_entropy     | 0.196    |
| total_timesteps    | 236500   |
| value_loss         | 5.16     |
---------------------------------
10.0
10.0
12.82
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 221      |
| explained_variance | -0.79    |
| fps                | 482      |
| nupdates           | 47400    |
| policy_entropy     | 0.00443  |
| total_timesteps    | 237000   |
| value_loss         | 81.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 223      |
| explained_variance | 0.946    |
| fps                | 482      |
| nupdates           | 47500    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 237500   |
| value_loss         | 5.81     |
---------------------------------
16.0
16.0
12.4
10.5
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 228      |
| explained_variance | 0.973    |
| fps                | 482      |
| nupdates           | 47600    |
| policy_entropy     | 0.0279   |
| total_timesteps    | 238000   |
| value_loss         | 5.56     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 226      |
| explained_variance | -0.589   |
| fps                | 482      |
| nupdates           | 47700    |
| policy_entropy     | 0.0787   |
| total_timesteps    | 238500   |
| value_loss         | 595      |
---------------------------------
16.0
16.0
12.0
13.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 227      |
| explained_variance | -0.515   |
| fps                | 482      |
| nupdates           | 47800    |
| policy_entropy     | 0.0397   |
| total_timesteps    | 239000   |
| value_loss         | 478      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | -2.1     |
| fps                | 482      |
| nupdates           | 47900    |
| policy_entropy     | 0.0558   |
| total_timesteps    | 239500   |
| value_loss         | 125      |
---------------------------------
16.0
16.0
12.16
16.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 229      |
| explained_variance | 0.998    |
| fps                | 482      |
| nupdates           | 48000    |
| policy_entropy     | 0.0202   |
| total_timesteps    | 240000   |
| value_loss         | 0.244    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 230      |
| explained_variance | 0.981    |
| fps                | 482      |
| nupdates           | 48100    |
| policy_entropy     | 0.0129   |
| total_timesteps    | 240500   |
| value_loss         | 2.19     |
---------------------------------
10.0
10.0
12.19
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | 0.408    |
| fps                | 482      |
| nupdates           | 48200    |
| policy_entropy     | 0.00332  |
| total_timesteps    | 241000   |
| value_loss         | 430      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.991    |
| fps                | 482      |
| nupdates           | 48300    |
| policy_entropy     | 0.0372   |
| total_timesteps    | 241500   |
| value_loss         | 0.32     |
---------------------------------
9.0
9.0
11.38
15.5
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 224      |
| explained_variance | -1.3     |
| fps                | 482      |
| nupdates           | 48400    |
| policy_entropy     | 0.0429   |
| total_timesteps    | 242000   |
| value_loss         | 450      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 225      |
| explained_variance | 0.862    |
| fps                | 482      |
| nupdates           | 48500    |
| policy_entropy     | 0.00747  |
| total_timesteps    | 242500   |
| value_loss         | 582      |
---------------------------------
11.0
11.0
12.23
10.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | 0.0869   |
| fps                | 482      |
| nupdates           | 48600    |
| policy_entropy     | 0.0754   |
| total_timesteps    | 243000   |
| value_loss         | 67.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 221      |
| explained_variance | 0.676    |
| fps                | 482      |
| nupdates           | 48700    |
| policy_entropy     | 0.00774  |
| total_timesteps    | 243500   |
| value_loss         | 157      |
---------------------------------
9.0
9.0
12.43
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.323    |
| fps                | 482      |
| nupdates           | 48800    |
| policy_entropy     | 0.0036   |
| total_timesteps    | 244000   |
| value_loss         | 369      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 225      |
| explained_variance | 0.996    |
| fps                | 482      |
| nupdates           | 48900    |
| policy_entropy     | 0.0232   |
| total_timesteps    | 244500   |
| value_loss         | 0.641    |
---------------------------------
9.0
9.0
11.92
9.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.987    |
| fps                | 482      |
| nupdates           | 49000    |
| policy_entropy     | 0.0252   |
| total_timesteps    | 245000   |
| value_loss         | 4.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 224      |
| explained_variance | -0.305   |
| fps                | 482      |
| nupdates           | 49100    |
| policy_entropy     | 0.00459  |
| total_timesteps    | 245500   |
| value_loss         | 69.5     |
---------------------------------
18.0
18.0
11.63
9.5
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | -2.11    |
| fps                | 482      |
| nupdates           | 49200    |
| policy_entropy     | 0.0467   |
| total_timesteps    | 246000   |
| value_loss         | 319      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | 0.818    |
| fps                | 482      |
| nupdates           | 49300    |
| policy_entropy     | 0.0991   |
| total_timesteps    | 246500   |
| value_loss         | 18.2     |
---------------------------------
8.0
8.0
12.15
13.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 223      |
| explained_variance | -0.519   |
| fps                | 482      |
| nupdates           | 49400    |
| policy_entropy     | 0.00691  |
| total_timesteps    | 247000   |
| value_loss         | 193      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.565    |
| fps                | 482      |
| nupdates           | 49500    |
| policy_entropy     | 0.117    |
| total_timesteps    | 247500   |
| value_loss         | 39.2     |
---------------------------------
10.0
10.0
12.59
15.5
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.0793   |
| fps                | 482      |
| nupdates           | 49600    |
| policy_entropy     | 0.0385   |
| total_timesteps    | 248000   |
| value_loss         | 466      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 225      |
| explained_variance | 0.635    |
| fps                | 482      |
| nupdates           | 49700    |
| policy_entropy     | 0.0154   |
| total_timesteps    | 248500   |
| value_loss         | 29.4     |
---------------------------------
10.0
10.0
12.37
10.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 227      |
| explained_variance | -0.448   |
| fps                | 482      |
| nupdates           | 49800    |
| policy_entropy     | 0.0816   |
| total_timesteps    | 249000   |
| value_loss         | 89       |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 227      |
| explained_variance | 0.451    |
| fps                | 482      |
| nupdates           | 49900    |
| policy_entropy     | 0.00939  |
| total_timesteps    | 249500   |
| value_loss         | 285      |
---------------------------------
16.0
16.0
11.92
11.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | -0.332   |
| fps                | 482      |
| nupdates           | 50000    |
| policy_entropy     | 0.0517   |
| total_timesteps    | 250000   |
| value_loss         | 127      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 225      |
| explained_variance | 0.927    |
| fps                | 482      |
| nupdates           | 50100    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 250500   |
| value_loss         | 14.5     |
---------------------------------
10.0
10.0
12.44
11.0
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 227      |
| explained_variance | -0.287   |
| fps                | 482      |
| nupdates           | 50200    |
| policy_entropy     | 0.0491   |
| total_timesteps    | 251000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 227      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 50300    |
| policy_entropy     | 0.119    |
| total_timesteps    | 251500   |
| value_loss         | 353      |
---------------------------------
15.0
15.0
13.92
13.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 222      |
| explained_variance | 0.963    |
| fps                | 482      |
| nupdates           | 50400    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 252000   |
| value_loss         | 1.6      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.835    |
| fps                | 482      |
| nupdates           | 50500    |
| policy_entropy     | 0.0256   |
| total_timesteps    | 252500   |
| value_loss         | 15       |
---------------------------------
11.0
11.0
12.38
13.5
---------------------------------
| ep_len_mean        | 12.4     |
| ep_reward_mean     | 225      |
| explained_variance | 0.263    |
| fps                | 482      |
| nupdates           | 50600    |
| policy_entropy     | 0.00832  |
| total_timesteps    | 253000   |
| value_loss         | 350      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | -10.5    |
| fps                | 482      |
| nupdates           | 50700    |
| policy_entropy     | 0.0284   |
| total_timesteps    | 253500   |
| value_loss         | 412      |
---------------------------------
16.0
16.0
13.39
13.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 224      |
| explained_variance | 0.838    |
| fps                | 482      |
| nupdates           | 50800    |
| policy_entropy     | 0.0164   |
| total_timesteps    | 254000   |
| value_loss         | 19.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.943    |
| fps                | 482      |
| nupdates           | 50900    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 254500   |
| value_loss         | 5.6      |
---------------------------------
10.0
10.0
13.33
12.5
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 227      |
| explained_variance | 0.946    |
| fps                | 482      |
| nupdates           | 51000    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 255000   |
| value_loss         | 6.3      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 226      |
| explained_variance | 0.941    |
| fps                | 481      |
| nupdates           | 51100    |
| policy_entropy     | 0.00415  |
| total_timesteps    | 255500   |
| value_loss         | 5.58     |
---------------------------------
16.0
16.0
12.32
10.0
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 227      |
| explained_variance | 0.957    |
| fps                | 481      |
| nupdates           | 51200    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 256000   |
| value_loss         | 3.15     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.981    |
| fps                | 481      |
| nupdates           | 51300    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 256500   |
| value_loss         | 1.87     |
---------------------------------
16.0
16.0
12.1
10.0
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | 0.952    |
| fps                | 481      |
| nupdates           | 51400    |
| policy_entropy     | 0.0425   |
| total_timesteps    | 257000   |
| value_loss         | 5.22     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 222      |
| explained_variance | -7.98    |
| fps                | 481      |
| nupdates           | 51500    |
| policy_entropy     | 0.365    |
| total_timesteps    | 257500   |
| value_loss         | 524      |
---------------------------------
15.0
15.0
13.02
10.5
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 220      |
| explained_variance | -0.123   |
| fps                | 481      |
| nupdates           | 51600    |
| policy_entropy     | 0.107    |
| total_timesteps    | 258000   |
| value_loss         | 52.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.706    |
| fps                | 481      |
| nupdates           | 51700    |
| policy_entropy     | 0.0564   |
| total_timesteps    | 258500   |
| value_loss         | 23.8     |
---------------------------------
9.0
9.0
12.83
12.5
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.68     |
| fps                | 481      |
| nupdates           | 51800    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 259000   |
| value_loss         | 321      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.368    |
| fps                | 481      |
| nupdates           | 51900    |
| policy_entropy     | 0.00227  |
| total_timesteps    | 259500   |
| value_loss         | 424      |
---------------------------------
11.0
11.0
12.21
10.0
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.994    |
| fps                | 481      |
| nupdates           | 52000    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 260000   |
| value_loss         | 1.01     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 224      |
| explained_variance | -0.292   |
| fps                | 481      |
| nupdates           | 52100    |
| policy_entropy     | 0.00522  |
| total_timesteps    | 260500   |
| value_loss         | 54.7     |
---------------------------------
10.0
10.0
11.49
10.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.974    |
| fps                | 481      |
| nupdates           | 52200    |
| policy_entropy     | 0.00902  |
| total_timesteps    | 261000   |
| value_loss         | 2.48     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.838    |
| fps                | 481      |
| nupdates           | 52300    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 261500   |
| value_loss         | 25.7     |
---------------------------------
16.0
16.0
12.57
9.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.437    |
| fps                | 481      |
| nupdates           | 52400    |
| policy_entropy     | 0.0298   |
| total_timesteps    | 262000   |
| value_loss         | 37.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.3     |
| ep_reward_mean     | 217      |
| explained_variance | -0.141   |
| fps                | 481      |
| nupdates           | 52500    |
| policy_entropy     | 0.00415  |
| total_timesteps    | 262500   |
| value_loss         | 169      |
---------------------------------
9.0
9.0
11.46
10.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.984    |
| fps                | 481      |
| nupdates           | 52600    |
| policy_entropy     | 0.00682  |
| total_timesteps    | 263000   |
| value_loss         | 1.38     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 222      |
| explained_variance | -0.851   |
| fps                | 481      |
| nupdates           | 52700    |
| policy_entropy     | 0.0234   |
| total_timesteps    | 263500   |
| value_loss         | 69.6     |
---------------------------------
9.0
9.0
12.08
9.5
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 224      |
| explained_variance | 0.894    |
| fps                | 481      |
| nupdates           | 52800    |
| policy_entropy     | 0.00298  |
| total_timesteps    | 264000   |
| value_loss         | 39.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 224      |
| explained_variance | 0.781    |
| fps                | 481      |
| nupdates           | 52900    |
| policy_entropy     | 0.0241   |
| total_timesteps    | 264500   |
| value_loss         | 18.2     |
---------------------------------
17.0
17.0
11.45
10.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 223      |
| explained_variance | 0.992    |
| fps                | 481      |
| nupdates           | 53000    |
| policy_entropy     | 0.0329   |
| total_timesteps    | 265000   |
| value_loss         | 0.271    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 223      |
| explained_variance | 0.368    |
| fps                | 481      |
| nupdates           | 53100    |
| policy_entropy     | 0.00251  |
| total_timesteps    | 265500   |
| value_loss         | 427      |
---------------------------------
9.0
9.0
11.99
9.5
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 223      |
| explained_variance | -0.0241  |
| fps                | 481      |
| nupdates           | 53200    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 266000   |
| value_loss         | 111      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.881    |
| fps                | 481      |
| nupdates           | 53300    |
| policy_entropy     | 0.00235  |
| total_timesteps    | 266500   |
| value_loss         | 526      |
---------------------------------
9.0
9.0
11.73
10.0
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 225      |
| explained_variance | 0.81     |
| fps                | 481      |
| nupdates           | 53400    |
| policy_entropy     | 0.00698  |
| total_timesteps    | 267000   |
| value_loss         | 24.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 224      |
| explained_variance | 0.934    |
| fps                | 481      |
| nupdates           | 53500    |
| policy_entropy     | 0.00302  |
| total_timesteps    | 267500   |
| value_loss         | 14.4     |
---------------------------------
15.0
15.0
11.43
9.0
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 225      |
| explained_variance | 0.969    |
| fps                | 481      |
| nupdates           | 53600    |
| policy_entropy     | 0.00585  |
| total_timesteps    | 268000   |
| value_loss         | 3.83     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 224      |
| explained_variance | 0.743    |
| fps                | 481      |
| nupdates           | 53700    |
| policy_entropy     | 0.00401  |
| total_timesteps    | 268500   |
| value_loss         | 310      |
---------------------------------
9.0
9.0
11.87
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.396    |
| fps                | 481      |
| nupdates           | 53800    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 269000   |
| value_loss         | 11.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | 0.535    |
| fps                | 481      |
| nupdates           | 53900    |
| policy_entropy     | 0.0057   |
| total_timesteps    | 269500   |
| value_loss         | 480      |
---------------------------------
15.0
15.0
11.83
10.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 227      |
| explained_variance | 0.952    |
| fps                | 481      |
| nupdates           | 54000    |
| policy_entropy     | 0.00713  |
| total_timesteps    | 270000   |
| value_loss         | 8.64     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 224      |
| explained_variance | 0.353    |
| fps                | 481      |
| nupdates           | 54100    |
| policy_entropy     | 0.0407   |
| total_timesteps    | 270500   |
| value_loss         | 73.4     |
---------------------------------
9.0
9.0
11.26
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | -0.541   |
| fps                | 481      |
| nupdates           | 54200    |
| policy_entropy     | 0.00356  |
| total_timesteps    | 271000   |
| value_loss         | 198      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.587    |
| fps                | 481      |
| nupdates           | 54300    |
| policy_entropy     | 0.00185  |
| total_timesteps    | 271500   |
| value_loss         | 258      |
---------------------------------
9.0
9.0
11.95
9.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 223      |
| explained_variance | -0.275   |
| fps                | 481      |
| nupdates           | 54400    |
| policy_entropy     | 0.00193  |
| total_timesteps    | 272000   |
| value_loss         | 54.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.784    |
| fps                | 481      |
| nupdates           | 54500    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 272500   |
| value_loss         | 37.1     |
---------------------------------
17.0
17.0
11.29
12.5
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | -0.367   |
| fps                | 481      |
| nupdates           | 54600    |
| policy_entropy     | 0.0557   |
| total_timesteps    | 273000   |
| value_loss         | 168      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 222      |
| explained_variance | 0.275    |
| fps                | 481      |
| nupdates           | 54700    |
| policy_entropy     | 0.00261  |
| total_timesteps    | 273500   |
| value_loss         | 376      |
---------------------------------
9.0
9.0
11.12
9.5
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 223      |
| explained_variance | -1.77    |
| fps                | 481      |
| nupdates           | 54800    |
| policy_entropy     | 0.00338  |
| total_timesteps    | 274000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 10.9     |
| ep_reward_mean     | 221      |
| explained_variance | -0.0766  |
| fps                | 481      |
| nupdates           | 54900    |
| policy_entropy     | 0.00422  |
| total_timesteps    | 274500   |
| value_loss         | 54.6     |
---------------------------------
8.0
8.0
11.05
9.0
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 221      |
| explained_variance | -0.0936  |
| fps                | 481      |
| nupdates           | 55000    |
| policy_entropy     | 0.00327  |
| total_timesteps    | 275000   |
| value_loss         | 47.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.821    |
| fps                | 481      |
| nupdates           | 55100    |
| policy_entropy     | 0.00441  |
| total_timesteps    | 275500   |
| value_loss         | 18.1     |
---------------------------------
10.0
10.0
11.49
12.5
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | -0.206   |
| fps                | 481      |
| nupdates           | 55200    |
| policy_entropy     | 0.135    |
| total_timesteps    | 276000   |
| value_loss         | 170      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 225      |
| explained_variance | -1.34    |
| fps                | 481      |
| nupdates           | 55300    |
| policy_entropy     | 0.00634  |
| total_timesteps    | 276500   |
| value_loss         | 60       |
---------------------------------
9.0
9.0
11.99
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 225      |
| explained_variance | 0.986    |
| fps                | 481      |
| nupdates           | 55400    |
| policy_entropy     | 0.0404   |
| total_timesteps    | 277000   |
| value_loss         | 1.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 226      |
| explained_variance | 0.435    |
| fps                | 481      |
| nupdates           | 55500    |
| policy_entropy     | 0.00471  |
| total_timesteps    | 277500   |
| value_loss         | 204      |
---------------------------------
10.0
10.0
11.8
9.5
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 227      |
| explained_variance | 0.981    |
| fps                | 481      |
| nupdates           | 55600    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 278000   |
| value_loss         | 1.44     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 226      |
| explained_variance | -1.47    |
| fps                | 481      |
| nupdates           | 55700    |
| policy_entropy     | 0.567    |
| total_timesteps    | 278500   |
| value_loss         | 168      |
---------------------------------
10.0
10.0
12.17
10.5
---------------------------------
| ep_len_mean        | 12.2     |
| ep_reward_mean     | 227      |
| explained_variance | 0.958    |
| fps                | 481      |
| nupdates           | 55800    |
| policy_entropy     | 0.00621  |
| total_timesteps    | 279000   |
| value_loss         | 8.49     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 227      |
| explained_variance | 0.976    |
| fps                | 481      |
| nupdates           | 55900    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 279500   |
| value_loss         | 2        |
---------------------------------
11.0
11.0
11.99
11.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 227      |
| explained_variance | 0.982    |
| fps                | 481      |
| nupdates           | 56000    |
| policy_entropy     | 0.0178   |
| total_timesteps    | 280000   |
| value_loss         | 1.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.976    |
| fps                | 481      |
| nupdates           | 56100    |
| policy_entropy     | 0.0281   |
| total_timesteps    | 280500   |
| value_loss         | 2.79     |
---------------------------------
16.0
16.0
11.9
11.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 226      |
| explained_variance | 0.71     |
| fps                | 481      |
| nupdates           | 56200    |
| policy_entropy     | 0.0462   |
| total_timesteps    | 281000   |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.847    |
| fps                | 481      |
| nupdates           | 56300    |
| policy_entropy     | 0.566    |
| total_timesteps    | 281500   |
| value_loss         | 1.03e+03 |
---------------------------------
9.0
9.0
12.62
9.0
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 226      |
| explained_variance | 0.43     |
| fps                | 481      |
| nupdates           | 56400    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 282000   |
| value_loss         | 299      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.6     |
| ep_reward_mean     | 226      |
| explained_variance | 0.993    |
| fps                | 481      |
| nupdates           | 56500    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 282500   |
| value_loss         | 0.739    |
---------------------------------
16.0
16.0
11.88
11.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | 0.988    |
| fps                | 481      |
| nupdates           | 56600    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 283000   |
| value_loss         | 0.962    |
---------------------------------
---------------------------------
| ep_len_mean        | 12.1     |
| ep_reward_mean     | 226      |
| explained_variance | 0.861    |
| fps                | 481      |
| nupdates           | 56700    |
| policy_entropy     | 0.00255  |
| total_timesteps    | 283500   |
| value_loss         | 605      |
---------------------------------
16.0
16.0
11.98
10.0
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 227      |
| explained_variance | -0.523   |
| fps                | 481      |
| nupdates           | 56800    |
| policy_entropy     | 0.0198   |
| total_timesteps    | 284000   |
| value_loss         | 510      |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | 0.991    |
| fps                | 481      |
| nupdates           | 56900    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 284500   |
| value_loss         | 3.2      |
---------------------------------
10.0
10.0
12.46
10.0
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.875    |
| fps                | 481      |
| nupdates           | 57000    |
| policy_entropy     | 0.0017   |
| total_timesteps    | 285000   |
| value_loss         | 498      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.7     |
| ep_reward_mean     | 223      |
| explained_variance | 0.967    |
| fps                | 481      |
| nupdates           | 57100    |
| policy_entropy     | 0.0048   |
| total_timesteps    | 285500   |
| value_loss         | 7.45     |
---------------------------------
16.0
16.0
12.46
12.5
---------------------------------
| ep_len_mean        | 12.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.952    |
| fps                | 481      |
| nupdates           | 57200    |
| policy_entropy     | 0.00765  |
| total_timesteps    | 286000   |
| value_loss         | 3.82     |
---------------------------------
---------------------------------
| ep_len_mean        | 12       |
| ep_reward_mean     | 226      |
| explained_variance | -0.527   |
| fps                | 481      |
| nupdates           | 57300    |
| policy_entropy     | 0.00314  |
| total_timesteps    | 286500   |
| value_loss         | 65.7     |
---------------------------------
9.0
9.0
11.93
10.0
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 224      |
| explained_variance | 0.389    |
| fps                | 481      |
| nupdates           | 57400    |
| policy_entropy     | 0.00207  |
| total_timesteps    | 287000   |
| value_loss         | 436      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.514    |
| fps                | 481      |
| nupdates           | 57500    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 287500   |
| value_loss         | 110      |
---------------------------------
16.0
16.0
11.18
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.991    |
| fps                | 481      |
| nupdates           | 57600    |
| policy_entropy     | 0.0087   |
| total_timesteps    | 288000   |
| value_loss         | 1.01     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.951    |
| fps                | 481      |
| nupdates           | 57700    |
| policy_entropy     | 0.0331   |
| total_timesteps    | 288500   |
| value_loss         | 4.82     |
---------------------------------
9.0
9.0
11.54
11.0
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 224      |
| explained_variance | 0.993    |
| fps                | 481      |
| nupdates           | 57800    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 289000   |
| value_loss         | 0.872    |
---------------------------------
---------------------------------
| ep_len_mean        | 11.7     |
| ep_reward_mean     | 226      |
| explained_variance | 0.925    |
| fps                | 481      |
| nupdates           | 57900    |
| policy_entropy     | 0.00755  |
| total_timesteps    | 289500   |
| value_loss         | 7.6      |
---------------------------------
9.0
9.0
11.32
10.0
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 224      |
| explained_variance | 0.575    |
| fps                | 481      |
| nupdates           | 58000    |
| policy_entropy     | 0.00592  |
| total_timesteps    | 290000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.1     |
| ep_reward_mean     | 223      |
| explained_variance | 0.413    |
| fps                | 481      |
| nupdates           | 58100    |
| policy_entropy     | 0.00192  |
| total_timesteps    | 290500   |
| value_loss         | 432      |
---------------------------------
10.0
10.0
11.22
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 224      |
| explained_variance | -1.33    |
| fps                | 481      |
| nupdates           | 58200    |
| policy_entropy     | 0.0316   |
| total_timesteps    | 291000   |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.991    |
| fps                | 481      |
| nupdates           | 58300    |
| policy_entropy     | 0.057    |
| total_timesteps    | 291500   |
| value_loss         | 0.428    |
---------------------------------
16.0
16.0
11.84
9.0
---------------------------------
| ep_len_mean        | 11.8     |
| ep_reward_mean     | 223      |
| explained_variance | 0.778    |
| fps                | 481      |
| nupdates           | 58400    |
| policy_entropy     | 0.00433  |
| total_timesteps    | 292000   |
| value_loss         | 20       |
---------------------------------
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 223      |
| explained_variance | 0.733    |
| fps                | 481      |
| nupdates           | 58500    |
| policy_entropy     | 0.0234   |
| total_timesteps    | 292500   |
| value_loss         | 19.8     |
---------------------------------
17.0
17.0
11.19
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.0757   |
| fps                | 481      |
| nupdates           | 58600    |
| policy_entropy     | 0.00287  |
| total_timesteps    | 293000   |
| value_loss         | 44.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 222      |
| explained_variance | -0.547   |
| fps                | 481      |
| nupdates           | 58700    |
| policy_entropy     | 0.00966  |
| total_timesteps    | 293500   |
| value_loss         | 59.3     |
---------------------------------
8.0
8.0
11.24
10.0
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 223      |
| explained_variance | -1.27    |
| fps                | 481      |
| nupdates           | 58800    |
| policy_entropy     | 0.0332   |
| total_timesteps    | 294000   |
| value_loss         | 251      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.4     |
| ep_reward_mean     | 225      |
| explained_variance | 0.817    |
| fps                | 481      |
| nupdates           | 58900    |
| policy_entropy     | 0.02     |
| total_timesteps    | 294500   |
| value_loss         | 19.1     |
---------------------------------
16.0
16.0
12.86
16.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 220      |
| explained_variance | -0.542   |
| fps                | 481      |
| nupdates           | 59000    |
| policy_entropy     | 0.0012   |
| total_timesteps    | 295000   |
| value_loss         | 199      |
---------------------------------
9.0
9.0
13.37
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.821    |
| fps                | 481      |
| nupdates           | 59200    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 296000   |
| value_loss         | 30.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.9     |
| ep_reward_mean     | 225      |
| explained_variance | -0.747   |
| fps                | 481      |
| nupdates           | 59300    |
| policy_entropy     | 0.00274  |
| total_timesteps    | 296500   |
| value_loss         | 83       |
---------------------------------
17.0
17.0
11.57
10.0
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0.79     |
| fps                | 480      |
| nupdates           | 59400    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 297000   |
| value_loss         | 28.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.62     |
| fps                | 481      |
| nupdates           | 59500    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 297500   |
| value_loss         | 281      |
---------------------------------
9.0
9.0
11.33
10.5
---------------------------------
| ep_len_mean        | 11.3     |
| ep_reward_mean     | 223      |
| explained_variance | -0.296   |
| fps                | 480      |
| nupdates           | 59600    |
| policy_entropy     | 0.00453  |
| total_timesteps    | 298000   |
| value_loss         | 71.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 11.6     |
| ep_reward_mean     | 225      |
| explained_variance | 0.537    |
| fps                | 480      |
| nupdates           | 59700    |
| policy_entropy     | 0.00385  |
| total_timesteps    | 298500   |
| value_loss         | 41.3     |
---------------------------------
10.0
10.0
11.47
9.5
---------------------------------
| ep_len_mean        | 11.5     |
| ep_reward_mean     | 225      |
| explained_variance | -0.676   |
| fps                | 480      |
| nupdates           | 59800    |
| policy_entropy     | 0.0471   |
| total_timesteps    | 299000   |
| value_loss         | 172      |
---------------------------------
---------------------------------
| ep_len_mean        | 11.2     |
| ep_reward_mean     | 224      |
| explained_variance | 0.798    |
| fps                | 480      |
| nupdates           | 59900    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 299500   |
| value_loss         | 27.9     |
---------------------------------
9.0
9.0
11.02
9.0
---------------------------------
| ep_len_mean        | 11       |
| ep_reward_mean     | 223      |
| explained_variance | 0.928    |
| fps                | 480      |
| nupdates           | 60000    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 300000   |
| value_loss         | 6.15     |
---------------------------------