___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | -0.00135 |
| fps                | 27       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 99       |
---------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BDF8E0F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BDF8E0F0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220C19C9E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220C19C9E48>>: AttributeError: module 'gast' has no attribute 'Index'
---------------------------------
| ep_len_mean        | 262      |
| ep_reward_mean     | -719     |
| explained_variance | -0.00519 |
| fps                | 368      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 127      |
---------------------------------
311.0
311.0
286.5
286.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 286      |
| ep_reward_mean     | -732     |
| explained_variance | -0.0388  |
| fps                | 385      |
| nupdates           | 200      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1000     |
| value_loss         | 53.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 489      |
| ep_reward_mean     | -1.6e+03 |
| explained_variance | -0.00358 |
| fps                | 399      |
| nupdates           | 300      |
| policy_entropy     | 1.1      |
| total_timesteps    | 1500     |
| value_loss         | 88.4     |
---------------------------------
92.0
92.0
247.5
159.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 248      |
| ep_reward_mean     | -696     |
| explained_variance | 0.00339  |
| fps                | 405      |
| nupdates           | 400      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2000     |
| value_loss         | 263      |
---------------------------------
---------------------------------
| ep_len_mean        | 224      |
| ep_reward_mean     | -602     |
| explained_variance | 0.00359  |
| fps                | 401      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 226      |
---------------------------------
306.0
306.0
247.0
159.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 247      |
| ep_reward_mean     | -690     |
| explained_variance | 0.0173   |
| fps                | 399      |
| nupdates           | 600      |
| policy_entropy     | 1.1      |
| total_timesteps    | 3000     |
| value_loss         | 132      |
---------------------------------
---------------------------------
| ep_len_mean        | 247      |
| ep_reward_mean     | -711     |
| explained_variance | -0.00471 |
| fps                | 399      |
| nupdates           | 700      |
| policy_entropy     | 1.09     |
| total_timesteps    | 3500     |
| value_loss         | 38.2     |
---------------------------------
71.0
71.0
246.0
181.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 246      |
| ep_reward_mean     | -685     |
| explained_variance | 5.96e-08 |
| fps                | 399      |
| nupdates           | 800      |
| policy_entropy     | 1.09     |
| total_timesteps    | 4000     |
| value_loss         | 500      |
---------------------------------
---------------------------------
| ep_len_mean        | 265      |
| ep_reward_mean     | -753     |
| explained_variance | 0.00642  |
| fps                | 403      |
| nupdates           | 900      |
| policy_entropy     | 1.07     |
| total_timesteps    | 4500     |
| value_loss         | 6.81     |
---------------------------------
532.0
532.0
280.88235294117646
279.5
---------------------------------
| ep_len_mean        | 281      |
| ep_reward_mean     | -816     |
| explained_variance | 5.25e-06 |
| fps                | 398      |
| nupdates           | 1000     |
| policy_entropy     | 1.07     |
| total_timesteps    | 5000     |
| value_loss         | 7.76     |
---------------------------------
----------------------------------
| ep_len_mean        | 277       |
| ep_reward_mean     | -793      |
| explained_variance | -0.000933 |
| fps                | 396       |
| nupdates           | 1100      |
| policy_entropy     | 1.03      |
| total_timesteps    | 5500      |
| value_loss         | 147       |
----------------------------------
70.0
70.0
266.3181818181818
252.0
---------------------------------
| ep_len_mean        | 266      |
| ep_reward_mean     | -758     |
| explained_variance | -0.00106 |
| fps                | 395      |
| nupdates           | 1200     |
| policy_entropy     | 0.937    |
| total_timesteps    | 6000     |
| value_loss         | 271      |
---------------------------------
---------------------------------
| ep_len_mean        | 268      |
| ep_reward_mean     | -776     |
| explained_variance | 0.000262 |
| fps                | 395      |
| nupdates           | 1300     |
| policy_entropy     | 0.944    |
| total_timesteps    | 6500     |
| value_loss         | 277      |
---------------------------------
225.0
225.0
254.33333333333334
193.0
---------------------------------
| ep_len_mean        | 254      |
| ep_reward_mean     | -724     |
| explained_variance | 0.000428 |
| fps                | 396      |
| nupdates           | 1400     |
| policy_entropy     | 0.923    |
| total_timesteps    | 7000     |
| value_loss         | 119      |
---------------------------------
---------------------------------
| ep_len_mean        | 264      |
| ep_reward_mean     | -766     |
| explained_variance | 0.000446 |
| fps                | 397      |
| nupdates           | 1500     |
| policy_entropy     | 0.9      |
| total_timesteps    | 7500     |
| value_loss         | 134      |
---------------------------------
93.0
93.0
238.33333333333334
96.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 238      |
| ep_reward_mean     | -669     |
| explained_variance | 5.17e-05 |
| fps                | 398      |
| nupdates           | 1600     |
| policy_entropy     | 0.927    |
| total_timesteps    | 8000     |
| value_loss         | 32.2     |
---------------------------------
----------------------------------
| ep_len_mean        | 200       |
| ep_reward_mean     | -515      |
| explained_variance | -0.000722 |
| fps                | 398       |
| nupdates           | 1700      |
| policy_entropy     | 0.803     |
| total_timesteps    | 8500      |
| value_loss         | 167       |
----------------------------------
20.0
20.0
171.76923076923077
38.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 172       |
| ep_reward_mean     | -405      |
| explained_variance | -7.39e-06 |
| fps                | 398       |
| nupdates           | 1800      |
| policy_entropy     | 0.806     |
| total_timesteps    | 9000      |
| value_loss         | 211       |
----------------------------------
---------------------------------
| ep_len_mean        | 166      |
| ep_reward_mean     | -383     |
| explained_variance | 0.00465  |
| fps                | 400      |
| nupdates           | 1900     |
| policy_entropy     | 0.729    |
| total_timesteps    | 9500     |
| value_loss         | 125      |
---------------------------------
69.0
69.0
146.35294117647058
27.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 146      |
| ep_reward_mean     | -305     |
| explained_variance | 0.000142 |
| fps                | 399      |
| nupdates           | 2000     |
| policy_entropy     | 0.626    |
| total_timesteps    | 10000    |
| value_loss         | 227      |
---------------------------------
----------------------------------
| ep_len_mean        | 133       |
| ep_reward_mean     | -252      |
| explained_variance | -0.000336 |
| fps                | 400       |
| nupdates           | 2100      |
| policy_entropy     | 0.624     |
| total_timesteps    | 10500     |
| value_loss         | 73.2      |
----------------------------------
34.0
34.0
122.04444444444445
24.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 122      |
| ep_reward_mean     | -208     |
| explained_variance | -0.142   |
| fps                | 401      |
| nupdates           | 2200     |
| policy_entropy     | 0.512    |
| total_timesteps    | 11000    |
| value_loss         | 47.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 119      |
| ep_reward_mean     | -196     |
| explained_variance | 0.000254 |
| fps                | 401      |
| nupdates           | 2300     |
| policy_entropy     | 1.01     |
| total_timesteps    | 11500    |
| value_loss         | 40.4     |
---------------------------------
226.0
226.0
121.3265306122449
41.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 121      |
| ep_reward_mean     | -199     |
| explained_variance | 9.39e-05 |
| fps                | 395      |
| nupdates           | 2400     |
| policy_entropy     | 0.807    |
| total_timesteps    | 12000    |
| value_loss         | 59.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 92.4     |
| ep_reward_mean     | -83.7    |
| explained_variance | 6.37e-05 |
| fps                | 396      |
| nupdates           | 2500     |
| policy_entropy     | 0.882    |
| total_timesteps    | 12500    |
| value_loss         | 140      |
---------------------------------
45.0
45.0
64.82
20.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 64.8      |
| ep_reward_mean     | 22.4      |
| explained_variance | -0.000703 |
| fps                | 397       |
| nupdates           | 2600      |
| policy_entropy     | 0.552     |
| total_timesteps    | 13000     |
| value_loss         | 236       |
----------------------------------
----------------------------------
| ep_len_mean        | 68.3      |
| ep_reward_mean     | 10.7      |
| explained_variance | -0.000159 |
| fps                | 398       |
| nupdates           | 2700      |
| policy_entropy     | 0.718     |
| total_timesteps    | 13500     |
| value_loss         | 195       |
----------------------------------
12.0
12.0
59.06
17.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 59.1      |
| ep_reward_mean     | 50.9      |
| explained_variance | -0.000932 |
| fps                | 398       |
| nupdates           | 2800      |
| policy_entropy     | 0.578     |
| total_timesteps    | 14000     |
| value_loss         | 6.08e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 55.7     |
| ep_reward_mean     | 66.2     |
| explained_variance | 0        |
| fps                | 398      |
| nupdates           | 2900     |
| policy_entropy     | 0.293    |
| total_timesteps    | 14500    |
| value_loss         | 13.8     |
---------------------------------
9.0
9.0
51.01
14.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 51       |
| ep_reward_mean     | 86.5     |
| explained_variance | 0        |
| fps                | 397      |
| nupdates           | 3000     |
| policy_entropy     | 0.466    |
| total_timesteps    | 15000    |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 47       |
| ep_reward_mean     | 103      |
| explained_variance | -3.87    |
| fps                | 396      |
| nupdates           | 3100     |
| policy_entropy     | 0.688    |
| total_timesteps    | 15500    |
| value_loss         | 367      |
---------------------------------
18.0
18.0
43.2
21.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 43.2     |
| ep_reward_mean     | 116      |
| explained_variance | 0        |
| fps                | 395      |
| nupdates           | 3200     |
| policy_entropy     | 0.0791   |
| total_timesteps    | 16000    |
| value_loss         | 12.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 44.1     |
| ep_reward_mean     | 116      |
| explained_variance | -0.00158 |
| fps                | 396      |
| nupdates           | 3300     |
| policy_entropy     | 0.124    |
| total_timesteps    | 16500    |
| value_loss         | 6.63e+04 |
---------------------------------
245.0
245.0
46.18
32.0
---------------------------------
| ep_len_mean        | 46.2     |
| ep_reward_mean     | 108      |
| explained_variance | 0        |
| fps                | 395      |
| nupdates           | 3400     |
| policy_entropy     | 0.0692   |
| total_timesteps    | 17000    |
| value_loss         | 10.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 49.2     |
| ep_reward_mean     | 102      |
| explained_variance | 1.19e-07 |
| fps                | 394      |
| nupdates           | 3500     |
| policy_entropy     | 0.135    |
| total_timesteps    | 17500    |
| value_loss         | 92.3     |
---------------------------------
13.0
13.0
55.62
68.0
---------------------------------
| ep_len_mean        | 55.6     |
| ep_reward_mean     | 85.6     |
| explained_variance | 0        |
| fps                | 394      |
| nupdates           | 3600     |
| policy_entropy     | 0.193    |
| total_timesteps    | 18000    |
| value_loss         | 8.87     |
---------------------------------
---------------------------------
| ep_len_mean        | 55.2     |
| ep_reward_mean     | 90.1     |
| explained_variance | -0.00821 |
| fps                | 393      |
| nupdates           | 3700     |
| policy_entropy     | 0.597    |
| total_timesteps    | 18500    |
| value_loss         | 38.2     |
---------------------------------
70.0
70.0
62.16
19.5
---------------------------------
| ep_len_mean        | 62.2     |
| ep_reward_mean     | 66.4     |
| explained_variance | -0.062   |
| fps                | 393      |
| nupdates           | 3800     |
| policy_entropy     | 0.45     |
| total_timesteps    | 19000    |
| value_loss         | 2.02e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 53.9     |
| ep_reward_mean     | 96       |
| explained_variance | -15.5    |
| fps                | 393      |
| nupdates           | 3900     |
| policy_entropy     | 0.319    |
| total_timesteps    | 19500    |
| value_loss         | 254      |
---------------------------------
23.0
23.0
52.12
19.5
---------------------------------
| ep_len_mean        | 52.1     |
| ep_reward_mean     | 102      |
| explained_variance | 1.19e-07 |
| fps                | 393      |
| nupdates           | 4000     |
| policy_entropy     | 0.214    |
| total_timesteps    | 20000    |
| value_loss         | 7.28     |
---------------------------------
---------------------------------
| ep_len_mean        | 53.1     |
| ep_reward_mean     | 102      |
| explained_variance | 0.0493   |
| fps                | 391      |
| nupdates           | 4100     |
| policy_entropy     | 0.279    |
| total_timesteps    | 20500    |
| value_loss         | 6.93     |
---------------------------------
72.0
72.0
54.61
14.0
---------------------------------
| ep_len_mean        | 54.6     |
| ep_reward_mean     | 98.5     |
| explained_variance | 1.19e-07 |
| fps                | 392      |
| nupdates           | 4200     |
| policy_entropy     | 0.507    |
| total_timesteps    | 21000    |
| value_loss         | 81.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 50.7     |
| ep_reward_mean     | 111      |
| explained_variance | 0        |
| fps                | 392      |
| nupdates           | 4300     |
| policy_entropy     | 0.288    |
| total_timesteps    | 21500    |
| value_loss         | 5.86     |
---------------------------------
9.0
9.0
29.34
13.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 29.3     |
| ep_reward_mean     | 173      |
| explained_variance | -0.237   |
| fps                | 392      |
| nupdates           | 4400     |
| policy_entropy     | 0.141    |
| total_timesteps    | 22000    |
| value_loss         | 170      |
---------------------------------
---------------------------------
| ep_len_mean        | 31.9     |
| ep_reward_mean     | 166      |
| explained_variance | -0.0463  |
| fps                | 393      |
| nupdates           | 4500     |
| policy_entropy     | 0.281    |
| total_timesteps    | 22500    |
| value_loss         | 2.23e+04 |
---------------------------------
137.0
137.0
31.4
24.5
---------------------------------
| ep_len_mean        | 31.4     |
| ep_reward_mean     | 167      |
| explained_variance | -0.0191  |
| fps                | 393      |
| nupdates           | 4600     |
| policy_entropy     | 0.599    |
| total_timesteps    | 23000    |
| value_loss         | 46.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 167      |
| explained_variance | -7.79    |
| fps                | 393      |
| nupdates           | 4700     |
| policy_entropy     | 0.15     |
| total_timesteps    | 23500    |
| value_loss         | 69.4     |
---------------------------------
28.0
28.0
28.73
22.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 28.7     |
| ep_reward_mean     | 173      |
| explained_variance | 0.0205   |
| fps                | 393      |
| nupdates           | 4800     |
| policy_entropy     | 0.532    |
| total_timesteps    | 24000    |
| value_loss         | 75.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 28.2     |
| ep_reward_mean     | 172      |
| explained_variance | -0.00899 |
| fps                | 393      |
| nupdates           | 4900     |
| policy_entropy     | 0.387    |
| total_timesteps    | 24500    |
| value_loss         | 4.36     |
---------------------------------
9.0
9.0
30.44
16.5
---------------------------------
| ep_len_mean        | 30.4     |
| ep_reward_mean     | 167      |
| explained_variance | -0.0354  |
| fps                | 393      |
| nupdates           | 5000     |
| policy_entropy     | 0.772    |
| total_timesteps    | 25000    |
| value_loss         | 4.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 29.1     |
| ep_reward_mean     | 169      |
| explained_variance | -7.03    |
| fps                | 393      |
| nupdates           | 5100     |
| policy_entropy     | 0.393    |
| total_timesteps    | 25500    |
| value_loss         | 23       |
---------------------------------
13.0
13.0
28.26
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 28.3     |
| ep_reward_mean     | 174      |
| explained_variance | 0.0302   |
| fps                | 393      |
| nupdates           | 5200     |
| policy_entropy     | 0.239    |
| total_timesteps    | 26000    |
| value_loss         | 8.67e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 181      |
| explained_variance | 0.0676   |
| fps                | 393      |
| nupdates           | 5300     |
| policy_entropy     | 0.573    |
| total_timesteps    | 26500    |
| value_loss         | 3.68     |
---------------------------------
9.0
9.0
25.78
34.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.8     |
| ep_reward_mean     | 183      |
| explained_variance | -0.06    |
| fps                | 393      |
| nupdates           | 5400     |
| policy_entropy     | 0.781    |
| total_timesteps    | 27000    |
| value_loss         | 3.1      |
---------------------------------
---------------------------------
| ep_len_mean        | 27.2     |
| ep_reward_mean     | 178      |
| explained_variance | -0.00153 |
| fps                | 393      |
| nupdates           | 5500     |
| policy_entropy     | 0.78     |
| total_timesteps    | 27500    |
| value_loss         | 34.1     |
---------------------------------
11.0
11.0
25.68
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.7     |
| ep_reward_mean     | 184      |
| explained_variance | -0.0813  |
| fps                | 393      |
| nupdates           | 5600     |
| policy_entropy     | 0.302    |
| total_timesteps    | 28000    |
| value_loss         | 4.87e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 25.6     |
| ep_reward_mean     | 182      |
| explained_variance | 0.000476 |
| fps                | 393      |
| nupdates           | 5700     |
| policy_entropy     | 0.715    |
| total_timesteps    | 28500    |
| value_loss         | 9.36e+04 |
---------------------------------
27.0
27.0
27.84
24.0
---------------------------------
| ep_len_mean        | 27.8     |
| ep_reward_mean     | 175      |
| explained_variance | 0.000477 |
| fps                | 392      |
| nupdates           | 5800     |
| policy_entropy     | 0.445    |
| total_timesteps    | 29000    |
| value_loss         | 128      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.8     |
| ep_reward_mean     | 178      |
| explained_variance | -7.49    |
| fps                | 392      |
| nupdates           | 5900     |
| policy_entropy     | 0.611    |
| total_timesteps    | 29500    |
| value_loss         | 154      |
---------------------------------
13.0
13.0
22.79
13.0
---------------------------------
| ep_len_mean        | 22.8     |
| ep_reward_mean     | 184      |
| explained_variance | 0.173    |
| fps                | 391      |
| nupdates           | 6000     |
| policy_entropy     | 0.0879   |
| total_timesteps    | 30000    |
| value_loss         | 206      |
---------------------------------
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 182      |
| explained_variance | 0.458    |
| fps                | 390      |
| nupdates           | 6100     |
| policy_entropy     | 0.283    |
| total_timesteps    | 30500    |
| value_loss         | 70.1     |
---------------------------------
39.0
39.0
22.68
11.0
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 184      |
| explained_variance | 0.0278   |
| fps                | 391      |
| nupdates           | 6200     |
| policy_entropy     | 0.0559   |
| total_timesteps    | 31000    |
| value_loss         | 54.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 191      |
| explained_variance | -2.57    |
| fps                | 388      |
| nupdates           | 6300     |
| policy_entropy     | 0.332    |
| total_timesteps    | 31500    |
| value_loss         | 50.4     |
---------------------------------
30.0
30.0
22.31
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 22.3      |
| ep_reward_mean     | 187       |
| explained_variance | -0.000221 |
| fps                | 388       |
| nupdates           | 6400      |
| policy_entropy     | 0.535     |
| total_timesteps    | 32000     |
| value_loss         | 62.1      |
----------------------------------
---------------------------------
| ep_len_mean        | 24.3     |
| ep_reward_mean     | 183      |
| explained_variance | -0.0864  |
| fps                | 388      |
| nupdates           | 6500     |
| policy_entropy     | 0.473    |
| total_timesteps    | 32500    |
| value_loss         | 7.59e+04 |
---------------------------------
29.0
29.0
24.35
21.5
----------------------------------
| ep_len_mean        | 24.4      |
| ep_reward_mean     | 183       |
| explained_variance | -0.000898 |
| fps                | 388       |
| nupdates           | 6600      |
| policy_entropy     | 0.682     |
| total_timesteps    | 33000     |
| value_loss         | 71.6      |
----------------------------------
---------------------------------
| ep_len_mean        | 26.6     |
| ep_reward_mean     | 176      |
| explained_variance | 0.000257 |
| fps                | 388      |
| nupdates           | 6700     |
| policy_entropy     | 0.913    |
| total_timesteps    | 33500    |
| value_loss         | 3.55     |
---------------------------------
13.0
13.0
26.78
12.5
---------------------------------
| ep_len_mean        | 26.8     |
| ep_reward_mean     | 176      |
| explained_variance | 0.00208  |
| fps                | 388      |
| nupdates           | 6800     |
| policy_entropy     | 0.983    |
| total_timesteps    | 34000    |
| value_loss         | 8.15     |
---------------------------------
---------------------------------
| ep_len_mean        | 28.1     |
| ep_reward_mean     | 172      |
| explained_variance | 0.0553   |
| fps                | 388      |
| nupdates           | 6900     |
| policy_entropy     | 0.743    |
| total_timesteps    | 34500    |
| value_loss         | 29.7     |
---------------------------------
51.0
51.0
24.91
17.5
---------------------------------
| ep_len_mean        | 24.9     |
| ep_reward_mean     | 182      |
| explained_variance | 1.19e-07 |
| fps                | 388      |
| nupdates           | 7000     |
| policy_entropy     | 0.23     |
| total_timesteps    | 35000    |
| value_loss         | 57.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 179      |
| explained_variance | 0.0147   |
| fps                | 388      |
| nupdates           | 7100     |
| policy_entropy     | 0.665    |
| total_timesteps    | 35500    |
| value_loss         | 37.7     |
---------------------------------
15.0
15.0
24.07
15.5
---------------------------------
| ep_len_mean        | 24.1     |
| ep_reward_mean     | 183      |
| explained_variance | 0.0569   |
| fps                | 388      |
| nupdates           | 7200     |
| policy_entropy     | 0.543    |
| total_timesteps    | 36000    |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 25       |
| ep_reward_mean     | 181      |
| explained_variance | 0.0132   |
| fps                | 388      |
| nupdates           | 7300     |
| policy_entropy     | 0.56     |
| total_timesteps    | 36500    |
| value_loss         | 76.2     |
---------------------------------
45.0
45.0
24.1
10.5
---------------------------------
| ep_len_mean        | 24.1     |
| ep_reward_mean     | 181      |
| explained_variance | 0.933    |
| fps                | 388      |
| nupdates           | 7400     |
| policy_entropy     | 0.234    |
| total_timesteps    | 37000    |
| value_loss         | 19.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 186      |
| explained_variance | -63.5    |
| fps                | 387      |
| nupdates           | 7500     |
| policy_entropy     | 0.255    |
| total_timesteps    | 37500    |
| value_loss         | 117      |
---------------------------------
28.0
28.0
20.88
18.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 191      |
| explained_variance | 0.34     |
| fps                | 388      |
| nupdates           | 7600     |
| policy_entropy     | 0.324    |
| total_timesteps    | 38000    |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 194      |
| explained_variance | -0.309   |
| fps                | 388      |
| nupdates           | 7700     |
| policy_entropy     | 0.0489   |
| total_timesteps    | 38500    |
| value_loss         | 686      |
---------------------------------
9.0
9.0
20.58
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 194      |
| explained_variance | 0.397    |
| fps                | 388      |
| nupdates           | 7800     |
| policy_entropy     | 0.0433   |
| total_timesteps    | 39000    |
| value_loss         | 810      |
---------------------------------
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 196      |
| explained_variance | -273     |
| fps                | 388      |
| nupdates           | 7900     |
| policy_entropy     | 0.433    |
| total_timesteps    | 39500    |
| value_loss         | 291      |
---------------------------------
16.0
16.0
18.55
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -5.59    |
| fps                | 388      |
| nupdates           | 8000     |
| policy_entropy     | 0.574    |
| total_timesteps    | 40000    |
| value_loss         | 74.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 205      |
| explained_variance | -0.113   |
| fps                | 388      |
| nupdates           | 8100     |
| policy_entropy     | 0.352    |
| total_timesteps    | 40500    |
| value_loss         | 6.93e+04 |
---------------------------------
25.0
25.0
15.39
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 208      |
| explained_variance | -0.454   |
| fps                | 387      |
| nupdates           | 8200     |
| policy_entropy     | 0.312    |
| total_timesteps    | 41000    |
| value_loss         | 6.12e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 210      |
| explained_variance | -4.17    |
| fps                | 387      |
| nupdates           | 8300     |
| policy_entropy     | 0.0901   |
| total_timesteps    | 41500    |
| value_loss         | 75.2     |
---------------------------------
9.0
9.0
16.15
11.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 206      |
| explained_variance | -3.58    |
| fps                | 387      |
| nupdates           | 8400     |
| policy_entropy     | 0.482    |
| total_timesteps    | 42000    |
| value_loss         | 241      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.37     |
| fps                | 387      |
| nupdates           | 8500     |
| policy_entropy     | 0.121    |
| total_timesteps    | 42500    |
| value_loss         | 5.35e+04 |
---------------------------------
23.0
23.0
17.84
10.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 203      |
| explained_variance | -0.0527  |
| fps                | 387      |
| nupdates           | 8600     |
| policy_entropy     | 0.702    |
| total_timesteps    | 43000    |
| value_loss         | 148      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 198      |
| explained_variance | -3.47    |
| fps                | 388      |
| nupdates           | 8700     |
| policy_entropy     | 0.26     |
| total_timesteps    | 43500    |
| value_loss         | 234      |
---------------------------------
10.0
10.0
17.47
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.026    |
| fps                | 388      |
| nupdates           | 8800     |
| policy_entropy     | 0.124    |
| total_timesteps    | 44000    |
| value_loss         | 196      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.218    |
| fps                | 388      |
| nupdates           | 8900     |
| policy_entropy     | 0.295    |
| total_timesteps    | 44500    |
| value_loss         | 2.97e+04 |
---------------------------------
10.0
10.0
15.68
16.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 208      |
| explained_variance | -0.0301  |
| fps                | 389      |
| nupdates           | 9000     |
| policy_entropy     | 0.0468   |
| total_timesteps    | 45000    |
| value_loss         | 1.21e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.597    |
| fps                | 389      |
| nupdates           | 9100     |
| policy_entropy     | 0.595    |
| total_timesteps    | 45500    |
| value_loss         | 65.5     |
---------------------------------
10.0
10.0
16.81
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.236    |
| fps                | 389      |
| nupdates           | 9200     |
| policy_entropy     | 0.348    |
| total_timesteps    | 46000    |
| value_loss         | 224      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0116   |
| fps                | 387      |
| nupdates           | 9300     |
| policy_entropy     | 0.0291   |
| total_timesteps    | 46500    |
| value_loss         | 463      |
---------------------------------
23.0
23.0
18.35
10.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 206      |
| explained_variance | -1.14    |
| fps                | 388      |
| nupdates           | 9400     |
| policy_entropy     | 0.0611   |
| total_timesteps    | 47000    |
| value_loss         | 183      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 206      |
| explained_variance | 0.469    |
| fps                | 388      |
| nupdates           | 9500     |
| policy_entropy     | 0.0683   |
| total_timesteps    | 47500    |
| value_loss         | 46.1     |
---------------------------------
48.0
48.0
16.59
23.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.222    |
| fps                | 388      |
| nupdates           | 9600     |
| policy_entropy     | 0.311    |
| total_timesteps    | 48000    |
| value_loss         | 168      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 208      |
| explained_variance | -0.626   |
| fps                | 388      |
| nupdates           | 9700     |
| policy_entropy     | 0.145    |
| total_timesteps    | 48500    |
| value_loss         | 2.04e+04 |
---------------------------------
9.0
9.0
18.03
10.0
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | 0.113    |
| fps                | 388      |
| nupdates           | 9800     |
| policy_entropy     | 0.0687   |
| total_timesteps    | 49000    |
| value_loss         | 175      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 196      |
| explained_variance | -2.97    |
| fps                | 388      |
| nupdates           | 9900     |
| policy_entropy     | 0.433    |
| total_timesteps    | 49500    |
| value_loss         | 12.7     |
---------------------------------
12.0
12.0
22.87
16.0
---------------------------------
| ep_len_mean        | 22.9     |
| ep_reward_mean     | 191      |
| explained_variance | -0.296   |
| fps                | 388      |
| nupdates           | 10000    |
| policy_entropy     | 0.366    |
| total_timesteps    | 50000    |
| value_loss         | 6.28e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 196      |
| explained_variance | -15.7    |
| fps                | 388      |
| nupdates           | 10100    |
| policy_entropy     | 0.263    |
| total_timesteps    | 50500    |
| value_loss         | 625      |
---------------------------------
9.0
9.0
19.91
17.0
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 198      |
| explained_variance | 0.879    |
| fps                | 388      |
| nupdates           | 10200    |
| policy_entropy     | 0.0232   |
| total_timesteps    | 51000    |
| value_loss         | 30.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | 0.567    |
| fps                | 387      |
| nupdates           | 10300    |
| policy_entropy     | 0.155    |
| total_timesteps    | 51500    |
| value_loss         | 203      |
---------------------------------
8.0
8.0
15.85
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | -0.0556  |
| fps                | 387      |
| nupdates           | 10400    |
| policy_entropy     | 0.121    |
| total_timesteps    | 52000    |
| value_loss         | 1.94e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 202      |
| explained_variance | -4.52    |
| fps                | 386      |
| nupdates           | 10500    |
| policy_entropy     | 0.404    |
| total_timesteps    | 52500    |
| value_loss         | 42.7     |
---------------------------------
9.0
9.0
16.24
9.0
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 205      |
| explained_variance | -5.77    |
| fps                | 386      |
| nupdates           | 10600    |
| policy_entropy     | 0.313    |
| total_timesteps    | 53000    |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.658    |
| fps                | 386      |
| nupdates           | 10700    |
| policy_entropy     | 0.0536   |
| total_timesteps    | 53500    |
| value_loss         | 44.1     |
---------------------------------
11.0
11.0
15.04
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 211      |
| explained_variance | -3.66    |
| fps                | 386      |
| nupdates           | 10800    |
| policy_entropy     | 0.0912   |
| total_timesteps    | 54000    |
| value_loss         | 397      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 204      |
| explained_variance | 0.11     |
| fps                | 385      |
| nupdates           | 10900    |
| policy_entropy     | 0.0305   |
| total_timesteps    | 54500    |
| value_loss         | 578      |
---------------------------------
22.0
22.0
15.87
21.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 206      |
| explained_variance | -1.61    |
| fps                | 385      |
| nupdates           | 11000    |
| policy_entropy     | 0.157    |
| total_timesteps    | 55000    |
| value_loss         | 416      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.479   |
| fps                | 385      |
| nupdates           | 11100    |
| policy_entropy     | 0.0636   |
| total_timesteps    | 55500    |
| value_loss         | 190      |
---------------------------------
23.0
23.0
14.16
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.491    |
| fps                | 385      |
| nupdates           | 11200    |
| policy_entropy     | 0.341    |
| total_timesteps    | 56000    |
| value_loss         | 19.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 385      |
| nupdates           | 11300    |
| policy_entropy     | 0.255    |
| total_timesteps    | 56500    |
| value_loss         | 212      |
---------------------------------
10.0
10.0
16.23
10.0
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 203      |
| explained_variance | -0.252   |
| fps                | 385      |
| nupdates           | 11400    |
| policy_entropy     | 0.343    |
| total_timesteps    | 57000    |
| value_loss         | 305      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 204      |
| explained_variance | 0.0793   |
| fps                | 385      |
| nupdates           | 11500    |
| policy_entropy     | 0.0745   |
| total_timesteps    | 57500    |
| value_loss         | 6.59e+03 |
---------------------------------
15.0
15.0
18.95
12.5
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 199      |
| explained_variance | -0.256   |
| fps                | 385      |
| nupdates           | 11600    |
| policy_entropy     | 0.158    |
| total_timesteps    | 58000    |
| value_loss         | 8.61e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 204      |
| explained_variance | -5.09    |
| fps                | 385      |
| nupdates           | 11700    |
| policy_entropy     | 0.236    |
| total_timesteps    | 58500    |
| value_loss         | 898      |
---------------------------------
26.0
26.0
17.48
11.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 203      |
| explained_variance | -0.355   |
| fps                | 385      |
| nupdates           | 11800    |
| policy_entropy     | 0.0235   |
| total_timesteps    | 59000    |
| value_loss         | 419      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 204      |
| explained_variance | -0.705   |
| fps                | 385      |
| nupdates           | 11900    |
| policy_entropy     | 0.024    |
| total_timesteps    | 59500    |
| value_loss         | 102      |
---------------------------------
9.0
9.0
15.33
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.285    |
| fps                | 385      |
| nupdates           | 12000    |
| policy_entropy     | 0.129    |
| total_timesteps    | 60000    |
| value_loss         | 266      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 209      |
| explained_variance | -0.298   |
| fps                | 385      |
| nupdates           | 12100    |
| policy_entropy     | 0.398    |
| total_timesteps    | 60500    |
| value_loss         | 3.93e+03 |
---------------------------------
11.0
11.0
16.46
11.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 385      |
| nupdates           | 12200    |
| policy_entropy     | 0.359    |
| total_timesteps    | 61000    |
| value_loss         | 229      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 206      |
| explained_variance | -0.181   |
| fps                | 385      |
| nupdates           | 12300    |
| policy_entropy     | 0.205    |
| total_timesteps    | 61500    |
| value_loss         | 2.81e+03 |
---------------------------------
9.0
9.0
15.61
11.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 207      |
| explained_variance | -0.678   |
| fps                | 385      |
| nupdates           | 12400    |
| policy_entropy     | 0.093    |
| total_timesteps    | 62000    |
| value_loss         | 193      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 205      |
| explained_variance | -0.72    |
| fps                | 384      |
| nupdates           | 12500    |
| policy_entropy     | 0.521    |
| total_timesteps    | 62500    |
| value_loss         | 430      |
---------------------------------
10.0
10.0
16.76
21.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.0314   |
| fps                | 384      |
| nupdates           | 12600    |
| policy_entropy     | 0.0962   |
| total_timesteps    | 63000    |
| value_loss         | 3.62e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.499    |
| fps                | 384      |
| nupdates           | 12700    |
| policy_entropy     | 0.0958   |
| total_timesteps    | 63500    |
| value_loss         | 45       |
---------------------------------
10.0
10.0
16.71
11.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.278    |
| fps                | 383      |
| nupdates           | 12800    |
| policy_entropy     | 0.528    |
| total_timesteps    | 64000    |
| value_loss         | 149      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 207      |
| explained_variance | -1.1     |
| fps                | 384      |
| nupdates           | 12900    |
| policy_entropy     | 0.0308   |
| total_timesteps    | 64500    |
| value_loss         | 6.12e+03 |
---------------------------------
10.0
10.0
17.24
9.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -0.0542  |
| fps                | 384      |
| nupdates           | 13000    |
| policy_entropy     | 0.0941   |
| total_timesteps    | 65000    |
| value_loss         | 892      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 203      |
| explained_variance | -2.83    |
| fps                | 384      |
| nupdates           | 13100    |
| policy_entropy     | 0.0216   |
| total_timesteps    | 65500    |
| value_loss         | 1.55e+03 |
---------------------------------
10.0
10.0
18.39
10.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 202      |
| explained_variance | 0.0677   |
| fps                | 383      |
| nupdates           | 13200    |
| policy_entropy     | 0.158    |
| total_timesteps    | 66000    |
| value_loss         | 511      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.836    |
| fps                | 383      |
| nupdates           | 13300    |
| policy_entropy     | 0.0388   |
| total_timesteps    | 66500    |
| value_loss         | 27.7     |
---------------------------------
21.0
21.0
14.21
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.29     |
| fps                | 383      |
| nupdates           | 13400    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 67000    |
| value_loss         | 185      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 213      |
| explained_variance | 1.19e-07 |
| fps                | 383      |
| nupdates           | 13500    |
| policy_entropy     | 0.0216   |
| total_timesteps    | 67500    |
| value_loss         | 46       |
---------------------------------
9.0
9.0
19.79
10.0
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 201      |
| explained_variance | -2.39    |
| fps                | 383      |
| nupdates           | 13600    |
| policy_entropy     | 0.0466   |
| total_timesteps    | 68000    |
| value_loss         | 501      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 201      |
| explained_variance | -0.0489  |
| fps                | 383      |
| nupdates           | 13700    |
| policy_entropy     | 0.0249   |
| total_timesteps    | 68500    |
| value_loss         | 3.36e+04 |
---------------------------------
10.0
10.0
21.25
10.0
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 193      |
| explained_variance | -0.126   |
| fps                | 383      |
| nupdates           | 13800    |
| policy_entropy     | 0.197    |
| total_timesteps    | 69000    |
| value_loss         | 6.85e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 22.3     |
| ep_reward_mean     | 191      |
| explained_variance | -40.6    |
| fps                | 382      |
| nupdates           | 13900    |
| policy_entropy     | 0.0845   |
| total_timesteps    | 69500    |
| value_loss         | 186      |
---------------------------------
29.0
29.0
16.39
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 201      |
| explained_variance | 0.831    |
| fps                | 382      |
| nupdates           | 14000    |
| policy_entropy     | 0.233    |
| total_timesteps    | 70000    |
| value_loss         | 126      |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 195      |
| explained_variance | 0.261    |
| fps                | 382      |
| nupdates           | 14100    |
| policy_entropy     | 0.0603   |
| total_timesteps    | 70500    |
| value_loss         | 741      |
---------------------------------
14.0
14.0
18.14
13.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 196      |
| explained_variance | 0.881    |
| fps                | 382      |
| nupdates           | 14200    |
| policy_entropy     | 0.0524   |
| total_timesteps    | 71000    |
| value_loss         | 644      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 201      |
| explained_variance | -1.49    |
| fps                | 382      |
| nupdates           | 14300    |
| policy_entropy     | 0.0706   |
| total_timesteps    | 71500    |
| value_loss         | 321      |
---------------------------------
9.0
9.0
16.18
10.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 204      |
| explained_variance | -7.43    |
| fps                | 382      |
| nupdates           | 14400    |
| policy_entropy     | 0.215    |
| total_timesteps    | 72000    |
| value_loss         | 233      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.388    |
| fps                | 383      |
| nupdates           | 14500    |
| policy_entropy     | 0.0728   |
| total_timesteps    | 72500    |
| value_loss         | 3.63e+03 |
---------------------------------
51.0
51.0
15.69
23.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 383      |
| nupdates           | 14600    |
| policy_entropy     | 0.426    |
| total_timesteps    | 73000    |
| value_loss         | 19.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.554    |
| fps                | 383      |
| nupdates           | 14700    |
| policy_entropy     | 0.138    |
| total_timesteps    | 73500    |
| value_loss         | 244      |
---------------------------------
10.0
10.0
16.34
11.5
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 383      |
| nupdates           | 14800    |
| policy_entropy     | 0.121    |
| total_timesteps    | 74000    |
| value_loss         | 116      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.403    |
| fps                | 383      |
| nupdates           | 14900    |
| policy_entropy     | 0.0409   |
| total_timesteps    | 74500    |
| value_loss         | 197      |
---------------------------------
20.0
20.0
18.38
10.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.0074   |
| fps                | 382      |
| nupdates           | 15000    |
| policy_entropy     | 0.417    |
| total_timesteps    | 75000    |
| value_loss         | 2.4e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 205      |
| explained_variance | -1.84    |
| fps                | 382      |
| nupdates           | 15100    |
| policy_entropy     | 0.0795   |
| total_timesteps    | 75500    |
| value_loss         | 333      |
---------------------------------
10.0
10.0
15.23
16.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 382      |
| nupdates           | 15200    |
| policy_entropy     | 0.572    |
| total_timesteps    | 76000    |
| value_loss         | 66.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0.552    |
| fps                | 383      |
| nupdates           | 15300    |
| policy_entropy     | 0.172    |
| total_timesteps    | 76500    |
| value_loss         | 65       |
---------------------------------
19.0
19.0
17.03
9.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 205      |
| explained_variance | 0        |
| fps                | 383      |
| nupdates           | 15400    |
| policy_entropy     | 0.777    |
| total_timesteps    | 77000    |
| value_loss         | 97.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 203      |
| explained_variance | 0.446    |
| fps                | 383      |
| nupdates           | 15500    |
| policy_entropy     | 0.0527   |
| total_timesteps    | 77500    |
| value_loss         | 814      |
---------------------------------
24.0
24.0
15.87
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.311    |
| fps                | 383      |
| nupdates           | 15600    |
| policy_entropy     | 0.024    |
| total_timesteps    | 78000    |
| value_loss         | 81.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 207      |
| explained_variance | -3.43    |
| fps                | 383      |
| nupdates           | 15700    |
| policy_entropy     | 0.311    |
| total_timesteps    | 78500    |
| value_loss         | 2.61e+03 |
---------------------------------
9.0
9.0
16.62
10.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0825   |
| fps                | 383      |
| nupdates           | 15800    |
| policy_entropy     | 0.313    |
| total_timesteps    | 79000    |
| value_loss         | 284      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 198      |
| explained_variance | -5       |
| fps                | 383      |
| nupdates           | 15900    |
| policy_entropy     | 0.0774   |
| total_timesteps    | 79500    |
| value_loss         | 2.14e+04 |
---------------------------------
15.0
15.0
18.11
13.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 197      |
| explained_variance | -35.4    |
| fps                | 383      |
| nupdates           | 16000    |
| policy_entropy     | 0.0468   |
| total_timesteps    | 80000    |
| value_loss         | 711      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 199      |
| explained_variance | 0.0356   |
| fps                | 383      |
| nupdates           | 16100    |
| policy_entropy     | 0.0259   |
| total_timesteps    | 80500    |
| value_loss         | 464      |
---------------------------------
11.0
11.0
18.69
14.0
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 200      |
| explained_variance | -0.147   |
| fps                | 383      |
| nupdates           | 16200    |
| policy_entropy     | 0.277    |
| total_timesteps    | 81000    |
| value_loss         | 1.13e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.115    |
| fps                | 383      |
| nupdates           | 16300    |
| policy_entropy     | 0.0212   |
| total_timesteps    | 81500    |
| value_loss         | 2.17e+03 |
---------------------------------
10.0
10.0
15.05
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.113   |
| fps                | 383      |
| nupdates           | 16400    |
| policy_entropy     | 0.0343   |
| total_timesteps    | 82000    |
| value_loss         | 893      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 206      |
| explained_variance | -0.501   |
| fps                | 383      |
| nupdates           | 16500    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 82500    |
| value_loss         | 131      |
---------------------------------
10.0
10.0
15.78
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.278   |
| fps                | 383      |
| nupdates           | 16600    |
| policy_entropy     | 0.0536   |
| total_timesteps    | 83000    |
| value_loss         | 149      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 202      |
| explained_variance | -2.23    |
| fps                | 383      |
| nupdates           | 16700    |
| policy_entropy     | 0.258    |
| total_timesteps    | 83500    |
| value_loss         | 4.68e+03 |
---------------------------------
10.0
10.0
15.21
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.794    |
| fps                | 383      |
| nupdates           | 16800    |
| policy_entropy     | 0.264    |
| total_timesteps    | 84000    |
| value_loss         | 42.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.193    |
| fps                | 383      |
| nupdates           | 16900    |
| policy_entropy     | 0.0592   |
| total_timesteps    | 84500    |
| value_loss         | 635      |
---------------------------------
23.0
23.0
13.19
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.442    |
| fps                | 383      |
| nupdates           | 17000    |
| policy_entropy     | 0.0217   |
| total_timesteps    | 85000    |
| value_loss         | 58.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 204      |
| explained_variance | -3.08    |
| fps                | 383      |
| nupdates           | 17100    |
| policy_entropy     | 0.0191   |
| total_timesteps    | 85500    |
| value_loss         | 786      |
---------------------------------
9.0
9.0
17.04
9.5
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 202      |
| explained_variance | 0.796    |
| fps                | 383      |
| nupdates           | 17200    |
| policy_entropy     | 0.0187   |
| total_timesteps    | 86000    |
| value_loss         | 22.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 202      |
| explained_variance | -0.534   |
| fps                | 383      |
| nupdates           | 17300    |
| policy_entropy     | 0.213    |
| total_timesteps    | 86500    |
| value_loss         | 1.52e+04 |
---------------------------------
10.0
10.0
15.31
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.362    |
| fps                | 383      |
| nupdates           | 17400    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 87000    |
| value_loss         | 488      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 212      |
| explained_variance | -1.86    |
| fps                | 382      |
| nupdates           | 17500    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 87500    |
| value_loss         | 186      |
---------------------------------
9.0
9.0
14.98
16.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 211      |
| explained_variance | -0.128   |
| fps                | 382      |
| nupdates           | 17600    |
| policy_entropy     | 0.251    |
| total_timesteps    | 88000    |
| value_loss         | 1.29e+03 |
---------------------------------
----------------------------------
| ep_len_mean        | 15        |
| ep_reward_mean     | 211       |
| explained_variance | -1.19e-07 |
| fps                | 382       |
| nupdates           | 17700     |
| policy_entropy     | 0.0682    |
| total_timesteps    | 88500     |
| value_loss         | 123       |
----------------------------------
10.0
10.0
18.55
26.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 199      |
| explained_variance | -0.974   |
| fps                | 382      |
| nupdates           | 17800    |
| policy_entropy     | 0.374    |
| total_timesteps    | 89000    |
| value_loss         | 41.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 197      |
| explained_variance | -0.679   |
| fps                | 382      |
| nupdates           | 17900    |
| policy_entropy     | 0.369    |
| total_timesteps    | 89500    |
| value_loss         | 60.3     |
---------------------------------
9.0
9.0
19.56
10.0
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 195      |
| explained_variance | 0.0125   |
| fps                | 382      |
| nupdates           | 18000    |
| policy_entropy     | 0.212    |
| total_timesteps    | 90000    |
| value_loss         | 1.92e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 195      |
| explained_variance | -2.64    |
| fps                | 382      |
| nupdates           | 18100    |
| policy_entropy     | 0.0188   |
| total_timesteps    | 90500    |
| value_loss         | 1.17e+03 |
---------------------------------
11.0
11.0
17.94
10.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | -1.72    |
| fps                | 382      |
| nupdates           | 18200    |
| policy_entropy     | 0.023    |
| total_timesteps    | 91000    |
| value_loss         | 7.55e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 206      |
| explained_variance | 0.316    |
| fps                | 383      |
| nupdates           | 18300    |
| policy_entropy     | 0.197    |
| total_timesteps    | 91500    |
| value_loss         | 2.32e+04 |
---------------------------------
13.0
13.0
16.29
10.5
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 209      |
| explained_variance | -3.96    |
| fps                | 382      |
| nupdates           | 18400    |
| policy_entropy     | 0.51     |
| total_timesteps    | 92000    |
| value_loss         | 634      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 210      |
| explained_variance | -5.49    |
| fps                | 383      |
| nupdates           | 18500    |
| policy_entropy     | 0.153    |
| total_timesteps    | 92500    |
| value_loss         | 180      |
---------------------------------
12.0
12.0
14.57
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.188    |
| fps                | 383      |
| nupdates           | 18600    |
| policy_entropy     | 0.0772   |
| total_timesteps    | 93000    |
| value_loss         | 1.14e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | -5.04    |
| fps                | 383      |
| nupdates           | 18700    |
| policy_entropy     | 0.599    |
| total_timesteps    | 93500    |
| value_loss         | 845      |
---------------------------------
10.0
10.0
18.69
11.0
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 195      |
| explained_variance | -7.36    |
| fps                | 382      |
| nupdates           | 18800    |
| policy_entropy     | 0.336    |
| total_timesteps    | 94000    |
| value_loss         | 127      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 193      |
| explained_variance | -3.66    |
| fps                | 382      |
| nupdates           | 18900    |
| policy_entropy     | 0.0552   |
| total_timesteps    | 94500    |
| value_loss         | 869      |
---------------------------------
12.0
12.0
22.42
11.0
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 182      |
| explained_variance | 0.0145   |
| fps                | 382      |
| nupdates           | 19000    |
| policy_entropy     | 0.131    |
| total_timesteps    | 95000    |
| value_loss         | 0.813    |
---------------------------------
---------------------------------
| ep_len_mean        | 24.7     |
| ep_reward_mean     | 175      |
| explained_variance | -2.12    |
| fps                | 382      |
| nupdates           | 19100    |
| policy_entropy     | 0.0409   |
| total_timesteps    | 95500    |
| value_loss         | 1.26e+05 |
---------------------------------
18.0
18.0
24.32
14.0
---------------------------------
| ep_len_mean        | 24.3     |
| ep_reward_mean     | 175      |
| explained_variance | 0.683    |
| fps                | 382      |
| nupdates           | 19200    |
| policy_entropy     | 0.0465   |
| total_timesteps    | 96000    |
| value_loss         | 986      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.6     |
| ep_reward_mean     | 177      |
| explained_variance | 0.0943   |
| fps                | 383      |
| nupdates           | 19300    |
| policy_entropy     | 0.612    |
| total_timesteps    | 96500    |
| value_loss         | 1.39e+05 |
---------------------------------
34.0
34.0
18.52
12.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 192      |
| explained_variance | -0.231   |
| fps                | 382      |
| nupdates           | 19400    |
| policy_entropy     | 0.218    |
| total_timesteps    | 97000    |
| value_loss         | 5.18e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 186      |
| explained_variance | -1.83    |
| fps                | 382      |
| nupdates           | 19500    |
| policy_entropy     | 0.0382   |
| total_timesteps    | 97500    |
| value_loss         | 75.4     |
---------------------------------
25.0
25.0
20.16
12.0
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 187      |
| explained_variance | -2.27    |
| fps                | 382      |
| nupdates           | 19600    |
| policy_entropy     | 0.0358   |
| total_timesteps    | 98000    |
| value_loss         | 723      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 199      |
| explained_variance | -0.38    |
| fps                | 382      |
| nupdates           | 19700    |
| policy_entropy     | 0.0408   |
| total_timesteps    | 98500    |
| value_loss         | 2.48e+04 |
---------------------------------
39.0
39.0
17.15
17.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 204      |
| explained_variance | -0.629   |
| fps                | 382      |
| nupdates           | 19800    |
| policy_entropy     | 0.15     |
| total_timesteps    | 99000    |
| value_loss         | 1.63e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.765    |
| fps                | 382      |
| nupdates           | 19900    |
| policy_entropy     | 0.242    |
| total_timesteps    | 99500    |
| value_loss         | 128      |
---------------------------------
13.0
13.0
16.83
10.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0808   |
| fps                | 382      |
| nupdates           | 20000    |
| policy_entropy     | 0.263    |
| total_timesteps    | 100000   |
| value_loss         | 3.27e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 204      |
| explained_variance | -0.0882  |
| fps                | 382      |
| nupdates           | 20100    |
| policy_entropy     | 0.0241   |
| total_timesteps    | 100500   |
| value_loss         | 316      |
---------------------------------
8.0
8.0
16.84
9.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | -0.238   |
| fps                | 382      |
| nupdates           | 20200    |
| policy_entropy     | 0.0542   |
| total_timesteps    | 101000   |
| value_loss         | 1.01e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | -2.3     |
| fps                | 382      |
| nupdates           | 20300    |
| policy_entropy     | 0.384    |
| total_timesteps    | 101500   |
| value_loss         | 134      |
---------------------------------
16.0
16.0
15.31
10.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0.0348   |
| fps                | 382      |
| nupdates           | 20400    |
| policy_entropy     | 0.716    |
| total_timesteps    | 102000   |
| value_loss         | 26.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | -3.94    |
| fps                | 382      |
| nupdates           | 20500    |
| policy_entropy     | 0.132    |
| total_timesteps    | 102500   |
| value_loss         | 3.54e+03 |
---------------------------------
9.0
9.0
17.49
9.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 205      |
| explained_variance | 0.0723   |
| fps                | 382      |
| nupdates           | 20600    |
| policy_entropy     | 0.0184   |
| total_timesteps    | 103000   |
| value_loss         | 356      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 204      |
| explained_variance | -4.82    |
| fps                | 382      |
| nupdates           | 20700    |
| policy_entropy     | 0.369    |
| total_timesteps    | 103500   |
| value_loss         | 469      |
---------------------------------
10.0
10.0
17.0
9.5
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 205      |
| explained_variance | 0.227    |
| fps                | 382      |
| nupdates           | 20800    |
| policy_entropy     | 0.0778   |
| total_timesteps    | 104000   |
| value_loss         | 286      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 205      |
| explained_variance | 0.532    |
| fps                | 382      |
| nupdates           | 20900    |
| policy_entropy     | 0.0308   |
| total_timesteps    | 104500   |
| value_loss         | 38.7     |
---------------------------------
10.0
10.0
16.65
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | -0.33    |
| fps                | 383      |
| nupdates           | 21000    |
| policy_entropy     | 0.0544   |
| total_timesteps    | 105000   |
| value_loss         | 213      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.348   |
| fps                | 383      |
| nupdates           | 21100    |
| policy_entropy     | 0.476    |
| total_timesteps    | 105500   |
| value_loss         | 98.7     |
---------------------------------
10.0
10.0
16.89
10.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.627    |
| fps                | 382      |
| nupdates           | 21200    |
| policy_entropy     | 0.0261   |
| total_timesteps    | 106000   |
| value_loss         | 291      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 199      |
| explained_variance | -6.39    |
| fps                | 382      |
| nupdates           | 21300    |
| policy_entropy     | 0.141    |
| total_timesteps    | 106500   |
| value_loss         | 2.66e+03 |
---------------------------------
11.0
11.0
19.72
11.0
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 200      |
| explained_variance | 0.452    |
| fps                | 382      |
| nupdates           | 21400    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 107000   |
| value_loss         | 378      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 199      |
| explained_variance | 0.0633   |
| fps                | 383      |
| nupdates           | 21500    |
| policy_entropy     | 0.0275   |
| total_timesteps    | 107500   |
| value_loss         | 1.26e+03 |
---------------------------------
13.0
13.0
18.64
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -1.93    |
| fps                | 383      |
| nupdates           | 21600    |
| policy_entropy     | 0.481    |
| total_timesteps    | 108000   |
| value_loss         | 620      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.109    |
| fps                | 383      |
| nupdates           | 21700    |
| policy_entropy     | 0.14     |
| total_timesteps    | 108500   |
| value_loss         | 244      |
---------------------------------
25.0
25.0
16.72
25.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 207      |
| explained_variance | -2.08    |
| fps                | 383      |
| nupdates           | 21800    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 109000   |
| value_loss         | 141      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 208      |
| explained_variance | 0        |
| fps                | 382      |
| nupdates           | 21900    |
| policy_entropy     | 0.575    |
| total_timesteps    | 109500   |
| value_loss         | 101      |
---------------------------------
32.0
32.0
16.61
9.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 206      |
| explained_variance | -1.2     |
| fps                | 382      |
| nupdates           | 22000    |
| policy_entropy     | 0.127    |
| total_timesteps    | 110000   |
| value_loss         | 464      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 206      |
| explained_variance | -0.0695  |
| fps                | 382      |
| nupdates           | 22100    |
| policy_entropy     | 0.0586   |
| total_timesteps    | 110500   |
| value_loss         | 458      |
---------------------------------
12.0
12.0
15.38
9.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 208      |
| explained_variance | -0.687   |
| fps                | 382      |
| nupdates           | 22200    |
| policy_entropy     | 0.0538   |
| total_timesteps    | 111000   |
| value_loss         | 244      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 209      |
| explained_variance | -8.12    |
| fps                | 382      |
| nupdates           | 22300    |
| policy_entropy     | 0.285    |
| total_timesteps    | 111500   |
| value_loss         | 247      |
---------------------------------
10.0
10.0
17.23
11.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -19.6    |
| fps                | 382      |
| nupdates           | 22400    |
| policy_entropy     | 0.726    |
| total_timesteps    | 112000   |
| value_loss         | 819      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.433    |
| fps                | 382      |
| nupdates           | 22500    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 112500   |
| value_loss         | 200      |
---------------------------------
8.0
8.0
18.49
9.5
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 205      |
| explained_variance | -1.37    |
| fps                | 382      |
| nupdates           | 22600    |
| policy_entropy     | 0.263    |
| total_timesteps    | 113000   |
| value_loss         | 281      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 207      |
| explained_variance | -0.622   |
| fps                | 383      |
| nupdates           | 22700    |
| policy_entropy     | 0.671    |
| total_timesteps    | 113500   |
| value_loss         | 520      |
---------------------------------
9.0
9.0
17.68
15.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 206      |
| explained_variance | -3.13    |
| fps                | 383      |
| nupdates           | 22800    |
| policy_entropy     | 0.0951   |
| total_timesteps    | 114000   |
| value_loss         | 1.42e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -3.07    |
| fps                | 383      |
| nupdates           | 22900    |
| policy_entropy     | 0.328    |
| total_timesteps    | 114500   |
| value_loss         | 575      |
---------------------------------
9.0
9.0
16.54
10.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 207      |
| explained_variance | 0.169    |
| fps                | 383      |
| nupdates           | 23000    |
| policy_entropy     | 0.0404   |
| total_timesteps    | 115000   |
| value_loss         | 27.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 207      |
| explained_variance | 0.312    |
| fps                | 383      |
| nupdates           | 23100    |
| policy_entropy     | 0.0447   |
| total_timesteps    | 115500   |
| value_loss         | 239      |
---------------------------------
26.0
26.0
15.82
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 207      |
| explained_variance | 0.867    |
| fps                | 383      |
| nupdates           | 23200    |
| policy_entropy     | 0.193    |
| total_timesteps    | 116000   |
| value_loss         | 351      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | -0.398   |
| fps                | 383      |
| nupdates           | 23300    |
| policy_entropy     | 0.282    |
| total_timesteps    | 116500   |
| value_loss         | 118      |
---------------------------------
23.0
23.0
15.3
11.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | -1.06    |
| fps                | 383      |
| nupdates           | 23400    |
| policy_entropy     | 0.198    |
| total_timesteps    | 117000   |
| value_loss         | 212      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | -0.914   |
| fps                | 383      |
| nupdates           | 23500    |
| policy_entropy     | 0.315    |
| total_timesteps    | 117500   |
| value_loss         | 299      |
---------------------------------
9.0
9.0
14.85
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.34     |
| fps                | 382      |
| nupdates           | 23600    |
| policy_entropy     | 0.0163   |
| total_timesteps    | 118000   |
| value_loss         | 459      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.55     |
| fps                | 382      |
| nupdates           | 23700    |
| policy_entropy     | 0.0238   |
| total_timesteps    | 118500   |
| value_loss         | 49.5     |
---------------------------------
19.0
19.0
15.57
9.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.555    |
| fps                | 382      |
| nupdates           | 23800    |
| policy_entropy     | 0.21     |
| total_timesteps    | 119000   |
| value_loss         | 59.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.724    |
| fps                | 382      |
| nupdates           | 23900    |
| policy_entropy     | 0.0233   |
| total_timesteps    | 119500   |
| value_loss         | 63.4     |
---------------------------------
22.0
22.0
14.6
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 211      |
| explained_variance | -3.63    |
| fps                | 382      |
| nupdates           | 24000    |
| policy_entropy     | 0.151    |
| total_timesteps    | 120000   |
| value_loss         | 119      |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 212      |
| explained_variance | -0.185   |
| fps                | 382      |
| nupdates           | 24100    |
| policy_entropy     | 0.803    |
| total_timesteps    | 120500   |
| value_loss         | 347      |
---------------------------------
11.0
11.0
14.79
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 207      |
| explained_variance | 0.616    |
| fps                | 382      |
| nupdates           | 24200    |
| policy_entropy     | 0.0199   |
| total_timesteps    | 121000   |
| value_loss         | 215      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 205      |
| explained_variance | -0.239   |
| fps                | 382      |
| nupdates           | 24300    |
| policy_entropy     | 0.195    |
| total_timesteps    | 121500   |
| value_loss         | 255      |
---------------------------------
35.0
35.0
17.53
22.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 203      |
| explained_variance | -2.69    |
| fps                | 382      |
| nupdates           | 24400    |
| policy_entropy     | 0.0326   |
| total_timesteps    | 122000   |
| value_loss         | 277      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.327   |
| fps                | 382      |
| nupdates           | 24500    |
| policy_entropy     | 0.156    |
| total_timesteps    | 122500   |
| value_loss         | 89       |
---------------------------------
21.0
21.0
15.64
21.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.312    |
| fps                | 382      |
| nupdates           | 24600    |
| policy_entropy     | 0.172    |
| total_timesteps    | 123000   |
| value_loss         | 34.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | -0.0169  |
| fps                | 382      |
| nupdates           | 24700    |
| policy_entropy     | 0.0112   |
| total_timesteps    | 123500   |
| value_loss         | 104      |
---------------------------------
9.0
9.0
14.36
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 215      |
| explained_variance | -1.33    |
| fps                | 382      |
| nupdates           | 24800    |
| policy_entropy     | 0.392    |
| total_timesteps    | 124000   |
| value_loss         | 315      |
---------------------------------
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.848    |
| fps                | 382      |
| nupdates           | 24900    |
| policy_entropy     | 0.305    |
| total_timesteps    | 124500   |
| value_loss         | 249      |
---------------------------------
112.0
112.0
14.98
26.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | -1.41    |
| fps                | 382      |
| nupdates           | 25000    |
| policy_entropy     | 0.282    |
| total_timesteps    | 125000   |
| value_loss         | 7.4e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 211      |
| explained_variance | -0.198   |
| fps                | 382      |
| nupdates           | 25100    |
| policy_entropy     | 0.11     |
| total_timesteps    | 125500   |
| value_loss         | 74.6     |
---------------------------------
9.0
9.0
15.96
11.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | 0.875    |
| fps                | 382      |
| nupdates           | 25200    |
| policy_entropy     | 0.0387   |
| total_timesteps    | 126000   |
| value_loss         | 62.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.962   |
| fps                | 382      |
| nupdates           | 25300    |
| policy_entropy     | 0.309    |
| total_timesteps    | 126500   |
| value_loss         | 159      |
---------------------------------
10.0
10.0
15.83
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | -5.74    |
| fps                | 382      |
| nupdates           | 25400    |
| policy_entropy     | 0.206    |
| total_timesteps    | 127000   |
| value_loss         | 939      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | -0.98    |
| fps                | 382      |
| nupdates           | 25500    |
| policy_entropy     | 0.14     |
| total_timesteps    | 127500   |
| value_loss         | 154      |
---------------------------------
25.0
25.0
14.67
9.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 208      |
| explained_variance | 0.436    |
| fps                | 382      |
| nupdates           | 25600    |
| policy_entropy     | 0.00848  |
| total_timesteps    | 128000   |
| value_loss         | 62.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 212      |
| explained_variance | -0.476   |
| fps                | 382      |
| nupdates           | 25700    |
| policy_entropy     | 0.094    |
| total_timesteps    | 128500   |
| value_loss         | 135      |
---------------------------------
9.0
9.0
13.51
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0943   |
| fps                | 382      |
| nupdates           | 25800    |
| policy_entropy     | 0.014    |
| total_timesteps    | 129000   |
| value_loss         | 442      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.8      |
| fps                | 382      |
| nupdates           | 25900    |
| policy_entropy     | 0.143    |
| total_timesteps    | 129500   |
| value_loss         | 292      |
---------------------------------
8.0
8.0
14.13
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.198    |
| fps                | 382      |
| nupdates           | 26000    |
| policy_entropy     | 0.167    |
| total_timesteps    | 130000   |
| value_loss         | 159      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.412    |
| fps                | 382      |
| nupdates           | 26100    |
| policy_entropy     | 0.475    |
| total_timesteps    | 130500   |
| value_loss         | 145      |
---------------------------------
9.0
9.0
14.67
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0        |
| fps                | 382      |
| nupdates           | 26200    |
| policy_entropy     | 0.272    |
| total_timesteps    | 131000   |
| value_loss         | 141      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 212      |
| explained_variance | -0.511   |
| fps                | 382      |
| nupdates           | 26300    |
| policy_entropy     | 0.0881   |
| total_timesteps    | 131500   |
| value_loss         | 494      |
---------------------------------
9.0
9.0
15.78
9.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.323    |
| fps                | 382      |
| nupdates           | 26400    |
| policy_entropy     | 0.0358   |
| total_timesteps    | 132000   |
| value_loss         | 60.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | -0.0315  |
| fps                | 381      |
| nupdates           | 26500    |
| policy_entropy     | 0.317    |
| total_timesteps    | 132500   |
| value_loss         | 534      |
---------------------------------
21.0
21.0
15.85
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | -0.215   |
| fps                | 381      |
| nupdates           | 26600    |
| policy_entropy     | 0.115    |
| total_timesteps    | 133000   |
| value_loss         | 438      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.186    |
| fps                | 381      |
| nupdates           | 26700    |
| policy_entropy     | 0.0694   |
| total_timesteps    | 133500   |
| value_loss         | 133      |
---------------------------------
10.0
10.0
17.81
10.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 202      |
| explained_variance | -12.8    |
| fps                | 381      |
| nupdates           | 26800    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 134000   |
| value_loss         | 1.36e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 204      |
| explained_variance | -4.95    |
| fps                | 381      |
| nupdates           | 26900    |
| policy_entropy     | 0.172    |
| total_timesteps    | 134500   |
| value_loss         | 2.03e+04 |
---------------------------------
10.0
10.0
17.31
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 204      |
| explained_variance | 0.35     |
| fps                | 381      |
| nupdates           | 27000    |
| policy_entropy     | 0.0306   |
| total_timesteps    | 135000   |
| value_loss         | 994      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 213      |
| explained_variance | -0.372   |
| fps                | 381      |
| nupdates           | 27100    |
| policy_entropy     | 0.0749   |
| total_timesteps    | 135500   |
| value_loss         | 261      |
---------------------------------
10.0
10.0
14.09
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | -0.711   |
| fps                | 381      |
| nupdates           | 27200    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 136000   |
| value_loss         | 66.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | -0.115   |
| fps                | 381      |
| nupdates           | 27300    |
| policy_entropy     | 0.123    |
| total_timesteps    | 136500   |
| value_loss         | 52.1     |
---------------------------------
9.0
9.0
15.17
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.641    |
| fps                | 381      |
| nupdates           | 27400    |
| policy_entropy     | 0.0317   |
| total_timesteps    | 137000   |
| value_loss         | 119      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.724    |
| fps                | 381      |
| nupdates           | 27500    |
| policy_entropy     | 0.134    |
| total_timesteps    | 137500   |
| value_loss         | 87.4     |
---------------------------------
10.0
10.0
13.41
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 215      |
| explained_variance | -1.45    |
| fps                | 381      |
| nupdates           | 27600    |
| policy_entropy     | 0.135    |
| total_timesteps    | 138000   |
| value_loss         | 173      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.605    |
| fps                | 381      |
| nupdates           | 27700    |
| policy_entropy     | 0.0429   |
| total_timesteps    | 138500   |
| value_loss         | 312      |
---------------------------------
44.0
44.0
14.66
15.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 213      |
| explained_variance | -5.99    |
| fps                | 381      |
| nupdates           | 27800    |
| policy_entropy     | 0.353    |
| total_timesteps    | 139000   |
| value_loss         | 448      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.443    |
| fps                | 381      |
| nupdates           | 27900    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 139500   |
| value_loss         | 125      |
---------------------------------
11.0
11.0
14.51
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | -0.861   |
| fps                | 381      |
| nupdates           | 28000    |
| policy_entropy     | 0.144    |
| total_timesteps    | 140000   |
| value_loss         | 306      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.398    |
| fps                | 380      |
| nupdates           | 28100    |
| policy_entropy     | 0.0594   |
| total_timesteps    | 140500   |
| value_loss         | 145      |
---------------------------------
21.0
21.0
14.38
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.817    |
| fps                | 380      |
| nupdates           | 28200    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 141000   |
| value_loss         | 735      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.731    |
| fps                | 380      |
| nupdates           | 28300    |
| policy_entropy     | 0.00755  |
| total_timesteps    | 141500   |
| value_loss         | 52.4     |
---------------------------------
9.0
9.0
14.9
21.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.855    |
| fps                | 380      |
| nupdates           | 28400    |
| policy_entropy     | 0.022    |
| total_timesteps    | 142000   |
| value_loss         | 67.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -13      |
| fps                | 380      |
| nupdates           | 28500    |
| policy_entropy     | 0.25     |
| total_timesteps    | 142500   |
| value_loss         | 1.6e+03  |
---------------------------------
29.0
29.0
17.55
16.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 205      |
| explained_variance | -2.4     |
| fps                | 380      |
| nupdates           | 28600    |
| policy_entropy     | 0.115    |
| total_timesteps    | 143000   |
| value_loss         | 1.62e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0.684    |
| fps                | 379      |
| nupdates           | 28700    |
| policy_entropy     | 0.0202   |
| total_timesteps    | 143500   |
| value_loss         | 63.6     |
---------------------------------
9.0
9.0
15.65
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 213      |
| explained_variance | -0.49    |
| fps                | 380      |
| nupdates           | 28800    |
| policy_entropy     | 0.235    |
| total_timesteps    | 144000   |
| value_loss         | 480      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 213      |
| explained_variance | -2.68    |
| fps                | 380      |
| nupdates           | 28900    |
| policy_entropy     | 0.137    |
| total_timesteps    | 144500   |
| value_loss         | 319      |
---------------------------------
9.0
9.0
14.56
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.374    |
| fps                | 380      |
| nupdates           | 29000    |
| policy_entropy     | 0.216    |
| total_timesteps    | 145000   |
| value_loss         | 446      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.442    |
| fps                | 380      |
| nupdates           | 29100    |
| policy_entropy     | 0.206    |
| total_timesteps    | 145500   |
| value_loss         | 18.9     |
---------------------------------
37.0
37.0
14.51
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.914    |
| fps                | 379      |
| nupdates           | 29200    |
| policy_entropy     | 0.00756  |
| total_timesteps    | 146000   |
| value_loss         | 15.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.956    |
| fps                | 380      |
| nupdates           | 29300    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 146500   |
| value_loss         | 15.5     |
---------------------------------
10.0
10.0
13.56
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.928    |
| fps                | 380      |
| nupdates           | 29400    |
| policy_entropy     | 0.0323   |
| total_timesteps    | 147000   |
| value_loss         | 29       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 217      |
| explained_variance | -0.00126 |
| fps                | 380      |
| nupdates           | 29500    |
| policy_entropy     | 0.136    |
| total_timesteps    | 147500   |
| value_loss         | 393      |
---------------------------------
12.0
12.0
14.15
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.278    |
| fps                | 380      |
| nupdates           | 29600    |
| policy_entropy     | 0.238    |
| total_timesteps    | 148000   |
| value_loss         | 248      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | 0.817    |
| fps                | 380      |
| nupdates           | 29700    |
| policy_entropy     | 0.0154   |
| total_timesteps    | 148500   |
| value_loss         | 45.9     |
---------------------------------
10.0
10.0
15.58
11.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.816    |
| fps                | 380      |
| nupdates           | 29800    |
| policy_entropy     | 0.0387   |
| total_timesteps    | 149000   |
| value_loss         | 38.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | -1.05    |
| fps                | 380      |
| nupdates           | 29900    |
| policy_entropy     | 0.0602   |
| total_timesteps    | 149500   |
| value_loss         | 144      |
---------------------------------
10.0
10.0
16.5
10.5
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.88     |
| fps                | 380      |
| nupdates           | 30000    |
| policy_entropy     | 0.0283   |
| total_timesteps    | 150000   |
| value_loss         | 31.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.279    |
| fps                | 380      |
| nupdates           | 30100    |
| policy_entropy     | 0.215    |
| total_timesteps    | 150500   |
| value_loss         | 263      |
---------------------------------
20.0
20.0
15.29
15.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.00222  |
| fps                | 380      |
| nupdates           | 30200    |
| policy_entropy     | 0.0391   |
| total_timesteps    | 151000   |
| value_loss         | 128      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.556    |
| fps                | 380      |
| nupdates           | 30300    |
| policy_entropy     | 0.0519   |
| total_timesteps    | 151500   |
| value_loss         | 214      |
---------------------------------
10.0
10.0
16.4
17.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.872    |
| fps                | 379      |
| nupdates           | 30400    |
| policy_entropy     | 0.0323   |
| total_timesteps    | 152000   |
| value_loss         | 321      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.235    |
| fps                | 380      |
| nupdates           | 30500    |
| policy_entropy     | 0.167    |
| total_timesteps    | 152500   |
| value_loss         | 267      |
---------------------------------
51.0
51.0
16.78
17.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.32     |
| fps                | 380      |
| nupdates           | 30600    |
| policy_entropy     | 0.0365   |
| total_timesteps    | 153000   |
| value_loss         | 221      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.821    |
| fps                | 380      |
| nupdates           | 30700    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 153500   |
| value_loss         | 411      |
---------------------------------
9.0
9.0
14.79
11.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 213      |
| explained_variance | -0.702   |
| fps                | 380      |
| nupdates           | 30800    |
| policy_entropy     | 0.532    |
| total_timesteps    | 154000   |
| value_loss         | 190      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.0841  |
| fps                | 380      |
| nupdates           | 30900    |
| policy_entropy     | 0.156    |
| total_timesteps    | 154500   |
| value_loss         | 306      |
---------------------------------
9.0
9.0
15.27
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.882    |
| fps                | 380      |
| nupdates           | 31000    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 155000   |
| value_loss         | 13.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.35     |
| fps                | 379      |
| nupdates           | 31100    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 155500   |
| value_loss         | 333      |
---------------------------------
9.0
9.0
13.83
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.266    |
| fps                | 378      |
| nupdates           | 31200    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 156000   |
| value_loss         | 62.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | -0.341   |
| fps                | 378      |
| nupdates           | 31300    |
| policy_entropy     | 0.428    |
| total_timesteps    | 156500   |
| value_loss         | 906      |
---------------------------------
9.0
9.0
16.32
10.5
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.636    |
| fps                | 378      |
| nupdates           | 31400    |
| policy_entropy     | 0.0983   |
| total_timesteps    | 157000   |
| value_loss         | 122      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.846    |
| fps                | 378      |
| nupdates           | 31500    |
| policy_entropy     | 0.0745   |
| total_timesteps    | 157500   |
| value_loss         | 28.2     |
---------------------------------
9.0
9.0
17.08
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 206      |
| explained_variance | -0.0327  |
| fps                | 378      |
| nupdates           | 31600    |
| policy_entropy     | 0.127    |
| total_timesteps    | 158000   |
| value_loss         | 913      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | -0.704   |
| fps                | 378      |
| nupdates           | 31700    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 158500   |
| value_loss         | 1.89e+03 |
---------------------------------
9.0
9.0
15.67
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.0778   |
| fps                | 378      |
| nupdates           | 31800    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 159000   |
| value_loss         | 521      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.217    |
| fps                | 378      |
| nupdates           | 31900    |
| policy_entropy     | 0.0123   |
| total_timesteps    | 159500   |
| value_loss         | 339      |
---------------------------------
22.0
22.0
15.07
15.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.401   |
| fps                | 378      |
| nupdates           | 32000    |
| policy_entropy     | 0.0657   |
| total_timesteps    | 160000   |
| value_loss         | 293      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.988    |
| fps                | 378      |
| nupdates           | 32100    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 160500   |
| value_loss         | 6.3      |
---------------------------------
28.0
28.0
15.59
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | -4.22    |
| fps                | 378      |
| nupdates           | 32200    |
| policy_entropy     | 0.152    |
| total_timesteps    | 161000   |
| value_loss         | 320      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0.929    |
| fps                | 377      |
| nupdates           | 32300    |
| policy_entropy     | 0.0339   |
| total_timesteps    | 161500   |
| value_loss         | 9.22     |
---------------------------------
26.0
26.0
14.72
11.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | -2.06    |
| fps                | 377      |
| nupdates           | 32400    |
| policy_entropy     | 0.259    |
| total_timesteps    | 162000   |
| value_loss         | 350      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 215      |
| explained_variance | -10.3    |
| fps                | 377      |
| nupdates           | 32500    |
| policy_entropy     | 0.195    |
| total_timesteps    | 162500   |
| value_loss         | 1.86e+03 |
---------------------------------
11.0
11.0
15.0
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.634    |
| fps                | 377      |
| nupdates           | 32600    |
| policy_entropy     | 0.0523   |
| total_timesteps    | 163000   |
| value_loss         | 27.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.412    |
| fps                | 377      |
| nupdates           | 32700    |
| policy_entropy     | 0.172    |
| total_timesteps    | 163500   |
| value_loss         | 63.8     |
---------------------------------
9.0
9.0
14.74
14.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.865    |
| fps                | 377      |
| nupdates           | 32800    |
| policy_entropy     | 0.056    |
| total_timesteps    | 164000   |
| value_loss         | 16.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | -1.13    |
| fps                | 377      |
| nupdates           | 32900    |
| policy_entropy     | 0.528    |
| total_timesteps    | 164500   |
| value_loss         | 40.8     |
---------------------------------
10.0
10.0
19.19
10.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 194      |
| explained_variance | -0.0764  |
| fps                | 377      |
| nupdates           | 33000    |
| policy_entropy     | 0.104    |
| total_timesteps    | 165000   |
| value_loss         | 7.01e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 21.1     |
| ep_reward_mean     | 187      |
| explained_variance | 0.0275   |
| fps                | 377      |
| nupdates           | 33100    |
| policy_entropy     | 0.19     |
| total_timesteps    | 165500   |
| value_loss         | 7.18e+04 |
---------------------------------
52.0
52.0
23.39
9.5
---------------------------------
| ep_len_mean        | 23.4     |
| ep_reward_mean     | 181      |
| explained_variance | -29.4    |
| fps                | 377      |
| nupdates           | 33200    |
| policy_entropy     | 0.228    |
| total_timesteps    | 166000   |
| value_loss         | 139      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -1.31    |
| fps                | 377      |
| nupdates           | 33300    |
| policy_entropy     | 0.455    |
| total_timesteps    | 166500   |
| value_loss         | 8.85e+04 |
---------------------------------
10.0
10.0
20.21
11.5
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 194      |
| explained_variance | -0.152   |
| fps                | 377      |
| nupdates           | 33400    |
| policy_entropy     | 0.114    |
| total_timesteps    | 167000   |
| value_loss         | 6.45e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 21.5     |
| ep_reward_mean     | 190      |
| explained_variance | -1.17    |
| fps                | 377      |
| nupdates           | 33500    |
| policy_entropy     | 0.585    |
| total_timesteps    | 167500   |
| value_loss         | 17.5     |
---------------------------------
23.0
23.0
19.57
12.5
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 194      |
| explained_variance | -0.398   |
| fps                | 377      |
| nupdates           | 33600    |
| policy_entropy     | 0.227    |
| total_timesteps    | 168000   |
| value_loss         | 4.6e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 193      |
| explained_variance | -18.9    |
| fps                | 377      |
| nupdates           | 33700    |
| policy_entropy     | 0.0786   |
| total_timesteps    | 168500   |
| value_loss         | 566      |
---------------------------------
33.0
33.0
18.17
9.5
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 200      |
| explained_variance | 0.688    |
| fps                | 377      |
| nupdates           | 33800    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 169000   |
| value_loss         | 326      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 202      |
| explained_variance | -0.0458  |
| fps                | 377      |
| nupdates           | 33900    |
| policy_entropy     | 0.241    |
| total_timesteps    | 169500   |
| value_loss         | 1.14e+04 |
---------------------------------
8.0
8.0
17.85
16.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 203      |
| explained_variance | -1.69    |
| fps                | 377      |
| nupdates           | 34000    |
| policy_entropy     | 0.0516   |
| total_timesteps    | 170000   |
| value_loss         | 4.22e+03 |
---------------------------------
----------------------------------
| ep_len_mean        | 17.9      |
| ep_reward_mean     | 203       |
| explained_variance | -2.38e-07 |
| fps                | 377       |
| nupdates           | 34100     |
| policy_entropy     | 0.446     |
| total_timesteps    | 170500    |
| value_loss         | 50.6      |
----------------------------------
10.0
10.0
19.14
10.0
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 200      |
| explained_variance | -0.00883 |
| fps                | 377      |
| nupdates           | 34200    |
| policy_entropy     | 0.356    |
| total_timesteps    | 171000   |
| value_loss         | 2.41e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 200      |
| explained_variance | 0.461    |
| fps                | 377      |
| nupdates           | 34300    |
| policy_entropy     | 0.013    |
| total_timesteps    | 171500   |
| value_loss         | 63.1     |
---------------------------------
9.0
9.0
19.3
10.0
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 200      |
| explained_variance | 0.49     |
| fps                | 377      |
| nupdates           | 34400    |
| policy_entropy     | 0.0161   |
| total_timesteps    | 172000   |
| value_loss         | 142      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 207      |
| explained_variance | 0.571    |
| fps                | 377      |
| nupdates           | 34500    |
| policy_entropy     | 0.297    |
| total_timesteps    | 172500   |
| value_loss         | 10.8     |
---------------------------------
10.0
10.0
16.97
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | 0.0938   |
| fps                | 377      |
| nupdates           | 34600    |
| policy_entropy     | 0.016    |
| total_timesteps    | 173000   |
| value_loss         | 1.55e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 208      |
| explained_variance | 0.869    |
| fps                | 377      |
| nupdates           | 34700    |
| policy_entropy     | 0.016    |
| total_timesteps    | 173500   |
| value_loss         | 415      |
---------------------------------
11.0
11.0
17.09
20.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 208      |
| explained_variance | 0.55     |
| fps                | 377      |
| nupdates           | 34800    |
| policy_entropy     | 0.444    |
| total_timesteps    | 174000   |
| value_loss         | 96.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.353    |
| fps                | 377      |
| nupdates           | 34900    |
| policy_entropy     | 0.015    |
| total_timesteps    | 174500   |
| value_loss         | 282      |
---------------------------------
10.0
10.0
16.08
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 1.19e-07 |
| fps                | 377      |
| nupdates           | 35000    |
| policy_entropy     | 0.443    |
| total_timesteps    | 175000   |
| value_loss         | 219      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 208      |
| explained_variance | -0.751   |
| fps                | 377      |
| nupdates           | 35100    |
| policy_entropy     | 0.69     |
| total_timesteps    | 175500   |
| value_loss         | 254      |
---------------------------------
10.0
10.0
17.34
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0.222    |
| fps                | 377      |
| nupdates           | 35200    |
| policy_entropy     | 0.0213   |
| total_timesteps    | 176000   |
| value_loss         | 674      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 205      |
| explained_variance | -4       |
| fps                | 377      |
| nupdates           | 35300    |
| policy_entropy     | 0.0375   |
| total_timesteps    | 176500   |
| value_loss         | 812      |
---------------------------------
10.0
10.0
16.99
10.5
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | 0.494    |
| fps                | 377      |
| nupdates           | 35400    |
| policy_entropy     | 0.492    |
| total_timesteps    | 177000   |
| value_loss         | 540      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.574    |
| fps                | 377      |
| nupdates           | 35500    |
| policy_entropy     | 0.0267   |
| total_timesteps    | 177500   |
| value_loss         | 46.2     |
---------------------------------
29.0
29.0
17.47
13.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 207      |
| explained_variance | -7.88    |
| fps                | 377      |
| nupdates           | 35600    |
| policy_entropy     | 0.353    |
| total_timesteps    | 178000   |
| value_loss         | 450      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 204      |
| explained_variance | -1.25    |
| fps                | 377      |
| nupdates           | 35700    |
| policy_entropy     | 0.446    |
| total_timesteps    | 178500   |
| value_loss         | 360      |
---------------------------------
22.0
22.0
17.91
16.5
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | -0.86    |
| fps                | 377      |
| nupdates           | 35800    |
| policy_entropy     | 0.0425   |
| total_timesteps    | 179000   |
| value_loss         | 176      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 205      |
| explained_variance | 0.925    |
| fps                | 377      |
| nupdates           | 35900    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 179500   |
| value_loss         | 7.21     |
---------------------------------
10.0
10.0
16.36
19.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.363    |
| fps                | 377      |
| nupdates           | 36000    |
| policy_entropy     | 0.21     |
| total_timesteps    | 180000   |
| value_loss         | 128      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 208      |
| explained_variance | -2.87    |
| fps                | 377      |
| nupdates           | 36100    |
| policy_entropy     | 0.525    |
| total_timesteps    | 180500   |
| value_loss         | 356      |
---------------------------------
26.0
26.0
17.82
18.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.562   |
| fps                | 377      |
| nupdates           | 36200    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 181000   |
| value_loss         | 138      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.335    |
| fps                | 377      |
| nupdates           | 36300    |
| policy_entropy     | 0.0314   |
| total_timesteps    | 181500   |
| value_loss         | 50.6     |
---------------------------------
24.0
24.0
17.46
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | -8.26    |
| fps                | 377      |
| nupdates           | 36400    |
| policy_entropy     | 0.0734   |
| total_timesteps    | 182000   |
| value_loss         | 468      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 203      |
| explained_variance | -0.595   |
| fps                | 377      |
| nupdates           | 36500    |
| policy_entropy     | 0.526    |
| total_timesteps    | 182500   |
| value_loss         | 293      |
---------------------------------
10.0
10.0
17.25
10.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.478    |
| fps                | 377      |
| nupdates           | 36600    |
| policy_entropy     | 0.356    |
| total_timesteps    | 183000   |
| value_loss         | 48.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.539   |
| fps                | 377      |
| nupdates           | 36700    |
| policy_entropy     | 0.0436   |
| total_timesteps    | 183500   |
| value_loss         | 29.5     |
---------------------------------
9.0
9.0
14.93
9.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.771    |
| fps                | 377      |
| nupdates           | 36800    |
| policy_entropy     | 0.139    |
| total_timesteps    | 184000   |
| value_loss         | 112      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | 0.643    |
| fps                | 377      |
| nupdates           | 36900    |
| policy_entropy     | 0.126    |
| total_timesteps    | 184500   |
| value_loss         | 73.1     |
---------------------------------
11.0
11.0
14.54
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0206  |
| fps                | 377      |
| nupdates           | 37000    |
| policy_entropy     | 0.353    |
| total_timesteps    | 185000   |
| value_loss         | 316      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | -0.487   |
| fps                | 377      |
| nupdates           | 37100    |
| policy_entropy     | 0.207    |
| total_timesteps    | 185500   |
| value_loss         | 149      |
---------------------------------
18.0
18.0
14.23
15.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.283    |
| fps                | 377      |
| nupdates           | 37200    |
| policy_entropy     | 0.342    |
| total_timesteps    | 186000   |
| value_loss         | 374      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | -0.268   |
| fps                | 377      |
| nupdates           | 37300    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 186500   |
| value_loss         | 288      |
---------------------------------
29.0
29.0
17.18
10.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.444    |
| fps                | 377      |
| nupdates           | 37400    |
| policy_entropy     | 0.00722  |
| total_timesteps    | 187000   |
| value_loss         | 44.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 205      |
| explained_variance | -5.38    |
| fps                | 377      |
| nupdates           | 37500    |
| policy_entropy     | 0.0482   |
| total_timesteps    | 187500   |
| value_loss         | 2.05e+03 |
---------------------------------
10.0
10.0
16.13
12.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.472    |
| fps                | 377      |
| nupdates           | 37600    |
| policy_entropy     | 0.167    |
| total_timesteps    | 188000   |
| value_loss         | 27.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 212      |
| explained_variance | -1.47    |
| fps                | 377      |
| nupdates           | 37700    |
| policy_entropy     | 0.316    |
| total_timesteps    | 188500   |
| value_loss         | 544      |
---------------------------------
11.0
11.0
17.22
11.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.877    |
| fps                | 377      |
| nupdates           | 37800    |
| policy_entropy     | 0.0296   |
| total_timesteps    | 189000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.509    |
| fps                | 377      |
| nupdates           | 37900    |
| policy_entropy     | 0.00733  |
| total_timesteps    | 189500   |
| value_loss         | 39       |
---------------------------------
10.0
10.0
16.17
11.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.656    |
| fps                | 377      |
| nupdates           | 38000    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 190000   |
| value_loss         | 54.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.909    |
| fps                | 377      |
| nupdates           | 38100    |
| policy_entropy     | 0.017    |
| total_timesteps    | 190500   |
| value_loss         | 8.1      |
---------------------------------
11.0
11.0
13.6
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | -0.264   |
| fps                | 377      |
| nupdates           | 38200    |
| policy_entropy     | 0.232    |
| total_timesteps    | 191000   |
| value_loss         | 316      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | -10.8    |
| fps                | 377      |
| nupdates           | 38300    |
| policy_entropy     | 0.262    |
| total_timesteps    | 191500   |
| value_loss         | 879      |
---------------------------------
22.0
22.0
15.04
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.744    |
| fps                | 377      |
| nupdates           | 38400    |
| policy_entropy     | 0.0395   |
| total_timesteps    | 192000   |
| value_loss         | 62.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.548    |
| fps                | 377      |
| nupdates           | 38500    |
| policy_entropy     | 0.018    |
| total_timesteps    | 192500   |
| value_loss         | 27.9     |
---------------------------------
10.0
10.0
13.85
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.946    |
| fps                | 377      |
| nupdates           | 38600    |
| policy_entropy     | 0.00699  |
| total_timesteps    | 193000   |
| value_loss         | 18.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.553   |
| fps                | 377      |
| nupdates           | 38700    |
| policy_entropy     | 0.168    |
| total_timesteps    | 193500   |
| value_loss         | 102      |
---------------------------------
20.0
20.0
16.62
20.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.275    |
| fps                | 377      |
| nupdates           | 38800    |
| policy_entropy     | 0.309    |
| total_timesteps    | 194000   |
| value_loss         | 130      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 377      |
| nupdates           | 38900    |
| policy_entropy     | 0.849    |
| total_timesteps    | 194500   |
| value_loss         | 128      |
---------------------------------
10.0
10.0
18.02
10.5
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 210      |
| explained_variance | 0.942    |
| fps                | 377      |
| nupdates           | 39000    |
| policy_entropy     | 0.223    |
| total_timesteps    | 195000   |
| value_loss         | 13       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.749    |
| fps                | 377      |
| nupdates           | 39100    |
| policy_entropy     | 0.0698   |
| total_timesteps    | 195500   |
| value_loss         | 84.9     |
---------------------------------
10.0
10.0
15.45
11.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.821    |
| fps                | 377      |
| nupdates           | 39200    |
| policy_entropy     | 0.152    |
| total_timesteps    | 196000   |
| value_loss         | 18.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | -0.193   |
| fps                | 377      |
| nupdates           | 39300    |
| policy_entropy     | 0.0645   |
| total_timesteps    | 196500   |
| value_loss         | 959      |
---------------------------------
13.0
13.0
14.28
11.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.918    |
| fps                | 377      |
| nupdates           | 39400    |
| policy_entropy     | 0.0265   |
| total_timesteps    | 197000   |
| value_loss         | 4.97     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.801    |
| fps                | 377      |
| nupdates           | 39500    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 197500   |
| value_loss         | 65.3     |
---------------------------------
10.0
10.0
14.51
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.766    |
| fps                | 377      |
| nupdates           | 39600    |
| policy_entropy     | 0.0607   |
| total_timesteps    | 198000   |
| value_loss         | 27.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | -0.708   |
| fps                | 377      |
| nupdates           | 39700    |
| policy_entropy     | 0.0221   |
| total_timesteps    | 198500   |
| value_loss         | 384      |
---------------------------------
9.0
9.0
15.0
20.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | 0.306    |
| fps                | 376      |
| nupdates           | 39800    |
| policy_entropy     | 0.221    |
| total_timesteps    | 199000   |
| value_loss         | 73.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 212      |
| explained_variance | -1.06    |
| fps                | 376      |
| nupdates           | 39900    |
| policy_entropy     | 0.272    |
| total_timesteps    | 199500   |
| value_loss         | 224      |
---------------------------------
12.0
12.0
14.68
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.101    |
| fps                | 376      |
| nupdates           | 40000    |
| policy_entropy     | 0.0687   |
| total_timesteps    | 200000   |
| value_loss         | 219      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.869    |
| fps                | 376      |
| nupdates           | 40100    |
| policy_entropy     | 0.02     |
| total_timesteps    | 200500   |
| value_loss         | 11.4     |
---------------------------------
48.0
48.0
13.38
11.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.0841   |
| fps                | 376      |
| nupdates           | 40200    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 201000   |
| value_loss         | 255      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.946    |
| fps                | 376      |
| nupdates           | 40300    |
| policy_entropy     | 0.0312   |
| total_timesteps    | 201500   |
| value_loss         | 7.62     |
---------------------------------
19.0
19.0
14.11
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.549    |
| fps                | 376      |
| nupdates           | 40400    |
| policy_entropy     | 0.0042   |
| total_timesteps    | 202000   |
| value_loss         | 404      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 215      |
| explained_variance | -6.7     |
| fps                | 376      |
| nupdates           | 40500    |
| policy_entropy     | 0.146    |
| total_timesteps    | 202500   |
| value_loss         | 700      |
---------------------------------
10.0
10.0
15.12
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.307    |
| fps                | 376      |
| nupdates           | 40600    |
| policy_entropy     | 0.167    |
| total_timesteps    | 203000   |
| value_loss         | 63.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.885    |
| fps                | 376      |
| nupdates           | 40700    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 203500   |
| value_loss         | 78.7     |
---------------------------------
22.0
22.0
14.31
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.0585   |
| fps                | 376      |
| nupdates           | 40800    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 204000   |
| value_loss         | 43.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.938    |
| fps                | 376      |
| nupdates           | 40900    |
| policy_entropy     | 0.154    |
| total_timesteps    | 204500   |
| value_loss         | 15.8     |
---------------------------------
9.0
9.0
15.08
15.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.419    |
| fps                | 375      |
| nupdates           | 41000    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 205000   |
| value_loss         | 401      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | -1.97    |
| fps                | 375      |
| nupdates           | 41100    |
| policy_entropy     | 0.213    |
| total_timesteps    | 205500   |
| value_loss         | 493      |
---------------------------------
11.0
11.0
14.77
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.49     |
| fps                | 375      |
| nupdates           | 41200    |
| policy_entropy     | 0.173    |
| total_timesteps    | 206000   |
| value_loss         | 529      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.326    |
| fps                | 375      |
| nupdates           | 41300    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 206500   |
| value_loss         | 438      |
---------------------------------
11.0
11.0
14.84
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 215      |
| explained_variance | -0.0362  |
| fps                | 375      |
| nupdates           | 41400    |
| policy_entropy     | 0.114    |
| total_timesteps    | 207000   |
| value_loss         | 903      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.488    |
| fps                | 375      |
| nupdates           | 41500    |
| policy_entropy     | 0.0991   |
| total_timesteps    | 207500   |
| value_loss         | 30.8     |
---------------------------------
20.0
20.0
13.94
10.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.572    |
| fps                | 375      |
| nupdates           | 41600    |
| policy_entropy     | 0.0205   |
| total_timesteps    | 208000   |
| value_loss         | 87.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | -0.122   |
| fps                | 375      |
| nupdates           | 41700    |
| policy_entropy     | 0.276    |
| total_timesteps    | 208500   |
| value_loss         | 120      |
---------------------------------
21.0
21.0
15.25
15.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.386    |
| fps                | 375      |
| nupdates           | 41800    |
| policy_entropy     | 0.193    |
| total_timesteps    | 209000   |
| value_loss         | 16.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 215      |
| explained_variance | -1.73    |
| fps                | 375      |
| nupdates           | 41900    |
| policy_entropy     | 0.14     |
| total_timesteps    | 209500   |
| value_loss         | 687      |
---------------------------------
38.0
38.0
15.85
19.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.914    |
| fps                | 375      |
| nupdates           | 42000    |
| policy_entropy     | 0.199    |
| total_timesteps    | 210000   |
| value_loss         | 2.39     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.666    |
| fps                | 375      |
| nupdates           | 42100    |
| policy_entropy     | 0.355    |
| total_timesteps    | 210500   |
| value_loss         | 26.6     |
---------------------------------
21.0
21.0
15.61
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.662    |
| fps                | 375      |
| nupdates           | 42200    |
| policy_entropy     | 0.0228   |
| total_timesteps    | 211000   |
| value_loss         | 28.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.878    |
| fps                | 375      |
| nupdates           | 42300    |
| policy_entropy     | 0.0118   |
| total_timesteps    | 211500   |
| value_loss         | 21.8     |
---------------------------------
25.0
25.0
14.56
11.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.883    |
| fps                | 375      |
| nupdates           | 42400    |
| policy_entropy     | 0.0304   |
| total_timesteps    | 212000   |
| value_loss         | 3.53     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.934    |
| fps                | 375      |
| nupdates           | 42500    |
| policy_entropy     | 0.00737  |
| total_timesteps    | 212500   |
| value_loss         | 29.7     |
---------------------------------
20.0
20.0
14.56
15.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | -2.03    |
| fps                | 375      |
| nupdates           | 42600    |
| policy_entropy     | 0.112    |
| total_timesteps    | 213000   |
| value_loss         | 147      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.733    |
| fps                | 375      |
| nupdates           | 42700    |
| policy_entropy     | 0.0249   |
| total_timesteps    | 213500   |
| value_loss         | 47.8     |
---------------------------------
9.0
9.0
15.69
12.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.642    |
| fps                | 375      |
| nupdates           | 42800    |
| policy_entropy     | 0.00951  |
| total_timesteps    | 214000   |
| value_loss         | 101      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.682    |
| fps                | 376      |
| nupdates           | 42900    |
| policy_entropy     | 0.0228   |
| total_timesteps    | 214500   |
| value_loss         | 53       |
---------------------------------
11.0
11.0
14.06
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.672    |
| fps                | 376      |
| nupdates           | 43000    |
| policy_entropy     | 0.00718  |
| total_timesteps    | 215000   |
| value_loss         | 46.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.974    |
| fps                | 376      |
| nupdates           | 43100    |
| policy_entropy     | 0.2      |
| total_timesteps    | 215500   |
| value_loss         | 3.88     |
---------------------------------
20.0
20.0
14.47
20.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.886    |
| fps                | 376      |
| nupdates           | 43200    |
| policy_entropy     | 0.0445   |
| total_timesteps    | 216000   |
| value_loss         | 88.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.725    |
| fps                | 375      |
| nupdates           | 43300    |
| policy_entropy     | 0.00684  |
| total_timesteps    | 216500   |
| value_loss         | 23.5     |
---------------------------------
10.0
10.0
14.98
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.995    |
| fps                | 375      |
| nupdates           | 43400    |
| policy_entropy     | 0.0235   |
| total_timesteps    | 217000   |
| value_loss         | 0.135    |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.731    |
| fps                | 376      |
| nupdates           | 43500    |
| policy_entropy     | 0.168    |
| total_timesteps    | 217500   |
| value_loss         | 9.22     |
---------------------------------
25.0
25.0
14.4
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | -1.52    |
| fps                | 376      |
| nupdates           | 43600    |
| policy_entropy     | 0.182    |
| total_timesteps    | 218000   |
| value_loss         | 801      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.17     |
| fps                | 376      |
| nupdates           | 43700    |
| policy_entropy     | 0.00623  |
| total_timesteps    | 218500   |
| value_loss         | 244      |
---------------------------------
21.0
21.0
14.6
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.967    |
| fps                | 376      |
| nupdates           | 43800    |
| policy_entropy     | 0.0248   |
| total_timesteps    | 219000   |
| value_loss         | 4.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.991    |
| fps                | 376      |
| nupdates           | 43900    |
| policy_entropy     | 0.00824  |
| total_timesteps    | 219500   |
| value_loss         | 6.93     |
---------------------------------
9.0
9.0
14.46
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | -4.29    |
| fps                | 376      |
| nupdates           | 44000    |
| policy_entropy     | 0.176    |
| total_timesteps    | 220000   |
| value_loss         | 1.14e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.95     |
| fps                | 376      |
| nupdates           | 44100    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 220500   |
| value_loss         | 5.72     |
---------------------------------
23.0
23.0
15.16
16.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.181   |
| fps                | 376      |
| nupdates           | 44200    |
| policy_entropy     | 0.0834   |
| total_timesteps    | 221000   |
| value_loss         | 489      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.475    |
| fps                | 376      |
| nupdates           | 44300    |
| policy_entropy     | 0.0945   |
| total_timesteps    | 221500   |
| value_loss         | 47.8     |
---------------------------------
20.0
20.0
13.43
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.603    |
| fps                | 376      |
| nupdates           | 44400    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 222000   |
| value_loss         | 57.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.324    |
| fps                | 376      |
| nupdates           | 44500    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 222500   |
| value_loss         | 473      |
---------------------------------
11.0
11.0
14.47
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0338  |
| fps                | 376      |
| nupdates           | 44600    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 223000   |
| value_loss         | 18.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.609    |
| fps                | 376      |
| nupdates           | 44700    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 223500   |
| value_loss         | 91.2     |
---------------------------------
11.0
11.0
14.45
18.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.0974   |
| fps                | 376      |
| nupdates           | 44800    |
| policy_entropy     | 0.0183   |
| total_timesteps    | 224000   |
| value_loss         | 262      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | -0.507   |
| fps                | 376      |
| nupdates           | 44900    |
| policy_entropy     | 0.00124  |
| total_timesteps    | 224500   |
| value_loss         | 270      |
---------------------------------
11.0
11.0
14.69
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.348    |
| fps                | 376      |
| nupdates           | 45000    |
| policy_entropy     | 0.0121   |
| total_timesteps    | 225000   |
| value_loss         | 591      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.653    |
| fps                | 376      |
| nupdates           | 45100    |
| policy_entropy     | 0.00424  |
| total_timesteps    | 225500   |
| value_loss         | 29.8     |
---------------------------------
11.0
11.0
14.91
20.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.892    |
| fps                | 376      |
| nupdates           | 45200    |
| policy_entropy     | 0.00897  |
| total_timesteps    | 226000   |
| value_loss         | 18.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.521    |
| fps                | 376      |
| nupdates           | 45300    |
| policy_entropy     | 0.0118   |
| total_timesteps    | 226500   |
| value_loss         | 309      |
---------------------------------
22.0
22.0
14.39
18.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.861    |
| fps                | 376      |
| nupdates           | 45400    |
| policy_entropy     | 0.019    |
| total_timesteps    | 227000   |
| value_loss         | 18.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.97     |
| fps                | 376      |
| nupdates           | 45500    |
| policy_entropy     | 0.00662  |
| total_timesteps    | 227500   |
| value_loss         | 3.45     |
---------------------------------
9.0
9.0
14.39
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.796    |
| fps                | 376      |
| nupdates           | 45600    |
| policy_entropy     | 0.0154   |
| total_timesteps    | 228000   |
| value_loss         | 30.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.954    |
| fps                | 376      |
| nupdates           | 45700    |
| policy_entropy     | 0.134    |
| total_timesteps    | 228500   |
| value_loss         | 4.58     |
---------------------------------
11.0
11.0
16.12
10.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | -0.478   |
| fps                | 376      |
| nupdates           | 45800    |
| policy_entropy     | 0.0585   |
| total_timesteps    | 229000   |
| value_loss         | 3.7e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.188    |
| fps                | 376      |
| nupdates           | 45900    |
| policy_entropy     | 0.0804   |
| total_timesteps    | 229500   |
| value_loss         | 1.14e+03 |
---------------------------------
9.0
9.0
15.82
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.922    |
| fps                | 376      |
| nupdates           | 46000    |
| policy_entropy     | 0.009    |
| total_timesteps    | 230000   |
| value_loss         | 15.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | 0.643    |
| fps                | 376      |
| nupdates           | 46100    |
| policy_entropy     | 0.00607  |
| total_timesteps    | 230500   |
| value_loss         | 13.7     |
---------------------------------
10.0
10.0
14.48
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.966    |
| fps                | 376      |
| nupdates           | 46200    |
| policy_entropy     | 0.0385   |
| total_timesteps    | 231000   |
| value_loss         | 80.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | -1.52    |
| fps                | 376      |
| nupdates           | 46300    |
| policy_entropy     | 0.181    |
| total_timesteps    | 231500   |
| value_loss         | 72.3     |
---------------------------------
10.0
10.0
14.7
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.862    |
| fps                | 376      |
| nupdates           | 46400    |
| policy_entropy     | 0.00735  |
| total_timesteps    | 232000   |
| value_loss         | 544      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.697    |
| fps                | 376      |
| nupdates           | 46500    |
| policy_entropy     | 0.00979  |
| total_timesteps    | 232500   |
| value_loss         | 587      |
---------------------------------
20.0
20.0
14.66
20.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.835    |
| fps                | 376      |
| nupdates           | 46600    |
| policy_entropy     | 0.12     |
| total_timesteps    | 233000   |
| value_loss         | 11.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.758    |
| fps                | 376      |
| nupdates           | 46700    |
| policy_entropy     | 0.00347  |
| total_timesteps    | 233500   |
| value_loss         | 24.8     |
---------------------------------
10.0
10.0
14.6
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | -2.55    |
| fps                | 376      |
| nupdates           | 46800    |
| policy_entropy     | 0.0662   |
| total_timesteps    | 234000   |
| value_loss         | 254      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.896    |
| fps                | 376      |
| nupdates           | 46900    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 234500   |
| value_loss         | 16.5     |
---------------------------------
10.0
10.0
12.95
10.0
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.976    |
| fps                | 376      |
| nupdates           | 47000    |
| policy_entropy     | 0.00828  |
| total_timesteps    | 235000   |
| value_loss         | 2.59     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 215      |
| explained_variance | 0.917    |
| fps                | 376      |
| nupdates           | 47100    |
| policy_entropy     | 0.0294   |
| total_timesteps    | 235500   |
| value_loss         | 30.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.874    |
| fps                | 376      |
| nupdates           | 47300    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 236500   |
| value_loss         | 755      |
---------------------------------
11.0
11.0
14.37
11.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.775    |
| fps                | 376      |
| nupdates           | 47400    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 237000   |
| value_loss         | 911      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.961    |
| fps                | 376      |
| nupdates           | 47500    |
| policy_entropy     | 0.101    |
| total_timesteps    | 237500   |
| value_loss         | 5.43     |
---------------------------------
19.0
19.0
15.13
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.88     |
| fps                | 376      |
| nupdates           | 47600    |
| policy_entropy     | 0.0161   |
| total_timesteps    | 238000   |
| value_loss         | 11.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.966    |
| fps                | 377      |
| nupdates           | 47700    |
| policy_entropy     | 0.02     |
| total_timesteps    | 238500   |
| value_loss         | 3.31     |
---------------------------------
19.0
19.0
15.45
16.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 219      |
| explained_variance | -0.037   |
| fps                | 377      |
| nupdates           | 47800    |
| policy_entropy     | 0.371    |
| total_timesteps    | 239000   |
| value_loss         | 307      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.323    |
| fps                | 377      |
| nupdates           | 47900    |
| policy_entropy     | 0.0814   |
| total_timesteps    | 239500   |
| value_loss         | 36.4     |
---------------------------------
10.0
10.0
15.89
11.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 218      |
| explained_variance | -0.478   |
| fps                | 377      |
| nupdates           | 48000    |
| policy_entropy     | 0.155    |
| total_timesteps    | 240000   |
| value_loss         | 74.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 216      |
| explained_variance | -1.38    |
| fps                | 377      |
| nupdates           | 48100    |
| policy_entropy     | 0.0619   |
| total_timesteps    | 240500   |
| value_loss         | 279      |
---------------------------------
21.0
21.0
16.04
11.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 217      |
| explained_variance | 0.638    |
| fps                | 377      |
| nupdates           | 48200    |
| policy_entropy     | 0.00755  |
| total_timesteps    | 241000   |
| value_loss         | 38.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.927    |
| fps                | 377      |
| nupdates           | 48300    |
| policy_entropy     | 0.00757  |
| total_timesteps    | 241500   |
| value_loss         | 3.46     |
---------------------------------
10.0
10.0
15.01
11.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0.873    |
| fps                | 377      |
| nupdates           | 48400    |
| policy_entropy     | 0.00929  |
| total_timesteps    | 242000   |
| value_loss         | 551      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.302    |
| fps                | 377      |
| nupdates           | 48500    |
| policy_entropy     | 0.00748  |
| total_timesteps    | 242500   |
| value_loss         | 26.4     |
---------------------------------
9.0
9.0
15.47
15.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.809    |
| fps                | 377      |
| nupdates           | 48600    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 243000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 220      |
| explained_variance | -0.489   |
| fps                | 377      |
| nupdates           | 48700    |
| policy_entropy     | 0.0205   |
| total_timesteps    | 243500   |
| value_loss         | 36.4     |
---------------------------------
11.0
11.0
15.21
11.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.918    |
| fps                | 377      |
| nupdates           | 48800    |
| policy_entropy     | 0.0745   |
| total_timesteps    | 244000   |
| value_loss         | 6.32     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0.808    |
| fps                | 377      |
| nupdates           | 48900    |
| policy_entropy     | 0.00823  |
| total_timesteps    | 244500   |
| value_loss         | 15.1     |
---------------------------------
10.0
10.0
14.72
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | -0.894   |
| fps                | 377      |
| nupdates           | 49000    |
| policy_entropy     | 0.0817   |
| total_timesteps    | 245000   |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.958    |
| fps                | 377      |
| nupdates           | 49100    |
| policy_entropy     | 0.124    |
| total_timesteps    | 245500   |
| value_loss         | 17.6     |
---------------------------------
10.0
10.0
14.94
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.807    |
| fps                | 377      |
| nupdates           | 49200    |
| policy_entropy     | 0.0171   |
| total_timesteps    | 246000   |
| value_loss         | 874      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 221      |
| explained_variance | -0.125   |
| fps                | 377      |
| nupdates           | 49300    |
| policy_entropy     | 0.0674   |
| total_timesteps    | 246500   |
| value_loss         | 296      |
---------------------------------
10.0
10.0
14.62
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 222      |
| explained_variance | 0.457    |
| fps                | 377      |
| nupdates           | 49400    |
| policy_entropy     | 0.107    |
| total_timesteps    | 247000   |
| value_loss         | 154      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 210      |
| explained_variance | -63.7    |
| fps                | 377      |
| nupdates           | 49500    |
| policy_entropy     | 0.0668   |
| total_timesteps    | 247500   |
| value_loss         | 1.06e+04 |
---------------------------------
20.0
20.0
16.88
20.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.65     |
| fps                | 377      |
| nupdates           | 49600    |
| policy_entropy     | 0.00404  |
| total_timesteps    | 248000   |
| value_loss         | 98.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.781    |
| fps                | 377      |
| nupdates           | 49700    |
| policy_entropy     | 0.0118   |
| total_timesteps    | 248500   |
| value_loss         | 15.5     |
---------------------------------
10.0
10.0
14.1
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.302    |
| fps                | 376      |
| nupdates           | 49800    |
| policy_entropy     | 0.00848  |
| total_timesteps    | 249000   |
| value_loss         | 380      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 222      |
| explained_variance | -0.389   |
| fps                | 377      |
| nupdates           | 49900    |
| policy_entropy     | 0.385    |
| total_timesteps    | 249500   |
| value_loss         | 226      |
---------------------------------
9.0
9.0
14.82
16.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.921    |
| fps                | 377      |
| nupdates           | 50000    |
| policy_entropy     | 0.0187   |
| total_timesteps    | 250000   |
| value_loss         | 8.93     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0        |
| fps                | 377      |
| nupdates           | 50100    |
| policy_entropy     | 0.0307   |
| total_timesteps    | 250500   |
| value_loss         | 368      |
---------------------------------
10.0
10.0
16.07
10.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 214      |
| explained_variance | -7.51    |
| fps                | 377      |
| nupdates           | 50200    |
| policy_entropy     | 0.295    |
| total_timesteps    | 251000   |
| value_loss         | 1.65e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 213      |
| explained_variance | -0.3     |
| fps                | 377      |
| nupdates           | 50300    |
| policy_entropy     | 0.00969  |
| total_timesteps    | 251500   |
| value_loss         | 28.2     |
---------------------------------
21.0
21.0
15.99
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 213      |
| explained_variance | 0.761    |
| fps                | 377      |
| nupdates           | 50400    |
| policy_entropy     | 0.125    |
| total_timesteps    | 252000   |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.345    |
| fps                | 377      |
| nupdates           | 50500    |
| policy_entropy     | 0.229    |
| total_timesteps    | 252500   |
| value_loss         | 34.9     |
---------------------------------
9.0
9.0
14.06
15.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | -0.647   |
| fps                | 376      |
| nupdates           | 50600    |
| policy_entropy     | 0.145    |
| total_timesteps    | 253000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.83     |
| fps                | 376      |
| nupdates           | 50700    |
| policy_entropy     | 0.00369  |
| total_timesteps    | 253500   |
| value_loss         | 233      |
---------------------------------
9.0
9.0
16.29
16.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.394    |
| fps                | 376      |
| nupdates           | 50800    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 254000   |
| value_loss         | 32.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.988    |
| fps                | 376      |
| nupdates           | 50900    |
| policy_entropy     | 0.0874   |
| total_timesteps    | 254500   |
| value_loss         | 3        |
---------------------------------
10.0
10.0
14.61
15.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 219      |
| explained_variance | -2.6     |
| fps                | 376      |
| nupdates           | 51000    |
| policy_entropy     | 0.134    |
| total_timesteps    | 255000   |
| value_loss         | 326      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.148    |
| fps                | 376      |
| nupdates           | 51100    |
| policy_entropy     | 0.0563   |
| total_timesteps    | 255500   |
| value_loss         | 161      |
---------------------------------
22.0
22.0
14.85
19.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.828    |
| fps                | 376      |
| nupdates           | 51200    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 256000   |
| value_loss         | 21.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.977    |
| fps                | 376      |
| nupdates           | 51300    |
| policy_entropy     | 0.00444  |
| total_timesteps    | 256500   |
| value_loss         | 5.18     |
---------------------------------
9.0
9.0
14.07
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.96     |
| fps                | 376      |
| nupdates           | 51400    |
| policy_entropy     | 0.00708  |
| total_timesteps    | 257000   |
| value_loss         | 11.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | -0.841   |
| fps                | 376      |
| nupdates           | 51500    |
| policy_entropy     | 0.00523  |
| total_timesteps    | 257500   |
| value_loss         | 199      |
---------------------------------
21.0
21.0
15.68
10.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | -2.61    |
| fps                | 376      |
| nupdates           | 51600    |
| policy_entropy     | 0.013    |
| total_timesteps    | 258000   |
| value_loss         | 457      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.733    |
| fps                | 376      |
| nupdates           | 51700    |
| policy_entropy     | 0.0089   |
| total_timesteps    | 258500   |
| value_loss         | 78.4     |
---------------------------------
10.0
10.0
15.36
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.0981  |
| fps                | 376      |
| nupdates           | 51800    |
| policy_entropy     | 0.11     |
| total_timesteps    | 259000   |
| value_loss         | 99.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | 0.219    |
| fps                | 377      |
| nupdates           | 51900    |
| policy_entropy     | 0.0619   |
| total_timesteps    | 259500   |
| value_loss         | 20.9     |
---------------------------------
10.0
10.0
14.11
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | -0.847   |
| fps                | 376      |
| nupdates           | 52000    |
| policy_entropy     | 0.00743  |
| total_timesteps    | 260000   |
| value_loss         | 78       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.641    |
| fps                | 377      |
| nupdates           | 52100    |
| policy_entropy     | 0.00662  |
| total_timesteps    | 260500   |
| value_loss         | 93.1     |
---------------------------------
22.0
22.0
13.6
11.5
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 219      |
| explained_variance | 0.941    |
| fps                | 377      |
| nupdates           | 52200    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 261000   |
| value_loss         | 21.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.944    |
| fps                | 377      |
| nupdates           | 52300    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 261500   |
| value_loss         | 17.9     |
---------------------------------
10.0
10.0
14.16
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | -1.77    |
| fps                | 376      |
| nupdates           | 52400    |
| policy_entropy     | 0.0409   |
| total_timesteps    | 262000   |
| value_loss         | 196      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 221      |
| explained_variance | -0.387   |
| fps                | 376      |
| nupdates           | 52500    |
| policy_entropy     | 0.234    |
| total_timesteps    | 262500   |
| value_loss         | 60.7     |
---------------------------------
11.0
11.0
15.36
10.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.726    |
| fps                | 376      |
| nupdates           | 52600    |
| policy_entropy     | 0.024    |
| total_timesteps    | 263000   |
| value_loss         | 40.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.735    |
| fps                | 376      |
| nupdates           | 52700    |
| policy_entropy     | 0.00552  |
| total_timesteps    | 263500   |
| value_loss         | 29.6     |
---------------------------------
10.0
10.0
14.18
17.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | -2.85    |
| fps                | 376      |
| nupdates           | 52800    |
| policy_entropy     | 0.0398   |
| total_timesteps    | 264000   |
| value_loss         | 188      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 223      |
| explained_variance | 0.648    |
| fps                | 376      |
| nupdates           | 52900    |
| policy_entropy     | 0.0699   |
| total_timesteps    | 264500   |
| value_loss         | 44.8     |
---------------------------------
10.0
10.0
14.22
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | -2.07    |
| fps                | 376      |
| nupdates           | 53000    |
| policy_entropy     | 0.131    |
| total_timesteps    | 265000   |
| value_loss         | 300      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.284    |
| fps                | 376      |
| nupdates           | 53100    |
| policy_entropy     | 0.00911  |
| total_timesteps    | 265500   |
| value_loss         | 354      |
---------------------------------
20.0
20.0
14.91
19.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.987    |
| fps                | 376      |
| nupdates           | 53200    |
| policy_entropy     | 0.00881  |
| total_timesteps    | 266000   |
| value_loss         | 8.48     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 220      |
| explained_variance | 0.258    |
| fps                | 376      |
| nupdates           | 53300    |
| policy_entropy     | 0.094    |
| total_timesteps    | 266500   |
| value_loss         | 56       |
---------------------------------
9.0
9.0
14.42
15.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.867    |
| fps                | 376      |
| nupdates           | 53400    |
| policy_entropy     | 0.00283  |
| total_timesteps    | 267000   |
| value_loss         | 40.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | -0.958   |
| fps                | 376      |
| nupdates           | 53500    |
| policy_entropy     | 0.0417   |
| total_timesteps    | 267500   |
| value_loss         | 50.6     |
---------------------------------
21.0
21.0
14.04
12.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.976    |
| fps                | 376      |
| nupdates           | 53600    |
| policy_entropy     | 0.0779   |
| total_timesteps    | 268000   |
| value_loss         | 3.72     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.963    |
| fps                | 376      |
| nupdates           | 53700    |
| policy_entropy     | 0.0471   |
| total_timesteps    | 268500   |
| value_loss         | 6.24     |
---------------------------------
9.0
9.0
14.94
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.751    |
| fps                | 376      |
| nupdates           | 53800    |
| policy_entropy     | 0.00529  |
| total_timesteps    | 269000   |
| value_loss         | 30.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.79     |
| fps                | 376      |
| nupdates           | 53900    |
| policy_entropy     | 0.0683   |
| total_timesteps    | 269500   |
| value_loss         | 241      |
---------------------------------
9.0
9.0
13.64
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.992    |
| fps                | 376      |
| nupdates           | 54000    |
| policy_entropy     | 0.00782  |
| total_timesteps    | 270000   |
| value_loss         | 1.47     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.824    |
| fps                | 376      |
| nupdates           | 54100    |
| policy_entropy     | 0.0331   |
| total_timesteps    | 270500   |
| value_loss         | 24.6     |
---------------------------------
21.0
21.0
13.94
15.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | -0.93    |
| fps                | 376      |
| nupdates           | 54200    |
| policy_entropy     | 0.0187   |
| total_timesteps    | 271000   |
| value_loss         | 31       |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 220      |
| explained_variance | -1.79    |
| fps                | 376      |
| nupdates           | 54300    |
| policy_entropy     | 0.255    |
| total_timesteps    | 271500   |
| value_loss         | 400      |
---------------------------------
20.0
20.0
13.67
16.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.549    |
| fps                | 376      |
| nupdates           | 54400    |
| policy_entropy     | 0.00771  |
| total_timesteps    | 272000   |
| value_loss         | 303      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.96     |
| fps                | 376      |
| nupdates           | 54500    |
| policy_entropy     | 0.0473   |
| total_timesteps    | 272500   |
| value_loss         | 2.53     |
---------------------------------
9.0
9.0
14.61
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.497    |
| fps                | 376      |
| nupdates           | 54600    |
| policy_entropy     | 0.0233   |
| total_timesteps    | 273000   |
| value_loss         | 71.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | -700     |
| fps                | 376      |
| nupdates           | 54700    |
| policy_entropy     | 0.61     |
| total_timesteps    | 273500   |
| value_loss         | 1.01e+04 |
---------------------------------
28.0
28.0
20.76
20.5
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 197      |
| explained_variance | -441     |
| fps                | 376      |
| nupdates           | 54800    |
| policy_entropy     | 0.00721  |
| total_timesteps    | 274000   |
| value_loss         | 473      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 196      |
| explained_variance | -6.44    |
| fps                | 376      |
| nupdates           | 54900    |
| policy_entropy     | 0.0934   |
| total_timesteps    | 274500   |
| value_loss         | 0.0112   |
---------------------------------
10.0
10.0
20.87
16.0
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 196      |
| explained_variance | -0.448   |
| fps                | 377      |
| nupdates           | 55000    |
| policy_entropy     | 0.544    |
| total_timesteps    | 275000   |
| value_loss         | 0.0091   |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 196      |
| explained_variance | -0.325   |
| fps                | 377      |
| nupdates           | 55100    |
| policy_entropy     | 0.143    |
| total_timesteps    | 275500   |
| value_loss         | 0.0591   |
---------------------------------
30.0
30.0
34.33
17.5
---------------------------------
| ep_len_mean        | 34.3     |
| ep_reward_mean     | 163      |
| explained_variance | 0.00151  |
| fps                | 377      |
| nupdates           | 55200    |
| policy_entropy     | 0.761    |
| total_timesteps    | 276000   |
| value_loss         | 96.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 34.3     |
| ep_reward_mean     | 163      |
| explained_variance | 0.00156  |
| fps                | 377      |
| nupdates           | 55300    |
| policy_entropy     | 0.337    |
| total_timesteps    | 276500   |
| value_loss         | 1.08     |
---------------------------------
30.0
30.0
34.33
17.5
---------------------------------
| ep_len_mean        | 34.3     |
| ep_reward_mean     | 163      |
| explained_variance | -182     |
| fps                | 377      |
| nupdates           | 55400    |
| policy_entropy     | 0.307    |
| total_timesteps    | 277000   |
| value_loss         | 0.122    |
---------------------------------
---------------------------------
| ep_len_mean        | 34.3     |
| ep_reward_mean     | 163      |
| explained_variance | -83.2    |
| fps                | 377      |
| nupdates           | 55500    |
| policy_entropy     | 0.637    |
| total_timesteps    | 277500   |
| value_loss         | 0.002    |
---------------------------------
12.0
12.0
50.69
18.0
----------------------------------
| ep_len_mean        | 50.7      |
| ep_reward_mean     | 117       |
| explained_variance | -0.000136 |
| fps                | 377       |
| nupdates           | 55600     |
| policy_entropy     | 0.253     |
| total_timesteps    | 278000    |
| value_loss         | 5.06      |
----------------------------------
---------------------------------
| ep_len_mean        | 50.7     |
| ep_reward_mean     | 117      |
| explained_variance | -0.307   |
| fps                | 377      |
| nupdates           | 55700    |
| policy_entropy     | 0.274    |
| total_timesteps    | 278500   |
| value_loss         | 1.37     |
---------------------------------
258.0
258.0
62.98
17.5
---------------------------------
| ep_len_mean        | 63       |
| ep_reward_mean     | 81.6     |
| explained_variance | 0.00188  |
| fps                | 377      |
| nupdates           | 55800    |
| policy_entropy     | 0.711    |
| total_timesteps    | 279000   |
| value_loss         | 1.77     |
---------------------------------
---------------------------------
| ep_len_mean        | 63       |
| ep_reward_mean     | 81.6     |
| explained_variance | -5.09    |
| fps                | 377      |
| nupdates           | 55900    |
| policy_entropy     | 0.685    |
| total_timesteps    | 279500   |
| value_loss         | 12.8     |
---------------------------------
9.0
9.0
69.32
12.5
---------------------------------
| ep_len_mean        | 69.3     |
| ep_reward_mean     | 69       |
| explained_variance | -17      |
| fps                | 377      |
| nupdates           | 56000    |
| policy_entropy     | 0.693    |
| total_timesteps    | 280000   |
| value_loss         | 0.147    |
---------------------------------
----------------------------------
| ep_len_mean        | 77        |
| ep_reward_mean     | 53.1      |
| explained_variance | -5.01e+07 |
| fps                | 377       |
| nupdates           | 56100     |
| policy_entropy     | 0.707     |
| total_timesteps    | 280500    |
| value_loss         | 1.28      |
----------------------------------
31.0
31.0
76.95
12.5
----------------------------------
| ep_len_mean        | 77        |
| ep_reward_mean     | 53.1      |
| explained_variance | -3.64e+04 |
| fps                | 377       |
| nupdates           | 56200     |
| policy_entropy     | 0.708     |
| total_timesteps    | 281000    |
| value_loss         | 0.000442  |
----------------------------------
---------------------------------
| ep_len_mean        | 77       |
| ep_reward_mean     | 53.1     |
| explained_variance | -4.92    |
| fps                | 377      |
| nupdates           | 56300    |
| policy_entropy     | 0.718    |
| total_timesteps    | 281500   |
| value_loss         | 1.36e-06 |
---------------------------------
1161.0
1161.0
88.36
13.5
---------------------------------
| ep_len_mean        | 88.4     |
| ep_reward_mean     | 29.2     |
| explained_variance | -3.5     |
| fps                | 377      |
| nupdates           | 56400    |
| policy_entropy     | 0.7      |
| total_timesteps    | 282000   |
| value_loss         | 9.22e-05 |
---------------------------------
---------------------------------
| ep_len_mean        | 94.1     |
| ep_reward_mean     | 14.4     |
| explained_variance | 0        |
| fps                | 377      |
| nupdates           | 56500    |
| policy_entropy     | 0.14     |
| total_timesteps    | 282500   |
| value_loss         | 42.1     |
---------------------------------
10.0
10.0
90.55
10.0
---------------------------------
| ep_len_mean        | 90.5     |
| ep_reward_mean     | 28.3     |
| explained_variance | -35      |
| fps                | 377      |
| nupdates           | 56600    |
| policy_entropy     | 0.102    |
| total_timesteps    | 283000   |
| value_loss         | 548      |
---------------------------------
---------------------------------
| ep_len_mean        | 90.7     |
| ep_reward_mean     | 26.3     |
| explained_variance | -0.196   |
| fps                | 377      |
| nupdates           | 56700    |
| policy_entropy     | 0.0766   |
| total_timesteps    | 283500   |
| value_loss         | 6.27e+04 |
---------------------------------
10.0
10.0
53.33
15.0
---------------------------------
| ep_len_mean        | 53.3     |
| ep_reward_mean     | 129      |
| explained_variance | -260     |
| fps                | 377      |
| nupdates           | 56800    |
| policy_entropy     | 0.748    |
| total_timesteps    | 284000   |
| value_loss         | 5.74     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 200      |
| explained_variance | -8.61    |
| fps                | 377      |
| nupdates           | 56900    |
| policy_entropy     | 0.323    |
| total_timesteps    | 284500   |
| value_loss         | 340      |
---------------------------------
10.0
10.0
19.77
16.0
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 204      |
| explained_variance | -1.1     |
| fps                | 377      |
| nupdates           | 57000    |
| policy_entropy     | 0.14     |
| total_timesteps    | 285000   |
| value_loss         | 4.38e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 201      |
| explained_variance | 0.474    |
| fps                | 377      |
| nupdates           | 57100    |
| policy_entropy     | 0.143    |
| total_timesteps    | 285500   |
| value_loss         | 152      |
---------------------------------
14.0
14.0
17.96
12.0
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 206      |
| explained_variance | -11      |
| fps                | 377      |
| nupdates           | 57200    |
| policy_entropy     | 0.385    |
| total_timesteps    | 286000   |
| value_loss         | 890      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 203      |
| explained_variance | -16      |
| fps                | 377      |
| nupdates           | 57300    |
| policy_entropy     | 0.457    |
| total_timesteps    | 286500   |
| value_loss         | 757      |
---------------------------------
14.0
14.0
18.19
12.5
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 201      |
| explained_variance | -0.136   |
| fps                | 377      |
| nupdates           | 57400    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 287000   |
| value_loss         | 193      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 202      |
| explained_variance | -0.253   |
| fps                | 377      |
| nupdates           | 57500    |
| policy_entropy     | 0.0561   |
| total_timesteps    | 287500   |
| value_loss         | 1.13e+04 |
---------------------------------
27.0
27.0
17.37
12.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 204      |
| explained_variance | -3.98    |
| fps                | 377      |
| nupdates           | 57600    |
| policy_entropy     | 0.0512   |
| total_timesteps    | 288000   |
| value_loss         | 473      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 196      |
| explained_variance | 0.39     |
| fps                | 377      |
| nupdates           | 57700    |
| policy_entropy     | 0.0156   |
| total_timesteps    | 288500   |
| value_loss         | 324      |
---------------------------------
9.0
9.0
19.8
9.5
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 198      |
| explained_variance | -1.01    |
| fps                | 377      |
| nupdates           | 57800    |
| policy_entropy     | 0.299    |
| total_timesteps    | 289000   |
| value_loss         | 553      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 199      |
| explained_variance | -0.149   |
| fps                | 377      |
| nupdates           | 57900    |
| policy_entropy     | 0.0714   |
| total_timesteps    | 289500   |
| value_loss         | 1.44e+04 |
---------------------------------
23.0
23.0
19.8
13.5
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 199      |
| explained_variance | -2.54    |
| fps                | 377      |
| nupdates           | 58000    |
| policy_entropy     | 0.438    |
| total_timesteps    | 290000   |
| value_loss         | 369      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 208      |
| explained_variance | -0.0638  |
| fps                | 377      |
| nupdates           | 58100    |
| policy_entropy     | 0.0831   |
| total_timesteps    | 290500   |
| value_loss         | 1.12e+04 |
---------------------------------
11.0
11.0
18.87
11.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 207      |
| explained_variance | -0.0052  |
| fps                | 377      |
| nupdates           | 58200    |
| policy_entropy     | 0.0781   |
| total_timesteps    | 291000   |
| value_loss         | 4.86e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 203      |
| explained_variance | -0.136   |
| fps                | 377      |
| nupdates           | 58300    |
| policy_entropy     | 0.21     |
| total_timesteps    | 291500   |
| value_loss         | 448      |
---------------------------------
24.0
24.0
20.18
11.0
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 205      |
| explained_variance | -0.243   |
| fps                | 377      |
| nupdates           | 58400    |
| policy_entropy     | 0.127    |
| total_timesteps    | 292000   |
| value_loss         | 2.13e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 206      |
| explained_variance | -0.784   |
| fps                | 377      |
| nupdates           | 58500    |
| policy_entropy     | 0.371    |
| total_timesteps    | 292500   |
| value_loss         | 90.7     |
---------------------------------
10.0
10.0
17.9
10.5
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 208      |
| explained_variance | -0.749   |
| fps                | 377      |
| nupdates           | 58600    |
| policy_entropy     | 0.0296   |
| total_timesteps    | 293000   |
| value_loss         | 4.22e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 214      |
| explained_variance | -13      |
| fps                | 377      |
| nupdates           | 58700    |
| policy_entropy     | 0.163    |
| total_timesteps    | 293500   |
| value_loss         | 523      |
---------------------------------
10.0
10.0
16.68
21.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 210      |
| explained_variance | -0.2     |
| fps                | 377      |
| nupdates           | 58800    |
| policy_entropy     | 0.0298   |
| total_timesteps    | 294000   |
| value_loss         | 2.11e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | -3.9     |
| fps                | 377      |
| nupdates           | 58900    |
| policy_entropy     | 0.517    |
| total_timesteps    | 294500   |
| value_loss         | 513      |
---------------------------------
23.0
23.0
18.97
23.0
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 204      |
| explained_variance | -4.75    |
| fps                | 377      |
| nupdates           | 59000    |
| policy_entropy     | 0.00703  |
| total_timesteps    | 295000   |
| value_loss         | 67.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 204      |
| explained_variance | -2.44    |
| fps                | 377      |
| nupdates           | 59100    |
| policy_entropy     | 0.144    |
| total_timesteps    | 295500   |
| value_loss         | 580      |
---------------------------------
11.0
11.0
18.91
11.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 205      |
| explained_variance | -0.566   |
| fps                | 377      |
| nupdates           | 59200    |
| policy_entropy     | 0.0136   |
| total_timesteps    | 296000   |
| value_loss         | 6.47e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 206      |
| explained_variance | -1.79    |
| fps                | 377      |
| nupdates           | 59300    |
| policy_entropy     | 0.0167   |
| total_timesteps    | 296500   |
| value_loss         | 1.17e+03 |
---------------------------------
10.0
10.0
16.89
16.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.737    |
| fps                | 377      |
| nupdates           | 59400    |
| policy_entropy     | 0.211    |
| total_timesteps    | 297000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0        |
| fps                | 377      |
| nupdates           | 59500    |
| policy_entropy     | 0.156    |
| total_timesteps    | 297500   |
| value_loss         | 96.1     |
---------------------------------
10.0
10.0
17.71
10.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 209      |
| explained_variance | -0.629   |
| fps                | 377      |
| nupdates           | 59600    |
| policy_entropy     | 0.0187   |
| total_timesteps    | 298000   |
| value_loss         | 278      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 209      |
| explained_variance | -3.87    |
| fps                | 377      |
| nupdates           | 59700    |
| policy_entropy     | 0.016    |
| total_timesteps    | 298500   |
| value_loss         | 525      |
---------------------------------
21.0
21.0
18.99
16.0
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 208      |
| explained_variance | -2.24    |
| fps                | 377      |
| nupdates           | 59800    |
| policy_entropy     | 0.428    |
| total_timesteps    | 299000   |
| value_loss         | 285      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.77     |
| fps                | 377      |
| nupdates           | 59900    |
| policy_entropy     | 0.046    |
| total_timesteps    | 299500   |
| value_loss         | 25.1     |
---------------------------------
10.0
10.0
17.6
10.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.962    |
| fps                | 377      |
| nupdates           | 60000    |
| policy_entropy     | 0.198    |
| total_timesteps    | 300000   |
| value_loss         | 3.86     |
---------------------------------