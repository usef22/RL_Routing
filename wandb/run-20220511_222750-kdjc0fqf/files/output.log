WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000023D44ECC080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000023D44ECC080>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000023D42469F98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000023D42469F98>>: AttributeError: module 'gast' has no attribute 'Index'
___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | 0.0623   |
| fps                | 29       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 154      |
---------------------------------
---------------------------------
| ep_len_mean        | 216      |
| ep_reward_mean     | -634     |
| explained_variance | -0.0134  |
| fps                | 417      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 704      |
---------------------------------
691.0
691.0
453.5
453.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 454       |
| ep_reward_mean     | -1.67e+03 |
| explained_variance | 0.0547    |
| fps                | 448       |
| nupdates           | 200       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1000      |
| value_loss         | 650       |
----------------------------------
----------------------------------
| ep_len_mean        | 349       |
| ep_reward_mean     | -1.19e+03 |
| explained_variance | -0.0571   |
| fps                | 464       |
| nupdates           | 300       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1500      |
| value_loss         | 278       |
----------------------------------
385.0
385.0
356.2
267.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 356       |
| ep_reward_mean     | -1.23e+03 |
| explained_variance | -0.0282   |
| fps                | 468       |
| nupdates           | 400       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2000      |
| value_loss         | 92.1      |
----------------------------------
----------------------------------
| ep_len_mean        | 379       |
| ep_reward_mean     | -1.27e+03 |
| explained_variance | 0.043     |
| fps                | 472       |
| nupdates           | 500       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2500      |
| value_loss         | 200       |
----------------------------------
246.0
246.0
359.85714285714283
267.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 360      |
| ep_reward_mean     | -1.2e+03 |
| explained_variance | 0.047    |
| fps                | 475      |
| nupdates           | 600      |
| policy_entropy     | 1.1      |
| total_timesteps    | 3000     |
| value_loss         | 17.1     |
---------------------------------
----------------------------------
| ep_len_mean        | 375       |
| ep_reward_mean     | -1.22e+03 |
| explained_variance | -0.000757 |
| fps                | 478       |
| nupdates           | 700       |
| policy_entropy     | 1.1       |
| total_timesteps    | 3500      |
| value_loss         | 505       |
----------------------------------
227.0
227.0
359.8
256.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 360      |
| ep_reward_mean     | -1.2e+03 |
| explained_variance | 0.00347  |
| fps                | 481      |
| nupdates           | 800      |
| policy_entropy     | 1.05     |
| total_timesteps    | 4000     |
| value_loss         | 250      |
---------------------------------
----------------------------------
| ep_len_mean        | 369       |
| ep_reward_mean     | -1.22e+03 |
| explained_variance | -0.000343 |
| fps                | 483       |
| nupdates           | 900       |
| policy_entropy     | 0.982     |
| total_timesteps    | 4500      |
| value_loss         | 359       |
----------------------------------
457.0
457.0
368.6363636363636
326.0
----------------------------------
| ep_len_mean        | 369       |
| ep_reward_mean     | -1.22e+03 |
| explained_variance | 0.000425  |
| fps                | 482       |
| nupdates           | 1000      |
| policy_entropy     | 1.02      |
| total_timesteps    | 5000      |
| value_loss         | 150       |
----------------------------------
----------------------------------
| ep_len_mean        | 369       |
| ep_reward_mean     | -1.22e+03 |
| explained_variance | 0.000308  |
| fps                | 482       |
| nupdates           | 1100      |
| policy_entropy     | 1.07      |
| total_timesteps    | 5500      |
| value_loss         | 94.5      |
----------------------------------
275.0
275.0
461.46153846153845
330.0
----------------------------------
| ep_len_mean        | 461       |
| ep_reward_mean     | -1.55e+03 |
| explained_variance | -9.75e-05 |
| fps                | 483       |
| nupdates           | 1200      |
| policy_entropy     | 1.09      |
| total_timesteps    | 6000      |
| value_loss         | 4.16e+04  |
----------------------------------
----------------------------------
| ep_len_mean        | 397       |
| ep_reward_mean     | -1.29e+03 |
| explained_variance | 2.13e-05  |
| fps                | 484       |
| nupdates           | 1300      |
| policy_entropy     | 1.07      |
| total_timesteps    | 6500      |
| value_loss         | 276       |
----------------------------------
167.0
167.0
380.1111111111111
197.0
----------------------------------
| ep_len_mean        | 380       |
| ep_reward_mean     | -1.21e+03 |
| explained_variance | 2.53e-05  |
| fps                | 485       |
| nupdates           | 1400      |
| policy_entropy     | 1.09      |
| total_timesteps    | 7000      |
| value_loss         | 137       |
----------------------------------
----------------------------------
| ep_len_mean        | 354       |
| ep_reward_mean     | -1.12e+03 |
| explained_variance | 0.000243  |
| fps                | 484       |
| nupdates           | 1500      |
| policy_entropy     | 1.09      |
| total_timesteps    | 7500      |
| value_loss         | 134       |
----------------------------------
380.0
380.0
355.5
181.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 356       |
| ep_reward_mean     | -1.12e+03 |
| explained_variance | 0.000525  |
| fps                | 482       |
| nupdates           | 1600      |
| policy_entropy     | 1.09      |
| total_timesteps    | 8000      |
| value_loss         | 168       |
----------------------------------
----------------------------------
| ep_len_mean        | 352       |
| ep_reward_mean     | -1.11e+03 |
| explained_variance | 1.19e-07  |
| fps                | 482       |
| nupdates           | 1700      |
| policy_entropy     | 1.07      |
| total_timesteps    | 8500      |
| value_loss         | 101       |
----------------------------------
41.0
41.0
321.0740740740741
139.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 321      |
| ep_reward_mean     | -985     |
| explained_variance | 0.000319 |
| fps                | 483      |
| nupdates           | 1800     |
| policy_entropy     | 1.08     |
| total_timesteps    | 9000     |
| value_loss         | 17.6     |
---------------------------------
----------------------------------
| ep_len_mean        | 326       |
| ep_reward_mean     | -1e+03    |
| explained_variance | -1.19e-07 |
| fps                | 483       |
| nupdates           | 1900      |
| policy_entropy     | 1.08      |
| total_timesteps    | 9500      |
| value_loss         | 121       |
----------------------------------
112.0
112.0
306.71875
106.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 307      |
| ep_reward_mean     | -926     |
| explained_variance | 3.46e-06 |
| fps                | 484      |
| nupdates           | 2000     |
| policy_entropy     | 1.04     |
| total_timesteps    | 10000    |
| value_loss         | 68.1     |
---------------------------------
----------------------------------
| ep_len_mean        | 307       |
| ep_reward_mean     | -926      |
| explained_variance | -6.08e-06 |
| fps                | 483       |
| nupdates           | 2100      |
| policy_entropy     | 0.95      |
| total_timesteps    | 10500     |
| value_loss         | 17.7      |
----------------------------------
294.0
294.0
317.79411764705884
149.0
---------------------------------
| ep_len_mean        | 318      |
| ep_reward_mean     | -960     |
| explained_variance | 1.04e-05 |
| fps                | 484      |
| nupdates           | 2200     |
| policy_entropy     | 0.933    |
| total_timesteps    | 11000    |
| value_loss         | 82.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 286      |
| ep_reward_mean     | -833     |
| explained_variance | 0.00113  |
| fps                | 484      |
| nupdates           | 2300     |
| policy_entropy     | 0.767    |
| total_timesteps    | 11500    |
| value_loss         | 376      |
---------------------------------
103.0
103.0
266.4888888888889
76.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 266      |
| ep_reward_mean     | -758     |
| explained_variance | -0.00027 |
| fps                | 484      |
| nupdates           | 2400     |
| policy_entropy     | 0.913    |
| total_timesteps    | 12000    |
| value_loss         | 75.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 239      |
| ep_reward_mean     | -655     |
| explained_variance | 2.46e-05 |
| fps                | 485      |
| nupdates           | 2500     |
| policy_entropy     | 0.994    |
| total_timesteps    | 12500    |
| value_loss         | 103      |
---------------------------------
87.0
87.0
220.3050847457627
58.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 220       |
| ep_reward_mean     | -584      |
| explained_variance | -6.08e-06 |
| fps                | 485       |
| nupdates           | 2600      |
| policy_entropy     | 0.934     |
| total_timesteps    | 13000     |
| value_loss         | 4.77e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 185      |
| ep_reward_mean     | -450     |
| explained_variance | 3.65e-05 |
| fps                | 484      |
| nupdates           | 2700     |
| policy_entropy     | 0.834    |
| total_timesteps    | 13500    |
| value_loss         | 47.2     |
---------------------------------
58.0
58.0
171.5625
19.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 172      |
| ep_reward_mean     | -397     |
| explained_variance | -0.00211 |
| fps                | 485      |
| nupdates           | 2800     |
| policy_entropy     | 0.596    |
| total_timesteps    | 14000    |
| value_loss         | 10.5     |
---------------------------------
----------------------------------
| ep_len_mean        | 165       |
| ep_reward_mean     | -369      |
| explained_variance | -5.47e-05 |
| fps                | 485       |
| nupdates           | 2900      |
| policy_entropy     | 0.52      |
| total_timesteps    | 14500     |
| value_loss         | 1.77e+04  |
----------------------------------
71.0
71.0
154.6875
27.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 155      |
| ep_reward_mean     | -329     |
| explained_variance | 6.71e-05 |
| fps                | 483      |
| nupdates           | 3000     |
| policy_entropy     | 1.01     |
| total_timesteps    | 15000    |
| value_loss         | 70.5     |
---------------------------------
----------------------------------
| ep_len_mean        | 145       |
| ep_reward_mean     | -287      |
| explained_variance | -2.03e-06 |
| fps                | 484       |
| nupdates           | 3100      |
| policy_entropy     | 0.372     |
| total_timesteps    | 15500     |
| value_loss         | 41.9      |
----------------------------------
14.0
14.0
94.74
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 94.7      |
| ep_reward_mean     | -91.1     |
| explained_variance | -1.99e-05 |
| fps                | 483       |
| nupdates           | 3200      |
| policy_entropy     | 0.376     |
| total_timesteps    | 16000     |
| value_loss         | 41.4      |
----------------------------------
---------------------------------
| ep_len_mean        | 78.8     |
| ep_reward_mean     | -28.5    |
| explained_variance | 0.00025  |
| fps                | 483      |
| nupdates           | 3300     |
| policy_entropy     | 0.571    |
| total_timesteps    | 16500    |
| value_loss         | 53       |
---------------------------------
37.0
37.0
56.03
19.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 56       |
| ep_reward_mean     | 57.5     |
| explained_variance | -0.138   |
| fps                | 483      |
| nupdates           | 3400     |
| policy_entropy     | 0.687    |
| total_timesteps    | 17000    |
| value_loss         | 24.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 48       |
| ep_reward_mean     | 91.9     |
| explained_variance | -0.00355 |
| fps                | 483      |
| nupdates           | 3500     |
| policy_entropy     | 0.813    |
| total_timesteps    | 17500    |
| value_loss         | 215      |
---------------------------------
12.0
12.0
43.95
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 44       |
| ep_reward_mean     | 111      |
| explained_variance | 0.0188   |
| fps                | 483      |
| nupdates           | 3600     |
| policy_entropy     | 0.726    |
| total_timesteps    | 18000    |
| value_loss         | 139      |
---------------------------------
---------------------------------
| ep_len_mean        | 38.5     |
| ep_reward_mean     | 134      |
| explained_variance | 0.00248  |
| fps                | 483      |
| nupdates           | 3700     |
| policy_entropy     | 0.655    |
| total_timesteps    | 18500    |
| value_loss         | 8.25     |
---------------------------------
13.0
13.0
33.61
28.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 33.6     |
| ep_reward_mean     | 154      |
| explained_variance | 0.000687 |
| fps                | 483      |
| nupdates           | 3800     |
| policy_entropy     | 0.623    |
| total_timesteps    | 19000    |
| value_loss         | 7.83     |
---------------------------------
----------------------------------
| ep_len_mean        | 33.2      |
| ep_reward_mean     | 160       |
| explained_variance | -0.000168 |
| fps                | 483       |
| nupdates           | 3900      |
| policy_entropy     | 0.719     |
| total_timesteps    | 19500     |
| value_loss         | 240       |
----------------------------------
25.0
25.0
34.58
22.5
---------------------------------
| ep_len_mean        | 34.6     |
| ep_reward_mean     | 151      |
| explained_variance | -0.0879  |
| fps                | 483      |
| nupdates           | 4000     |
| policy_entropy     | 0.454    |
| total_timesteps    | 20000    |
| value_loss         | 4.1e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 35.4     |
| ep_reward_mean     | 149      |
| explained_variance | 0.0688   |
| fps                | 483      |
| nupdates           | 4100     |
| policy_entropy     | 0.66     |
| total_timesteps    | 20500    |
| value_loss         | 33.2     |
---------------------------------
56.0
56.0
37.8
21.5
----------------------------------
| ep_len_mean        | 37.8      |
| ep_reward_mean     | 143       |
| explained_variance | -0.000223 |
| fps                | 483       |
| nupdates           | 4200      |
| policy_entropy     | 0.481     |
| total_timesteps    | 21000     |
| value_loss         | 9.99e+04  |
----------------------------------
---------------------------------
| ep_len_mean        | 37.2     |
| ep_reward_mean     | 145      |
| explained_variance | 0        |
| fps                | 484      |
| nupdates           | 4300     |
| policy_entropy     | 0.382    |
| total_timesteps    | 21500    |
| value_loss         | 481      |
---------------------------------
16.0
16.0
40.12
19.5
----------------------------------
| ep_len_mean        | 40.1      |
| ep_reward_mean     | 130       |
| explained_variance | -0.000894 |
| fps                | 483       |
| nupdates           | 4400      |
| policy_entropy     | 0.787     |
| total_timesteps    | 22000     |
| value_loss         | 77.3      |
----------------------------------
---------------------------------
| ep_len_mean        | 40.9     |
| ep_reward_mean     | 126      |
| explained_variance | -0.00123 |
| fps                | 483      |
| nupdates           | 4500     |
| policy_entropy     | 0.533    |
| total_timesteps    | 22500    |
| value_loss         | 4.37e+04 |
---------------------------------
98.0
98.0
40.87
14.5
---------------------------------
| ep_len_mean        | 40.9     |
| ep_reward_mean     | 126      |
| explained_variance | 0.0128   |
| fps                | 483      |
| nupdates           | 4600     |
| policy_entropy     | 0.79     |
| total_timesteps    | 23000    |
| value_loss         | 4.34     |
---------------------------------
----------------------------------
| ep_len_mean        | 42.6      |
| ep_reward_mean     | 122       |
| explained_variance | -0.000135 |
| fps                | 483       |
| nupdates           | 4700      |
| policy_entropy     | 0.777     |
| total_timesteps    | 23500     |
| value_loss         | 27.5      |
----------------------------------
10.0
10.0
42.99
13.5
---------------------------------
| ep_len_mean        | 43       |
| ep_reward_mean     | 121      |
| explained_variance | 0.514    |
| fps                | 483      |
| nupdates           | 4800     |
| policy_entropy     | 0.502    |
| total_timesteps    | 24000    |
| value_loss         | 382      |
---------------------------------
----------------------------------
| ep_len_mean        | 36        |
| ep_reward_mean     | 143       |
| explained_variance | -0.000161 |
| fps                | 483       |
| nupdates           | 4900      |
| policy_entropy     | 0.434     |
| total_timesteps    | 24500     |
| value_loss         | 25.7      |
----------------------------------
9.0
9.0
40.26
17.0
---------------------------------
| ep_len_mean        | 40.3     |
| ep_reward_mean     | 126      |
| explained_variance | -0.395   |
| fps                | 483      |
| nupdates           | 5000     |
| policy_entropy     | 0.638    |
| total_timesteps    | 25000    |
| value_loss         | 48.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 42.6     |
| ep_reward_mean     | 120      |
| explained_variance | -21.5    |
| fps                | 483      |
| nupdates           | 5100     |
| policy_entropy     | 0.514    |
| total_timesteps    | 25500    |
| value_loss         | 125      |
---------------------------------
91.0
91.0
42.85
37.0
---------------------------------
| ep_len_mean        | 42.9     |
| ep_reward_mean     | 123      |
| explained_variance | 0.00392  |
| fps                | 483      |
| nupdates           | 5200     |
| policy_entropy     | 0.612    |
| total_timesteps    | 26000    |
| value_loss         | 29.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 43.9     |
| ep_reward_mean     | 124      |
| explained_variance | -0.00024 |
| fps                | 483      |
| nupdates           | 5300     |
| policy_entropy     | 0.831    |
| total_timesteps    | 26500    |
| value_loss         | 281      |
---------------------------------
17.0
17.0
42.69
20.5
---------------------------------
| ep_len_mean        | 42.7     |
| ep_reward_mean     | 127      |
| explained_variance | 0.928    |
| fps                | 483      |
| nupdates           | 5400     |
| policy_entropy     | 0.31     |
| total_timesteps    | 27000    |
| value_loss         | 31.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 37       |
| ep_reward_mean     | 139      |
| explained_variance | -0.514   |
| fps                | 483      |
| nupdates           | 5500     |
| policy_entropy     | 0.526    |
| total_timesteps    | 27500    |
| value_loss         | 2.36     |
---------------------------------
11.0
11.0
38.04
17.5
---------------------------------
| ep_len_mean        | 38       |
| ep_reward_mean     | 139      |
| explained_variance | 0.00262  |
| fps                | 482      |
| nupdates           | 5600     |
| policy_entropy     | 0.629    |
| total_timesteps    | 28000    |
| value_loss         | 60.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 35.8     |
| ep_reward_mean     | 151      |
| explained_variance | -0.00729 |
| fps                | 483      |
| nupdates           | 5700     |
| policy_entropy     | 0.244    |
| total_timesteps    | 28500    |
| value_loss         | 19.4     |
---------------------------------
23.0
23.0
35.8
19.5
---------------------------------
| ep_len_mean        | 35.8     |
| ep_reward_mean     | 151      |
| explained_variance | 0.000998 |
| fps                | 483      |
| nupdates           | 5800     |
| policy_entropy     | 0.658    |
| total_timesteps    | 29000    |
| value_loss         | 56.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.6     |
| ep_reward_mean     | 138      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 5900     |
| policy_entropy     | 0.336    |
| total_timesteps    | 29500    |
| value_loss         | 0.919    |
---------------------------------
126.0
126.0
38.13
29.0
---------------------------------
| ep_len_mean        | 38.1     |
| ep_reward_mean     | 139      |
| explained_variance | 0.0451   |
| fps                | 482      |
| nupdates           | 6000     |
| policy_entropy     | 0.57     |
| total_timesteps    | 30000    |
| value_loss         | 0.658    |
---------------------------------
---------------------------------
| ep_len_mean        | 38.9     |
| ep_reward_mean     | 137      |
| explained_variance | 7.49e-05 |
| fps                | 482      |
| nupdates           | 6100     |
| policy_entropy     | 0.904    |
| total_timesteps    | 30500    |
| value_loss         | 0.565    |
---------------------------------
16.0
16.0
39.5
14.5
---------------------------------
| ep_len_mean        | 39.5     |
| ep_reward_mean     | 136      |
| explained_variance | -0.421   |
| fps                | 482      |
| nupdates           | 6200     |
| policy_entropy     | 0.454    |
| total_timesteps    | 31000    |
| value_loss         | 61.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 38       |
| ep_reward_mean     | 143      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 6300     |
| policy_entropy     | 0.251    |
| total_timesteps    | 31500    |
| value_loss         | 0.473    |
---------------------------------
10.0
10.0
37.21
12.0
---------------------------------
| ep_len_mean        | 37.2     |
| ep_reward_mean     | 146      |
| explained_variance | -0.0066  |
| fps                | 482      |
| nupdates           | 6400     |
| policy_entropy     | 0.624    |
| total_timesteps    | 32000    |
| value_loss         | 5.5      |
---------------------------------
---------------------------------
| ep_len_mean        | 31.5     |
| ep_reward_mean     | 169      |
| explained_variance | -8.21    |
| fps                | 482      |
| nupdates           | 6500     |
| policy_entropy     | 0.411    |
| total_timesteps    | 32500    |
| value_loss         | 102      |
---------------------------------
30.0
30.0
25.72
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.7     |
| ep_reward_mean     | 182      |
| explained_variance | 0.0456   |
| fps                | 481      |
| nupdates           | 6600     |
| policy_entropy     | 0.341    |
| total_timesteps    | 33000    |
| value_loss         | 15.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 183      |
| explained_variance | 0.13     |
| fps                | 481      |
| nupdates           | 6700     |
| policy_entropy     | 0.572    |
| total_timesteps    | 33500    |
| value_loss         | 0.189    |
---------------------------------
10.0
10.0
25.37
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 182      |
| explained_variance | 0.634    |
| fps                | 481      |
| nupdates           | 6800     |
| policy_entropy     | 0.202    |
| total_timesteps    | 34000    |
| value_loss         | 55.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.2     |
| ep_reward_mean     | 183      |
| explained_variance | -0.00567 |
| fps                | 481      |
| nupdates           | 6900     |
| policy_entropy     | 0.287    |
| total_timesteps    | 34500    |
| value_loss         | 14.9     |
---------------------------------
56.0
56.0
29.01
26.0
---------------------------------
| ep_len_mean        | 29       |
| ep_reward_mean     | 169      |
| explained_variance | -0.132   |
| fps                | 481      |
| nupdates           | 7000     |
| policy_entropy     | 0.399    |
| total_timesteps    | 35000    |
| value_loss         | 9.09e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 28.8     |
| ep_reward_mean     | 169      |
| explained_variance | 0.956    |
| fps                | 481      |
| nupdates           | 7100     |
| policy_entropy     | 0.422    |
| total_timesteps    | 35500    |
| value_loss         | 9.8      |
---------------------------------
10.0
10.0
31.6
28.5
---------------------------------
| ep_len_mean        | 31.6     |
| ep_reward_mean     | 162      |
| explained_variance | -0.0299  |
| fps                | 481      |
| nupdates           | 7200     |
| policy_entropy     | 0.316    |
| total_timesteps    | 36000    |
| value_loss         | 3.18e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 31.7     |
| ep_reward_mean     | 160      |
| explained_variance | -0.38    |
| fps                | 481      |
| nupdates           | 7300     |
| policy_entropy     | 0.177    |
| total_timesteps    | 36500    |
| value_loss         | 589      |
---------------------------------
15.0
15.0
30.81
12.5
---------------------------------
| ep_len_mean        | 30.8     |
| ep_reward_mean     | 160      |
| explained_variance | -4.13    |
| fps                | 481      |
| nupdates           | 7400     |
| policy_entropy     | 0.587    |
| total_timesteps    | 37000    |
| value_loss         | 3.95     |
---------------------------------
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 159      |
| explained_variance | 0.000891 |
| fps                | 481      |
| nupdates           | 7500     |
| policy_entropy     | 0.336    |
| total_timesteps    | 37500    |
| value_loss         | 41.4     |
---------------------------------
16.0
16.0
28.64
18.5
---------------------------------
| ep_len_mean        | 28.6     |
| ep_reward_mean     | 167      |
| explained_variance | 0        |
| fps                | 481      |
| nupdates           | 7600     |
| policy_entropy     | 0.241    |
| total_timesteps    | 38000    |
| value_loss         | 0.0221   |
---------------------------------
---------------------------------
| ep_len_mean        | 29.1     |
| ep_reward_mean     | 167      |
| explained_variance | 0        |
| fps                | 481      |
| nupdates           | 7700     |
| policy_entropy     | 0.313    |
| total_timesteps    | 38500    |
| value_loss         | 376      |
---------------------------------
24.0
24.0
37.47
25.5
---------------------------------
| ep_len_mean        | 37.5     |
| ep_reward_mean     | 114      |
| explained_variance | 0        |
| fps                | 481      |
| nupdates           | 7800     |
| policy_entropy     | 0.575    |
| total_timesteps    | 39000    |
| value_loss         | 0.15     |
---------------------------------
----------------------------------
| ep_len_mean        | 38.8      |
| ep_reward_mean     | 110       |
| explained_variance | -1.26e+08 |
| fps                | 481       |
| nupdates           | 7900      |
| policy_entropy     | 0.22      |
| total_timesteps    | 39500     |
| value_loss         | 4.02      |
----------------------------------
146.0
146.0
38.82
30.0
----------------------------------
| ep_len_mean        | 38.8      |
| ep_reward_mean     | 110       |
| explained_variance | -7.98e+04 |
| fps                | 482       |
| nupdates           | 8000      |
| policy_entropy     | 0.623     |
| total_timesteps    | 40000     |
| value_loss         | 0.146     |
----------------------------------
---------------------------------
| ep_len_mean        | 38.8     |
| ep_reward_mean     | 110      |
| explained_variance | -43.1    |
| fps                | 482      |
| nupdates           | 8100     |
| policy_entropy     | 0.687    |
| total_timesteps    | 40500    |
| value_loss         | 0.0277   |
---------------------------------
10.0
10.0
56.69
36.5
---------------------------------
| ep_len_mean        | 56.7     |
| ep_reward_mean     | 72       |
| explained_variance | 0.00268  |
| fps                | 482      |
| nupdates           | 8200     |
| policy_entropy     | 0.372    |
| total_timesteps    | 41000    |
| value_loss         | 9.66e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 56.7     |
| ep_reward_mean     | 72       |
| explained_variance | 0.181    |
| fps                | 482      |
| nupdates           | 8300     |
| policy_entropy     | 0.397    |
| total_timesteps    | 41500    |
| value_loss         | 193      |
---------------------------------
10.0
10.0
56.69
36.5
---------------------------------
| ep_len_mean        | 56.7     |
| ep_reward_mean     | 72       |
| explained_variance | -16.9    |
| fps                | 482      |
| nupdates           | 8400     |
| policy_entropy     | 0.723    |
| total_timesteps    | 42000    |
| value_loss         | 0.000598 |
---------------------------------
---------------------------------
| ep_len_mean        | 56.7     |
| ep_reward_mean     | 72       |
| explained_variance | -0.0314  |
| fps                | 482      |
| nupdates           | 8500     |
| policy_entropy     | 0.813    |
| total_timesteps    | 42500    |
| value_loss         | 8.31     |
---------------------------------
1958.0
1958.0
76.17
47.5
---------------------------------
| ep_len_mean        | 76.2     |
| ep_reward_mean     | 30.8     |
| explained_variance | -0.192   |
| fps                | 482      |
| nupdates           | 8600     |
| policy_entropy     | 0.33     |
| total_timesteps    | 43000    |
| value_loss         | 8.47     |
---------------------------------
---------------------------------
| ep_len_mean        | 79.6     |
| ep_reward_mean     | 13.6     |
| explained_variance | 0.000119 |
| fps                | 482      |
| nupdates           | 8700     |
| policy_entropy     | 0.61     |
| total_timesteps    | 43500    |
| value_loss         | 19.2     |
---------------------------------
47.0
47.0
78.47
21.0
---------------------------------
| ep_len_mean        | 78.5     |
| ep_reward_mean     | 15.9     |
| explained_variance | 0.0112   |
| fps                | 482      |
| nupdates           | 8800     |
| policy_entropy     | 0.717    |
| total_timesteps    | 44000    |
| value_loss         | 72.6     |
---------------------------------
----------------------------------
| ep_len_mean        | 80.7      |
| ep_reward_mean     | 8.02      |
| explained_variance | -1.19e-07 |
| fps                | 482       |
| nupdates           | 8900      |
| policy_entropy     | 0.21      |
| total_timesteps    | 44500     |
| value_loss         | 359       |
----------------------------------
30.0
30.0
85.29
45.5
---------------------------------
| ep_len_mean        | 85.3     |
| ep_reward_mean     | -26.6    |
| explained_variance | 5.96e-08 |
| fps                | 482      |
| nupdates           | 9000     |
| policy_entropy     | 0.623    |
| total_timesteps    | 45000    |
| value_loss         | 0.00874  |
---------------------------------
---------------------------------
| ep_len_mean        | 87       |
| ep_reward_mean     | -29.2    |
| explained_variance | -257     |
| fps                | 482      |
| nupdates           | 9100     |
| policy_entropy     | 0.761    |
| total_timesteps    | 45500    |
| value_loss         | 0.0371   |
---------------------------------
10.0
10.0
86.98
55.0
---------------------------------
| ep_len_mean        | 87       |
| ep_reward_mean     | -29.2    |
| explained_variance | -307     |
| fps                | 482      |
| nupdates           | 9200     |
| policy_entropy     | 0.569    |
| total_timesteps    | 46000    |
| value_loss         | 0.0334   |
---------------------------------
---------------------------------
| ep_len_mean        | 100      |
| ep_reward_mean     | -65.3    |
| explained_variance | -1.25    |
| fps                | 482      |
| nupdates           | 9300     |
| policy_entropy     | 0.7      |
| total_timesteps    | 46500    |
| value_loss         | 0.414    |
---------------------------------
15.0
15.0
100.05
32.0
---------------------------------
| ep_len_mean        | 100      |
| ep_reward_mean     | -65.3    |
| explained_variance | -415     |
| fps                | 482      |
| nupdates           | 9400     |
| policy_entropy     | 0.69     |
| total_timesteps    | 47000    |
| value_loss         | 0.000863 |
---------------------------------
---------------------------------
| ep_len_mean        | 108      |
| ep_reward_mean     | -83.4    |
| explained_variance | 0.0348   |
| fps                | 482      |
| nupdates           | 9500     |
| policy_entropy     | 0.608    |
| total_timesteps    | 47500    |
| value_loss         | 11       |
---------------------------------
93.0
93.0
112.08
19.5
---------------------------------
| ep_len_mean        | 112      |
| ep_reward_mean     | -93      |
| explained_variance | -13.6    |
| fps                | 482      |
| nupdates           | 9600     |
| policy_entropy     | 0.569    |
| total_timesteps    | 48000    |
| value_loss         | 5.7      |
---------------------------------
----------------------------------
| ep_len_mean        | 115       |
| ep_reward_mean     | -99.5     |
| explained_variance | -1.64e+04 |
| fps                | 483       |
| nupdates           | 9700      |
| policy_entropy     | 0.566     |
| total_timesteps    | 48500     |
| value_loss         | 30.3      |
----------------------------------
13.0
13.0
114.86
69.5
---------------------------------
| ep_len_mean        | 115      |
| ep_reward_mean     | -99.5    |
| explained_variance | -11.5    |
| fps                | 483      |
| nupdates           | 9800     |
| policy_entropy     | 0.569    |
| total_timesteps    | 49000    |
| value_loss         | 0.00903  |
---------------------------------
----------------------------------
| ep_len_mean        | 115       |
| ep_reward_mean     | -99.5     |
| explained_variance | -2.24e+03 |
| fps                | 483       |
| nupdates           | 9900      |
| policy_entropy     | 0.739     |
| total_timesteps    | 49500     |
| value_loss         | 0.00148   |
----------------------------------
9.0
9.0
128.58
75.0
---------------------------------
| ep_len_mean        | 129      |
| ep_reward_mean     | -127     |
| explained_variance | -207     |
| fps                | 483      |
| nupdates           | 10000    |
| policy_entropy     | 0.733    |
| total_timesteps    | 50000    |
| value_loss         | 0.0496   |
---------------------------------
---------------------------------
| ep_len_mean        | 134      |
| ep_reward_mean     | -140     |
| explained_variance | -0.024   |
| fps                | 483      |
| nupdates           | 10100    |
| policy_entropy     | 0.238    |
| total_timesteps    | 50500    |
| value_loss         | 0.348    |
---------------------------------
11.0
11.0
136.72
35.0
---------------------------------
| ep_len_mean        | 137      |
| ep_reward_mean     | -145     |
| explained_variance | -0.759   |
| fps                | 483      |
| nupdates           | 10200    |
| policy_entropy     | 0.651    |
| total_timesteps    | 51000    |
| value_loss         | 2.87e-05 |
---------------------------------
---------------------------------
| ep_len_mean        | 137      |
| ep_reward_mean     | -145     |
| explained_variance | -16.5    |
| fps                | 483      |
| nupdates           | 10300    |
| policy_entropy     | 0.595    |
| total_timesteps    | 51500    |
| value_loss         | 0.0161   |
---------------------------------
17.0
17.0
143.88
14.0
---------------------------------
| ep_len_mean        | 144      |
| ep_reward_mean     | -160     |
| explained_variance | -129     |
| fps                | 483      |
| nupdates           | 10400    |
| policy_entropy     | 0.701    |
| total_timesteps    | 52000    |
| value_loss         | 0.0882   |
---------------------------------
---------------------------------
| ep_len_mean        | 147      |
| ep_reward_mean     | -163     |
| explained_variance | -0.0792  |
| fps                | 483      |
| nupdates           | 10500    |
| policy_entropy     | 0.467    |
| total_timesteps    | 52500    |
| value_loss         | 3.35e+04 |
---------------------------------
12.0
12.0
149.35
16.0
---------------------------------
| ep_len_mean        | 149      |
| ep_reward_mean     | -166     |
| explained_variance | -0.00192 |
| fps                | 483      |
| nupdates           | 10600    |
| policy_entropy     | 0.284    |
| total_timesteps    | 53000    |
| value_loss         | 3.05e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 96.8     |
| ep_reward_mean     | -7.2     |
| explained_variance | -3.58    |
| fps                | 483      |
| nupdates           | 10700    |
| policy_entropy     | 0.636    |
| total_timesteps    | 53500    |
| value_loss         | 0.073    |
---------------------------------
13.0
13.0
92.63
23.0
---------------------------------
| ep_len_mean        | 92.6     |
| ep_reward_mean     | 28.8     |
| explained_variance | -80.5    |
| fps                | 483      |
| nupdates           | 10800    |
| policy_entropy     | 0.167    |
| total_timesteps    | 54000    |
| value_loss         | 25.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 80.3     |
| ep_reward_mean     | 62.6     |
| explained_variance | -134     |
| fps                | 483      |
| nupdates           | 10900    |
| policy_entropy     | 0.274    |
| total_timesteps    | 54500    |
| value_loss         | 469      |
---------------------------------
420.0
420.0
76.5
24.0
---------------------------------
| ep_len_mean        | 76.5     |
| ep_reward_mean     | 70.2     |
| explained_variance | -5.34    |
| fps                | 483      |
| nupdates           | 11000    |
| policy_entropy     | 0.375    |
| total_timesteps    | 55000    |
| value_loss         | 0.000557 |
---------------------------------
---------------------------------
| ep_len_mean        | 75.8     |
| ep_reward_mean     | 72.7     |
| explained_variance | -13.4    |
| fps                | 483      |
| nupdates           | 11100    |
| policy_entropy     | 0.393    |
| total_timesteps    | 55500    |
| value_loss         | 9.38     |
---------------------------------
423.0
423.0
79.79
52.5
---------------------------------
| ep_len_mean        | 79.8     |
| ep_reward_mean     | 59.4     |
| explained_variance | -335     |
| fps                | 483      |
| nupdates           | 11200    |
| policy_entropy     | 0.571    |
| total_timesteps    | 56000    |
| value_loss         | 18.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 82.1     |
| ep_reward_mean     | 54.7     |
| explained_variance | -257     |
| fps                | 483      |
| nupdates           | 11300    |
| policy_entropy     | 0.672    |
| total_timesteps    | 56500    |
| value_loss         | 0.0208   |
---------------------------------
10.0
10.0
85.94
52.5
---------------------------------
| ep_len_mean        | 85.9     |
| ep_reward_mean     | 42.2     |
| explained_variance | -39.2    |
| fps                | 483      |
| nupdates           | 11400    |
| policy_entropy     | 0.39     |
| total_timesteps    | 57000    |
| value_loss         | 0.674    |
---------------------------------
---------------------------------
| ep_len_mean        | 52.7     |
| ep_reward_mean     | 111      |
| explained_variance | -209     |
| fps                | 483      |
| nupdates           | 11500    |
| policy_entropy     | 0.152    |
| total_timesteps    | 57500    |
| value_loss         | 985      |
---------------------------------
44.0
44.0
50.98
14.0
---------------------------------
| ep_len_mean        | 51       |
| ep_reward_mean     | 114      |
| explained_variance | -109     |
| fps                | 483      |
| nupdates           | 11600    |
| policy_entropy     | 0.0639   |
| total_timesteps    | 58000    |
| value_loss         | 0.00637  |
---------------------------------
---------------------------------
| ep_len_mean        | 51       |
| ep_reward_mean     | 114      |
| explained_variance | -4.84    |
| fps                | 482      |
| nupdates           | 11700    |
| policy_entropy     | 0.108    |
| total_timesteps    | 58500    |
| value_loss         | 0.000554 |
---------------------------------
1023.0
1023.0
60.96
18.0
---------------------------------
| ep_len_mean        | 61       |
| ep_reward_mean     | 93.7     |
| explained_variance | -232     |
| fps                | 482      |
| nupdates           | 11800    |
| policy_entropy     | 0.745    |
| total_timesteps    | 59000    |
| value_loss         | 0.0118   |
---------------------------------
---------------------------------
| ep_len_mean        | 61       |
| ep_reward_mean     | 93.7     |
| explained_variance | -1.8     |
| fps                | 482      |
| nupdates           | 11900    |
| policy_entropy     | 0.787    |
| total_timesteps    | 59500    |
| value_loss         | 0.0083   |
---------------------------------
9.0
9.0
68.35
13.5
---------------------------------
| ep_len_mean        | 68.3     |
| ep_reward_mean     | 78.2     |
| explained_variance | 0.0112   |
| fps                | 482      |
| nupdates           | 12000    |
| policy_entropy     | 0.348    |
| total_timesteps    | 60000    |
| value_loss         | 2.94e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 72       |
| ep_reward_mean     | 69.4     |
| explained_variance | -0.641   |
| fps                | 483      |
| nupdates           | 12100    |
| policy_entropy     | 0.165    |
| total_timesteps    | 60500    |
| value_loss         | 1.44e+05 |
---------------------------------
10.0
10.0
68.57
12.5
---------------------------------
| ep_len_mean        | 68.6     |
| ep_reward_mean     | 78.1     |
| explained_variance | -0.0339  |
| fps                | 482      |
| nupdates           | 12200    |
| policy_entropy     | 0.396    |
| total_timesteps    | 61000    |
| value_loss         | 26       |
---------------------------------
---------------------------------
| ep_len_mean        | 51.3     |
| ep_reward_mean     | 123      |
| explained_variance | -11.4    |
| fps                | 482      |
| nupdates           | 12300    |
| policy_entropy     | 0.393    |
| total_timesteps    | 61500    |
| value_loss         | 39.4     |
---------------------------------
39.0
39.0
46.3
10.0
---------------------------------
| ep_len_mean        | 46.3     |
| ep_reward_mean     | 140      |
| explained_variance | -0.328   |
| fps                | 482      |
| nupdates           | 12400    |
| policy_entropy     | 0.178    |
| total_timesteps    | 62000    |
| value_loss         | 493      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.5     |
| ep_reward_mean     | 184      |
| explained_variance | -0.984   |
| fps                | 482      |
| nupdates           | 12500    |
| policy_entropy     | 0.299    |
| total_timesteps    | 62500    |
| value_loss         | 195      |
---------------------------------
10.0
10.0
23.15
16.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 23.1     |
| ep_reward_mean     | 190      |
| explained_variance | -0.387   |
| fps                | 482      |
| nupdates           | 12600    |
| policy_entropy     | 0.234    |
| total_timesteps    | 63000    |
| value_loss         | 387      |
---------------------------------
---------------------------------
| ep_len_mean        | 24.4     |
| ep_reward_mean     | 188      |
| explained_variance | -0.448   |
| fps                | 482      |
| nupdates           | 12700    |
| policy_entropy     | 0.764    |
| total_timesteps    | 63500    |
| value_loss         | 0.0469   |
---------------------------------
25.0
25.0
22.65
14.5
---------------------------------
| ep_len_mean        | 22.6     |
| ep_reward_mean     | 187      |
| explained_variance | 0.466    |
| fps                | 482      |
| nupdates           | 12800    |
| policy_entropy     | 0.106    |
| total_timesteps    | 64000    |
| value_loss         | 1.6e+05  |
---------------------------------
---------------------------------
| ep_len_mean        | 24.8     |
| ep_reward_mean     | 182      |
| explained_variance | 1.19e-07 |
| fps                | 482      |
| nupdates           | 12900    |
| policy_entropy     | 0.826    |
| total_timesteps    | 64500    |
| value_loss         | 0.000386 |
---------------------------------
9.0
9.0
25.95
10.0
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 180      |
| explained_variance | -18.7    |
| fps                | 482      |
| nupdates           | 13000    |
| policy_entropy     | 0.63     |
| total_timesteps    | 65000    |
| value_loss         | 0.593    |
---------------------------------
---------------------------------
| ep_len_mean        | 27.2     |
| ep_reward_mean     | 178      |
| explained_variance | -0.103   |
| fps                | 482      |
| nupdates           | 13100    |
| policy_entropy     | 0.297    |
| total_timesteps    | 65500    |
| value_loss         | 3.19e+04 |
---------------------------------
28.0
28.0
27.6
14.5
---------------------------------
| ep_len_mean        | 27.6     |
| ep_reward_mean     | 177      |
| explained_variance | 0.553    |
| fps                | 482      |
| nupdates           | 13200    |
| policy_entropy     | 0.181    |
| total_timesteps    | 66000    |
| value_loss         | 60.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 29.6     |
| ep_reward_mean     | 172      |
| explained_variance | -0.0151  |
| fps                | 482      |
| nupdates           | 13300    |
| policy_entropy     | 0.34     |
| total_timesteps    | 66500    |
| value_loss         | 6.66e+04 |
---------------------------------
26.0
26.0
27.39
21.5
---------------------------------
| ep_len_mean        | 27.4     |
| ep_reward_mean     | 179      |
| explained_variance | 0.899    |
| fps                | 482      |
| nupdates           | 13400    |
| policy_entropy     | 0.222    |
| total_timesteps    | 67000    |
| value_loss         | 16       |
---------------------------------
---------------------------------
| ep_len_mean        | 23.5     |
| ep_reward_mean     | 185      |
| explained_variance | -0.38    |
| fps                | 482      |
| nupdates           | 13500    |
| policy_entropy     | 0.14     |
| total_timesteps    | 67500    |
| value_loss         | 66.9     |
---------------------------------
13.0
13.0
24.84
24.0
---------------------------------
| ep_len_mean        | 24.8     |
| ep_reward_mean     | 183      |
| explained_variance | 0.561    |
| fps                | 482      |
| nupdates           | 13600    |
| policy_entropy     | 0.492    |
| total_timesteps    | 68000    |
| value_loss         | 23.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.5     |
| ep_reward_mean     | 178      |
| explained_variance | 0.517    |
| fps                | 482      |
| nupdates           | 13700    |
| policy_entropy     | 0.366    |
| total_timesteps    | 68500    |
| value_loss         | 31.5     |
---------------------------------
10.0
10.0
25.91
12.5
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 179      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 13800    |
| policy_entropy     | 0.495    |
| total_timesteps    | 69000    |
| value_loss         | 0.00524  |
---------------------------------
---------------------------------
| ep_len_mean        | 29       |
| ep_reward_mean     | 175      |
| explained_variance | -0.911   |
| fps                | 482      |
| nupdates           | 13900    |
| policy_entropy     | 0.534    |
| total_timesteps    | 69500    |
| value_loss         | 24.4     |
---------------------------------
23.0
23.0
30.24
20.5
---------------------------------
| ep_len_mean        | 30.2     |
| ep_reward_mean     | 173      |
| explained_variance | -0.122   |
| fps                | 482      |
| nupdates           | 14000    |
| policy_entropy     | 0.503    |
| total_timesteps    | 70000    |
| value_loss         | 195      |
---------------------------------
---------------------------------
| ep_len_mean        | 33.5     |
| ep_reward_mean     | 166      |
| explained_variance | -0.34    |
| fps                | 482      |
| nupdates           | 14100    |
| policy_entropy     | 0.114    |
| total_timesteps    | 70500    |
| value_loss         | 2.28     |
---------------------------------
10.0
10.0
34.69
18.0
---------------------------------
| ep_len_mean        | 34.7     |
| ep_reward_mean     | 165      |
| explained_variance | -1.97    |
| fps                | 482      |
| nupdates           | 14200    |
| policy_entropy     | 0.562    |
| total_timesteps    | 71000    |
| value_loss         | 24.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 29.9     |
| ep_reward_mean     | 179      |
| explained_variance | -338     |
| fps                | 482      |
| nupdates           | 14300    |
| policy_entropy     | 0.609    |
| total_timesteps    | 71500    |
| value_loss         | 0.297    |
---------------------------------
21.0
21.0
31.16
25.0
---------------------------------
| ep_len_mean        | 31.2     |
| ep_reward_mean     | 175      |
| explained_variance | 0.633    |
| fps                | 482      |
| nupdates           | 14400    |
| policy_entropy     | 0.135    |
| total_timesteps    | 72000    |
| value_loss         | 53.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 31       |
| ep_reward_mean     | 175      |
| explained_variance | -277     |
| fps                | 482      |
| nupdates           | 14500    |
| policy_entropy     | 0.891    |
| total_timesteps    | 72500    |
| value_loss         | 0.00177  |
---------------------------------
10.0
10.0
30.68
13.5
---------------------------------
| ep_len_mean        | 30.7     |
| ep_reward_mean     | 176      |
| explained_variance | 0.00501  |
| fps                | 482      |
| nupdates           | 14600    |
| policy_entropy     | 0.0623   |
| total_timesteps    | 73000    |
| value_loss         | 2.84e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 28       |
| ep_reward_mean     | 181      |
| explained_variance | -0.611   |
| fps                | 482      |
| nupdates           | 14700    |
| policy_entropy     | 0.105    |
| total_timesteps    | 73500    |
| value_loss         | 1.37e+05 |
---------------------------------
10.0
10.0
28.27
18.5
---------------------------------
| ep_len_mean        | 28.3     |
| ep_reward_mean     | 180      |
| explained_variance | -182     |
| fps                | 482      |
| nupdates           | 14800    |
| policy_entropy     | 0.777    |
| total_timesteps    | 74000    |
| value_loss         | 0.478    |
---------------------------------
---------------------------------
| ep_len_mean        | 32.1     |
| ep_reward_mean     | 171      |
| explained_variance | -0.39    |
| fps                | 482      |
| nupdates           | 14900    |
| policy_entropy     | 0.302    |
| total_timesteps    | 74500    |
| value_loss         | 375      |
---------------------------------
10.0
10.0
30.81
21.0
---------------------------------
| ep_len_mean        | 30.8     |
| ep_reward_mean     | 173      |
| explained_variance | -0.554   |
| fps                | 482      |
| nupdates           | 15000    |
| policy_entropy     | 0.237    |
| total_timesteps    | 75000    |
| value_loss         | 322      |
---------------------------------
---------------------------------
| ep_len_mean        | 26.7     |
| ep_reward_mean     | 181      |
| explained_variance | -5.1     |
| fps                | 482      |
| nupdates           | 15100    |
| policy_entropy     | 0.906    |
| total_timesteps    | 75500    |
| value_loss         | 3.01     |
---------------------------------
26.0
26.0
28.54
25.0
---------------------------------
| ep_len_mean        | 28.5     |
| ep_reward_mean     | 177      |
| explained_variance | 0.701    |
| fps                | 482      |
| nupdates           | 15200    |
| policy_entropy     | 0.0519   |
| total_timesteps    | 76000    |
| value_loss         | 0.59     |
---------------------------------
---------------------------------
| ep_len_mean        | 28.8     |
| ep_reward_mean     | 174      |
| explained_variance | -0.0489  |
| fps                | 482      |
| nupdates           | 15300    |
| policy_entropy     | 0.0594   |
| total_timesteps    | 76500    |
| value_loss         | 7.04e+04 |
---------------------------------
34.0
34.0
24.57
22.5
---------------------------------
| ep_len_mean        | 24.6     |
| ep_reward_mean     | 186      |
| explained_variance | -0.0365  |
| fps                | 482      |
| nupdates           | 15400    |
| policy_entropy     | 0.552    |
| total_timesteps    | 77000    |
| value_loss         | 2.42e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 23.7     |
| ep_reward_mean     | 188      |
| explained_variance | 0.886    |
| fps                | 482      |
| nupdates           | 15500    |
| policy_entropy     | 0.0731   |
| total_timesteps    | 77500    |
| value_loss         | 28.9     |
---------------------------------
9.0
9.0
20.77
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 195      |
| explained_variance | -15.8    |
| fps                | 482      |
| nupdates           | 15600    |
| policy_entropy     | 0.338    |
| total_timesteps    | 78000    |
| value_loss         | 26.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 198      |
| explained_variance | -1.75    |
| fps                | 482      |
| nupdates           | 15700    |
| policy_entropy     | 0.282    |
| total_timesteps    | 78500    |
| value_loss         | 53.5     |
---------------------------------
11.0
11.0
20.47
10.0
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 194      |
| explained_variance | -1.11    |
| fps                | 482      |
| nupdates           | 15800    |
| policy_entropy     | 0.136    |
| total_timesteps    | 79000    |
| value_loss         | 1.33e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 197      |
| explained_variance | 0.834    |
| fps                | 482      |
| nupdates           | 15900    |
| policy_entropy     | 0.391    |
| total_timesteps    | 79500    |
| value_loss         | 74.9     |
---------------------------------
21.0
21.0
21.76
20.5
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 190      |
| explained_variance | -176     |
| fps                | 482      |
| nupdates           | 16000    |
| policy_entropy     | 0.308    |
| total_timesteps    | 80000    |
| value_loss         | 835      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.3     |
| ep_reward_mean     | 190      |
| explained_variance | -0.0762  |
| fps                | 482      |
| nupdates           | 16100    |
| policy_entropy     | 0.773    |
| total_timesteps    | 80500    |
| value_loss         | 0.922    |
---------------------------------
24.0
24.0
21.54
13.0
---------------------------------
| ep_len_mean        | 21.5     |
| ep_reward_mean     | 192      |
| explained_variance | -2.94    |
| fps                | 482      |
| nupdates           | 16200    |
| policy_entropy     | 0.717    |
| total_timesteps    | 81000    |
| value_loss         | 3.97     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.5     |
| ep_reward_mean     | 189      |
| explained_variance | -11.9    |
| fps                | 482      |
| nupdates           | 16300    |
| policy_entropy     | 0.35     |
| total_timesteps    | 81500    |
| value_loss         | 60.4     |
---------------------------------
9.0
9.0
20.07
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 196      |
| explained_variance | -1.5     |
| fps                | 482      |
| nupdates           | 16400    |
| policy_entropy     | 0.22     |
| total_timesteps    | 82000    |
| value_loss         | 1.01e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 201      |
| explained_variance | -6.88    |
| fps                | 482      |
| nupdates           | 16500    |
| policy_entropy     | 0.0799   |
| total_timesteps    | 82500    |
| value_loss         | 72.5     |
---------------------------------
9.0
9.0
17.74
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 206      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 16600    |
| policy_entropy     | 0.134    |
| total_timesteps    | 83000    |
| value_loss         | 106      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 201      |
| explained_variance | -0.764   |
| fps                | 482      |
| nupdates           | 16700    |
| policy_entropy     | 0.531    |
| total_timesteps    | 83500    |
| value_loss         | 40.9     |
---------------------------------
41.0
41.0
21.13
30.5
---------------------------------
| ep_len_mean        | 21.1     |
| ep_reward_mean     | 197      |
| explained_variance | -9.48    |
| fps                | 482      |
| nupdates           | 16800    |
| policy_entropy     | 0.268    |
| total_timesteps    | 84000    |
| value_loss         | 16       |
---------------------------------
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 192      |
| explained_variance | 0.173    |
| fps                | 482      |
| nupdates           | 16900    |
| policy_entropy     | 0.416    |
| total_timesteps    | 84500    |
| value_loss         | 108      |
---------------------------------
10.0
10.0
21.91
13.0
---------------------------------
| ep_len_mean        | 21.9     |
| ep_reward_mean     | 192      |
| explained_variance | 0        |
| fps                | 482      |
| nupdates           | 17000    |
| policy_entropy     | 0.45     |
| total_timesteps    | 85000    |
| value_loss         | 0.415    |
---------------------------------
---------------------------------
| ep_len_mean        | 23.3     |
| ep_reward_mean     | 189      |
| explained_variance | -5.19    |
| fps                | 482      |
| nupdates           | 17100    |
| policy_entropy     | 0.417    |
| total_timesteps    | 85500    |
| value_loss         | 1.35e+05 |
---------------------------------
34.0
34.0
20.73
10.0
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 196      |
| explained_variance | -0.177   |
| fps                | 482      |
| nupdates           | 17200    |
| policy_entropy     | 0.221    |
| total_timesteps    | 86000    |
| value_loss         | 5.48e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 198      |
| explained_variance | -739     |
| fps                | 481      |
| nupdates           | 17300    |
| policy_entropy     | 0.509    |
| total_timesteps    | 86500    |
| value_loss         | 112      |
---------------------------------
10.0
10.0
19.51
20.5
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 199      |
| explained_variance | -280     |
| fps                | 481      |
| nupdates           | 17400    |
| policy_entropy     | 0.496    |
| total_timesteps    | 87000    |
| value_loss         | 47.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 201      |
| explained_variance | -0.0743  |
| fps                | 481      |
| nupdates           | 17500    |
| policy_entropy     | 0.224    |
| total_timesteps    | 87500    |
| value_loss         | 274      |
---------------------------------
10.0
10.0
20.51
10.0
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 199      |
| explained_variance | -22.5    |
| fps                | 481      |
| nupdates           | 17600    |
| policy_entropy     | 0.301    |
| total_timesteps    | 88000    |
| value_loss         | 154      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 199      |
| explained_variance | -5.41    |
| fps                | 481      |
| nupdates           | 17700    |
| policy_entropy     | 0.245    |
| total_timesteps    | 88500    |
| value_loss         | 145      |
---------------------------------
9.0
9.0
19.16
15.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 202      |
| explained_variance | -0.0956  |
| fps                | 481      |
| nupdates           | 17800    |
| policy_entropy     | 0.301    |
| total_timesteps    | 89000    |
| value_loss         | 213      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 202      |
| explained_variance | -2.9     |
| fps                | 481      |
| nupdates           | 17900    |
| policy_entropy     | 0.348    |
| total_timesteps    | 89500    |
| value_loss         | 660      |
---------------------------------
13.0
13.0
19.84
29.0
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 198      |
| explained_variance | -4.73    |
| fps                | 481      |
| nupdates           | 18000    |
| policy_entropy     | 0.0485   |
| total_timesteps    | 90000    |
| value_loss         | 1.1e+05  |
---------------------------------
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 198      |
| explained_variance | 0.615    |
| fps                | 481      |
| nupdates           | 18100    |
| policy_entropy     | 0.41     |
| total_timesteps    | 90500    |
| value_loss         | 75.6     |
---------------------------------
29.0
29.0
20.59
11.5
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 198      |
| explained_variance | -4.59    |
| fps                | 481      |
| nupdates           | 18200    |
| policy_entropy     | 0.0919   |
| total_timesteps    | 91000    |
| value_loss         | 88.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 198      |
| explained_variance | -0.0209  |
| fps                | 481      |
| nupdates           | 18300    |
| policy_entropy     | 0.152    |
| total_timesteps    | 91500    |
| value_loss         | 6.33e+04 |
---------------------------------
42.0
42.0
20.06
15.5
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 200      |
| explained_variance | 0.868    |
| fps                | 481      |
| nupdates           | 18400    |
| policy_entropy     | 0.0705   |
| total_timesteps    | 92000    |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 202      |
| explained_variance | -19.2    |
| fps                | 481      |
| nupdates           | 18500    |
| policy_entropy     | 0.645    |
| total_timesteps    | 92500    |
| value_loss         | 107      |
---------------------------------
79.0
79.0
19.38
18.0
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 200      |
| explained_variance | 0.73     |
| fps                | 481      |
| nupdates           | 18600    |
| policy_entropy     | 0.0958   |
| total_timesteps    | 93000    |
| value_loss         | 73.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 200      |
| explained_variance | 0.233    |
| fps                | 481      |
| nupdates           | 18700    |
| policy_entropy     | 0.129    |
| total_timesteps    | 93500    |
| value_loss         | 1.02e+05 |
---------------------------------
26.0
26.0
19.61
10.0
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 202      |
| explained_variance | -16.6    |
| fps                | 481      |
| nupdates           | 18800    |
| policy_entropy     | 0.0948   |
| total_timesteps    | 94000    |
| value_loss         | 60.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 204      |
| explained_variance | -0.159   |
| fps                | 481      |
| nupdates           | 18900    |
| policy_entropy     | 0.121    |
| total_timesteps    | 94500    |
| value_loss         | 7.44e+04 |
---------------------------------
9.0
9.0
19.17
13.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 203      |
| explained_variance | 0.486    |
| fps                | 481      |
| nupdates           | 19000    |
| policy_entropy     | 0.101    |
| total_timesteps    | 95000    |
| value_loss         | 224      |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 202      |
| explained_variance | 0.278    |
| fps                | 481      |
| nupdates           | 19100    |
| policy_entropy     | 0.609    |
| total_timesteps    | 95500    |
| value_loss         | 14.7     |
---------------------------------
11.0
11.0
17.91
18.5
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | 0.474    |
| fps                | 481      |
| nupdates           | 19200    |
| policy_entropy     | 0.327    |
| total_timesteps    | 96000    |
| value_loss         | 411      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 202      |
| explained_variance | 0.741    |
| fps                | 481      |
| nupdates           | 19300    |
| policy_entropy     | 0.035    |
| total_timesteps    | 96500    |
| value_loss         | 74.2     |
---------------------------------
35.0
35.0
19.37
12.5
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 203      |
| explained_variance | -0.783   |
| fps                | 481      |
| nupdates           | 19400    |
| policy_entropy     | 0.0381   |
| total_timesteps    | 97000    |
| value_loss         | 351      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 203      |
| explained_variance | -3.55    |
| fps                | 481      |
| nupdates           | 19500    |
| policy_entropy     | 0.78     |
| total_timesteps    | 97500    |
| value_loss         | 44.5     |
---------------------------------
44.0
44.0
18.62
21.5
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0.328    |
| fps                | 481      |
| nupdates           | 19600    |
| policy_entropy     | 0.0351   |
| total_timesteps    | 98000    |
| value_loss         | 556      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 200      |
| explained_variance | -0.519   |
| fps                | 481      |
| nupdates           | 19700    |
| policy_entropy     | 0.0586   |
| total_timesteps    | 98500    |
| value_loss         | 651      |
---------------------------------
34.0
34.0
19.13
11.0
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 202      |
| explained_variance | -0.0332  |
| fps                | 481      |
| nupdates           | 19800    |
| policy_entropy     | 0.11     |
| total_timesteps    | 99000    |
| value_loss         | 1.26e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 200      |
| explained_variance | 0.111    |
| fps                | 481      |
| nupdates           | 19900    |
| policy_entropy     | 0.275    |
| total_timesteps    | 99500    |
| value_loss         | 4.46e+04 |
---------------------------------
20.0
20.0
20.66
19.5
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 199      |
| explained_variance | 0.463    |
| fps                | 481      |
| nupdates           | 20000    |
| policy_entropy     | 0.725    |
| total_timesteps    | 100000   |
| value_loss         | 92.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 194      |
| explained_variance | -1.12    |
| fps                | 481      |
| nupdates           | 20100    |
| policy_entropy     | 0.583    |
| total_timesteps    | 100500   |
| value_loss         | 36.1     |
---------------------------------
12.0
12.0
21.69
10.0
---------------------------------
| ep_len_mean        | 21.7     |
| ep_reward_mean     | 196      |
| explained_variance | 0.163    |
| fps                | 481      |
| nupdates           | 20200    |
| policy_entropy     | 0.0644   |
| total_timesteps    | 101000   |
| value_loss         | 1.87e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 198      |
| explained_variance | 0.188    |
| fps                | 480      |
| nupdates           | 20300    |
| policy_entropy     | 0.0595   |
| total_timesteps    | 101500   |
| value_loss         | 4.7e+03  |
---------------------------------
9.0
9.0
20.96
12.5
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 199      |
| explained_variance | -0.61    |
| fps                | 480      |
| nupdates           | 20400    |
| policy_entropy     | 0.574    |
| total_timesteps    | 102000   |
| value_loss         | 166      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 202      |
| explained_variance | 0.931    |
| fps                | 480      |
| nupdates           | 20500    |
| policy_entropy     | 0.0793   |
| total_timesteps    | 102500   |
| value_loss         | 8.52     |
---------------------------------
9.0
9.0
20.19
11.0
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 200      |
| explained_variance | -0.495   |
| fps                | 480      |
| nupdates           | 20600    |
| policy_entropy     | 0.0359   |
| total_timesteps    | 103000   |
| value_loss         | 387      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 199      |
| explained_variance | 0.199    |
| fps                | 480      |
| nupdates           | 20700    |
| policy_entropy     | 0.184    |
| total_timesteps    | 103500   |
| value_loss         | 1.03e+04 |
---------------------------------
17.0
17.0
20.92
19.5
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 198      |
| explained_variance | 0        |
| fps                | 480      |
| nupdates           | 20800    |
| policy_entropy     | 0.513    |
| total_timesteps    | 104000   |
| value_loss         | 39.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.3     |
| ep_reward_mean     | 200      |
| explained_variance | -1.04    |
| fps                | 480      |
| nupdates           | 20900    |
| policy_entropy     | 0.0796   |
| total_timesteps    | 104500   |
| value_loss         | 25.3     |
---------------------------------
9.0
9.0
19.46
10.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 202      |
| explained_variance | -0.689   |
| fps                | 480      |
| nupdates           | 21000    |
| policy_entropy     | 0.467    |
| total_timesteps    | 105000   |
| value_loss         | 125      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 198      |
| explained_variance | -8.88    |
| fps                | 480      |
| nupdates           | 21100    |
| policy_entropy     | 0.23     |
| total_timesteps    | 105500   |
| value_loss         | 598      |
---------------------------------
37.0
37.0
21.29
11.5
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 196      |
| explained_variance | -2.06    |
| fps                | 480      |
| nupdates           | 21200    |
| policy_entropy     | 0.087    |
| total_timesteps    | 106000   |
| value_loss         | 16.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 199      |
| explained_variance | -1.33    |
| fps                | 480      |
| nupdates           | 21300    |
| policy_entropy     | 0.382    |
| total_timesteps    | 106500   |
| value_loss         | 115      |
---------------------------------
17.0
17.0
20.9
11.0
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 196      |
| explained_variance | -0.117   |
| fps                | 480      |
| nupdates           | 21400    |
| policy_entropy     | 0.1      |
| total_timesteps    | 107000   |
| value_loss         | 2.23e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 201      |
| explained_variance | -16      |
| fps                | 480      |
| nupdates           | 21500    |
| policy_entropy     | 0.224    |
| total_timesteps    | 107500   |
| value_loss         | 285      |
---------------------------------
25.0
25.0
19.6
11.5
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 200      |
| explained_variance | -0.47    |
| fps                | 480      |
| nupdates           | 21600    |
| policy_entropy     | 0.0565   |
| total_timesteps    | 108000   |
| value_loss         | 430      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 200      |
| explained_variance | 0.769    |
| fps                | 480      |
| nupdates           | 21700    |
| policy_entropy     | 0.672    |
| total_timesteps    | 108500   |
| value_loss         | 27.1     |
---------------------------------
10.0
10.0
19.19
10.5
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 202      |
| explained_variance | -1.04    |
| fps                | 480      |
| nupdates           | 21800    |
| policy_entropy     | 0.686    |
| total_timesteps    | 109000   |
| value_loss         | 64.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 201      |
| explained_variance | 0.583    |
| fps                | 480      |
| nupdates           | 21900    |
| policy_entropy     | 0.0798   |
| total_timesteps    | 109500   |
| value_loss         | 3.49e+03 |
---------------------------------
10.0
10.0
19.06
10.5
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 202      |
| explained_variance | -9.72    |
| fps                | 480      |
| nupdates           | 22000    |
| policy_entropy     | 0.566    |
| total_timesteps    | 110000   |
| value_loss         | 226      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 203      |
| explained_variance | -1.8     |
| fps                | 480      |
| nupdates           | 22100    |
| policy_entropy     | 0.0513   |
| total_timesteps    | 110500   |
| value_loss         | 77.5     |
---------------------------------
10.0
10.0
19.24
16.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 201      |
| explained_variance | 0.132    |
| fps                | 480      |
| nupdates           | 22200    |
| policy_entropy     | 0.0702   |
| total_timesteps    | 111000   |
| value_loss         | 7.55e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 202      |
| explained_variance | 0.206    |
| fps                | 480      |
| nupdates           | 22300    |
| policy_entropy     | 0.366    |
| total_timesteps    | 111500   |
| value_loss         | 92.2     |
---------------------------------
10.0
10.0
18.83
14.0
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 202      |
| explained_variance | -0.125   |
| fps                | 480      |
| nupdates           | 22400    |
| policy_entropy     | 0.329    |
| total_timesteps    | 112000   |
| value_loss         | 57.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 203      |
| explained_variance | -1.46    |
| fps                | 480      |
| nupdates           | 22500    |
| policy_entropy     | 0.119    |
| total_timesteps    | 112500   |
| value_loss         | 106      |
---------------------------------
9.0
9.0
17.53
9.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | 0.236    |
| fps                | 480      |
| nupdates           | 22600    |
| policy_entropy     | 0.0581   |
| total_timesteps    | 113000   |
| value_loss         | 123      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.32     |
| fps                | 480      |
| nupdates           | 22700    |
| policy_entropy     | 0.0692   |
| total_timesteps    | 113500   |
| value_loss         | 163      |
---------------------------------
22.0
22.0
17.03
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 207      |
| explained_variance | 0.77     |
| fps                | 480      |
| nupdates           | 22800    |
| policy_entropy     | 0.035    |
| total_timesteps    | 114000   |
| value_loss         | 898      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 205      |
| explained_variance | -5.48    |
| fps                | 480      |
| nupdates           | 22900    |
| policy_entropy     | 0.243    |
| total_timesteps    | 114500   |
| value_loss         | 835      |
---------------------------------
24.0
24.0
18.51
12.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 203      |
| explained_variance | 0.782    |
| fps                | 480      |
| nupdates           | 23000    |
| policy_entropy     | 0.0367   |
| total_timesteps    | 115000   |
| value_loss         | 223      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 205      |
| explained_variance | 0.649    |
| fps                | 480      |
| nupdates           | 23100    |
| policy_entropy     | 0.0882   |
| total_timesteps    | 115500   |
| value_loss         | 50.4     |
---------------------------------
27.0
27.0
19.76
14.5
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 205      |
| explained_variance | -4.44    |
| fps                | 480      |
| nupdates           | 23200    |
| policy_entropy     | 0.453    |
| total_timesteps    | 116000   |
| value_loss         | 298      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 207      |
| explained_variance | -2.71    |
| fps                | 480      |
| nupdates           | 23300    |
| policy_entropy     | 0.791    |
| total_timesteps    | 116500   |
| value_loss         | 85.2     |
---------------------------------
25.0
25.0
18.85
11.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 205      |
| explained_variance | -1.98    |
| fps                | 479      |
| nupdates           | 23400    |
| policy_entropy     | 0.235    |
| total_timesteps    | 117000   |
| value_loss         | 1.16e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 203      |
| explained_variance | -2.31    |
| fps                | 480      |
| nupdates           | 23500    |
| policy_entropy     | 0.205    |
| total_timesteps    | 117500   |
| value_loss         | 370      |
---------------------------------
38.0
38.0
21.27
36.0
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 201      |
| explained_variance | -33.3    |
| fps                | 480      |
| nupdates           | 23600    |
| policy_entropy     | 0.392    |
| total_timesteps    | 118000   |
| value_loss         | 400      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 200      |
| explained_variance | -2.73    |
| fps                | 480      |
| nupdates           | 23700    |
| policy_entropy     | 0.21     |
| total_timesteps    | 118500   |
| value_loss         | 22.4     |
---------------------------------
53.0
53.0
22.94
42.0
---------------------------------
| ep_len_mean        | 22.9     |
| ep_reward_mean     | 193      |
| explained_variance | 0.139    |
| fps                | 480      |
| nupdates           | 23800    |
| policy_entropy     | 0.341    |
| total_timesteps    | 119000   |
| value_loss         | 110      |
---------------------------------
---------------------------------
| ep_len_mean        | 24.3     |
| ep_reward_mean     | 187      |
| explained_variance | -2.71    |
| fps                | 480      |
| nupdates           | 23900    |
| policy_entropy     | 0.096    |
| total_timesteps    | 119500   |
| value_loss         | 98.1     |
---------------------------------
10.0
10.0
23.48
20.5
---------------------------------
| ep_len_mean        | 23.5     |
| ep_reward_mean     | 187      |
| explained_variance | -3.52    |
| fps                | 480      |
| nupdates           | 24000    |
| policy_entropy     | 0.559    |
| total_timesteps    | 120000   |
| value_loss         | 19.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 21.7     |
| ep_reward_mean     | 191      |
| explained_variance | 0        |
| fps                | 480      |
| nupdates           | 24100    |
| policy_entropy     | 0.336    |
| total_timesteps    | 120500   |
| value_loss         | 69.8     |
---------------------------------
9.0
9.0
19.75
10.0
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 195      |
| explained_variance | -3.99    |
| fps                | 480      |
| nupdates           | 24200    |
| policy_entropy     | 0.174    |
| total_timesteps    | 121000   |
| value_loss         | 2.51e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 199      |
| explained_variance | -39.9    |
| fps                | 479      |
| nupdates           | 24300    |
| policy_entropy     | 0.579    |
| total_timesteps    | 121500   |
| value_loss         | 682      |
---------------------------------
10.0
10.0
17.88
13.5
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 200      |
| explained_variance | 0.223    |
| fps                | 479      |
| nupdates           | 24400    |
| policy_entropy     | 0.0671   |
| total_timesteps    | 122000   |
| value_loss         | 78.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 202      |
| explained_variance | -5.8     |
| fps                | 479      |
| nupdates           | 24500    |
| policy_entropy     | 0.569    |
| total_timesteps    | 122500   |
| value_loss         | 167      |
---------------------------------
22.0
22.0
18.81
13.0
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 200      |
| explained_variance | -1.92    |
| fps                | 479      |
| nupdates           | 24600    |
| policy_entropy     | 0.259    |
| total_timesteps    | 123000   |
| value_loss         | 69       |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 200      |
| explained_variance | -0.0553  |
| fps                | 479      |
| nupdates           | 24700    |
| policy_entropy     | 0.392    |
| total_timesteps    | 123500   |
| value_loss         | 1.22e+04 |
---------------------------------
38.0
38.0
19.99
12.0
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 200      |
| explained_variance | -0.828   |
| fps                | 479      |
| nupdates           | 24800    |
| policy_entropy     | 0.34     |
| total_timesteps    | 124000   |
| value_loss         | 675      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 202      |
| explained_variance | 0.084    |
| fps                | 479      |
| nupdates           | 24900    |
| policy_entropy     | 0.0679   |
| total_timesteps    | 124500   |
| value_loss         | 429      |
---------------------------------
28.0
28.0
18.69
19.5
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 202      |
| explained_variance | 0.37     |
| fps                | 479      |
| nupdates           | 25000    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 125000   |
| value_loss         | 623      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 204      |
| explained_variance | -0.542   |
| fps                | 479      |
| nupdates           | 25100    |
| policy_entropy     | 0.0254   |
| total_timesteps    | 125500   |
| value_loss         | 304      |
---------------------------------
11.0
11.0
18.37
16.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 202      |
| explained_variance | -3.96    |
| fps                | 479      |
| nupdates           | 25200    |
| policy_entropy     | 0.456    |
| total_timesteps    | 126000   |
| value_loss         | 234      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 201      |
| explained_variance | 0        |
| fps                | 479      |
| nupdates           | 25300    |
| policy_entropy     | 0.798    |
| total_timesteps    | 126500   |
| value_loss         | 22       |
---------------------------------
28.0
28.0
19.2
16.5
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 204      |
| explained_variance | 0.77     |
| fps                | 479      |
| nupdates           | 25400    |
| policy_entropy     | 0.695    |
| total_timesteps    | 127000   |
| value_loss         | 161      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 205      |
| explained_variance | -3.13    |
| fps                | 479      |
| nupdates           | 25500    |
| policy_entropy     | 0.633    |
| total_timesteps    | 127500   |
| value_loss         | 324      |
---------------------------------
9.0
9.0
17.6
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.907    |
| fps                | 479      |
| nupdates           | 25600    |
| policy_entropy     | 0.0498   |
| total_timesteps    | 128000   |
| value_loss         | 76.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 207      |
| explained_variance | -2.41    |
| fps                | 479      |
| nupdates           | 25700    |
| policy_entropy     | 0.294    |
| total_timesteps    | 128500   |
| value_loss         | 594      |
---------------------------------
33.0
33.0
17.85
19.5
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 205      |
| explained_variance | -1.59    |
| fps                | 479      |
| nupdates           | 25800    |
| policy_entropy     | 0.463    |
| total_timesteps    | 129000   |
| value_loss         | 880      |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | 0.635    |
| fps                | 479      |
| nupdates           | 25900    |
| policy_entropy     | 0.0126   |
| total_timesteps    | 129500   |
| value_loss         | 23.2     |
---------------------------------
10.0
10.0
18.22
10.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 202      |
| explained_variance | -0.28    |
| fps                | 479      |
| nupdates           | 26000    |
| policy_entropy     | 0.0311   |
| total_timesteps    | 130000   |
| value_loss         | 1.45e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 204      |
| explained_variance | 0.834    |
| fps                | 479      |
| nupdates           | 26100    |
| policy_entropy     | 0.0415   |
| total_timesteps    | 130500   |
| value_loss         | 33.8     |
---------------------------------
23.0
23.0
17.02
21.5
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 205      |
| explained_variance | -0.906   |
| fps                | 479      |
| nupdates           | 26200    |
| policy_entropy     | 0.176    |
| total_timesteps    | 131000   |
| value_loss         | 1.95e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 207      |
| explained_variance | 0        |
| fps                | 479      |
| nupdates           | 26300    |
| policy_entropy     | 0.705    |
| total_timesteps    | 131500   |
| value_loss         | 17       |
---------------------------------
10.0
10.0
16.58
12.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 207      |
| explained_variance | 0.771    |
| fps                | 479      |
| nupdates           | 26400    |
| policy_entropy     | 0.0192   |
| total_timesteps    | 132000   |
| value_loss         | 180      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 208      |
| explained_variance | -1.28    |
| fps                | 479      |
| nupdates           | 26500    |
| policy_entropy     | 0.128    |
| total_timesteps    | 132500   |
| value_loss         | 454      |
---------------------------------
9.0
9.0
15.42
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.58     |
| fps                | 479      |
| nupdates           | 26600    |
| policy_entropy     | 0.0798   |
| total_timesteps    | 133000   |
| value_loss         | 110      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 208      |
| explained_variance | -0.0932  |
| fps                | 479      |
| nupdates           | 26700    |
| policy_entropy     | 0.323    |
| total_timesteps    | 133500   |
| value_loss         | 67.3     |
---------------------------------
13.0
13.0
16.39
22.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | -0.724   |
| fps                | 479      |
| nupdates           | 26800    |
| policy_entropy     | 0.0244   |
| total_timesteps    | 134000   |
| value_loss         | 559      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.865    |
| fps                | 479      |
| nupdates           | 26900    |
| policy_entropy     | 0.0472   |
| total_timesteps    | 134500   |
| value_loss         | 14.7     |
---------------------------------
10.0
10.0
15.97
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 213      |
| explained_variance | 0.625    |
| fps                | 479      |
| nupdates           | 27000    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 135000   |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 210      |
| explained_variance | 5.96e-08 |
| fps                | 479      |
| nupdates           | 27100    |
| policy_entropy     | 0.753    |
| total_timesteps    | 135500   |
| value_loss         | 129      |
---------------------------------
10.0
10.0
15.04
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 210      |
| explained_variance | 0.011    |
| fps                | 479      |
| nupdates           | 27200    |
| policy_entropy     | 0.0602   |
| total_timesteps    | 136000   |
| value_loss         | 131      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | -0.174   |
| fps                | 479      |
| nupdates           | 27300    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 136500   |
| value_loss         | 361      |
---------------------------------
20.0
20.0
15.06
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | 5.96e-08 |
| fps                | 479      |
| nupdates           | 27400    |
| policy_entropy     | 0.12     |
| total_timesteps    | 137000   |
| value_loss         | 269      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -75.5    |
| fps                | 479      |
| nupdates           | 27500    |
| policy_entropy     | 0.169    |
| total_timesteps    | 137500   |
| value_loss         | 1.05e+03 |
---------------------------------
24.0
24.0
19.23
11.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 199      |
| explained_variance | -2.05    |
| fps                | 479      |
| nupdates           | 27600    |
| policy_entropy     | 0.0561   |
| total_timesteps    | 138000   |
| value_loss         | 36.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 198      |
| explained_variance | 0.58     |
| fps                | 479      |
| nupdates           | 27700    |
| policy_entropy     | 0.531    |
| total_timesteps    | 138500   |
| value_loss         | 41.8     |
---------------------------------
9.0
9.0
20.82
19.0
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 194      |
| explained_variance | 0        |
| fps                | 479      |
| nupdates           | 27800    |
| policy_entropy     | 0.744    |
| total_timesteps    | 139000   |
| value_loss         | 13.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 206      |
| explained_variance | -2.12    |
| fps                | 479      |
| nupdates           | 27900    |
| policy_entropy     | 0.409    |
| total_timesteps    | 139500   |
| value_loss         | 403      |
---------------------------------
9.0
9.0
18.4
22.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 206      |
| explained_variance | -38.1    |
| fps                | 479      |
| nupdates           | 28000    |
| policy_entropy     | 0.331    |
| total_timesteps    | 140000   |
| value_loss         | 880      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 205      |
| explained_variance | -1.15    |
| fps                | 479      |
| nupdates           | 28100    |
| policy_entropy     | 0.0669   |
| total_timesteps    | 140500   |
| value_loss         | 5.51e+03 |
---------------------------------
11.0
11.0
19.28
11.5
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 205      |
| explained_variance | -1.59    |
| fps                | 479      |
| nupdates           | 28200    |
| policy_entropy     | 0.279    |
| total_timesteps    | 141000   |
| value_loss         | 223      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.386    |
| fps                | 479      |
| nupdates           | 28300    |
| policy_entropy     | 0.0315   |
| total_timesteps    | 141500   |
| value_loss         | 3.55e+03 |
---------------------------------
12.0
12.0
19.16
9.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 203      |
| explained_variance | -0.312   |
| fps                | 479      |
| nupdates           | 28400    |
| policy_entropy     | 0.144    |
| total_timesteps    | 142000   |
| value_loss         | 290      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 202      |
| explained_variance | -13.9    |
| fps                | 479      |
| nupdates           | 28500    |
| policy_entropy     | 0.643    |
| total_timesteps    | 142500   |
| value_loss         | 652      |
---------------------------------
26.0
26.0
19.03
15.5
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 204      |
| explained_variance | -0.053   |
| fps                | 479      |
| nupdates           | 28600    |
| policy_entropy     | 0.0203   |
| total_timesteps    | 143000   |
| value_loss         | 88.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 203      |
| explained_variance | -0.557   |
| fps                | 479      |
| nupdates           | 28700    |
| policy_entropy     | 0.362    |
| total_timesteps    | 143500   |
| value_loss         | 59.5     |
---------------------------------
9.0
9.0
19.78
10.0
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 203      |
| explained_variance | -1.16    |
| fps                | 479      |
| nupdates           | 28800    |
| policy_entropy     | 0.193    |
| total_timesteps    | 144000   |
| value_loss         | 509      |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | -3       |
| fps                | 478      |
| nupdates           | 28900    |
| policy_entropy     | 0.237    |
| total_timesteps    | 144500   |
| value_loss         | 327      |
---------------------------------
9.0
9.0
17.62
10.0
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 204      |
| explained_variance | -0.486   |
| fps                | 478      |
| nupdates           | 29000    |
| policy_entropy     | 0.29     |
| total_timesteps    | 145000   |
| value_loss         | 405      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 207      |
| explained_variance | 0.704    |
| fps                | 478      |
| nupdates           | 29100    |
| policy_entropy     | 0.0423   |
| total_timesteps    | 145500   |
| value_loss         | 23.9     |
---------------------------------
25.0
25.0
16.61
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 205      |
| explained_variance | 0.932    |
| fps                | 478      |
| nupdates           | 29200    |
| policy_entropy     | 0.0377   |
| total_timesteps    | 146000   |
| value_loss         | 41.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.963    |
| fps                | 478      |
| nupdates           | 29300    |
| policy_entropy     | 0.16     |
| total_timesteps    | 146500   |
| value_loss         | 3.63     |
---------------------------------
11.0
11.0
15.78
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 208      |
| explained_variance | -2       |
| fps                | 478      |
| nupdates           | 29400    |
| policy_entropy     | 0.0722   |
| total_timesteps    | 147000   |
| value_loss         | 132      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 208      |
| explained_variance | -16.8    |
| fps                | 478      |
| nupdates           | 29500    |
| policy_entropy     | 0.652    |
| total_timesteps    | 147500   |
| value_loss         | 548      |
---------------------------------
10.0
10.0
17.18
10.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 207      |
| explained_variance | -0.626   |
| fps                | 478      |
| nupdates           | 29600    |
| policy_entropy     | 0.0233   |
| total_timesteps    | 148000   |
| value_loss         | 416      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 206      |
| explained_variance | -1.1     |
| fps                | 478      |
| nupdates           | 29700    |
| policy_entropy     | 0.0371   |
| total_timesteps    | 148500   |
| value_loss         | 288      |
---------------------------------
11.0
11.0
18.57
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 206      |
| explained_variance | -1.76    |
| fps                | 478      |
| nupdates           | 29800    |
| policy_entropy     | 0.26     |
| total_timesteps    | 149000   |
| value_loss         | 115      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 209      |
| explained_variance | -1.66    |
| fps                | 478      |
| nupdates           | 29900    |
| policy_entropy     | 0.357    |
| total_timesteps    | 149500   |
| value_loss         | 107      |
---------------------------------
10.0
10.0
16.76
10.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 478      |
| nupdates           | 30000    |
| policy_entropy     | 0.838    |
| total_timesteps    | 150000   |
| value_loss         | 66.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 210      |
| explained_variance | -2.66    |
| fps                | 478      |
| nupdates           | 30100    |
| policy_entropy     | 0.451    |
| total_timesteps    | 150500   |
| value_loss         | 202      |
---------------------------------
9.0
9.0
16.87
11.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 212      |
| explained_variance | -0.19    |
| fps                | 478      |
| nupdates           | 30200    |
| policy_entropy     | 0.147    |
| total_timesteps    | 151000   |
| value_loss         | 224      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.834    |
| fps                | 478      |
| nupdates           | 30300    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 151500   |
| value_loss         | 14.1     |
---------------------------------
9.0
9.0
16.59
15.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 211      |
| explained_variance | -0.718   |
| fps                | 478      |
| nupdates           | 30400    |
| policy_entropy     | 0.0289   |
| total_timesteps    | 152000   |
| value_loss         | 341      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.84     |
| fps                | 478      |
| nupdates           | 30500    |
| policy_entropy     | 0.0401   |
| total_timesteps    | 152500   |
| value_loss         | 32.2     |
---------------------------------
10.0
10.0
17.36
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 209      |
| explained_variance | -1.83    |
| fps                | 478      |
| nupdates           | 30600    |
| policy_entropy     | 0.185    |
| total_timesteps    | 153000   |
| value_loss         | 249      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0.506    |
| fps                | 478      |
| nupdates           | 30700    |
| policy_entropy     | 0.0181   |
| total_timesteps    | 153500   |
| value_loss         | 439      |
---------------------------------
11.0
11.0
16.64
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | -0.188   |
| fps                | 478      |
| nupdates           | 30800    |
| policy_entropy     | 0.381    |
| total_timesteps    | 154000   |
| value_loss         | 263      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | -0.462   |
| fps                | 478      |
| nupdates           | 30900    |
| policy_entropy     | 0.2      |
| total_timesteps    | 154500   |
| value_loss         | 87.6     |
---------------------------------
22.0
22.0
15.82
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 212      |
| explained_variance | -6.42    |
| fps                | 478      |
| nupdates           | 31000    |
| policy_entropy     | 0.181    |
| total_timesteps    | 155000   |
| value_loss         | 387      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | 0.583    |
| fps                | 478      |
| nupdates           | 31100    |
| policy_entropy     | 0.0314   |
| total_timesteps    | 155500   |
| value_loss         | 55.7     |
---------------------------------
20.0
20.0
16.71
12.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.0698   |
| fps                | 478      |
| nupdates           | 31200    |
| policy_entropy     | 0.0242   |
| total_timesteps    | 156000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 210      |
| explained_variance | -0.307   |
| fps                | 478      |
| nupdates           | 31300    |
| policy_entropy     | 0.157    |
| total_timesteps    | 156500   |
| value_loss         | 1.33e+03 |
---------------------------------
10.0
10.0
15.69
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.423    |
| fps                | 478      |
| nupdates           | 31400    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 157000   |
| value_loss         | 78.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.285    |
| fps                | 478      |
| nupdates           | 31500    |
| policy_entropy     | 0.111    |
| total_timesteps    | 157500   |
| value_loss         | 379      |
---------------------------------
11.0
11.0
16.74
12.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.803    |
| fps                | 478      |
| nupdates           | 31600    |
| policy_entropy     | 0.0237   |
| total_timesteps    | 158000   |
| value_loss         | 52.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.301    |
| fps                | 478      |
| nupdates           | 31700    |
| policy_entropy     | 0.116    |
| total_timesteps    | 158500   |
| value_loss         | 142      |
---------------------------------
19.0
19.0
16.14
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.156    |
| fps                | 478      |
| nupdates           | 31800    |
| policy_entropy     | 0.508    |
| total_timesteps    | 159000   |
| value_loss         | 92.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.309    |
| fps                | 478      |
| nupdates           | 31900    |
| policy_entropy     | 0.255    |
| total_timesteps    | 159500   |
| value_loss         | 191      |
---------------------------------
10.0
10.0
16.13
20.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 212      |
| explained_variance | -0.671   |
| fps                | 478      |
| nupdates           | 32000    |
| policy_entropy     | 0.172    |
| total_timesteps    | 160000   |
| value_loss         | 298      |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 201      |
| explained_variance | -1.07    |
| fps                | 478      |
| nupdates           | 32100    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 160500   |
| value_loss         | 983      |
---------------------------------
19.0
19.0
18.86
15.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 200      |
| explained_variance | -1.66    |
| fps                | 478      |
| nupdates           | 32200    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 161000   |
| value_loss         | 1.24e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 200      |
| explained_variance | 0        |
| fps                | 478      |
| nupdates           | 32300    |
| policy_entropy     | 0.409    |
| total_timesteps    | 161500   |
| value_loss         | 111      |
---------------------------------
11.0
11.0
21.4
15.5
---------------------------------
| ep_len_mean        | 21.4     |
| ep_reward_mean     | 196      |
| explained_variance | -6.11    |
| fps                | 478      |
| nupdates           | 32400    |
| policy_entropy     | 0.165    |
| total_timesteps    | 162000   |
| value_loss         | 595      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 209      |
| explained_variance | -9.77    |
| fps                | 478      |
| nupdates           | 32500    |
| policy_entropy     | 0.707    |
| total_timesteps    | 162500   |
| value_loss         | 562      |
---------------------------------
23.0
23.0
19.46
20.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 206      |
| explained_variance | -0.605   |
| fps                | 478      |
| nupdates           | 32600    |
| policy_entropy     | 0.323    |
| total_timesteps    | 163000   |
| value_loss         | 140      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 213      |
| explained_variance | -0.218   |
| fps                | 478      |
| nupdates           | 32700    |
| policy_entropy     | 0.0175   |
| total_timesteps    | 163500   |
| value_loss         | 238      |
---------------------------------
30.0
30.0
16.54
13.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.189    |
| fps                | 478      |
| nupdates           | 32800    |
| policy_entropy     | 0.0413   |
| total_timesteps    | 164000   |
| value_loss         | 137      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 204      |
| explained_variance | -4.23    |
| fps                | 478      |
| nupdates           | 32900    |
| policy_entropy     | 0.414    |
| total_timesteps    | 164500   |
| value_loss         | 377      |
---------------------------------
11.0
11.0
18.15
11.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 202      |
| explained_variance | 0.0285   |
| fps                | 478      |
| nupdates           | 33000    |
| policy_entropy     | 0.0262   |
| total_timesteps    | 165000   |
| value_loss         | 59.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 199      |
| explained_variance | -22.8    |
| fps                | 478      |
| nupdates           | 33100    |
| policy_entropy     | 0.489    |
| total_timesteps    | 165500   |
| value_loss         | 548      |
---------------------------------
10.0
10.0
18.24
10.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 198      |
| explained_variance | 0.294    |
| fps                | 478      |
| nupdates           | 33200    |
| policy_entropy     | 0.361    |
| total_timesteps    | 166000   |
| value_loss         | 396      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 204      |
| explained_variance | 0.101    |
| fps                | 478      |
| nupdates           | 33300    |
| policy_entropy     | 0.308    |
| total_timesteps    | 166500   |
| value_loss         | 398      |
---------------------------------
38.0
38.0
18.25
20.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 202      |
| explained_variance | 0.623    |
| fps                | 477      |
| nupdates           | 33400    |
| policy_entropy     | 0.512    |
| total_timesteps    | 167000   |
| value_loss         | 71       |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.711    |
| fps                | 477      |
| nupdates           | 33500    |
| policy_entropy     | 0.0472   |
| total_timesteps    | 167500   |
| value_loss         | 175      |
---------------------------------
10.0
10.0
17.92
19.5
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.518    |
| fps                | 477      |
| nupdates           | 33600    |
| policy_entropy     | 0.125    |
| total_timesteps    | 168000   |
| value_loss         | 400      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 212      |
| explained_variance | 0.963    |
| fps                | 477      |
| nupdates           | 33700    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 168500   |
| value_loss         | 16.4     |
---------------------------------
34.0
34.0
17.49
10.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 207      |
| explained_variance | -14.8    |
| fps                | 477      |
| nupdates           | 33800    |
| policy_entropy     | 0.445    |
| total_timesteps    | 169000   |
| value_loss         | 1.2e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 205      |
| explained_variance | -4.72    |
| fps                | 477      |
| nupdates           | 33900    |
| policy_entropy     | 0.83     |
| total_timesteps    | 169500   |
| value_loss         | 235      |
---------------------------------
36.0
36.0
17.66
14.0
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 205      |
| explained_variance | 0.183    |
| fps                | 477      |
| nupdates           | 34000    |
| policy_entropy     | 0.0253   |
| total_timesteps    | 170000   |
| value_loss         | 361      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 205      |
| explained_variance | -1.86    |
| fps                | 477      |
| nupdates           | 34100    |
| policy_entropy     | 0.172    |
| total_timesteps    | 170500   |
| value_loss         | 297      |
---------------------------------
21.0
21.0
16.78
10.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 210      |
| explained_variance | -2.34    |
| fps                | 477      |
| nupdates           | 34200    |
| policy_entropy     | 0.0493   |
| total_timesteps    | 171000   |
| value_loss         | 52.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.0803   |
| fps                | 477      |
| nupdates           | 34300    |
| policy_entropy     | 0.354    |
| total_timesteps    | 171500   |
| value_loss         | 62.3     |
---------------------------------
22.0
22.0
17.47
21.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 209      |
| explained_variance | -2.74    |
| fps                | 477      |
| nupdates           | 34400    |
| policy_entropy     | 0.0614   |
| total_timesteps    | 172000   |
| value_loss         | 386      |
---------------------------------
----------------------------------
| ep_len_mean        | 17.3      |
| ep_reward_mean     | 209       |
| explained_variance | -1.19e-07 |
| fps                | 477       |
| nupdates           | 34500     |
| policy_entropy     | 0.678     |
| total_timesteps    | 172500    |
| value_loss         | 137       |
----------------------------------
24.0
24.0
17.46
22.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.789    |
| fps                | 477      |
| nupdates           | 34600    |
| policy_entropy     | 0.0207   |
| total_timesteps    | 173000   |
| value_loss         | 244      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.72     |
| fps                | 477      |
| nupdates           | 34700    |
| policy_entropy     | 0.07     |
| total_timesteps    | 173500   |
| value_loss         | 63.3     |
---------------------------------
20.0
20.0
16.29
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.118    |
| fps                | 477      |
| nupdates           | 34800    |
| policy_entropy     | 0.293    |
| total_timesteps    | 174000   |
| value_loss         | 267      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.403    |
| fps                | 477      |
| nupdates           | 34900    |
| policy_entropy     | 0.105    |
| total_timesteps    | 174500   |
| value_loss         | 220      |
---------------------------------
11.0
11.0
16.82
15.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 210      |
| explained_variance | -3.48    |
| fps                | 477      |
| nupdates           | 35000    |
| policy_entropy     | 0.61     |
| total_timesteps    | 175000   |
| value_loss         | 570      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.0792  |
| fps                | 477      |
| nupdates           | 35100    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 175500   |
| value_loss         | 56.9     |
---------------------------------
18.0
18.0
17.48
14.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.727    |
| fps                | 477      |
| nupdates           | 35200    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 176000   |
| value_loss         | 263      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.227    |
| fps                | 477      |
| nupdates           | 35300    |
| policy_entropy     | 0.0195   |
| total_timesteps    | 176500   |
| value_loss         | 213      |
---------------------------------
10.0
10.0
14.42
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.753    |
| fps                | 477      |
| nupdates           | 35400    |
| policy_entropy     | 0.336    |
| total_timesteps    | 177000   |
| value_loss         | 28.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.555    |
| fps                | 477      |
| nupdates           | 35500    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 177500   |
| value_loss         | 442      |
---------------------------------
9.0
9.0
15.89
9.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 210      |
| explained_variance | 0.0147   |
| fps                | 477      |
| nupdates           | 35600    |
| policy_entropy     | 0.294    |
| total_timesteps    | 178000   |
| value_loss         | 34       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 210      |
| explained_variance | -1.88    |
| fps                | 477      |
| nupdates           | 35700    |
| policy_entropy     | 0.204    |
| total_timesteps    | 178500   |
| value_loss         | 292      |
---------------------------------
9.0
9.0
14.96
15.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | 0.393    |
| fps                | 477      |
| nupdates           | 35800    |
| policy_entropy     | 0.0879   |
| total_timesteps    | 179000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 210      |
| explained_variance | -0.999   |
| fps                | 477      |
| nupdates           | 35900    |
| policy_entropy     | 0.176    |
| total_timesteps    | 179500   |
| value_loss         | 252      |
---------------------------------
9.0
9.0
14.97
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 211      |
| explained_variance | 0.395    |
| fps                | 477      |
| nupdates           | 36000    |
| policy_entropy     | 0.0219   |
| total_timesteps    | 180000   |
| value_loss         | 24.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.731    |
| fps                | 477      |
| nupdates           | 36100    |
| policy_entropy     | 0.0537   |
| total_timesteps    | 180500   |
| value_loss         | 125      |
---------------------------------
19.0
19.0
14.99
10.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 211      |
| explained_variance | 0.427    |
| fps                | 477      |
| nupdates           | 36200    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 181000   |
| value_loss         | 130      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.594    |
| fps                | 477      |
| nupdates           | 36300    |
| policy_entropy     | 0.16     |
| total_timesteps    | 181500   |
| value_loss         | 132      |
---------------------------------
10.0
10.0
14.62
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 213      |
| explained_variance | -1.51    |
| fps                | 477      |
| nupdates           | 36400    |
| policy_entropy     | 0.282    |
| total_timesteps    | 182000   |
| value_loss         | 148      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 214      |
| explained_variance | -0.669   |
| fps                | 477      |
| nupdates           | 36500    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 182500   |
| value_loss         | 2.01e+03 |
---------------------------------
10.0
10.0
14.48
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | -0.846   |
| fps                | 477      |
| nupdates           | 36600    |
| policy_entropy     | 0.119    |
| total_timesteps    | 183000   |
| value_loss         | 529      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.954    |
| fps                | 477      |
| nupdates           | 36700    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 183500   |
| value_loss         | 5.94     |
---------------------------------
10.0
10.0
14.8
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | -0.358   |
| fps                | 477      |
| nupdates           | 36800    |
| policy_entropy     | 0.27     |
| total_timesteps    | 184000   |
| value_loss         | 116      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | -0.413   |
| fps                | 477      |
| nupdates           | 36900    |
| policy_entropy     | 0.264    |
| total_timesteps    | 184500   |
| value_loss         | 129      |
---------------------------------
9.0
9.0
16.16
16.0
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.773    |
| fps                | 477      |
| nupdates           | 37000    |
| policy_entropy     | 0.00911  |
| total_timesteps    | 185000   |
| value_loss         | 873      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 209      |
| explained_variance | -1.26    |
| fps                | 477      |
| nupdates           | 37100    |
| policy_entropy     | 0.181    |
| total_timesteps    | 185500   |
| value_loss         | 103      |
---------------------------------
20.0
20.0
16.74
11.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.669    |
| fps                | 477      |
| nupdates           | 37200    |
| policy_entropy     | 0.0418   |
| total_timesteps    | 186000   |
| value_loss         | 58       |
---------------------------------
----------------------------------
| ep_len_mean        | 15.9      |
| ep_reward_mean     | 212       |
| explained_variance | -1.19e-07 |
| fps                | 477       |
| nupdates           | 37300     |
| policy_entropy     | 0.284     |
| total_timesteps    | 186500    |
| value_loss         | 215       |
----------------------------------
9.0
9.0
15.9
14.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.917    |
| fps                | 477      |
| nupdates           | 37400    |
| policy_entropy     | 0.00932  |
| total_timesteps    | 187000   |
| value_loss         | 8.85     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.397    |
| fps                | 477      |
| nupdates           | 37500    |
| policy_entropy     | 0.18     |
| total_timesteps    | 187500   |
| value_loss         | 126      |
---------------------------------
11.0
11.0
17.54
11.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 207      |
| explained_variance | 0.775    |
| fps                | 477      |
| nupdates           | 37600    |
| policy_entropy     | 0.0207   |
| total_timesteps    | 188000   |
| value_loss         | 33.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.43     |
| fps                | 477      |
| nupdates           | 37700    |
| policy_entropy     | 0.274    |
| total_timesteps    | 188500   |
| value_loss         | 27.1     |
---------------------------------
22.0
22.0
17.8
15.5
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 209      |
| explained_variance | -1.11    |
| fps                | 477      |
| nupdates           | 37800    |
| policy_entropy     | 0.154    |
| total_timesteps    | 189000   |
| value_loss         | 123      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.476    |
| fps                | 477      |
| nupdates           | 37900    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 189500   |
| value_loss         | 49       |
---------------------------------
32.0
32.0
16.65
16.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.858    |
| fps                | 477      |
| nupdates           | 38000    |
| policy_entropy     | 0.179    |
| total_timesteps    | 190000   |
| value_loss         | 59.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.101    |
| fps                | 477      |
| nupdates           | 38100    |
| policy_entropy     | 0.149    |
| total_timesteps    | 190500   |
| value_loss         | 88.9     |
---------------------------------
10.0
10.0
15.48
12.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0        |
| fps                | 477      |
| nupdates           | 38200    |
| policy_entropy     | 0.356    |
| total_timesteps    | 191000   |
| value_loss         | 142      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 211      |
| explained_variance | 0.431    |
| fps                | 477      |
| nupdates           | 38300    |
| policy_entropy     | 0.515    |
| total_timesteps    | 191500   |
| value_loss         | 276      |
---------------------------------
23.0
23.0
16.7
19.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 212      |
| explained_variance | 0.857    |
| fps                | 477      |
| nupdates           | 38400    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 192000   |
| value_loss         | 530      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.733    |
| fps                | 477      |
| nupdates           | 38500    |
| policy_entropy     | 0.237    |
| total_timesteps    | 192500   |
| value_loss         | 7.41     |
---------------------------------
22.0
22.0
16.0
10.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | -0.23    |
| fps                | 477      |
| nupdates           | 38600    |
| policy_entropy     | 0.0134   |
| total_timesteps    | 193000   |
| value_loss         | 249      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.666    |
| fps                | 477      |
| nupdates           | 38700    |
| policy_entropy     | 0.0234   |
| total_timesteps    | 193500   |
| value_loss         | 135      |
---------------------------------
10.0
10.0
16.05
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.676    |
| fps                | 477      |
| nupdates           | 38800    |
| policy_entropy     | 0.0303   |
| total_timesteps    | 194000   |
| value_loss         | 33       |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | -15.2    |
| fps                | 477      |
| nupdates           | 38900    |
| policy_entropy     | 0.00665  |
| total_timesteps    | 194500   |
| value_loss         | 2.15e+03 |
---------------------------------
10.0
10.0
15.98
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 208      |
| explained_variance | 0.592    |
| fps                | 477      |
| nupdates           | 39000    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 195000   |
| value_loss         | 89       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.584    |
| fps                | 477      |
| nupdates           | 39100    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 195500   |
| value_loss         | 59.2     |
---------------------------------
13.0
13.0
14.62
19.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.518    |
| fps                | 477      |
| nupdates           | 39200    |
| policy_entropy     | 0.134    |
| total_timesteps    | 196000   |
| value_loss         | 77.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.895    |
| fps                | 477      |
| nupdates           | 39300    |
| policy_entropy     | 0.11     |
| total_timesteps    | 196500   |
| value_loss         | 12.8     |
---------------------------------
23.0
23.0
16.13
20.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.152    |
| fps                | 477      |
| nupdates           | 39400    |
| policy_entropy     | 0.153    |
| total_timesteps    | 197000   |
| value_loss         | 79.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.948    |
| fps                | 477      |
| nupdates           | 39500    |
| policy_entropy     | 0.0987   |
| total_timesteps    | 197500   |
| value_loss         | 33.3     |
---------------------------------
11.0
11.0
16.83
15.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 213      |
| explained_variance | -1.61    |
| fps                | 477      |
| nupdates           | 39600    |
| policy_entropy     | 0.131    |
| total_timesteps    | 198000   |
| value_loss         | 54.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.221    |
| fps                | 477      |
| nupdates           | 39700    |
| policy_entropy     | 0.11     |
| total_timesteps    | 198500   |
| value_loss         | 97.1     |
---------------------------------
9.0
9.0
17.79
10.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 211      |
| explained_variance | -87      |
| fps                | 477      |
| nupdates           | 39800    |
| policy_entropy     | 0.492    |
| total_timesteps    | 199000   |
| value_loss         | 2.02e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 209      |
| explained_variance | -0.212   |
| fps                | 477      |
| nupdates           | 39900    |
| policy_entropy     | 0.0685   |
| total_timesteps    | 199500   |
| value_loss         | 148      |
---------------------------------
10.0
10.0
15.26
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | -1.53    |
| fps                | 477      |
| nupdates           | 40000    |
| policy_entropy     | 0.156    |
| total_timesteps    | 200000   |
| value_loss         | 539      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.6      |
| fps                | 477      |
| nupdates           | 40100    |
| policy_entropy     | 0.153    |
| total_timesteps    | 200500   |
| value_loss         | 8.88     |
---------------------------------
26.0
26.0
13.84
10.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 214      |
| explained_variance | -5.7     |
| fps                | 476      |
| nupdates           | 40200    |
| policy_entropy     | 0.143    |
| total_timesteps    | 201000   |
| value_loss         | 336      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | -1.69    |
| fps                | 476      |
| nupdates           | 40300    |
| policy_entropy     | 0.122    |
| total_timesteps    | 201500   |
| value_loss         | 425      |
---------------------------------
15.0
15.0
14.97
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 5.96e-08 |
| fps                | 476      |
| nupdates           | 40400    |
| policy_entropy     | 0.439    |
| total_timesteps    | 202000   |
| value_loss         | 537      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 208      |
| explained_variance | -124     |
| fps                | 476      |
| nupdates           | 40500    |
| policy_entropy     | 0.365    |
| total_timesteps    | 202500   |
| value_loss         | 2.28e+03 |
---------------------------------
10.0
10.0
17.78
15.0
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.614    |
| fps                | 476      |
| nupdates           | 40600    |
| policy_entropy     | 0.0255   |
| total_timesteps    | 203000   |
| value_loss         | 240      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 207      |
| explained_variance | 0.863    |
| fps                | 476      |
| nupdates           | 40700    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 203500   |
| value_loss         | 204      |
---------------------------------
10.0
10.0
16.17
10.0
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.85     |
| fps                | 476      |
| nupdates           | 40800    |
| policy_entropy     | 0.00899  |
| total_timesteps    | 204000   |
| value_loss         | 409      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | -26.8    |
| fps                | 476      |
| nupdates           | 40900    |
| policy_entropy     | 0.6      |
| total_timesteps    | 204500   |
| value_loss         | 2.2e+03  |
---------------------------------
9.0
9.0
18.03
10.5
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | -0.805   |
| fps                | 476      |
| nupdates           | 41000    |
| policy_entropy     | 0.078    |
| total_timesteps    | 205000   |
| value_loss         | 2.07e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 206      |
| explained_variance | 0.894    |
| fps                | 476      |
| nupdates           | 41100    |
| policy_entropy     | 0.00982  |
| total_timesteps    | 205500   |
| value_loss         | 50.8     |
---------------------------------
9.0
9.0
17.1
11.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 206      |
| explained_variance | -1.62    |
| fps                | 476      |
| nupdates           | 41200    |
| policy_entropy     | 0.273    |
| total_timesteps    | 206000   |
| value_loss         | 1.01e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 212      |
| explained_variance | -0.329   |
| fps                | 476      |
| nupdates           | 41300    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 206500   |
| value_loss         | 207      |
---------------------------------
10.0
10.0
15.58
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.916    |
| fps                | 476      |
| nupdates           | 41400    |
| policy_entropy     | 0.029    |
| total_timesteps    | 207000   |
| value_loss         | 2.72     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 207      |
| explained_variance | -12.4    |
| fps                | 476      |
| nupdates           | 41500    |
| policy_entropy     | 0.0358   |
| total_timesteps    | 207500   |
| value_loss         | 1.27e+04 |
---------------------------------
19.0
19.0
15.84
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | -1.01    |
| fps                | 476      |
| nupdates           | 41600    |
| policy_entropy     | 0.0762   |
| total_timesteps    | 208000   |
| value_loss         | 316      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 209      |
| explained_variance | 0.979    |
| fps                | 476      |
| nupdates           | 41700    |
| policy_entropy     | 0.0491   |
| total_timesteps    | 208500   |
| value_loss         | 4.16     |
---------------------------------
10.0
10.0
14.39
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.903    |
| fps                | 476      |
| nupdates           | 41800    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 209000   |
| value_loss         | 3.11     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.948    |
| fps                | 476      |
| nupdates           | 41900    |
| policy_entropy     | 0.00962  |
| total_timesteps    | 209500   |
| value_loss         | 12.7     |
---------------------------------
10.0
10.0
13.86
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.836    |
| fps                | 476      |
| nupdates           | 42000    |
| policy_entropy     | 0.011    |
| total_timesteps    | 210000   |
| value_loss         | 14.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.679    |
| fps                | 476      |
| nupdates           | 42100    |
| policy_entropy     | 0.0151   |
| total_timesteps    | 210500   |
| value_loss         | 67.7     |
---------------------------------
11.0
11.0
14.51
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.938    |
| fps                | 476      |
| nupdates           | 42200    |
| policy_entropy     | 0.00869  |
| total_timesteps    | 211000   |
| value_loss         | 7.88     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 213      |
| explained_variance | -0.116   |
| fps                | 476      |
| nupdates           | 42300    |
| policy_entropy     | 0.00913  |
| total_timesteps    | 211500   |
| value_loss         | 362      |
---------------------------------
10.0
10.0
16.05
16.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.408    |
| fps                | 476      |
| nupdates           | 42400    |
| policy_entropy     | 0.00785  |
| total_timesteps    | 212000   |
| value_loss         | 376      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.572    |
| fps                | 476      |
| nupdates           | 42500    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 212500   |
| value_loss         | 6.71     |
---------------------------------
9.0
9.0
15.08
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 212      |
| explained_variance | -0.898   |
| fps                | 476      |
| nupdates           | 42600    |
| policy_entropy     | 0.0488   |
| total_timesteps    | 213000   |
| value_loss         | 59.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 213      |
| explained_variance | -1.01    |
| fps                | 476      |
| nupdates           | 42700    |
| policy_entropy     | 0.00681  |
| total_timesteps    | 213500   |
| value_loss         | 63.7     |
---------------------------------
10.0
10.0
15.75
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.784    |
| fps                | 476      |
| nupdates           | 42800    |
| policy_entropy     | 0.00746  |
| total_timesteps    | 214000   |
| value_loss         | 351      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0        |
| fps                | 476      |
| nupdates           | 42900    |
| policy_entropy     | 0.322    |
| total_timesteps    | 214500   |
| value_loss         | 347      |
---------------------------------
10.0
10.0
17.48
11.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 212      |
| explained_variance | -2.68    |
| fps                | 476      |
| nupdates           | 43000    |
| policy_entropy     | 0.125    |
| total_timesteps    | 215000   |
| value_loss         | 417      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 217      |
| explained_variance | 0.928    |
| fps                | 476      |
| nupdates           | 43100    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 215500   |
| value_loss         | 5.96     |
---------------------------------
20.0
20.0
15.64
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.288    |
| fps                | 476      |
| nupdates           | 43200    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 216000   |
| value_loss         | 56.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.806    |
| fps                | 476      |
| nupdates           | 43300    |
| policy_entropy     | 0.00683  |
| total_timesteps    | 216500   |
| value_loss         | 34.1     |
---------------------------------
10.0
10.0
14.17
14.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.965    |
| fps                | 476      |
| nupdates           | 43400    |
| policy_entropy     | 0.00863  |
| total_timesteps    | 217000   |
| value_loss         | 4.07     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | -0.139   |
| fps                | 476      |
| nupdates           | 43500    |
| policy_entropy     | 0.188    |
| total_timesteps    | 217500   |
| value_loss         | 165      |
---------------------------------
10.0
10.0
14.97
16.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.954    |
| fps                | 476      |
| nupdates           | 43600    |
| policy_entropy     | 0.209    |
| total_timesteps    | 218000   |
| value_loss         | 2.68     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.953    |
| fps                | 476      |
| nupdates           | 43700    |
| policy_entropy     | 0.0634   |
| total_timesteps    | 218500   |
| value_loss         | 10.3     |
---------------------------------
22.0
22.0
16.02
11.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | 0.39     |
| fps                | 476      |
| nupdates           | 43800    |
| policy_entropy     | 0.0917   |
| total_timesteps    | 219000   |
| value_loss         | 77       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.771    |
| fps                | 476      |
| nupdates           | 43900    |
| policy_entropy     | 0.0109   |
| total_timesteps    | 219500   |
| value_loss         | 9.75     |
---------------------------------
20.0
20.0
15.62
19.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.553    |
| fps                | 476      |
| nupdates           | 44000    |
| policy_entropy     | 0.159    |
| total_timesteps    | 220000   |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.35     |
| fps                | 476      |
| nupdates           | 44100    |
| policy_entropy     | 0.00883  |
| total_timesteps    | 220500   |
| value_loss         | 497      |
---------------------------------
20.0
20.0
15.26
10.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.195    |
| fps                | 476      |
| nupdates           | 44200    |
| policy_entropy     | 0.065    |
| total_timesteps    | 221000   |
| value_loss         | 170      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.786    |
| fps                | 476      |
| nupdates           | 44300    |
| policy_entropy     | 0.214    |
| total_timesteps    | 221500   |
| value_loss         | 9.42     |
---------------------------------
11.0
11.0
15.05
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.946    |
| fps                | 476      |
| nupdates           | 44400    |
| policy_entropy     | 0.00901  |
| total_timesteps    | 222000   |
| value_loss         | 3.85     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.956    |
| fps                | 476      |
| nupdates           | 44500    |
| policy_entropy     | 0.0561   |
| total_timesteps    | 222500   |
| value_loss         | 3.54     |
---------------------------------
10.0
10.0
14.34
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.586    |
| fps                | 476      |
| nupdates           | 44600    |
| policy_entropy     | 0.0294   |
| total_timesteps    | 223000   |
| value_loss         | 5.71     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.179    |
| fps                | 476      |
| nupdates           | 44700    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 223500   |
| value_loss         | 38.1     |
---------------------------------
10.0
10.0
14.94
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.97     |
| fps                | 476      |
| nupdates           | 44800    |
| policy_entropy     | 0.00827  |
| total_timesteps    | 224000   |
| value_loss         | 8.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.404    |
| fps                | 476      |
| nupdates           | 44900    |
| policy_entropy     | 0.00685  |
| total_timesteps    | 224500   |
| value_loss         | 29.4     |
---------------------------------
13.0
13.0
16.52
16.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 212      |
| explained_variance | 0.983    |
| fps                | 476      |
| nupdates           | 45000    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 225000   |
| value_loss         | 11.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.457    |
| fps                | 476      |
| nupdates           | 45100    |
| policy_entropy     | 0.0818   |
| total_timesteps    | 225500   |
| value_loss         | 417      |
---------------------------------
19.0
19.0
14.75
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.911    |
| fps                | 476      |
| nupdates           | 45200    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 226000   |
| value_loss         | 12.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 214      |
| explained_variance | -3.02    |
| fps                | 476      |
| nupdates           | 45300    |
| policy_entropy     | 0.103    |
| total_timesteps    | 226500   |
| value_loss         | 183      |
---------------------------------
54.0
54.0
15.23
20.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | -1.64    |
| fps                | 476      |
| nupdates           | 45400    |
| policy_entropy     | 0.185    |
| total_timesteps    | 227000   |
| value_loss         | 225      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.855    |
| fps                | 475      |
| nupdates           | 45500    |
| policy_entropy     | 0.0396   |
| total_timesteps    | 227500   |
| value_loss         | 5.4      |
---------------------------------
11.0
11.0
15.38
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.99     |
| fps                | 475      |
| nupdates           | 45600    |
| policy_entropy     | 0.00752  |
| total_timesteps    | 228000   |
| value_loss         | 1.95     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | 0.916    |
| fps                | 475      |
| nupdates           | 45700    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 228500   |
| value_loss         | 13.3     |
---------------------------------
32.0
32.0
13.94
14.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.739    |
| fps                | 475      |
| nupdates           | 45800    |
| policy_entropy     | 0.0462   |
| total_timesteps    | 229000   |
| value_loss         | 18.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | -1.85    |
| fps                | 475      |
| nupdates           | 45900    |
| policy_entropy     | 0.115    |
| total_timesteps    | 229500   |
| value_loss         | 122      |
---------------------------------
11.0
11.0
15.11
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0        |
| fps                | 475      |
| nupdates           | 46000    |
| policy_entropy     | 0.288    |
| total_timesteps    | 230000   |
| value_loss         | 156      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.923    |
| fps                | 475      |
| nupdates           | 46100    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 230500   |
| value_loss         | 10.9     |
---------------------------------
22.0
22.0
16.01
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 211      |
| explained_variance | -3.39    |
| fps                | 475      |
| nupdates           | 46200    |
| policy_entropy     | 0.0973   |
| total_timesteps    | 231000   |
| value_loss         | 350      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.929    |
| fps                | 475      |
| nupdates           | 46300    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 231500   |
| value_loss         | 10.4     |
---------------------------------
9.0
9.0
14.13
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -0.89    |
| fps                | 475      |
| nupdates           | 46400    |
| policy_entropy     | 0.198    |
| total_timesteps    | 232000   |
| value_loss         | 51.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.82     |
| fps                | 475      |
| nupdates           | 46500    |
| policy_entropy     | 0.00611  |
| total_timesteps    | 232500   |
| value_loss         | 2.07e+03 |
---------------------------------
28.0
28.0
15.28
16.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.951    |
| fps                | 475      |
| nupdates           | 46600    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 233000   |
| value_loss         | 4.86     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 212      |
| explained_variance | -2.58    |
| fps                | 475      |
| nupdates           | 46700    |
| policy_entropy     | 0.04     |
| total_timesteps    | 233500   |
| value_loss         | 487      |
---------------------------------
21.0
21.0
16.07
20.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.482   |
| fps                | 475      |
| nupdates           | 46800    |
| policy_entropy     | 0.086    |
| total_timesteps    | 234000   |
| value_loss         | 44.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.997    |
| fps                | 475      |
| nupdates           | 46900    |
| policy_entropy     | 0.00715  |
| total_timesteps    | 234500   |
| value_loss         | 0.288    |
---------------------------------
10.0
10.0
17.45
10.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.336    |
| fps                | 475      |
| nupdates           | 47000    |
| policy_entropy     | 0.0106   |
| total_timesteps    | 235000   |
| value_loss         | 17.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 208      |
| explained_variance | 0.986    |
| fps                | 475      |
| nupdates           | 47100    |
| policy_entropy     | 0.00702  |
| total_timesteps    | 235500   |
| value_loss         | 4.51     |
---------------------------------
10.0
10.0
15.98
16.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | 0.593    |
| fps                | 475      |
| nupdates           | 47200    |
| policy_entropy     | 0.118    |
| total_timesteps    | 236000   |
| value_loss         | 20.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0.941    |
| fps                | 475      |
| nupdates           | 47300    |
| policy_entropy     | 0.0188   |
| total_timesteps    | 236500   |
| value_loss         | 13.7     |
---------------------------------
20.0
20.0
14.78
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | -1.14    |
| fps                | 475      |
| nupdates           | 47400    |
| policy_entropy     | 0.048    |
| total_timesteps    | 237000   |
| value_loss         | 751      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.634    |
| fps                | 475      |
| nupdates           | 47500    |
| policy_entropy     | 0.0106   |
| total_timesteps    | 237500   |
| value_loss         | 107      |
---------------------------------
9.0
9.0
14.42
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.876    |
| fps                | 475      |
| nupdates           | 47600    |
| policy_entropy     | 0.00531  |
| total_timesteps    | 238000   |
| value_loss         | 15.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.0701   |
| fps                | 475      |
| nupdates           | 47700    |
| policy_entropy     | 0.137    |
| total_timesteps    | 238500   |
| value_loss         | 66.7     |
---------------------------------
9.0
9.0
14.52
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.978    |
| fps                | 475      |
| nupdates           | 47800    |
| policy_entropy     | 0.0584   |
| total_timesteps    | 239000   |
| value_loss         | 6.42     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | -4.57    |
| fps                | 475      |
| nupdates           | 47900    |
| policy_entropy     | 0.0888   |
| total_timesteps    | 239500   |
| value_loss         | 401      |
---------------------------------
9.0
9.0
14.3
11.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.512    |
| fps                | 475      |
| nupdates           | 48000    |
| policy_entropy     | 0.00973  |
| total_timesteps    | 240000   |
| value_loss         | 9.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 216      |
| explained_variance | 0.957    |
| fps                | 475      |
| nupdates           | 48100    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 240500   |
| value_loss         | 11.3     |
---------------------------------
11.0
11.0
13.3
10.5
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.977    |
| fps                | 475      |
| nupdates           | 48200    |
| policy_entropy     | 0.00908  |
| total_timesteps    | 241000   |
| value_loss         | 2.81     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0        |
| fps                | 475      |
| nupdates           | 48300    |
| policy_entropy     | 0.076    |
| total_timesteps    | 241500   |
| value_loss         | 526      |
---------------------------------
20.0
20.0
14.47
18.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.985    |
| fps                | 475      |
| nupdates           | 48400    |
| policy_entropy     | 0.0156   |
| total_timesteps    | 242000   |
| value_loss         | 19.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.219    |
| fps                | 475      |
| nupdates           | 48500    |
| policy_entropy     | 0.155    |
| total_timesteps    | 242500   |
| value_loss         | 304      |
---------------------------------
10.0
10.0
14.83
9.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.918    |
| fps                | 475      |
| nupdates           | 48600    |
| policy_entropy     | 0.00468  |
| total_timesteps    | 243000   |
| value_loss         | 3.89     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.945    |
| fps                | 475      |
| nupdates           | 48700    |
| policy_entropy     | 0.209    |
| total_timesteps    | 243500   |
| value_loss         | 9.42     |
---------------------------------
10.0
10.0
14.42
10.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.895    |
| fps                | 475      |
| nupdates           | 48800    |
| policy_entropy     | 0.00789  |
| total_timesteps    | 244000   |
| value_loss         | 452      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 218      |
| explained_variance | -0.624   |
| fps                | 475      |
| nupdates           | 48900    |
| policy_entropy     | 0.136    |
| total_timesteps    | 244500   |
| value_loss         | 718      |
---------------------------------
20.0
20.0
13.59
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | -0.641   |
| fps                | 474      |
| nupdates           | 49000    |
| policy_entropy     | 0.0926   |
| total_timesteps    | 245000   |
| value_loss         | 738      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | -2.35    |
| fps                | 474      |
| nupdates           | 49100    |
| policy_entropy     | 0.00538  |
| total_timesteps    | 245500   |
| value_loss         | 142      |
---------------------------------
9.0
9.0
14.28
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | -15.1    |
| fps                | 474      |
| nupdates           | 49200    |
| policy_entropy     | 0.072    |
| total_timesteps    | 246000   |
| value_loss         | 1.06e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.528    |
| fps                | 474      |
| nupdates           | 49300    |
| policy_entropy     | 0.0602   |
| total_timesteps    | 246500   |
| value_loss         | 56       |
---------------------------------
10.0
10.0
13.52
10.0
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.996    |
| fps                | 474      |
| nupdates           | 49400    |
| policy_entropy     | 0.00837  |
| total_timesteps    | 247000   |
| value_loss         | 0.108    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.941    |
| fps                | 474      |
| nupdates           | 49500    |
| policy_entropy     | 0.00814  |
| total_timesteps    | 247500   |
| value_loss         | 6.3      |
---------------------------------
9.0
9.0
13.76
11.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.969    |
| fps                | 474      |
| nupdates           | 49600    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 248000   |
| value_loss         | 4.79     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -3.16    |
| fps                | 474      |
| nupdates           | 49700    |
| policy_entropy     | 0.102    |
| total_timesteps    | 248500   |
| value_loss         | 464      |
---------------------------------
20.0
20.0
14.77
19.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.909    |
| fps                | 474      |
| nupdates           | 49800    |
| policy_entropy     | 0.0464   |
| total_timesteps    | 249000   |
| value_loss         | 26       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.553    |
| fps                | 474      |
| nupdates           | 49900    |
| policy_entropy     | 0.171    |
| total_timesteps    | 249500   |
| value_loss         | 136      |
---------------------------------
9.0
9.0
14.98
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.447    |
| fps                | 474      |
| nupdates           | 50000    |
| policy_entropy     | 0.119    |
| total_timesteps    | 250000   |
| value_loss         | 39.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.848    |
| fps                | 474      |
| nupdates           | 50100    |
| policy_entropy     | 0.00817  |
| total_timesteps    | 250500   |
| value_loss         | 6.94     |
---------------------------------
9.0
9.0
13.6
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.969    |
| fps                | 474      |
| nupdates           | 50200    |
| policy_entropy     | 0.0226   |
| total_timesteps    | 251000   |
| value_loss         | 1.74     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | -1.75    |
| fps                | 474      |
| nupdates           | 50300    |
| policy_entropy     | 0.102    |
| total_timesteps    | 251500   |
| value_loss         | 1.02e+03 |
---------------------------------
10.0
10.0
14.36
10.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | -1.63    |
| fps                | 474      |
| nupdates           | 50400    |
| policy_entropy     | 0.119    |
| total_timesteps    | 252000   |
| value_loss         | 680      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | -1.25    |
| fps                | 474      |
| nupdates           | 50500    |
| policy_entropy     | 0.0317   |
| total_timesteps    | 252500   |
| value_loss         | 219      |
---------------------------------
10.0
10.0
14.1
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.998    |
| fps                | 474      |
| nupdates           | 50600    |
| policy_entropy     | 0.00884  |
| total_timesteps    | 253000   |
| value_loss         | 0.388    |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.342   |
| fps                | 474      |
| nupdates           | 50700    |
| policy_entropy     | 0.15     |
| total_timesteps    | 253500   |
| value_loss         | 64.8     |
---------------------------------
9.0
9.0
14.18
19.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.965    |
| fps                | 474      |
| nupdates           | 50800    |
| policy_entropy     | 0.0249   |
| total_timesteps    | 254000   |
| value_loss         | 3.65     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.732    |
| fps                | 474      |
| nupdates           | 50900    |
| policy_entropy     | 0.0857   |
| total_timesteps    | 254500   |
| value_loss         | 61.6     |
---------------------------------
19.0
19.0
15.2
11.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.937    |
| fps                | 474      |
| nupdates           | 51000    |
| policy_entropy     | 0.00785  |
| total_timesteps    | 255000   |
| value_loss         | 7.05     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | -10.1    |
| fps                | 474      |
| nupdates           | 51100    |
| policy_entropy     | 0.374    |
| total_timesteps    | 255500   |
| value_loss         | 533      |
---------------------------------
10.0
10.0
14.6
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.572   |
| fps                | 474      |
| nupdates           | 51200    |
| policy_entropy     | 0.0527   |
| total_timesteps    | 256000   |
| value_loss         | 120      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | -5.34    |
| fps                | 474      |
| nupdates           | 51300    |
| policy_entropy     | 0.0728   |
| total_timesteps    | 256500   |
| value_loss         | 236      |
---------------------------------
10.0
10.0
13.68
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.356    |
| fps                | 474      |
| nupdates           | 51400    |
| policy_entropy     | 0.228    |
| total_timesteps    | 257000   |
| value_loss         | 200      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.964    |
| fps                | 474      |
| nupdates           | 51500    |
| policy_entropy     | 0.139    |
| total_timesteps    | 257500   |
| value_loss         | 22.3     |
---------------------------------
11.0
11.0
13.63
11.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.243   |
| fps                | 474      |
| nupdates           | 51600    |
| policy_entropy     | 0.0659   |
| total_timesteps    | 258000   |
| value_loss         | 624      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 219      |
| explained_variance | -2.69    |
| fps                | 474      |
| nupdates           | 51700    |
| policy_entropy     | 0.0789   |
| total_timesteps    | 258500   |
| value_loss         | 664      |
---------------------------------
10.0
10.0
14.25
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.945    |
| fps                | 474      |
| nupdates           | 51800    |
| policy_entropy     | 0.00236  |
| total_timesteps    | 259000   |
| value_loss         | 2.56     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.97     |
| fps                | 474      |
| nupdates           | 51900    |
| policy_entropy     | 0.00446  |
| total_timesteps    | 259500   |
| value_loss         | 1.17     |
---------------------------------
19.0
19.0
12.77
10.0
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.971    |
| fps                | 474      |
| nupdates           | 52000    |
| policy_entropy     | 0.0503   |
| total_timesteps    | 260000   |
| value_loss         | 1.5      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0        |
| fps                | 474      |
| nupdates           | 52100    |
| policy_entropy     | 0.0853   |
| total_timesteps    | 260500   |
| value_loss         | 384      |
---------------------------------
19.0
19.0
15.1
10.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | -0.125   |
| fps                | 474      |
| nupdates           | 52200    |
| policy_entropy     | 0.148    |
| total_timesteps    | 261000   |
| value_loss         | 60.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.981    |
| fps                | 474      |
| nupdates           | 52300    |
| policy_entropy     | 0.00591  |
| total_timesteps    | 261500   |
| value_loss         | 3.66     |
---------------------------------
9.0
9.0
14.05
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.305    |
| fps                | 474      |
| nupdates           | 52400    |
| policy_entropy     | 0.154    |
| total_timesteps    | 262000   |
| value_loss         | 85.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 209      |
| explained_variance | -36.9    |
| fps                | 474      |
| nupdates           | 52500    |
| policy_entropy     | 0.0553   |
| total_timesteps    | 262500   |
| value_loss         | 2.36e+03 |
---------------------------------
9.0
9.0
15.45
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | -7.26    |
| fps                | 474      |
| nupdates           | 52600    |
| policy_entropy     | 0.342    |
| total_timesteps    | 263000   |
| value_loss         | 927      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 208      |
| explained_variance | -1.44    |
| fps                | 474      |
| nupdates           | 52700    |
| policy_entropy     | 0.104    |
| total_timesteps    | 263500   |
| value_loss         | 417      |
---------------------------------
9.0
9.0
14.37
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.073    |
| fps                | 474      |
| nupdates           | 52800    |
| policy_entropy     | 0.147    |
| total_timesteps    | 264000   |
| value_loss         | 89.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | -0.0197  |
| fps                | 474      |
| nupdates           | 52900    |
| policy_entropy     | 0.0924   |
| total_timesteps    | 264500   |
| value_loss         | 661      |
---------------------------------
22.0
22.0
14.59
9.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.165    |
| fps                | 474      |
| nupdates           | 53000    |
| policy_entropy     | 0.136    |
| total_timesteps    | 265000   |
| value_loss         | 162      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.988    |
| fps                | 474      |
| nupdates           | 53100    |
| policy_entropy     | 0.025    |
| total_timesteps    | 265500   |
| value_loss         | 2.52     |
---------------------------------
32.0
32.0
15.27
19.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.945    |
| fps                | 474      |
| nupdates           | 53200    |
| policy_entropy     | 0.189    |
| total_timesteps    | 266000   |
| value_loss         | 7.43     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.858    |
| fps                | 474      |
| nupdates           | 53300    |
| policy_entropy     | 0.25     |
| total_timesteps    | 266500   |
| value_loss         | 22.8     |
---------------------------------
36.0
36.0
14.71
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | -0.621   |
| fps                | 474      |
| nupdates           | 53400    |
| policy_entropy     | 0.137    |
| total_timesteps    | 267000   |
| value_loss         | 73       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.738    |
| fps                | 474      |
| nupdates           | 53500    |
| policy_entropy     | 0.00692  |
| total_timesteps    | 267500   |
| value_loss         | 18.3     |
---------------------------------
20.0
20.0
14.35
19.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.997    |
| fps                | 474      |
| nupdates           | 53600    |
| policy_entropy     | 0.0223   |
| total_timesteps    | 268000   |
| value_loss         | 3.22     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.162    |
| fps                | 474      |
| nupdates           | 53700    |
| policy_entropy     | 0.0654   |
| total_timesteps    | 268500   |
| value_loss         | 65.3     |
---------------------------------
31.0
31.0
14.14
20.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.973    |
| fps                | 474      |
| nupdates           | 53800    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 269000   |
| value_loss         | 13.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0        |
| fps                | 474      |
| nupdates           | 53900    |
| policy_entropy     | 0.17     |
| total_timesteps    | 269500   |
| value_loss         | 363      |
---------------------------------
9.0
9.0
15.06
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.971    |
| fps                | 474      |
| nupdates           | 54000    |
| policy_entropy     | 0.00371  |
| total_timesteps    | 270000   |
| value_loss         | 3.57     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.975    |
| fps                | 474      |
| nupdates           | 54100    |
| policy_entropy     | 0.00556  |
| total_timesteps    | 270500   |
| value_loss         | 26.6     |
---------------------------------
10.0
10.0
15.03
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | -0.605   |
| fps                | 474      |
| nupdates           | 54200    |
| policy_entropy     | 0.329    |
| total_timesteps    | 271000   |
| value_loss         | 49.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.996    |
| fps                | 474      |
| nupdates           | 54300    |
| policy_entropy     | 0.00652  |
| total_timesteps    | 271500   |
| value_loss         | 0.287    |
---------------------------------
19.0
19.0
13.38
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.684    |
| fps                | 474      |
| nupdates           | 54400    |
| policy_entropy     | 0.149    |
| total_timesteps    | 272000   |
| value_loss         | 13.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.968    |
| fps                | 474      |
| nupdates           | 54500    |
| policy_entropy     | 0.00576  |
| total_timesteps    | 272500   |
| value_loss         | 4.21     |
---------------------------------
9.0
9.0
14.2
9.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | -0.861   |
| fps                | 474      |
| nupdates           | 54600    |
| policy_entropy     | 0.0669   |
| total_timesteps    | 273000   |
| value_loss         | 742      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 217      |
| explained_variance | -11.1    |
| fps                | 474      |
| nupdates           | 54700    |
| policy_entropy     | 0.0173   |
| total_timesteps    | 273500   |
| value_loss         | 393      |
---------------------------------
20.0
20.0
14.28
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | -4.07    |
| fps                | 474      |
| nupdates           | 54800    |
| policy_entropy     | 0.0658   |
| total_timesteps    | 274000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.986    |
| fps                | 474      |
| nupdates           | 54900    |
| policy_entropy     | 0.00325  |
| total_timesteps    | 274500   |
| value_loss         | 2.84     |
---------------------------------
20.0
20.0
13.63
10.5
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.87     |
| fps                | 474      |
| nupdates           | 55000    |
| policy_entropy     | 0.00666  |
| total_timesteps    | 275000   |
| value_loss         | 8.91     |
---------------------------------
---------------------------------
| ep_len_mean        | 12.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.108    |
| fps                | 474      |
| nupdates           | 55100    |
| policy_entropy     | 0.0386   |
| total_timesteps    | 275500   |
| value_loss         | 109      |
---------------------------------
10.0
10.0
13.65
11.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 218      |
| explained_variance | -1.67    |
| fps                | 474      |
| nupdates           | 55200    |
| policy_entropy     | 0.0663   |
| total_timesteps    | 276000   |
| value_loss         | 401      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.324    |
| fps                | 474      |
| nupdates           | 55300    |
| policy_entropy     | 0.0867   |
| total_timesteps    | 276500   |
| value_loss         | 29.6     |
---------------------------------
19.0
19.0
14.75
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | -0.106   |
| fps                | 474      |
| nupdates           | 55400    |
| policy_entropy     | 0.0967   |
| total_timesteps    | 277000   |
| value_loss         | 101      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.984    |
| fps                | 474      |
| nupdates           | 55500    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 277500   |
| value_loss         | 1.58     |
---------------------------------
25.0
25.0
13.61
10.0
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | -2.87    |
| fps                | 474      |
| nupdates           | 55600    |
| policy_entropy     | 0.0839   |
| total_timesteps    | 278000   |
| value_loss         | 419      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.985    |
| fps                | 474      |
| nupdates           | 55700    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 278500   |
| value_loss         | 3.45     |
---------------------------------
18.0
18.0
14.06
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.901    |
| fps                | 474      |
| nupdates           | 55800    |
| policy_entropy     | 0.311    |
| total_timesteps    | 279000   |
| value_loss         | 3.45     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 214      |
| explained_variance | -0.787   |
| fps                | 474      |
| nupdates           | 55900    |
| policy_entropy     | 0.0494   |
| total_timesteps    | 279500   |
| value_loss         | 676      |
---------------------------------
10.0
10.0
13.24
10.0
---------------------------------
| ep_len_mean        | 13.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.98     |
| fps                | 474      |
| nupdates           | 56000    |
| policy_entropy     | 0.0125   |
| total_timesteps    | 280000   |
| value_loss         | 3.13     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.998    |
| fps                | 474      |
| nupdates           | 56100    |
| policy_entropy     | 0.00384  |
| total_timesteps    | 280500   |
| value_loss         | 0.401    |
---------------------------------
9.0
9.0
13.84
15.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.992    |
| fps                | 474      |
| nupdates           | 56200    |
| policy_entropy     | 0.0435   |
| total_timesteps    | 281000   |
| value_loss         | 2.07     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.989    |
| fps                | 474      |
| nupdates           | 56300    |
| policy_entropy     | 0.0345   |
| total_timesteps    | 281500   |
| value_loss         | 1.83     |
---------------------------------
10.0
10.0
14.82
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.334    |
| fps                | 474      |
| nupdates           | 56400    |
| policy_entropy     | 0.00473  |
| total_timesteps    | 282000   |
| value_loss         | 549      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.392    |
| fps                | 474      |
| nupdates           | 56500    |
| policy_entropy     | 0.225    |
| total_timesteps    | 282500   |
| value_loss         | 32.5     |
---------------------------------
9.0
9.0
14.49
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.966    |
| fps                | 474      |
| nupdates           | 56600    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 283000   |
| value_loss         | 18.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.798    |
| fps                | 474      |
| nupdates           | 56700    |
| policy_entropy     | 0.0823   |
| total_timesteps    | 283500   |
| value_loss         | 10.7     |
---------------------------------
10.0
10.0
13.67
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.424    |
| fps                | 474      |
| nupdates           | 56800    |
| policy_entropy     | 0.025    |
| total_timesteps    | 284000   |
| value_loss         | 51.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0        |
| fps                | 474      |
| nupdates           | 56900    |
| policy_entropy     | 0.0256   |
| total_timesteps    | 284500   |
| value_loss         | 211      |
---------------------------------
20.0
20.0
17.13
18.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0.22     |
| fps                | 474      |
| nupdates           | 57000    |
| policy_entropy     | 0.00518  |
| total_timesteps    | 285000   |
| value_loss         | 668      |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | -3.17    |
| fps                | 474      |
| nupdates           | 57100    |
| policy_entropy     | 0.0554   |
| total_timesteps    | 285500   |
| value_loss         | 2.05e+04 |
---------------------------------
22.0
22.0
18.04
10.0
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | -2.76    |
| fps                | 474      |
| nupdates           | 57200    |
| policy_entropy     | 0.00464  |
| total_timesteps    | 286000   |
| value_loss         | 746      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.947    |
| fps                | 474      |
| nupdates           | 57300    |
| policy_entropy     | 0.00295  |
| total_timesteps    | 286500   |
| value_loss         | 2.74     |
---------------------------------
9.0
9.0
15.07
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | -0.259   |
| fps                | 474      |
| nupdates           | 57400    |
| policy_entropy     | 0.0161   |
| total_timesteps    | 287000   |
| value_loss         | 117      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.356    |
| fps                | 474      |
| nupdates           | 57500    |
| policy_entropy     | 0.0368   |
| total_timesteps    | 287500   |
| value_loss         | 32.2     |
---------------------------------
22.0
22.0
15.89
20.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.925    |
| fps                | 474      |
| nupdates           | 57600    |
| policy_entropy     | 0.00407  |
| total_timesteps    | 288000   |
| value_loss         | 844      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.734    |
| fps                | 474      |
| nupdates           | 57700    |
| policy_entropy     | 0.00238  |
| total_timesteps    | 288500   |
| value_loss         | 18.1     |
---------------------------------
21.0
21.0
15.84
15.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 217      |
| explained_variance | -0.157   |
| fps                | 474      |
| nupdates           | 57800    |
| policy_entropy     | 0.00442  |
| total_timesteps    | 289000   |
| value_loss         | 213      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.364    |
| fps                | 474      |
| nupdates           | 57900    |
| policy_entropy     | 0.00402  |
| total_timesteps    | 289500   |
| value_loss         | 452      |
---------------------------------
20.0
20.0
14.9
20.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | -1.72    |
| fps                | 474      |
| nupdates           | 58000    |
| policy_entropy     | 0.0623   |
| total_timesteps    | 290000   |
| value_loss         | 421      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 216      |
| explained_variance | -5.43    |
| fps                | 474      |
| nupdates           | 58100    |
| policy_entropy     | 0.0748   |
| total_timesteps    | 290500   |
| value_loss         | 541      |
---------------------------------
10.0
10.0
15.15
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | -1.84    |
| fps                | 474      |
| nupdates           | 58200    |
| policy_entropy     | 0.0542   |
| total_timesteps    | 291000   |
| value_loss         | 322      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.988    |
| fps                | 474      |
| nupdates           | 58300    |
| policy_entropy     | 0.0201   |
| total_timesteps    | 291500   |
| value_loss         | 2        |
---------------------------------
10.0
10.0
13.44
14.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.601    |
| fps                | 473      |
| nupdates           | 58400    |
| policy_entropy     | 0.0692   |
| total_timesteps    | 292000   |
| value_loss         | 79.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.92     |
| fps                | 473      |
| nupdates           | 58500    |
| policy_entropy     | 0.00852  |
| total_timesteps    | 292500   |
| value_loss         | 2.53     |
---------------------------------
19.0
19.0
14.4
15.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.84     |
| fps                | 473      |
| nupdates           | 58600    |
| policy_entropy     | 0.00293  |
| total_timesteps    | 293000   |
| value_loss         | 51.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 220      |
| explained_variance | 0.9      |
| fps                | 473      |
| nupdates           | 58700    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 293500   |
| value_loss         | 39       |
---------------------------------
10.0
10.0
14.13
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | -0.0537  |
| fps                | 473      |
| nupdates           | 58800    |
| policy_entropy     | 0.138    |
| total_timesteps    | 294000   |
| value_loss         | 75.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.312    |
| fps                | 473      |
| nupdates           | 58900    |
| policy_entropy     | 0.00437  |
| total_timesteps    | 294500   |
| value_loss         | 457      |
---------------------------------
20.0
20.0
14.43
15.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.96     |
| fps                | 473      |
| nupdates           | 59000    |
| policy_entropy     | 0.0128   |
| total_timesteps    | 295000   |
| value_loss         | 8.58     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.982    |
| fps                | 473      |
| nupdates           | 59100    |
| policy_entropy     | 0.00648  |
| total_timesteps    | 295500   |
| value_loss         | 7.39     |
---------------------------------
9.0
9.0
14.98
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0.992    |
| fps                | 473      |
| nupdates           | 59200    |
| policy_entropy     | 0.0217   |
| total_timesteps    | 296000   |
| value_loss         | 1.08     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | -2.43    |
| fps                | 473      |
| nupdates           | 59300    |
| policy_entropy     | 0.0353   |
| total_timesteps    | 296500   |
| value_loss         | 474      |
---------------------------------
20.0
20.0
14.08
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.625    |
| fps                | 473      |
| nupdates           | 59400    |
| policy_entropy     | 0.013    |
| total_timesteps    | 297000   |
| value_loss         | 63.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.684    |
| fps                | 473      |
| nupdates           | 59500    |
| policy_entropy     | 0.0213   |
| total_timesteps    | 297500   |
| value_loss         | 14.3     |
---------------------------------
20.0
20.0
14.05
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -2.88    |
| fps                | 473      |
| nupdates           | 59600    |
| policy_entropy     | 0.0306   |
| total_timesteps    | 298000   |
| value_loss         | 457      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.816    |
| fps                | 473      |
| nupdates           | 59700    |
| policy_entropy     | 0.196    |
| total_timesteps    | 298500   |
| value_loss         | 190      |
---------------------------------
20.0
20.0
14.52
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.968    |
| fps                | 473      |
| nupdates           | 59800    |
| policy_entropy     | 0.00541  |
| total_timesteps    | 299000   |
| value_loss         | 6.4      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.991    |
| fps                | 473      |
| nupdates           | 59900    |
| policy_entropy     | 0.0119   |
| total_timesteps    | 299500   |
| value_loss         | 1.16     |
---------------------------------
10.0
10.0
13.94
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.77     |
| fps                | 473      |
| nupdates           | 60000    |
| policy_entropy     | 0.00261  |
| total_timesteps    | 300000   |
| value_loss         | 45.5     |
---------------------------------