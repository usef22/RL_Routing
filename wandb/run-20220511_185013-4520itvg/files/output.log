___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | -0.0403  |
| fps                | 29       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 98.3     |
---------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220B89A3438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220B89A3438>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BBB917B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000220BBB917B8>>: AttributeError: module 'gast' has no attribute 'Index'
---------------------------------
| ep_len_mean        | 285      |
| ep_reward_mean     | -950     |
| explained_variance | 0.0301   |
| fps                | 421      |
| nupdates           | 100      |
| policy_entropy     | 1.1      |
| total_timesteps    | 500      |
| value_loss         | 77.7     |
---------------------------------
85.0
85.0
302.6666666666667
285.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 303       |
| ep_reward_mean     | -1.02e+03 |
| explained_variance | 0.0551    |
| fps                | 438       |
| nupdates           | 200       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1000      |
| value_loss         | 162       |
----------------------------------
----------------------------------
| ep_len_mean        | 340       |
| ep_reward_mean     | -1.09e+03 |
| explained_variance | -0.0346   |
| fps                | 452       |
| nupdates           | 300       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1500      |
| value_loss         | 46.7      |
----------------------------------
352.0
352.0
342.8
352.0
----------------------------------
| ep_len_mean        | 343       |
| ep_reward_mean     | -1.08e+03 |
| explained_variance | 0.00146   |
| fps                | 456       |
| nupdates           | 400       |
| policy_entropy     | 1.1       |
| total_timesteps    | 2000      |
| value_loss         | 168       |
----------------------------------
---------------------------------
| ep_len_mean        | 309      |
| ep_reward_mean     | -929     |
| explained_variance | 0.037    |
| fps                | 462      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 248      |
---------------------------------
641.0
641.0
350.5
363.0
----------------------------------
| ep_len_mean        | 350       |
| ep_reward_mean     | -1.08e+03 |
| explained_variance | -0.0541   |
| fps                | 464       |
| nupdates           | 600       |
| policy_entropy     | 1.09      |
| total_timesteps    | 3000      |
| value_loss         | 73.9      |
----------------------------------
----------------------------------
| ep_len_mean        | 350       |
| ep_reward_mean     | -1.08e+03 |
| explained_variance | -0.0288   |
| fps                | 464       |
| nupdates           | 700       |
| policy_entropy     | 1.03      |
| total_timesteps    | 3500      |
| value_loss         | 167       |
----------------------------------
53.0
53.0
373.3
363.0
----------------------------------
| ep_len_mean        | 373       |
| ep_reward_mean     | -1.16e+03 |
| explained_variance | -0.0214   |
| fps                | 467       |
| nupdates           | 800       |
| policy_entropy     | 0.998     |
| total_timesteps    | 4000      |
| value_loss         | 230       |
----------------------------------
----------------------------------
| ep_len_mean        | 356       |
| ep_reward_mean     | -1.1e+03  |
| explained_variance | -1.19e-07 |
| fps                | 470       |
| nupdates           | 900       |
| policy_entropy     | 0.941     |
| total_timesteps    | 4500      |
| value_loss         | 7.02      |
----------------------------------
295.0
295.0
356.2142857142857
363.0
----------------------------------
| ep_len_mean        | 356       |
| ep_reward_mean     | -1.08e+03 |
| explained_variance | -0.000126 |
| fps                | 470       |
| nupdates           | 1000      |
| policy_entropy     | 1.01      |
| total_timesteps    | 5000      |
| value_loss         | 561       |
----------------------------------
----------------------------------
| ep_len_mean        | 340       |
| ep_reward_mean     | -1.03e+03 |
| explained_variance | 0.00418   |
| fps                | 470       |
| nupdates           | 1100      |
| policy_entropy     | 0.985     |
| total_timesteps    | 5500      |
| value_loss         | 145       |
----------------------------------
323.0
323.0
327.1111111111111
298.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 327      |
| ep_reward_mean     | -983     |
| explained_variance | 0.0124   |
| fps                | 470      |
| nupdates           | 1200     |
| policy_entropy     | 0.931    |
| total_timesteps    | 6000     |
| value_loss         | 513      |
---------------------------------
---------------------------------
| ep_len_mean        | 316      |
| ep_reward_mean     | -923     |
| explained_variance | 0.000162 |
| fps                | 471      |
| nupdates           | 1300     |
| policy_entropy     | 0.982    |
| total_timesteps    | 6500     |
| value_loss         | 87.2     |
---------------------------------
82.0
82.0
305.95454545454544
269.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 306      |
| ep_reward_mean     | -881     |
| explained_variance | 0        |
| fps                | 472      |
| nupdates           | 1400     |
| policy_entropy     | 0.801    |
| total_timesteps    | 7000     |
| value_loss         | 464      |
---------------------------------
---------------------------------
| ep_len_mean        | 287      |
| ep_reward_mean     | -814     |
| explained_variance | 0.00389  |
| fps                | 473      |
| nupdates           | 1500     |
| policy_entropy     | 0.9      |
| total_timesteps    | 7500     |
| value_loss         | 7.4      |
---------------------------------
62.0
62.0
247.625
73.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 248      |
| ep_reward_mean     | -664     |
| explained_variance | 4.72e-05 |
| fps                | 471      |
| nupdates           | 1600     |
| policy_entropy     | 1.01     |
| total_timesteps    | 8000     |
| value_loss         | 604      |
---------------------------------
---------------------------------
| ep_len_mean        | 234      |
| ep_reward_mean     | -618     |
| explained_variance | 0.000598 |
| fps                | 472      |
| nupdates           | 1700     |
| policy_entropy     | 0.82     |
| total_timesteps    | 8500     |
| value_loss         | 23.6     |
---------------------------------
105.0
105.0
198.0888888888889
49.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 198       |
| ep_reward_mean     | -484      |
| explained_variance | -9.54e-07 |
| fps                | 473       |
| nupdates           | 1800      |
| policy_entropy     | 0.854     |
| total_timesteps    | 9000      |
| value_loss         | 50.1      |
----------------------------------
---------------------------------
| ep_len_mean        | 175      |
| ep_reward_mean     | -394     |
| explained_variance | 7.36e-05 |
| fps                | 473      |
| nupdates           | 1900     |
| policy_entropy     | 0.766    |
| total_timesteps    | 9500     |
| value_loss         | 167      |
---------------------------------
24.0
24.0
158.44444444444446
46.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 158       |
| ep_reward_mean     | -330      |
| explained_variance | -3.28e-05 |
| fps                | 473       |
| nupdates           | 2000      |
| policy_entropy     | 0.748     |
| total_timesteps    | 10000     |
| value_loss         | 469       |
----------------------------------
---------------------------------
| ep_len_mean        | 145      |
| ep_reward_mean     | -283     |
| explained_variance | 0.000124 |
| fps                | 470      |
| nupdates           | 2100     |
| policy_entropy     | 0.904    |
| total_timesteps    | 10500    |
| value_loss         | 90.3     |
---------------------------------
20.0
20.0
129.36470588235295
37.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 129      |
| ep_reward_mean     | -223     |
| explained_variance | -0.00912 |
| fps                | 470      |
| nupdates           | 2200     |
| policy_entropy     | 0.434    |
| total_timesteps    | 11000    |
| value_loss         | 1.44e+04 |
---------------------------------
----------------------------------
| ep_len_mean        | 116       |
| ep_reward_mean     | -170      |
| explained_variance | -0.000359 |
| fps                | 471       |
| nupdates           | 2300      |
| policy_entropy     | 0.793     |
| total_timesteps    | 11500     |
| value_loss         | 26.5      |
----------------------------------
13.0
13.0
68.59
19.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 68.6     |
| ep_reward_mean     | 12.6     |
| explained_variance | -0.0245  |
| fps                | 471      |
| nupdates           | 2400     |
| policy_entropy     | 0.445    |
| total_timesteps    | 12000    |
| value_loss         | 2.79e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 46.3     |
| ep_reward_mean     | 96.2     |
| explained_variance | -0.317   |
| fps                | 471      |
| nupdates           | 2500     |
| policy_entropy     | 0.191    |
| total_timesteps    | 12500    |
| value_loss         | 169      |
---------------------------------
41.0
41.0
40.8
18.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 40.8     |
| ep_reward_mean     | 121      |
| explained_variance | 0.17     |
| fps                | 470      |
| nupdates           | 2600     |
| policy_entropy     | 0.435    |
| total_timesteps    | 13000    |
| value_loss         | 1.41e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 41.4     |
| ep_reward_mean     | 122      |
| explained_variance | 0.0135   |
| fps                | 469      |
| nupdates           | 2700     |
| policy_entropy     | 0.513    |
| total_timesteps    | 13500    |
| value_loss         | 6.84e+04 |
---------------------------------
23.0
23.0
38.7
24.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 38.7     |
| ep_reward_mean     | 136      |
| explained_variance | -0.0453  |
| fps                | 469      |
| nupdates           | 2800     |
| policy_entropy     | 0.303    |
| total_timesteps    | 14000    |
| value_loss         | 3.03e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 40.2     |
| ep_reward_mean     | 125      |
| explained_variance | 5.96e-08 |
| fps                | 470      |
| nupdates           | 2900     |
| policy_entropy     | 0.163    |
| total_timesteps    | 14500    |
| value_loss         | 15       |
---------------------------------
90.0
90.0
40.3
25.5
---------------------------------
| ep_len_mean        | 40.3     |
| ep_reward_mean     | 128      |
| explained_variance | -0.519   |
| fps                | 470      |
| nupdates           | 3000     |
| policy_entropy     | 0.62     |
| total_timesteps    | 15000    |
| value_loss         | 191      |
---------------------------------
---------------------------------
| ep_len_mean        | 40.9     |
| ep_reward_mean     | 125      |
| explained_variance | 0.0384   |
| fps                | 470      |
| nupdates           | 3100     |
| policy_entropy     | 0.498    |
| total_timesteps    | 15500    |
| value_loss         | 16       |
---------------------------------
13.0
13.0
41.5
30.5
---------------------------------
| ep_len_mean        | 41.5     |
| ep_reward_mean     | 127      |
| explained_variance | -0.0451  |
| fps                | 469      |
| nupdates           | 3200     |
| policy_entropy     | 0.712    |
| total_timesteps    | 16000    |
| value_loss         | 13.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 44.3     |
| ep_reward_mean     | 120      |
| explained_variance | 0.000377 |
| fps                | 469      |
| nupdates           | 3300     |
| policy_entropy     | 0.525    |
| total_timesteps    | 16500    |
| value_loss         | 6.38e+04 |
---------------------------------
15.0
15.0
44.5
17.5
---------------------------------
| ep_len_mean        | 44.5     |
| ep_reward_mean     | 118      |
| explained_variance | 0.00146  |
| fps                | 470      |
| nupdates           | 3400     |
| policy_entropy     | 0.357    |
| total_timesteps    | 17000    |
| value_loss         | 5.02e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 44.5     |
| ep_reward_mean     | 118      |
| explained_variance | -0.0167  |
| fps                | 468      |
| nupdates           | 3500     |
| policy_entropy     | 0.591    |
| total_timesteps    | 17500    |
| value_loss         | 23.8     |
---------------------------------
29.0
29.0
49.46
17.0
---------------------------------
| ep_len_mean        | 49.5     |
| ep_reward_mean     | 98.6     |
| explained_variance | -1.12    |
| fps                | 468      |
| nupdates           | 3600     |
| policy_entropy     | 0.253    |
| total_timesteps    | 18000    |
| value_loss         | 98.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 45.2     |
| ep_reward_mean     | 111      |
| explained_variance | 0.503    |
| fps                | 468      |
| nupdates           | 3700     |
| policy_entropy     | 0.368    |
| total_timesteps    | 18500    |
| value_loss         | 67.3     |
---------------------------------
56.0
56.0
42.54
33.0
----------------------------------
| ep_len_mean        | 42.5      |
| ep_reward_mean     | 126       |
| explained_variance | -6.21e-05 |
| fps                | 468       |
| nupdates           | 3800      |
| policy_entropy     | 0.707     |
| total_timesteps    | 19000     |
| value_loss         | 8.74e+04  |
----------------------------------
----------------------------------
| ep_len_mean        | 41.9      |
| ep_reward_mean     | 130       |
| explained_variance | -7.84e-05 |
| fps                | 469       |
| nupdates           | 3900      |
| policy_entropy     | 0.985     |
| total_timesteps    | 19500     |
| value_loss         | 91.1      |
----------------------------------
22.0
22.0
44.77
33.5
---------------------------------
| ep_len_mean        | 44.8     |
| ep_reward_mean     | 119      |
| explained_variance | 5.96e-08 |
| fps                | 468      |
| nupdates           | 4000     |
| policy_entropy     | 0.838    |
| total_timesteps    | 20000    |
| value_loss         | 8.58     |
---------------------------------
---------------------------------
| ep_len_mean        | 40.1     |
| ep_reward_mean     | 129      |
| explained_variance | 0.00359  |
| fps                | 469      |
| nupdates           | 4100     |
| policy_entropy     | 0.979    |
| total_timesteps    | 20500    |
| value_loss         | 28.4     |
---------------------------------
13.0
13.0
42.0
18.5
---------------------------------
| ep_len_mean        | 42       |
| ep_reward_mean     | 124      |
| explained_variance | 0.19     |
| fps                | 468      |
| nupdates           | 4200     |
| policy_entropy     | 0.681    |
| total_timesteps    | 21000    |
| value_loss         | 6.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 45.8     |
| ep_reward_mean     | 116      |
| explained_variance | -0.0716  |
| fps                | 468      |
| nupdates           | 4300     |
| policy_entropy     | 0.209    |
| total_timesteps    | 21500    |
| value_loss         | 166      |
---------------------------------
13.0
13.0
39.55
20.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 39.5     |
| ep_reward_mean     | 140      |
| explained_variance | -0.234   |
| fps                | 468      |
| nupdates           | 4400     |
| policy_entropy     | 0.33     |
| total_timesteps    | 22000    |
| value_loss         | 34.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 38.3     |
| ep_reward_mean     | 143      |
| explained_variance | 5.96e-08 |
| fps                | 468      |
| nupdates           | 4500     |
| policy_entropy     | 0.196    |
| total_timesteps    | 22500    |
| value_loss         | 82.8     |
---------------------------------
9.0
9.0
37.86
13.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 37.9     |
| ep_reward_mean     | 145      |
| explained_variance | -0.0848  |
| fps                | 468      |
| nupdates           | 4600     |
| policy_entropy     | 0.293    |
| total_timesteps    | 23000    |
| value_loss         | 4.21e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 35.3     |
| ep_reward_mean     | 157      |
| explained_variance | 0.0149   |
| fps                | 468      |
| nupdates           | 4700     |
| policy_entropy     | 0.772    |
| total_timesteps    | 23500    |
| value_loss         | 5.64     |
---------------------------------
139.0
139.0
37.2
27.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 37.2     |
| ep_reward_mean     | 152      |
| explained_variance | 0.00136  |
| fps                | 468      |
| nupdates           | 4800     |
| policy_entropy     | 0.581    |
| total_timesteps    | 24000    |
| value_loss         | 77.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.2     |
| ep_reward_mean     | 152      |
| explained_variance | 0        |
| fps                | 468      |
| nupdates           | 4900     |
| policy_entropy     | 0.0725   |
| total_timesteps    | 24500    |
| value_loss         | 74.5     |
---------------------------------
12.0
12.0
43.09
13.5
---------------------------------
| ep_len_mean        | 43.1     |
| ep_reward_mean     | 128      |
| explained_variance | -13.1    |
| fps                | 468      |
| nupdates           | 5000     |
| policy_entropy     | 0.351    |
| total_timesteps    | 25000    |
| value_loss         | 3.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 39.9     |
| ep_reward_mean     | 133      |
| explained_variance | -0.251   |
| fps                | 468      |
| nupdates           | 5100     |
| policy_entropy     | 0.288    |
| total_timesteps    | 25500    |
| value_loss         | 344      |
---------------------------------
47.0
47.0
41.5
33.5
---------------------------------
| ep_len_mean        | 41.5     |
| ep_reward_mean     | 125      |
| explained_variance | -0.0613  |
| fps                | 468      |
| nupdates           | 5200     |
| policy_entropy     | 0.636    |
| total_timesteps    | 26000    |
| value_loss         | 51.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 41.8     |
| ep_reward_mean     | 124      |
| explained_variance | -0.00047 |
| fps                | 468      |
| nupdates           | 5300     |
| policy_entropy     | 0.801    |
| total_timesteps    | 26500    |
| value_loss         | 74.9     |
---------------------------------
45.0
45.0
39.57
15.5
---------------------------------
| ep_len_mean        | 39.6     |
| ep_reward_mean     | 129      |
| explained_variance | 0.00114  |
| fps                | 468      |
| nupdates           | 5400     |
| policy_entropy     | 0.298    |
| total_timesteps    | 27000    |
| value_loss         | 68.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 38.9     |
| ep_reward_mean     | 127      |
| explained_variance | -0.0025  |
| fps                | 468      |
| nupdates           | 5500     |
| policy_entropy     | 0.984    |
| total_timesteps    | 27500    |
| value_loss         | 12.4     |
---------------------------------
25.0
25.0
32.3
29.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 32.3     |
| ep_reward_mean     | 154      |
| explained_variance | -7.94    |
| fps                | 468      |
| nupdates           | 5600     |
| policy_entropy     | 0.137    |
| total_timesteps    | 28000    |
| value_loss         | 245      |
---------------------------------
----------------------------------
| ep_len_mean        | 33.9      |
| ep_reward_mean     | 149       |
| explained_variance | -0.000689 |
| fps                | 469       |
| nupdates           | 5700      |
| policy_entropy     | 0.593     |
| total_timesteps    | 28500     |
| value_loss         | 4.96e+04  |
----------------------------------
15.0
15.0
36.01
14.5
---------------------------------
| ep_len_mean        | 36       |
| ep_reward_mean     | 141      |
| explained_variance | -8.11    |
| fps                | 469      |
| nupdates           | 5800     |
| policy_entropy     | 0.455    |
| total_timesteps    | 29000    |
| value_loss         | 47.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 32.5     |
| ep_reward_mean     | 153      |
| explained_variance | 0.00348  |
| fps                | 469      |
| nupdates           | 5900     |
| policy_entropy     | 0.904    |
| total_timesteps    | 29500    |
| value_loss         | 56.5     |
---------------------------------
14.0
14.0
35.21
15.0
---------------------------------
| ep_len_mean        | 35.2     |
| ep_reward_mean     | 146      |
| explained_variance | -0.00591 |
| fps                | 469      |
| nupdates           | 6000     |
| policy_entropy     | 0.637    |
| total_timesteps    | 30000    |
| value_loss         | 61.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.1     |
| ep_reward_mean     | 137      |
| explained_variance | 0.878    |
| fps                | 469      |
| nupdates           | 6100     |
| policy_entropy     | 0.319    |
| total_timesteps    | 30500    |
| value_loss         | 18.6     |
---------------------------------
13.0
13.0
35.57
12.5
----------------------------------
| ep_len_mean        | 35.6      |
| ep_reward_mean     | 143       |
| explained_variance | -0.000349 |
| fps                | 469       |
| nupdates           | 6200      |
| policy_entropy     | 0.887     |
| total_timesteps    | 31000     |
| value_loss         | 156       |
----------------------------------
----------------------------------
| ep_len_mean        | 35        |
| ep_reward_mean     | 144       |
| explained_variance | -1.19e-07 |
| fps                | 468       |
| nupdates           | 6300      |
| policy_entropy     | 0.358     |
| total_timesteps    | 31500     |
| value_loss         | 1.13      |
----------------------------------
76.0
76.0
31.51
36.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 31.5     |
| ep_reward_mean     | 157      |
| explained_variance | -24.2    |
| fps                | 468      |
| nupdates           | 6400     |
| policy_entropy     | 0.401    |
| total_timesteps    | 32000    |
| value_loss         | 163      |
---------------------------------
---------------------------------
| ep_len_mean        | 34       |
| ep_reward_mean     | 150      |
| explained_variance | 0.645    |
| fps                | 468      |
| nupdates           | 6500     |
| policy_entropy     | 0.202    |
| total_timesteps    | 32500    |
| value_loss         | 243      |
---------------------------------
39.0
39.0
31.11
13.5
---------------------------------
| ep_len_mean        | 31.1     |
| ep_reward_mean     | 156      |
| explained_variance | -0.0332  |
| fps                | 468      |
| nupdates           | 6600     |
| policy_entropy     | 0.301    |
| total_timesteps    | 33000    |
| value_loss         | 2.77e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 26.8     |
| ep_reward_mean     | 168      |
| explained_variance | 0        |
| fps                | 468      |
| nupdates           | 6700     |
| policy_entropy     | 0.147    |
| total_timesteps    | 33500    |
| value_loss         | 54.5     |
---------------------------------
26.0
26.0
26.05
23.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 26.1      |
| ep_reward_mean     | 173       |
| explained_variance | -6.26e-05 |
| fps                | 468       |
| nupdates           | 6800      |
| policy_entropy     | 0.877     |
| total_timesteps    | 34000     |
| value_loss         | 0.22      |
----------------------------------
---------------------------------
| ep_len_mean        | 26.4     |
| ep_reward_mean     | 172      |
| explained_variance | 0        |
| fps                | 468      |
| nupdates           | 6900     |
| policy_entropy     | 0.355    |
| total_timesteps    | 34500    |
| value_loss         | 53.3     |
---------------------------------
12.0
12.0
24.38
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 24.4     |
| ep_reward_mean     | 179      |
| explained_variance | -0.0643  |
| fps                | 468      |
| nupdates           | 7000     |
| policy_entropy     | 0.677    |
| total_timesteps    | 35000    |
| value_loss         | 16.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 177      |
| explained_variance | -0.00974 |
| fps                | 468      |
| nupdates           | 7100     |
| policy_entropy     | 0.508    |
| total_timesteps    | 35500    |
| value_loss         | 52.2     |
---------------------------------
15.0
15.0
24.74
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 24.7     |
| ep_reward_mean     | 183      |
| explained_variance | -0.157   |
| fps                | 468      |
| nupdates           | 7200     |
| policy_entropy     | 0.285    |
| total_timesteps    | 36000    |
| value_loss         | 2.89e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 186      |
| explained_variance | -0.306   |
| fps                | 468      |
| nupdates           | 7300     |
| policy_entropy     | 0.759    |
| total_timesteps    | 36500    |
| value_loss         | 71.5     |
---------------------------------
10.0
10.0
20.93
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 192      |
| explained_variance | 0.285    |
| fps                | 468      |
| nupdates           | 7400     |
| policy_entropy     | 0.77     |
| total_timesteps    | 37000    |
| value_loss         | 33       |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 197      |
| explained_variance | -33.5    |
| fps                | 468      |
| nupdates           | 7500     |
| policy_entropy     | 0.658    |
| total_timesteps    | 37500    |
| value_loss         | 298      |
---------------------------------
9.0
9.0
18.96
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 197      |
| explained_variance | -6.88    |
| fps                | 467      |
| nupdates           | 7600     |
| policy_entropy     | 0.569    |
| total_timesteps    | 38000    |
| value_loss         | 154      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 200      |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 7700     |
| policy_entropy     | 0.361    |
| total_timesteps    | 38500    |
| value_loss         | 69       |
---------------------------------
9.0
9.0
21.04
18.5
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 189      |
| explained_variance | -39.1    |
| fps                | 466      |
| nupdates           | 7800     |
| policy_entropy     | 0.62     |
| total_timesteps    | 39000    |
| value_loss         | 459      |
---------------------------------
---------------------------------
| ep_len_mean        | 25       |
| ep_reward_mean     | 179      |
| explained_variance | 0.0345   |
| fps                | 466      |
| nupdates           | 7900     |
| policy_entropy     | 0.388    |
| total_timesteps    | 39500    |
| value_loss         | 0.148    |
---------------------------------
35.0
35.0
26.32
14.0
---------------------------------
| ep_len_mean        | 26.3     |
| ep_reward_mean     | 178      |
| explained_variance | -0.018   |
| fps                | 466      |
| nupdates           | 8000     |
| policy_entropy     | 0.612    |
| total_timesteps    | 40000    |
| value_loss         | 3.02e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 26.6     |
| ep_reward_mean     | 176      |
| explained_variance | 0.0427   |
| fps                | 466      |
| nupdates           | 8100     |
| policy_entropy     | 0.472    |
| total_timesteps    | 40500    |
| value_loss         | 47.1     |
---------------------------------
11.0
11.0
27.26
11.0
---------------------------------
| ep_len_mean        | 27.3     |
| ep_reward_mean     | 172      |
| explained_variance | -0.786   |
| fps                | 466      |
| nupdates           | 8200     |
| policy_entropy     | 0.262    |
| total_timesteps    | 41000    |
| value_loss         | 1.4e+05  |
---------------------------------
---------------------------------
| ep_len_mean        | 26.9     |
| ep_reward_mean     | 175      |
| explained_variance | -0.00973 |
| fps                | 467      |
| nupdates           | 8300     |
| policy_entropy     | 0.677    |
| total_timesteps    | 41500    |
| value_loss         | 0.0457   |
---------------------------------
15.0
15.0
22.81
13.5
---------------------------------
| ep_len_mean        | 22.8     |
| ep_reward_mean     | 185      |
| explained_variance | -0.216   |
| fps                | 467      |
| nupdates           | 8400     |
| policy_entropy     | 0.344    |
| total_timesteps    | 42000    |
| value_loss         | 87.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 186      |
| explained_variance | 0.0157   |
| fps                | 466      |
| nupdates           | 8500     |
| policy_entropy     | 1.05     |
| total_timesteps    | 42500    |
| value_loss         | 61       |
---------------------------------
102.0
102.0
22.15
11.0
---------------------------------
| ep_len_mean        | 22.1     |
| ep_reward_mean     | 190      |
| explained_variance | 0.927    |
| fps                | 466      |
| nupdates           | 8600     |
| policy_entropy     | 0.289    |
| total_timesteps    | 43000    |
| value_loss         | 22.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 24.9     |
| ep_reward_mean     | 182      |
| explained_variance | -0.00247 |
| fps                | 466      |
| nupdates           | 8700     |
| policy_entropy     | 0.742    |
| total_timesteps    | 43500    |
| value_loss         | 29.6     |
---------------------------------
41.0
41.0
28.06
43.0
---------------------------------
| ep_len_mean        | 28.1     |
| ep_reward_mean     | 171      |
| explained_variance | -1.89    |
| fps                | 466      |
| nupdates           | 8800     |
| policy_entropy     | 0.425    |
| total_timesteps    | 44000    |
| value_loss         | 1.24     |
---------------------------------
---------------------------------
| ep_len_mean        | 26.4     |
| ep_reward_mean     | 175      |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 8900     |
| policy_entropy     | 0.194    |
| total_timesteps    | 44500    |
| value_loss         | 42.1     |
---------------------------------
34.0
34.0
27.41
18.0
---------------------------------
| ep_len_mean        | 27.4     |
| ep_reward_mean     | 172      |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 9000     |
| policy_entropy     | 0.335    |
| total_timesteps    | 45000    |
| value_loss         | 41.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 27.2     |
| ep_reward_mean     | 171      |
| explained_variance | -0.0813  |
| fps                | 466      |
| nupdates           | 9100     |
| policy_entropy     | 0.56     |
| total_timesteps    | 45500    |
| value_loss         | 18.9     |
---------------------------------
9.0
9.0
27.04
11.5
---------------------------------
| ep_len_mean        | 27       |
| ep_reward_mean     | 175      |
| explained_variance | -0.832   |
| fps                | 466      |
| nupdates           | 9200     |
| policy_entropy     | 0.104    |
| total_timesteps    | 46000    |
| value_loss         | 649      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 181      |
| explained_variance | 1.19e-07 |
| fps                | 466      |
| nupdates           | 9300     |
| policy_entropy     | 0.331    |
| total_timesteps    | 46500    |
| value_loss         | 0.00154  |
---------------------------------
10.0
10.0
25.89
16.0
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 181      |
| explained_variance | 0.212    |
| fps                | 466      |
| nupdates           | 9400     |
| policy_entropy     | 0.0863   |
| total_timesteps    | 47000    |
| value_loss         | 274      |
---------------------------------
---------------------------------
| ep_len_mean        | 23.8     |
| ep_reward_mean     | 188      |
| explained_variance | -0.108   |
| fps                | 466      |
| nupdates           | 9500     |
| policy_entropy     | 0.253    |
| total_timesteps    | 47500    |
| value_loss         | 6.03e+04 |
---------------------------------
10.0
10.0
22.87
23.0
---------------------------------
| ep_len_mean        | 22.9     |
| ep_reward_mean     | 190      |
| explained_variance | -3.63    |
| fps                | 466      |
| nupdates           | 9600     |
| policy_entropy     | 0.442    |
| total_timesteps    | 48000    |
| value_loss         | 122      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.5     |
| ep_reward_mean     | 192      |
| explained_variance | 0.564    |
| fps                | 466      |
| nupdates           | 9700     |
| policy_entropy     | 0.182    |
| total_timesteps    | 48500    |
| value_loss         | 61.8     |
---------------------------------
320.0
320.0
25.62
17.5
----------------------------------
| ep_len_mean        | 25.6      |
| ep_reward_mean     | 184       |
| explained_variance | -2.08e+03 |
| fps                | 466       |
| nupdates           | 9800      |
| policy_entropy     | 0.872     |
| total_timesteps    | 49000     |
| value_loss         | 0.000464  |
----------------------------------
---------------------------------
| ep_len_mean        | 30.4     |
| ep_reward_mean     | 171      |
| explained_variance | -4.26    |
| fps                | 466      |
| nupdates           | 9900     |
| policy_entropy     | 0.156    |
| total_timesteps    | 49500    |
| value_loss         | 0.042    |
---------------------------------
32.0
32.0
30.42
21.5
---------------------------------
| ep_len_mean        | 30.4     |
| ep_reward_mean     | 171      |
| explained_variance | 0.231    |
| fps                | 466      |
| nupdates           | 10000    |
| policy_entropy     | 0.233    |
| total_timesteps    | 50000    |
| value_loss         | 10.8     |
---------------------------------
----------------------------------
| ep_len_mean        | 37.8      |
| ep_reward_mean     | 152       |
| explained_variance | -2.14e+04 |
| fps                | 466       |
| nupdates           | 10100     |
| policy_entropy     | 0.639     |
| total_timesteps    | 50500     |
| value_loss         | 0.149     |
----------------------------------
16.0
16.0
37.84
13.5
---------------------------------
| ep_len_mean        | 37.8     |
| ep_reward_mean     | 152      |
| explained_variance | -241     |
| fps                | 467      |
| nupdates           | 10200    |
| policy_entropy     | 0.714    |
| total_timesteps    | 51000    |
| value_loss         | 0.00134  |
---------------------------------
---------------------------------
| ep_len_mean        | 48.8     |
| ep_reward_mean     | 129      |
| explained_variance | -0.0262  |
| fps                | 466      |
| nupdates           | 10300    |
| policy_entropy     | 0.468    |
| total_timesteps    | 51500    |
| value_loss         | 39.1     |
---------------------------------
60.0
60.0
49.29
10.5
----------------------------------
| ep_len_mean        | 49.3      |
| ep_reward_mean     | 128       |
| explained_variance | -1.73e+03 |
| fps                | 467       |
| nupdates           | 10400     |
| policy_entropy     | 0.422     |
| total_timesteps    | 52000     |
| value_loss         | 0.114     |
----------------------------------
---------------------------------
| ep_len_mean        | 49.3     |
| ep_reward_mean     | 128      |
| explained_variance | -0.00232 |
| fps                | 466      |
| nupdates           | 10500    |
| policy_entropy     | 0.338    |
| total_timesteps    | 52500    |
| value_loss         | 62       |
---------------------------------
19.0
19.0
58.93
17.5
---------------------------------
| ep_len_mean        | 58.9     |
| ep_reward_mean     | 102      |
| explained_variance | -0.0251  |
| fps                | 467      |
| nupdates           | 10600    |
| policy_entropy     | 0.319    |
| total_timesteps    | 53000    |
| value_loss         | 90       |
---------------------------------
---------------------------------
| ep_len_mean        | 67.8     |
| ep_reward_mean     | 82.4     |
| explained_variance | -0.214   |
| fps                | 467      |
| nupdates           | 10700    |
| policy_entropy     | 0.671    |
| total_timesteps    | 53500    |
| value_loss         | 0.00104  |
---------------------------------
26.0
26.0
71.4
86.5
---------------------------------
| ep_len_mean        | 71.4     |
| ep_reward_mean     | 73.6     |
| explained_variance | -0.496   |
| fps                | 467      |
| nupdates           | 10800    |
| policy_entropy     | 0.67     |
| total_timesteps    | 54000    |
| value_loss         | 0.0545   |
---------------------------------
---------------------------------
| ep_len_mean        | 75.3     |
| ep_reward_mean     | 64       |
| explained_variance | -0.0797  |
| fps                | 467      |
| nupdates           | 10900    |
| policy_entropy     | 0.702    |
| total_timesteps    | 54500    |
| value_loss         | 0.00973  |
---------------------------------
56.0
56.0
77.38
19.5
---------------------------------
| ep_len_mean        | 77.4     |
| ep_reward_mean     | 57.2     |
| explained_variance | -44.8    |
| fps                | 466      |
| nupdates           | 11000    |
| policy_entropy     | 0.621    |
| total_timesteps    | 55000    |
| value_loss         | 0.188    |
---------------------------------
---------------------------------
| ep_len_mean        | 80.6     |
| ep_reward_mean     | 50.1     |
| explained_variance | 0.0153   |
| fps                | 466      |
| nupdates           | 11100    |
| policy_entropy     | 0.782    |
| total_timesteps    | 55500    |
| value_loss         | 7.21     |
---------------------------------
9.0
9.0
79.82
10.0
---------------------------------
| ep_len_mean        | 79.8     |
| ep_reward_mean     | 49.9     |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 11200    |
| policy_entropy     | 0.11     |
| total_timesteps    | 56000    |
| value_loss         | 381      |
---------------------------------
---------------------------------
| ep_len_mean        | 84       |
| ep_reward_mean     | 28.1     |
| explained_variance | -2.56    |
| fps                | 466      |
| nupdates           | 11300    |
| policy_entropy     | 0.615    |
| total_timesteps    | 56500    |
| value_loss         | 0.152    |
---------------------------------
30.0
30.0
87.67
31.5
----------------------------------
| ep_len_mean        | 87.7      |
| ep_reward_mean     | 19.9      |
| explained_variance | -2.43e+05 |
| fps                | 466       |
| nupdates           | 11400     |
| policy_entropy     | 0.558     |
| total_timesteps    | 57000     |
| value_loss         | 0.125     |
----------------------------------
---------------------------------
| ep_len_mean        | 81.2     |
| ep_reward_mean     | 38.7     |
| explained_variance | 0.2      |
| fps                | 466      |
| nupdates           | 11500    |
| policy_entropy     | 0.451    |
| total_timesteps    | 57500    |
| value_loss         | 577      |
---------------------------------
15.0
15.0
53.56
25.0
----------------------------------
| ep_len_mean        | 53.6      |
| ep_reward_mean     | 103       |
| explained_variance | -1.19e-07 |
| fps                | 467       |
| nupdates           | 11600     |
| policy_entropy     | 0.163     |
| total_timesteps    | 58000     |
| value_loss         | 37.4      |
----------------------------------
---------------------------------
| ep_len_mean        | 44.1     |
| ep_reward_mean     | 124      |
| explained_variance | 0.786    |
| fps                | 467      |
| nupdates           | 11700    |
| policy_entropy     | 0.183    |
| total_timesteps    | 58500    |
| value_loss         | 221      |
---------------------------------
28.0
28.0
41.71
13.5
---------------------------------
| ep_len_mean        | 41.7     |
| ep_reward_mean     | 132      |
| explained_variance | 6.17e-05 |
| fps                | 467      |
| nupdates           | 11800    |
| policy_entropy     | 0.639    |
| total_timesteps    | 59000    |
| value_loss         | 3.4e-06  |
---------------------------------
---------------------------------
| ep_len_mean        | 42.1     |
| ep_reward_mean     | 130      |
| explained_variance | -0.0614  |
| fps                | 466      |
| nupdates           | 11900    |
| policy_entropy     | 0.381    |
| total_timesteps    | 59500    |
| value_loss         | 6.37e+04 |
---------------------------------
11.0
11.0
40.63
11.0
---------------------------------
| ep_len_mean        | 40.6     |
| ep_reward_mean     | 134      |
| explained_variance | 0.0667   |
| fps                | 466      |
| nupdates           | 12000    |
| policy_entropy     | 0.495    |
| total_timesteps    | 60000    |
| value_loss         | 8.85e-10 |
---------------------------------
---------------------------------
| ep_len_mean        | 40.6     |
| ep_reward_mean     | 134      |
| explained_variance | -5.42    |
| fps                | 466      |
| nupdates           | 12100    |
| policy_entropy     | 0.686    |
| total_timesteps    | 60500    |
| value_loss         | 0.000137 |
---------------------------------
11.0
11.0
40.63
11.0
---------------------------------
| ep_len_mean        | 40.6     |
| ep_reward_mean     | 134      |
| explained_variance | 0.0129   |
| fps                | 467      |
| nupdates           | 12200    |
| policy_entropy     | 0.531    |
| total_timesteps    | 61000    |
| value_loss         | 6.89     |
---------------------------------
----------------------------------
| ep_len_mean        | 54.8      |
| ep_reward_mean     | 83.9      |
| explained_variance | -3.11e+04 |
| fps                | 467       |
| nupdates           | 12300     |
| policy_entropy     | 0.398     |
| total_timesteps    | 61500     |
| value_loss         | 1.89      |
----------------------------------
718.0
718.0
61.82
12.0
---------------------------------
| ep_len_mean        | 61.8     |
| ep_reward_mean     | 62.5     |
| explained_variance | 0        |
| fps                | 467      |
| nupdates           | 12400    |
| policy_entropy     | 0.26     |
| total_timesteps    | 62000    |
| value_loss         | 0.0285   |
---------------------------------
---------------------------------
| ep_len_mean        | 61.8     |
| ep_reward_mean     | 62.5     |
| explained_variance | 0        |
| fps                | 467      |
| nupdates           | 12500    |
| policy_entropy     | 0.263    |
| total_timesteps    | 62500    |
| value_loss         | 368      |
---------------------------------
1031.0
1031.0
71.97
12.0
---------------------------------
| ep_len_mean        | 72       |
| ep_reward_mean     | 16.7     |
| explained_variance | 0        |
| fps                | 467      |
| nupdates           | 12600    |
| policy_entropy     | 0.115    |
| total_timesteps    | 63000    |
| value_loss         | 0.443    |
---------------------------------
---------------------------------
| ep_len_mean        | 78       |
| ep_reward_mean     | 2.77     |
| explained_variance | -0.0631  |
| fps                | 467      |
| nupdates           | 12700    |
| policy_entropy     | 0.638    |
| total_timesteps    | 63500    |
| value_loss         | 1.37e+05 |
---------------------------------
25.0
25.0
80.43
24.5
---------------------------------
| ep_len_mean        | 80.4     |
| ep_reward_mean     | 0.23     |
| explained_variance | -38.5    |
| fps                | 467      |
| nupdates           | 12800    |
| policy_entropy     | 0.451    |
| total_timesteps    | 64000    |
| value_loss         | 0.0179   |
---------------------------------
---------------------------------
| ep_len_mean        | 72.2     |
| ep_reward_mean     | 29.2     |
| explained_variance | 0.165    |
| fps                | 467      |
| nupdates           | 12900    |
| policy_entropy     | 0.314    |
| total_timesteps    | 64500    |
| value_loss         | 678      |
---------------------------------
23.0
23.0
71.28
25.0
---------------------------------
| ep_len_mean        | 71.3     |
| ep_reward_mean     | 33.4     |
| explained_variance | -0.119   |
| fps                | 467      |
| nupdates           | 13000    |
| policy_entropy     | 0.386    |
| total_timesteps    | 65000    |
| value_loss         | 9.32e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 66.2     |
| ep_reward_mean     | 46       |
| explained_variance | -0.132   |
| fps                | 467      |
| nupdates           | 13100    |
| policy_entropy     | 0.182    |
| total_timesteps    | 65500    |
| value_loss         | 3.28e+04 |
---------------------------------
21.0
21.0
64.32
22.5
---------------------------------
| ep_len_mean        | 64.3     |
| ep_reward_mean     | 49.7     |
| explained_variance | -15.3    |
| fps                | 467      |
| nupdates           | 13200    |
| policy_entropy     | 0.572    |
| total_timesteps    | 66000    |
| value_loss         | 11.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 27.6     |
| ep_reward_mean     | 179      |
| explained_variance | -14.8    |
| fps                | 467      |
| nupdates           | 13300    |
| policy_entropy     | 0.396    |
| total_timesteps    | 66500    |
| value_loss         | 23.4     |
---------------------------------
68.0
68.0
27.7
28.5
---------------------------------
| ep_len_mean        | 27.7     |
| ep_reward_mean     | 175      |
| explained_variance | -3.77    |
| fps                | 467      |
| nupdates           | 13400    |
| policy_entropy     | 0.42     |
| total_timesteps    | 67000    |
| value_loss         | 1.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 29.4     |
| ep_reward_mean     | 169      |
| explained_variance | 0.0266   |
| fps                | 467      |
| nupdates           | 13500    |
| policy_entropy     | 0.758    |
| total_timesteps    | 67500    |
| value_loss         | 53.3     |
---------------------------------
109.0
109.0
32.03
38.5
---------------------------------
| ep_len_mean        | 32       |
| ep_reward_mean     | 162      |
| explained_variance | 0.0771   |
| fps                | 467      |
| nupdates           | 13600    |
| policy_entropy     | 0.138    |
| total_timesteps    | 68000    |
| value_loss         | 484      |
---------------------------------
---------------------------------
| ep_len_mean        | 33.2     |
| ep_reward_mean     | 156      |
| explained_variance | -0.191   |
| fps                | 467      |
| nupdates           | 13700    |
| policy_entropy     | 0.36     |
| total_timesteps    | 68500    |
| value_loss         | 9.89     |
---------------------------------
9.0
9.0
35.16
10.5
---------------------------------
| ep_len_mean        | 35.2     |
| ep_reward_mean     | 152      |
| explained_variance | -86.5    |
| fps                | 467      |
| nupdates           | 13800    |
| policy_entropy     | 0.729    |
| total_timesteps    | 69000    |
| value_loss         | 49.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 35.1     |
| ep_reward_mean     | 152      |
| explained_variance | -446     |
| fps                | 467      |
| nupdates           | 13900    |
| policy_entropy     | 0.603    |
| total_timesteps    | 69500    |
| value_loss         | 0.323    |
---------------------------------
10.0
10.0
36.1
10.0
---------------------------------
| ep_len_mean        | 36.1     |
| ep_reward_mean     | 151      |
| explained_variance | -167     |
| fps                | 467      |
| nupdates           | 14000    |
| policy_entropy     | 0.399    |
| total_timesteps    | 70000    |
| value_loss         | 179      |
---------------------------------
---------------------------------
| ep_len_mean        | 31.4     |
| ep_reward_mean     | 167      |
| explained_variance | -220     |
| fps                | 467      |
| nupdates           | 14100    |
| policy_entropy     | 0.589    |
| total_timesteps    | 70500    |
| value_loss         | 73.6     |
---------------------------------
11.0
11.0
27.38
14.0
---------------------------------
| ep_len_mean        | 27.4     |
| ep_reward_mean     | 180      |
| explained_variance | 0.816    |
| fps                | 467      |
| nupdates           | 14200    |
| policy_entropy     | 0.273    |
| total_timesteps    | 71000    |
| value_loss         | 29.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 186      |
| explained_variance | -518     |
| fps                | 467      |
| nupdates           | 14300    |
| policy_entropy     | 0.599    |
| total_timesteps    | 71500    |
| value_loss         | 4.07     |
---------------------------------
30.0
30.0
22.69
19.0
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 191      |
| explained_variance | 0.402    |
| fps                | 467      |
| nupdates           | 14400    |
| policy_entropy     | 0.471    |
| total_timesteps    | 72000    |
| value_loss         | 62.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 191      |
| explained_variance | -5.33    |
| fps                | 467      |
| nupdates           | 14500    |
| policy_entropy     | 0.322    |
| total_timesteps    | 72500    |
| value_loss         | 129      |
---------------------------------
10.0
10.0
20.01
18.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 198      |
| explained_variance | -0.713   |
| fps                | 467      |
| nupdates           | 14600    |
| policy_entropy     | 0.415    |
| total_timesteps    | 73000    |
| value_loss         | 71.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 198      |
| explained_variance | -7.27    |
| fps                | 467      |
| nupdates           | 14700    |
| policy_entropy     | 0.172    |
| total_timesteps    | 73500    |
| value_loss         | 332      |
---------------------------------
8.0
8.0
20.86
18.5
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 192      |
| explained_variance | -0.183   |
| fps                | 467      |
| nupdates           | 14800    |
| policy_entropy     | 0.109    |
| total_timesteps    | 74000    |
| value_loss         | 2.57e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 189      |
| explained_variance | 0.505    |
| fps                | 467      |
| nupdates           | 14900    |
| policy_entropy     | 0.556    |
| total_timesteps    | 74500    |
| value_loss         | 316      |
---------------------------------
14.0
14.0
22.65
12.5
---------------------------------
| ep_len_mean        | 22.6     |
| ep_reward_mean     | 185      |
| explained_variance | -0.00493 |
| fps                | 467      |
| nupdates           | 15000    |
| policy_entropy     | 0.645    |
| total_timesteps    | 75000    |
| value_loss         | 3.93     |
---------------------------------
---------------------------------
| ep_len_mean        | 23.9     |
| ep_reward_mean     | 181      |
| explained_variance | -6.25    |
| fps                | 467      |
| nupdates           | 15100    |
| policy_entropy     | 0.158    |
| total_timesteps    | 75500    |
| value_loss         | 108      |
---------------------------------
22.0
22.0
26.21
24.0
---------------------------------
| ep_len_mean        | 26.2     |
| ep_reward_mean     | 177      |
| explained_variance | -0.512   |
| fps                | 467      |
| nupdates           | 15200    |
| policy_entropy     | 0.469    |
| total_timesteps    | 76000    |
| value_loss         | 107      |
---------------------------------
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 188      |
| explained_variance | 0.663    |
| fps                | 467      |
| nupdates           | 15300    |
| policy_entropy     | 0.246    |
| total_timesteps    | 76500    |
| value_loss         | 59.8     |
---------------------------------
9.0
9.0
21.62
10.0
---------------------------------
| ep_len_mean        | 21.6     |
| ep_reward_mean     | 190      |
| explained_variance | 0        |
| fps                | 467      |
| nupdates           | 15400    |
| policy_entropy     | 0.754    |
| total_timesteps    | 77000    |
| value_loss         | 6.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 195      |
| explained_variance | -2.33    |
| fps                | 467      |
| nupdates           | 15500    |
| policy_entropy     | 0.671    |
| total_timesteps    | 77500    |
| value_loss         | 14.2     |
---------------------------------
10.0
10.0
17.37
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 203      |
| explained_variance | 0.737    |
| fps                | 467      |
| nupdates           | 15600    |
| policy_entropy     | 0.288    |
| total_timesteps    | 78000    |
| value_loss         | 27.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.757    |
| fps                | 467      |
| nupdates           | 15700    |
| policy_entropy     | 0.0938   |
| total_timesteps    | 78500    |
| value_loss         | 5.31e+04 |
---------------------------------
25.0
25.0
17.02
19.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 206      |
| explained_variance | -8.08    |
| fps                | 467      |
| nupdates           | 15800    |
| policy_entropy     | 0.27     |
| total_timesteps    | 79000    |
| value_loss         | 435      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 202      |
| explained_variance | -1.12    |
| fps                | 467      |
| nupdates           | 15900    |
| policy_entropy     | 0.0754   |
| total_timesteps    | 79500    |
| value_loss         | 43.7     |
---------------------------------
10.0
10.0
19.26
24.5
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 199      |
| explained_variance | -0.286   |
| fps                | 467      |
| nupdates           | 16000    |
| policy_entropy     | 0.0455   |
| total_timesteps    | 80000    |
| value_loss         | 476      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.8     |
| ep_reward_mean     | 193      |
| explained_variance | -3.24    |
| fps                | 467      |
| nupdates           | 16100    |
| policy_entropy     | 0.0659   |
| total_timesteps    | 80500    |
| value_loss         | 168      |
---------------------------------
10.0
10.0
20.93
11.0
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 192      |
| explained_variance | -1.52    |
| fps                | 467      |
| nupdates           | 16200    |
| policy_entropy     | 0.173    |
| total_timesteps    | 81000    |
| value_loss         | 1.24e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 192      |
| explained_variance | -0.176   |
| fps                | 467      |
| nupdates           | 16300    |
| policy_entropy     | 0.125    |
| total_timesteps    | 81500    |
| value_loss         | 2.47e+04 |
---------------------------------
13.0
13.0
20.9
10.0
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 191      |
| explained_variance | -1.36    |
| fps                | 467      |
| nupdates           | 16400    |
| policy_entropy     | 0.211    |
| total_timesteps    | 82000    |
| value_loss         | 92.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 195      |
| explained_variance | -2.03    |
| fps                | 466      |
| nupdates           | 16500    |
| policy_entropy     | 0.194    |
| total_timesteps    | 82500    |
| value_loss         | 859      |
---------------------------------
11.0
11.0
18.91
11.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 198      |
| explained_variance | -2.47    |
| fps                | 466      |
| nupdates           | 16600    |
| policy_entropy     | 0.393    |
| total_timesteps    | 83000    |
| value_loss         | 50.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 197      |
| explained_variance | -0.16    |
| fps                | 466      |
| nupdates           | 16700    |
| policy_entropy     | 0.223    |
| total_timesteps    | 83500    |
| value_loss         | 1.85e+04 |
---------------------------------
30.0
30.0
18.28
12.0
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 201      |
| explained_variance | -0.254   |
| fps                | 466      |
| nupdates           | 16800    |
| policy_entropy     | 0.0516   |
| total_timesteps    | 84000    |
| value_loss         | 1.41e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.578    |
| fps                | 466      |
| nupdates           | 16900    |
| policy_entropy     | 0.365    |
| total_timesteps    | 84500    |
| value_loss         | 221      |
---------------------------------
10.0
10.0
15.4
18.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | 1.19e-07 |
| fps                | 466      |
| nupdates           | 17000    |
| policy_entropy     | 0.341    |
| total_timesteps    | 85000    |
| value_loss         | 91.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 207      |
| explained_variance | 5.96e-08 |
| fps                | 466      |
| nupdates           | 17100    |
| policy_entropy     | 0.193    |
| total_timesteps    | 85500    |
| value_loss         | 249      |
---------------------------------
10.0
10.0
18.58
17.5
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -2.44    |
| fps                | 466      |
| nupdates           | 17200    |
| policy_entropy     | 0.0939   |
| total_timesteps    | 86000    |
| value_loss         | 63.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 202      |
| explained_variance | -0.616   |
| fps                | 466      |
| nupdates           | 17300    |
| policy_entropy     | 0.242    |
| total_timesteps    | 86500    |
| value_loss         | 1.03e+03 |
---------------------------------
9.0
9.0
17.07
19.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 203      |
| explained_variance | 0.233    |
| fps                | 466      |
| nupdates           | 17400    |
| policy_entropy     | 0.0315   |
| total_timesteps    | 87000    |
| value_loss         | 467      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 205      |
| explained_variance | 0.00277  |
| fps                | 466      |
| nupdates           | 17500    |
| policy_entropy     | 0.0481   |
| total_timesteps    | 87500    |
| value_loss         | 5.53e+03 |
---------------------------------
10.0
10.0
17.35
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 206      |
| explained_variance | -1.9     |
| fps                | 466      |
| nupdates           | 17600    |
| policy_entropy     | 0.469    |
| total_timesteps    | 88000    |
| value_loss         | 475      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 200      |
| explained_variance | 0.418    |
| fps                | 466      |
| nupdates           | 17700    |
| policy_entropy     | 0.04     |
| total_timesteps    | 88500    |
| value_loss         | 512      |
---------------------------------
10.0
10.0
18.31
10.0
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 203      |
| explained_variance | 0.459    |
| fps                | 466      |
| nupdates           | 17800    |
| policy_entropy     | 0.374    |
| total_timesteps    | 89000    |
| value_loss         | 48.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 201      |
| explained_variance | -0.14    |
| fps                | 466      |
| nupdates           | 17900    |
| policy_entropy     | 0.401    |
| total_timesteps    | 89500    |
| value_loss         | 80.3     |
---------------------------------
29.0
29.0
17.54
10.0
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 204      |
| explained_variance | 0.423    |
| fps                | 466      |
| nupdates           | 18000    |
| policy_entropy     | 0.307    |
| total_timesteps    | 90000    |
| value_loss         | 177      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 201      |
| explained_variance | 0.434    |
| fps                | 466      |
| nupdates           | 18100    |
| policy_entropy     | 0.0339   |
| total_timesteps    | 90500    |
| value_loss         | 419      |
---------------------------------
10.0
10.0
18.51
10.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 200      |
| explained_variance | 0.686    |
| fps                | 466      |
| nupdates           | 18200    |
| policy_entropy     | 0.262    |
| total_timesteps    | 91000    |
| value_loss         | 54.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 204      |
| explained_variance | -0.66    |
| fps                | 466      |
| nupdates           | 18300    |
| policy_entropy     | 0.234    |
| total_timesteps    | 91500    |
| value_loss         | 217      |
---------------------------------
10.0
10.0
18.95
11.5
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 199      |
| explained_variance | -3.06    |
| fps                | 466      |
| nupdates           | 18400    |
| policy_entropy     | 0.274    |
| total_timesteps    | 92000    |
| value_loss         | 2.25e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 199      |
| explained_variance | -3.64    |
| fps                | 466      |
| nupdates           | 18500    |
| policy_entropy     | 0.256    |
| total_timesteps    | 92500    |
| value_loss         | 221      |
---------------------------------
11.0
11.0
18.74
12.0
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 199      |
| explained_variance | -0.0289  |
| fps                | 466      |
| nupdates           | 18600    |
| policy_entropy     | 0.297    |
| total_timesteps    | 93000    |
| value_loss         | 1.06e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 196      |
| explained_variance | 0.0662   |
| fps                | 466      |
| nupdates           | 18700    |
| policy_entropy     | 0.028    |
| total_timesteps    | 93500    |
| value_loss         | 1.13e+03 |
---------------------------------
9.0
9.0
17.27
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 202      |
| explained_variance | -0.253   |
| fps                | 466      |
| nupdates           | 18800    |
| policy_entropy     | 0.0627   |
| total_timesteps    | 94000    |
| value_loss         | 1.55e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 18900    |
| policy_entropy     | 0.271    |
| total_timesteps    | 94500    |
| value_loss         | 100      |
---------------------------------
10.0
10.0
18.96
11.5
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 202      |
| explained_variance | -0.166   |
| fps                | 466      |
| nupdates           | 19000    |
| policy_entropy     | 0.0866   |
| total_timesteps    | 95000    |
| value_loss         | 3.34e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 202      |
| explained_variance | -2.19    |
| fps                | 466      |
| nupdates           | 19100    |
| policy_entropy     | 0.272    |
| total_timesteps    | 95500    |
| value_loss         | 1.33e+04 |
---------------------------------
9.0
9.0
19.54
10.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 200      |
| explained_variance | 0.117    |
| fps                | 466      |
| nupdates           | 19200    |
| policy_entropy     | 0.463    |
| total_timesteps    | 96000    |
| value_loss         | 30.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 199      |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 19300    |
| policy_entropy     | 0.166    |
| total_timesteps    | 96500    |
| value_loss         | 181      |
---------------------------------
9.0
9.0
19.89
17.0
---------------------------------
| ep_len_mean        | 19.9     |
| ep_reward_mean     | 196      |
| explained_variance | -0.13    |
| fps                | 466      |
| nupdates           | 19400    |
| policy_entropy     | 0.254    |
| total_timesteps    | 97000    |
| value_loss         | 2.8e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 202      |
| explained_variance | -0.145   |
| fps                | 466      |
| nupdates           | 19500    |
| policy_entropy     | 0.225    |
| total_timesteps    | 97500    |
| value_loss         | 154      |
---------------------------------
13.0
13.0
18.48
12.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 202      |
| explained_variance | 0.265    |
| fps                | 466      |
| nupdates           | 19600    |
| policy_entropy     | 0.474    |
| total_timesteps    | 98000    |
| value_loss         | 310      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -0.115   |
| fps                | 466      |
| nupdates           | 19700    |
| policy_entropy     | 0.713    |
| total_timesteps    | 98500    |
| value_loss         | 74.5     |
---------------------------------
10.0
10.0
17.81
13.5
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 202      |
| explained_variance | -1.53    |
| fps                | 466      |
| nupdates           | 19800    |
| policy_entropy     | 0.606    |
| total_timesteps    | 99000    |
| value_loss         | 121      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 202      |
| explained_variance | 0        |
| fps                | 466      |
| nupdates           | 19900    |
| policy_entropy     | 0.253    |
| total_timesteps    | 99500    |
| value_loss         | 313      |
---------------------------------
42.0
42.0
19.3
16.0
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 195      |
| explained_variance | -1.96    |
| fps                | 466      |
| nupdates           | 20000    |
| policy_entropy     | 0.323    |
| total_timesteps    | 100000   |
| value_loss         | 114      |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 194      |
| explained_variance | -0.0698  |
| fps                | 466      |
| nupdates           | 20100    |
| policy_entropy     | 0.373    |
| total_timesteps    | 100500   |
| value_loss         | 4.87e+03 |
---------------------------------
10.0
10.0
19.58
12.0
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 196      |
| explained_variance | 0.558    |
| fps                | 466      |
| nupdates           | 20200    |
| policy_entropy     | 0.194    |
| total_timesteps    | 101000   |
| value_loss         | 6.28e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 201      |
| explained_variance | 0        |
| fps                | 465      |
| nupdates           | 20300    |
| policy_entropy     | 0.552    |
| total_timesteps    | 101500   |
| value_loss         | 556      |
---------------------------------
45.0
45.0
18.29
11.5
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 200      |
| explained_variance | 0.141    |
| fps                | 465      |
| nupdates           | 20400    |
| policy_entropy     | 0.456    |
| total_timesteps    | 102000   |
| value_loss         | 5.27e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 200      |
| explained_variance | 0.538    |
| fps                | 466      |
| nupdates           | 20500    |
| policy_entropy     | 0.0317   |
| total_timesteps    | 102500   |
| value_loss         | 364      |
---------------------------------
9.0
9.0
18.12
27.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 200      |
| explained_variance | -2.81    |
| fps                | 466      |
| nupdates           | 20600    |
| policy_entropy     | 0.0647   |
| total_timesteps    | 103000   |
| value_loss         | 7.16e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 204      |
| explained_variance | 0.453    |
| fps                | 465      |
| nupdates           | 20700    |
| policy_entropy     | 0.102    |
| total_timesteps    | 103500   |
| value_loss         | 572      |
---------------------------------
13.0
13.0
18.4
10.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 204      |
| explained_variance | -1.05    |
| fps                | 465      |
| nupdates           | 20800    |
| policy_entropy     | 0.316    |
| total_timesteps    | 104000   |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | 0.179    |
| fps                | 465      |
| nupdates           | 20900    |
| policy_entropy     | 0.126    |
| total_timesteps    | 104500   |
| value_loss         | 868      |
---------------------------------
13.0
13.0
17.41
15.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.194    |
| fps                | 465      |
| nupdates           | 21000    |
| policy_entropy     | 0.15     |
| total_timesteps    | 105000   |
| value_loss         | 428      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | -3.65    |
| fps                | 465      |
| nupdates           | 21100    |
| policy_entropy     | 0.384    |
| total_timesteps    | 105500   |
| value_loss         | 261      |
---------------------------------
26.0
26.0
18.87
22.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 202      |
| explained_variance | -21.9    |
| fps                | 465      |
| nupdates           | 21200    |
| policy_entropy     | 0.294    |
| total_timesteps    | 106000   |
| value_loss         | 482      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 200      |
| explained_variance | -13.9    |
| fps                | 465      |
| nupdates           | 21300    |
| policy_entropy     | 0.194    |
| total_timesteps    | 106500   |
| value_loss         | 1.63e+03 |
---------------------------------
26.0
26.0
20.27
26.5
---------------------------------
| ep_len_mean        | 20.3     |
| ep_reward_mean     | 196      |
| explained_variance | -0.0505  |
| fps                | 465      |
| nupdates           | 21400    |
| policy_entropy     | 0.47     |
| total_timesteps    | 107000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 198      |
| explained_variance | -3.37    |
| fps                | 465      |
| nupdates           | 21500    |
| policy_entropy     | 0.0855   |
| total_timesteps    | 107500   |
| value_loss         | 411      |
---------------------------------
9.0
9.0
18.71
13.5
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 199      |
| explained_variance | 0.914    |
| fps                | 465      |
| nupdates           | 21600    |
| policy_entropy     | 0.0255   |
| total_timesteps    | 108000   |
| value_loss         | 804      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 198      |
| explained_variance | -0.879   |
| fps                | 465      |
| nupdates           | 21700    |
| policy_entropy     | 0.537    |
| total_timesteps    | 108500   |
| value_loss         | 183      |
---------------------------------
9.0
9.0
17.1
9.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 203      |
| explained_variance | 0.494    |
| fps                | 465      |
| nupdates           | 21800    |
| policy_entropy     | 0.0711   |
| total_timesteps    | 109000   |
| value_loss         | 202      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 205      |
| explained_variance | -1.18    |
| fps                | 465      |
| nupdates           | 21900    |
| policy_entropy     | 0.282    |
| total_timesteps    | 109500   |
| value_loss         | 444      |
---------------------------------
10.0
10.0
16.14
10.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0438   |
| fps                | 465      |
| nupdates           | 22000    |
| policy_entropy     | 0.162    |
| total_timesteps    | 110000   |
| value_loss         | 79       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0348   |
| fps                | 465      |
| nupdates           | 22100    |
| policy_entropy     | 0.565    |
| total_timesteps    | 110500   |
| value_loss         | 204      |
---------------------------------
32.0
32.0
16.09
16.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.14    |
| fps                | 465      |
| nupdates           | 22200    |
| policy_entropy     | 0.0793   |
| total_timesteps    | 111000   |
| value_loss         | 363      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.33    |
| fps                | 465      |
| nupdates           | 22300    |
| policy_entropy     | 0.164    |
| total_timesteps    | 111500   |
| value_loss         | 891      |
---------------------------------
10.0
10.0
16.58
15.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | -21.9    |
| fps                | 465      |
| nupdates           | 22400    |
| policy_entropy     | 0.341    |
| total_timesteps    | 112000   |
| value_loss         | 760      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 203      |
| explained_variance | -3.07    |
| fps                | 465      |
| nupdates           | 22500    |
| policy_entropy     | 0.559    |
| total_timesteps    | 112500   |
| value_loss         | 161      |
---------------------------------
29.0
29.0
18.38
16.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 203      |
| explained_variance | 0.103    |
| fps                | 465      |
| nupdates           | 22600    |
| policy_entropy     | 0.0233   |
| total_timesteps    | 113000   |
| value_loss         | 581      |
---------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 204      |
| explained_variance | -3.01    |
| fps                | 465      |
| nupdates           | 22700    |
| policy_entropy     | 0.484    |
| total_timesteps    | 113500   |
| value_loss         | 186      |
---------------------------------
10.0
10.0
18.77
12.0
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 200      |
| explained_variance | -1.3     |
| fps                | 465      |
| nupdates           | 22800    |
| policy_entropy     | 0.043    |
| total_timesteps    | 114000   |
| value_loss         | 364      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 202      |
| explained_variance | 0.681    |
| fps                | 465      |
| nupdates           | 22900    |
| policy_entropy     | 0.0307   |
| total_timesteps    | 114500   |
| value_loss         | 97.7     |
---------------------------------
34.0
34.0
18.89
10.0
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 201      |
| explained_variance | -0.00505 |
| fps                | 465      |
| nupdates           | 23000    |
| policy_entropy     | 0.101    |
| total_timesteps    | 115000   |
| value_loss         | 495      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 204      |
| explained_variance | 0.225    |
| fps                | 465      |
| nupdates           | 23100    |
| policy_entropy     | 0.279    |
| total_timesteps    | 115500   |
| value_loss         | 185      |
---------------------------------
23.0
23.0
15.81
9.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.709    |
| fps                | 465      |
| nupdates           | 23200    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 116000   |
| value_loss         | 21.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 465      |
| nupdates           | 23300    |
| policy_entropy     | 0.53     |
| total_timesteps    | 116500   |
| value_loss         | 127      |
---------------------------------
9.0
9.0
15.45
9.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | -0.0106  |
| fps                | 465      |
| nupdates           | 23400    |
| policy_entropy     | 0.667    |
| total_timesteps    | 117000   |
| value_loss         | 126      |
---------------------------------
----------------------------------
| ep_len_mean        | 15.4      |
| ep_reward_mean     | 210       |
| explained_variance | -2.38e-07 |
| fps                | 465       |
| nupdates           | 23500     |
| policy_entropy     | 0.203     |
| total_timesteps    | 117500    |
| value_loss         | 203       |
----------------------------------
11.0
11.0
17.49
10.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 203      |
| explained_variance | -0.861   |
| fps                | 465      |
| nupdates           | 23600    |
| policy_entropy     | 0.471    |
| total_timesteps    | 118000   |
| value_loss         | 389      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.559    |
| fps                | 465      |
| nupdates           | 23700    |
| policy_entropy     | 0.033    |
| total_timesteps    | 118500   |
| value_loss         | 39.4     |
---------------------------------
10.0
10.0
16.71
10.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 204      |
| explained_variance | 0.892    |
| fps                | 465      |
| nupdates           | 23800    |
| policy_entropy     | 0.045    |
| total_timesteps    | 119000   |
| value_loss         | 65.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 208      |
| explained_variance | 0.0215   |
| fps                | 465      |
| nupdates           | 23900    |
| policy_entropy     | 0.0308   |
| total_timesteps    | 119500   |
| value_loss         | 131      |
---------------------------------
53.0
53.0
15.32
18.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.72     |
| fps                | 464      |
| nupdates           | 24000    |
| policy_entropy     | 0.0474   |
| total_timesteps    | 120000   |
| value_loss         | 57       |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 205      |
| explained_variance | 0.456    |
| fps                | 464      |
| nupdates           | 24100    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 120500   |
| value_loss         | 340      |
---------------------------------
10.0
10.0
16.25
10.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 206      |
| explained_variance | 0.884    |
| fps                | 464      |
| nupdates           | 24200    |
| policy_entropy     | 0.0387   |
| total_timesteps    | 121000   |
| value_loss         | 35.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 206      |
| explained_variance | -4.29    |
| fps                | 465      |
| nupdates           | 24300    |
| policy_entropy     | 0.278    |
| total_timesteps    | 121500   |
| value_loss         | 975      |
---------------------------------
11.0
11.0
17.12
11.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 206      |
| explained_variance | 0        |
| fps                | 464      |
| nupdates           | 24400    |
| policy_entropy     | 0.552    |
| total_timesteps    | 122000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 207      |
| explained_variance | 0.327    |
| fps                | 464      |
| nupdates           | 24500    |
| policy_entropy     | 0.138    |
| total_timesteps    | 122500   |
| value_loss         | 105      |
---------------------------------
43.0
43.0
15.43
18.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 209      |
| explained_variance | -2.52    |
| fps                | 464      |
| nupdates           | 24600    |
| policy_entropy     | 0.234    |
| total_timesteps    | 123000   |
| value_loss         | 660      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 204      |
| explained_variance | 0.621    |
| fps                | 464      |
| nupdates           | 24700    |
| policy_entropy     | 0.0395   |
| total_timesteps    | 123500   |
| value_loss         | 580      |
---------------------------------
10.0
10.0
17.0
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 203      |
| explained_variance | -0.25    |
| fps                | 464      |
| nupdates           | 24800    |
| policy_entropy     | 0.148    |
| total_timesteps    | 124000   |
| value_loss         | 24.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 203      |
| explained_variance | -0.6     |
| fps                | 464      |
| nupdates           | 24900    |
| policy_entropy     | 0.294    |
| total_timesteps    | 124500   |
| value_loss         | 114      |
---------------------------------
10.0
10.0
16.96
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 208      |
| explained_variance | -40.1    |
| fps                | 464      |
| nupdates           | 25000    |
| policy_entropy     | 0.47     |
| total_timesteps    | 125000   |
| value_loss         | 1.06e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | -0.155   |
| fps                | 464      |
| nupdates           | 25100    |
| policy_entropy     | 0.309    |
| total_timesteps    | 125500   |
| value_loss         | 125      |
---------------------------------
10.0
10.0
16.52
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.921    |
| fps                | 464      |
| nupdates           | 25200    |
| policy_entropy     | 0.0482   |
| total_timesteps    | 126000   |
| value_loss         | 15.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | 0.478    |
| fps                | 464      |
| nupdates           | 25300    |
| policy_entropy     | 0.0253   |
| total_timesteps    | 126500   |
| value_loss         | 116      |
---------------------------------
9.0
9.0
16.92
12.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.452    |
| fps                | 464      |
| nupdates           | 25400    |
| policy_entropy     | 0.0223   |
| total_timesteps    | 127000   |
| value_loss         | 20.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | 0.275    |
| fps                | 464      |
| nupdates           | 25500    |
| policy_entropy     | 0.626    |
| total_timesteps    | 127500   |
| value_loss         | 201      |
---------------------------------
10.0
10.0
15.81
17.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.635    |
| fps                | 464      |
| nupdates           | 25600    |
| policy_entropy     | 0.0597   |
| total_timesteps    | 128000   |
| value_loss         | 62.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 203      |
| explained_variance | -58.9    |
| fps                | 464      |
| nupdates           | 25700    |
| policy_entropy     | 0.0304   |
| total_timesteps    | 128500   |
| value_loss         | 1.08e+04 |
---------------------------------
10.0
10.0
19.38
14.0
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 199      |
| explained_variance | -3.56    |
| fps                | 464      |
| nupdates           | 25800    |
| policy_entropy     | 0.425    |
| total_timesteps    | 129000   |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 197      |
| explained_variance | -0.323   |
| fps                | 464      |
| nupdates           | 25900    |
| policy_entropy     | 0.5      |
| total_timesteps    | 129500   |
| value_loss         | 599      |
---------------------------------
18.0
18.0
20.99
14.0
---------------------------------
| ep_len_mean        | 21       |
| ep_reward_mean     | 196      |
| explained_variance | 0.557    |
| fps                | 464      |
| nupdates           | 26000    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 130000   |
| value_loss         | 1.69e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 204      |
| explained_variance | 0.11     |
| fps                | 464      |
| nupdates           | 26100    |
| policy_entropy     | 0.206    |
| total_timesteps    | 130500   |
| value_loss         | 4.87e+03 |
---------------------------------
11.0
11.0
18.27
12.0
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 206      |
| explained_variance | -0.897   |
| fps                | 464      |
| nupdates           | 26200    |
| policy_entropy     | 0.0917   |
| total_timesteps    | 131000   |
| value_loss         | 653      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 203      |
| explained_variance | 0.195    |
| fps                | 464      |
| nupdates           | 26300    |
| policy_entropy     | 0.098    |
| total_timesteps    | 131500   |
| value_loss         | 97.5     |
---------------------------------
9.0
9.0
18.72
10.5
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 200      |
| explained_variance | -5.03    |
| fps                | 464      |
| nupdates           | 26400    |
| policy_entropy     | 0.372    |
| total_timesteps    | 132000   |
| value_loss         | 241      |
---------------------------------
----------------------------------
| ep_len_mean        | 19.1      |
| ep_reward_mean     | 201       |
| explained_variance | -1.19e-07 |
| fps                | 464       |
| nupdates           | 26500     |
| policy_entropy     | 0.276     |
| total_timesteps    | 132500    |
| value_loss         | 143       |
----------------------------------
9.0
9.0
19.99
11.5
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 200      |
| explained_variance | -0.944   |
| fps                | 464      |
| nupdates           | 26600    |
| policy_entropy     | 0.519    |
| total_timesteps    | 133000   |
| value_loss         | 253      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.893    |
| fps                | 464      |
| nupdates           | 26700    |
| policy_entropy     | 0.018    |
| total_timesteps    | 133500   |
| value_loss         | 11.7     |
---------------------------------
9.0
9.0
17.42
11.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.879    |
| fps                | 464      |
| nupdates           | 26800    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 134000   |
| value_loss         | 23.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.283    |
| fps                | 464      |
| nupdates           | 26900    |
| policy_entropy     | 0.166    |
| total_timesteps    | 134500   |
| value_loss         | 74.7     |
---------------------------------
10.0
10.0
16.06
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.866    |
| fps                | 464      |
| nupdates           | 27000    |
| policy_entropy     | 0.463    |
| total_timesteps    | 135000   |
| value_loss         | 212      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.423    |
| fps                | 464      |
| nupdates           | 27100    |
| policy_entropy     | 0.171    |
| total_timesteps    | 135500   |
| value_loss         | 45.6     |
---------------------------------
13.0
13.0
18.66
12.0
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 202      |
| explained_variance | 0.307    |
| fps                | 464      |
| nupdates           | 27200    |
| policy_entropy     | 0.0181   |
| total_timesteps    | 136000   |
| value_loss         | 59.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 203      |
| explained_variance | 0.524    |
| fps                | 464      |
| nupdates           | 27300    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 136500   |
| value_loss         | 42.5     |
---------------------------------
10.0
10.0
17.45
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.938    |
| fps                | 464      |
| nupdates           | 27400    |
| policy_entropy     | 0.0351   |
| total_timesteps    | 137000   |
| value_loss         | 10.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 204      |
| explained_variance | -14      |
| fps                | 464      |
| nupdates           | 27500    |
| policy_entropy     | 0.118    |
| total_timesteps    | 137500   |
| value_loss         | 1.04e+03 |
---------------------------------
10.0
10.0
16.81
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | -1.8     |
| fps                | 464      |
| nupdates           | 27600    |
| policy_entropy     | 0.516    |
| total_timesteps    | 138000   |
| value_loss         | 364      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | -0.23    |
| fps                | 464      |
| nupdates           | 27700    |
| policy_entropy     | 0.202    |
| total_timesteps    | 138500   |
| value_loss         | 119      |
---------------------------------
10.0
10.0
17.5
9.5
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 206      |
| explained_variance | 0.79     |
| fps                | 464      |
| nupdates           | 27800    |
| policy_entropy     | 0.0648   |
| total_timesteps    | 139000   |
| value_loss         | 28.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 208      |
| explained_variance | -1.11    |
| fps                | 464      |
| nupdates           | 27900    |
| policy_entropy     | 0.263    |
| total_timesteps    | 139500   |
| value_loss         | 236      |
---------------------------------
9.0
9.0
15.76
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 207      |
| explained_variance | 0.0889   |
| fps                | 464      |
| nupdates           | 28000    |
| policy_entropy     | 0.17     |
| total_timesteps    | 140000   |
| value_loss         | 110      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 210      |
| explained_variance | -1.78    |
| fps                | 464      |
| nupdates           | 28100    |
| policy_entropy     | 0.212    |
| total_timesteps    | 140500   |
| value_loss         | 120      |
---------------------------------
25.0
25.0
15.33
12.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | -0.259   |
| fps                | 464      |
| nupdates           | 28200    |
| policy_entropy     | 0.341    |
| total_timesteps    | 141000   |
| value_loss         | 532      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | -0.199   |
| fps                | 464      |
| nupdates           | 28300    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 141500   |
| value_loss         | 230      |
---------------------------------
10.0
10.0
17.24
10.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.863    |
| fps                | 464      |
| nupdates           | 28400    |
| policy_entropy     | 0.0328   |
| total_timesteps    | 142000   |
| value_loss         | 20.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 207      |
| explained_variance | -1.38    |
| fps                | 464      |
| nupdates           | 28500    |
| policy_entropy     | 0.192    |
| total_timesteps    | 142500   |
| value_loss         | 99.8     |
---------------------------------
10.0
10.0
17.41
13.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.955    |
| fps                | 463      |
| nupdates           | 28600    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 143000   |
| value_loss         | 8.25     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 213      |
| explained_variance | 0.283    |
| fps                | 463      |
| nupdates           | 28700    |
| policy_entropy     | 0.196    |
| total_timesteps    | 143500   |
| value_loss         | 66.3     |
---------------------------------
10.0
10.0
17.1
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.581    |
| fps                | 463      |
| nupdates           | 28800    |
| policy_entropy     | 0.176    |
| total_timesteps    | 144000   |
| value_loss         | 50.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 210      |
| explained_variance | -0.143   |
| fps                | 463      |
| nupdates           | 28900    |
| policy_entropy     | 0.127    |
| total_timesteps    | 144500   |
| value_loss         | 105      |
---------------------------------
10.0
10.0
15.83
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.621    |
| fps                | 463      |
| nupdates           | 29000    |
| policy_entropy     | 0.0473   |
| total_timesteps    | 145000   |
| value_loss         | 158      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | -0.46    |
| fps                | 463      |
| nupdates           | 29100    |
| policy_entropy     | 0.0986   |
| total_timesteps    | 145500   |
| value_loss         | 632      |
---------------------------------
21.0
21.0
16.81
16.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 210      |
| explained_variance | -6.07    |
| fps                | 463      |
| nupdates           | 29200    |
| policy_entropy     | 0.104    |
| total_timesteps    | 146000   |
| value_loss         | 2.23e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.773    |
| fps                | 463      |
| nupdates           | 29300    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 146500   |
| value_loss         | 328      |
---------------------------------
23.0
23.0
15.92
13.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.605    |
| fps                | 463      |
| nupdates           | 29400    |
| policy_entropy     | 0.42     |
| total_timesteps    | 147000   |
| value_loss         | 112      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | -0.282   |
| fps                | 463      |
| nupdates           | 29500    |
| policy_entropy     | 0.48     |
| total_timesteps    | 147500   |
| value_loss         | 505      |
---------------------------------
38.0
38.0
16.65
11.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | -3.79    |
| fps                | 463      |
| nupdates           | 29600    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 148000   |
| value_loss         | 1.17e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 203      |
| explained_variance | -0.258   |
| fps                | 463      |
| nupdates           | 29700    |
| policy_entropy     | 0.219    |
| total_timesteps    | 148500   |
| value_loss         | 152      |
---------------------------------
22.0
22.0
19.21
12.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 206      |
| explained_variance | 0.464    |
| fps                | 463      |
| nupdates           | 29800    |
| policy_entropy     | 0.138    |
| total_timesteps    | 149000   |
| value_loss         | 41.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 205      |
| explained_variance | -1.02    |
| fps                | 463      |
| nupdates           | 29900    |
| policy_entropy     | 0.149    |
| total_timesteps    | 149500   |
| value_loss         | 522      |
---------------------------------
54.0
54.0
18.65
24.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 206      |
| explained_variance | -1.43    |
| fps                | 463      |
| nupdates           | 30000    |
| policy_entropy     | 0.0206   |
| total_timesteps    | 150000   |
| value_loss         | 184      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.663    |
| fps                | 463      |
| nupdates           | 30100    |
| policy_entropy     | 0.0305   |
| total_timesteps    | 150500   |
| value_loss         | 98.9     |
---------------------------------
30.0
30.0
19.34
22.5
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 205      |
| explained_variance | -2.9     |
| fps                | 463      |
| nupdates           | 30200    |
| policy_entropy     | 0.172    |
| total_timesteps    | 151000   |
| value_loss         | 878      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 208      |
| explained_variance | -1.58    |
| fps                | 463      |
| nupdates           | 30300    |
| policy_entropy     | 0.499    |
| total_timesteps    | 151500   |
| value_loss         | 340      |
---------------------------------
10.0
10.0
17.57
10.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 210      |
| explained_variance | 0.844    |
| fps                | 463      |
| nupdates           | 30400    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 152000   |
| value_loss         | 14.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | -0.411   |
| fps                | 463      |
| nupdates           | 30500    |
| policy_entropy     | 0.106    |
| total_timesteps    | 152500   |
| value_loss         | 409      |
---------------------------------
9.0
9.0
16.58
21.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.0879   |
| fps                | 463      |
| nupdates           | 30600    |
| policy_entropy     | 0.224    |
| total_timesteps    | 153000   |
| value_loss         | 179      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 211      |
| explained_variance | -0.39    |
| fps                | 463      |
| nupdates           | 30700    |
| policy_entropy     | 0.459    |
| total_timesteps    | 153500   |
| value_loss         | 100      |
---------------------------------
10.0
10.0
17.45
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.542    |
| fps                | 463      |
| nupdates           | 30800    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 154000   |
| value_loss         | 72.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 211      |
| explained_variance | -0.817   |
| fps                | 463      |
| nupdates           | 30900    |
| policy_entropy     | 0.248    |
| total_timesteps    | 154500   |
| value_loss         | 554      |
---------------------------------
13.0
13.0
16.95
13.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.941    |
| fps                | 462      |
| nupdates           | 31000    |
| policy_entropy     | 0.077    |
| total_timesteps    | 155000   |
| value_loss         | 21.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.957    |
| fps                | 462      |
| nupdates           | 31100    |
| policy_entropy     | 0.0386   |
| total_timesteps    | 155500   |
| value_loss         | 10.4     |
---------------------------------
10.0
10.0
15.04
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 209      |
| explained_variance | 0.879    |
| fps                | 462      |
| nupdates           | 31200    |
| policy_entropy     | 0.091    |
| total_timesteps    | 156000   |
| value_loss         | 54.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.628    |
| fps                | 462      |
| nupdates           | 31300    |
| policy_entropy     | 0.0129   |
| total_timesteps    | 156500   |
| value_loss         | 29.8     |
---------------------------------
11.0
11.0
15.49
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 210      |
| explained_variance | 0.861    |
| fps                | 462      |
| nupdates           | 31400    |
| policy_entropy     | 0.0212   |
| total_timesteps    | 157000   |
| value_loss         | 15.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 212      |
| explained_variance | 0.423    |
| fps                | 462      |
| nupdates           | 31500    |
| policy_entropy     | 0.139    |
| total_timesteps    | 157500   |
| value_loss         | 68.9     |
---------------------------------
10.0
10.0
15.89
15.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.562    |
| fps                | 462      |
| nupdates           | 31600    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 158000   |
| value_loss         | 171      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.725    |
| fps                | 462      |
| nupdates           | 31700    |
| policy_entropy     | 0.0222   |
| total_timesteps    | 158500   |
| value_loss         | 76.8     |
---------------------------------
55.0
55.0
15.84
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0355   |
| fps                | 462      |
| nupdates           | 31800    |
| policy_entropy     | 0.0404   |
| total_timesteps    | 159000   |
| value_loss         | 246      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 212      |
| explained_variance | -0.592   |
| fps                | 462      |
| nupdates           | 31900    |
| policy_entropy     | 0.0856   |
| total_timesteps    | 159500   |
| value_loss         | 65       |
---------------------------------
9.0
9.0
16.29
11.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 213      |
| explained_variance | 1.19e-07 |
| fps                | 462      |
| nupdates           | 32000    |
| policy_entropy     | 0.227    |
| total_timesteps    | 160000   |
| value_loss         | 174      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 208      |
| explained_variance | 0.252    |
| fps                | 462      |
| nupdates           | 32100    |
| policy_entropy     | 0.178    |
| total_timesteps    | 160500   |
| value_loss         | 340      |
---------------------------------
9.0
9.0
15.99
12.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | -0.0481  |
| fps                | 462      |
| nupdates           | 32200    |
| policy_entropy     | 0.227    |
| total_timesteps    | 161000   |
| value_loss         | 53.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 206      |
| explained_variance | -1.82    |
| fps                | 462      |
| nupdates           | 32300    |
| policy_entropy     | 0.164    |
| total_timesteps    | 161500   |
| value_loss         | 642      |
---------------------------------
23.0
23.0
16.87
11.5
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 210      |
| explained_variance | -0.223   |
| fps                | 462      |
| nupdates           | 32400    |
| policy_entropy     | 0.00918  |
| total_timesteps    | 162000   |
| value_loss         | 214      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 207      |
| explained_variance | -0.487   |
| fps                | 462      |
| nupdates           | 32500    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 162500   |
| value_loss         | 198      |
---------------------------------
10.0
10.0
16.26
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 209      |
| explained_variance | 0.282    |
| fps                | 462      |
| nupdates           | 32600    |
| policy_entropy     | 0.607    |
| total_timesteps    | 163000   |
| value_loss         | 202      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.782    |
| fps                | 462      |
| nupdates           | 32700    |
| policy_entropy     | 0.0981   |
| total_timesteps    | 163500   |
| value_loss         | 307      |
---------------------------------
20.0
20.0
16.14
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.313    |
| fps                | 462      |
| nupdates           | 32800    |
| policy_entropy     | 0.011    |
| total_timesteps    | 164000   |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | -0.356   |
| fps                | 462      |
| nupdates           | 32900    |
| policy_entropy     | 0.312    |
| total_timesteps    | 164500   |
| value_loss         | 257      |
---------------------------------
9.0
9.0
15.42
16.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.72     |
| fps                | 462      |
| nupdates           | 33000    |
| policy_entropy     | 0.0271   |
| total_timesteps    | 165000   |
| value_loss         | 54.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.803    |
| fps                | 462      |
| nupdates           | 33100    |
| policy_entropy     | 0.03     |
| total_timesteps    | 165500   |
| value_loss         | 40.5     |
---------------------------------
11.0
11.0
13.94
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 33200    |
| policy_entropy     | 0.232    |
| total_timesteps    | 166000   |
| value_loss         | 88.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0.925    |
| fps                | 462      |
| nupdates           | 33300    |
| policy_entropy     | 0.00911  |
| total_timesteps    | 166500   |
| value_loss         | 490      |
---------------------------------
27.0
27.0
15.84
23.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | -0.411   |
| fps                | 462      |
| nupdates           | 33400    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 167000   |
| value_loss         | 91.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.939    |
| fps                | 462      |
| nupdates           | 33500    |
| policy_entropy     | 0.00796  |
| total_timesteps    | 167500   |
| value_loss         | 11       |
---------------------------------
22.0
22.0
16.63
20.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.714   |
| fps                | 462      |
| nupdates           | 33600    |
| policy_entropy     | 0.562    |
| total_timesteps    | 168000   |
| value_loss         | 480      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 208      |
| explained_variance | -1.81    |
| fps                | 462      |
| nupdates           | 33700    |
| policy_entropy     | 0.102    |
| total_timesteps    | 168500   |
| value_loss         | 334      |
---------------------------------
29.0
29.0
16.8
17.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.729    |
| fps                | 462      |
| nupdates           | 33800    |
| policy_entropy     | 0.118    |
| total_timesteps    | 169000   |
| value_loss         | 514      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.906    |
| fps                | 461      |
| nupdates           | 33900    |
| policy_entropy     | 0.0229   |
| total_timesteps    | 169500   |
| value_loss         | 10.8     |
---------------------------------
10.0
10.0
15.6
10.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0        |
| fps                | 462      |
| nupdates           | 34000    |
| policy_entropy     | 0.177    |
| total_timesteps    | 170000   |
| value_loss         | 143      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 200      |
| explained_variance | -0.402   |
| fps                | 462      |
| nupdates           | 34100    |
| policy_entropy     | 0.0379   |
| total_timesteps    | 170500   |
| value_loss         | 5.66e+03 |
---------------------------------
9.0
9.0
18.58
10.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 200      |
| explained_variance | -1.64    |
| fps                | 462      |
| nupdates           | 34200    |
| policy_entropy     | 0.138    |
| total_timesteps    | 171000   |
| value_loss         | 347      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 197      |
| explained_variance | 0.0931   |
| fps                | 462      |
| nupdates           | 34300    |
| policy_entropy     | 0.155    |
| total_timesteps    | 171500   |
| value_loss         | 85.3     |
---------------------------------
11.0
11.0
16.93
14.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 207      |
| explained_variance | -1.09    |
| fps                | 462      |
| nupdates           | 34400    |
| policy_entropy     | 0.392    |
| total_timesteps    | 172000   |
| value_loss         | 630      |
---------------------------------
23.0
23.0
17.29
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 207      |
| explained_variance | 0.711    |
| fps                | 462      |
| nupdates           | 34600    |
| policy_entropy     | 0.0511   |
| total_timesteps    | 173000   |
| value_loss         | 34       |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.834    |
| fps                | 462      |
| nupdates           | 34700    |
| policy_entropy     | 0.016    |
| total_timesteps    | 173500   |
| value_loss         | 181      |
---------------------------------
10.0
10.0
17.0
10.0
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 212      |
| explained_variance | 0.12     |
| fps                | 462      |
| nupdates           | 34800    |
| policy_entropy     | 0.0711   |
| total_timesteps    | 174000   |
| value_loss         | 216      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 210      |
| explained_variance | 0.738    |
| fps                | 462      |
| nupdates           | 34900    |
| policy_entropy     | 0.0234   |
| total_timesteps    | 174500   |
| value_loss         | 24.2     |
---------------------------------
22.0
22.0
17.99
15.5
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 208      |
| explained_variance | 0.074    |
| fps                | 461      |
| nupdates           | 35000    |
| policy_entropy     | 0.00925  |
| total_timesteps    | 175000   |
| value_loss         | 37.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.947    |
| fps                | 462      |
| nupdates           | 35100    |
| policy_entropy     | 0.0341   |
| total_timesteps    | 175500   |
| value_loss         | 41.5     |
---------------------------------
11.0
11.0
18.39
10.5
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 206      |
| explained_variance | -0.00436 |
| fps                | 461      |
| nupdates           | 35200    |
| policy_entropy     | 0.225    |
| total_timesteps    | 176000   |
| value_loss         | 1.22e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 209      |
| explained_variance | 0.882    |
| fps                | 461      |
| nupdates           | 35300    |
| policy_entropy     | 0.00833  |
| total_timesteps    | 176500   |
| value_loss         | 28.4     |
---------------------------------
10.0
10.0
17.42
15.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.858    |
| fps                | 461      |
| nupdates           | 35400    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 177000   |
| value_loss         | 38.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.775    |
| fps                | 461      |
| nupdates           | 35500    |
| policy_entropy     | 0.0152   |
| total_timesteps    | 177500   |
| value_loss         | 12.3     |
---------------------------------
11.0
11.0
15.49
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.757    |
| fps                | 461      |
| nupdates           | 35600    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 178000   |
| value_loss         | 45.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.978    |
| fps                | 461      |
| nupdates           | 35700    |
| policy_entropy     | 0.0861   |
| total_timesteps    | 178500   |
| value_loss         | 2.75     |
---------------------------------
10.0
10.0
15.4
15.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.828    |
| fps                | 461      |
| nupdates           | 35800    |
| policy_entropy     | 0.0222   |
| total_timesteps    | 179000   |
| value_loss         | 51.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 211      |
| explained_variance | -7.93    |
| fps                | 461      |
| nupdates           | 35900    |
| policy_entropy     | 0.496    |
| total_timesteps    | 179500   |
| value_loss         | 793      |
---------------------------------
38.0
38.0
16.46
10.5
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.37     |
| fps                | 461      |
| nupdates           | 36000    |
| policy_entropy     | 0.0566   |
| total_timesteps    | 180000   |
| value_loss         | 124      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 207      |
| explained_variance | -5.55    |
| fps                | 461      |
| nupdates           | 36100    |
| policy_entropy     | 0.207    |
| total_timesteps    | 180500   |
| value_loss         | 84.9     |
---------------------------------
10.0
10.0
16.57
10.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | 0.435    |
| fps                | 461      |
| nupdates           | 36200    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 181000   |
| value_loss         | 368      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 212      |
| explained_variance | -1.16    |
| fps                | 461      |
| nupdates           | 36300    |
| policy_entropy     | 0.184    |
| total_timesteps    | 181500   |
| value_loss         | 118      |
---------------------------------
28.0
28.0
15.1
17.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | -1.32    |
| fps                | 461      |
| nupdates           | 36400    |
| policy_entropy     | 0.251    |
| total_timesteps    | 182000   |
| value_loss         | 245      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.783    |
| fps                | 461      |
| nupdates           | 36500    |
| policy_entropy     | 0.28     |
| total_timesteps    | 182500   |
| value_loss         | 21.4     |
---------------------------------
21.0
21.0
16.29
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.836    |
| fps                | 461      |
| nupdates           | 36600    |
| policy_entropy     | 0.0603   |
| total_timesteps    | 183000   |
| value_loss         | 16.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.151    |
| fps                | 461      |
| nupdates           | 36700    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 183500   |
| value_loss         | 543      |
---------------------------------
9.0
9.0
16.95
17.5
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 209      |
| explained_variance | 0.41     |
| fps                | 461      |
| nupdates           | 36800    |
| policy_entropy     | 0.285    |
| total_timesteps    | 184000   |
| value_loss         | 66.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | -0.386   |
| fps                | 461      |
| nupdates           | 36900    |
| policy_entropy     | 0.353    |
| total_timesteps    | 184500   |
| value_loss         | 668      |
---------------------------------
26.0
26.0
14.77
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.904    |
| fps                | 461      |
| nupdates           | 37000    |
| policy_entropy     | 0.00689  |
| total_timesteps    | 185000   |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.801    |
| fps                | 461      |
| nupdates           | 37100    |
| policy_entropy     | 0.105    |
| total_timesteps    | 185500   |
| value_loss         | 212      |
---------------------------------
11.0
11.0
15.94
15.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.977    |
| fps                | 461      |
| nupdates           | 37200    |
| policy_entropy     | 0.0545   |
| total_timesteps    | 186000   |
| value_loss         | 2.36     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | -0.155   |
| fps                | 461      |
| nupdates           | 37300    |
| policy_entropy     | 0.0887   |
| total_timesteps    | 186500   |
| value_loss         | 52.8     |
---------------------------------
9.0
9.0
18.2
10.5
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 208      |
| explained_variance | -0.984   |
| fps                | 461      |
| nupdates           | 37400    |
| policy_entropy     | 0.0869   |
| total_timesteps    | 187000   |
| value_loss         | 2.95e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 208      |
| explained_variance | -1.9     |
| fps                | 461      |
| nupdates           | 37500    |
| policy_entropy     | 0.0754   |
| total_timesteps    | 187500   |
| value_loss         | 157      |
---------------------------------
30.0
30.0
18.24
18.0
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 206      |
| explained_variance | 0.654    |
| fps                | 461      |
| nupdates           | 37600    |
| policy_entropy     | 0.0284   |
| total_timesteps    | 188000   |
| value_loss         | 12.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 37700    |
| policy_entropy     | 0.357    |
| total_timesteps    | 188500   |
| value_loss         | 122      |
---------------------------------
23.0
23.0
19.11
22.0
---------------------------------
| ep_len_mean        | 19.1     |
| ep_reward_mean     | 203      |
| explained_variance | -7.63    |
| fps                | 461      |
| nupdates           | 37800    |
| policy_entropy     | 0.00894  |
| total_timesteps    | 189000   |
| value_loss         | 1.59e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 207      |
| explained_variance | 0.943    |
| fps                | 461      |
| nupdates           | 37900    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 189500   |
| value_loss         | 26       |
---------------------------------
24.0
24.0
17.07
15.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.716    |
| fps                | 461      |
| nupdates           | 38000    |
| policy_entropy     | 0.0582   |
| total_timesteps    | 190000   |
| value_loss         | 329      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.222    |
| fps                | 461      |
| nupdates           | 38100    |
| policy_entropy     | 0.155    |
| total_timesteps    | 190500   |
| value_loss         | 29.2     |
---------------------------------
13.0
13.0
16.3
10.0
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 210      |
| explained_variance | -0.796   |
| fps                | 461      |
| nupdates           | 38200    |
| policy_entropy     | 0.0313   |
| total_timesteps    | 191000   |
| value_loss         | 9.31e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 207      |
| explained_variance | 0.383    |
| fps                | 461      |
| nupdates           | 38300    |
| policy_entropy     | 0.0604   |
| total_timesteps    | 191500   |
| value_loss         | 335      |
---------------------------------
11.0
11.0
16.91
15.5
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 207      |
| explained_variance | -0.0358  |
| fps                | 461      |
| nupdates           | 38400    |
| policy_entropy     | 0.117    |
| total_timesteps    | 192000   |
| value_loss         | 187      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.252    |
| fps                | 461      |
| nupdates           | 38500    |
| policy_entropy     | 0.00652  |
| total_timesteps    | 192500   |
| value_loss         | 429      |
---------------------------------
22.0
22.0
16.47
25.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 213      |
| explained_variance | -1.64    |
| fps                | 461      |
| nupdates           | 38600    |
| policy_entropy     | 0.0605   |
| total_timesteps    | 193000   |
| value_loss         | 1.05e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.923    |
| fps                | 461      |
| nupdates           | 38700    |
| policy_entropy     | 0.0199   |
| total_timesteps    | 193500   |
| value_loss         | 21.9     |
---------------------------------
10.0
10.0
16.65
16.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | -5.53    |
| fps                | 461      |
| nupdates           | 38800    |
| policy_entropy     | 0.149    |
| total_timesteps    | 194000   |
| value_loss         | 3.14e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 211      |
| explained_variance | -19.4    |
| fps                | 461      |
| nupdates           | 38900    |
| policy_entropy     | 0.0899   |
| total_timesteps    | 194500   |
| value_loss         | 1.96e+03 |
---------------------------------
11.0
11.0
16.92
11.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 211      |
| explained_variance | -2.01    |
| fps                | 461      |
| nupdates           | 39000    |
| policy_entropy     | 0.0665   |
| total_timesteps    | 195000   |
| value_loss         | 271      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 208      |
| explained_variance | 0.166    |
| fps                | 461      |
| nupdates           | 39100    |
| policy_entropy     | 0.00608  |
| total_timesteps    | 195500   |
| value_loss         | 687      |
---------------------------------
10.0
10.0
17.44
10.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 208      |
| explained_variance | -149     |
| fps                | 461      |
| nupdates           | 39200    |
| policy_entropy     | 0.538    |
| total_timesteps    | 196000   |
| value_loss         | 2.7e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.875    |
| fps                | 461      |
| nupdates           | 39300    |
| policy_entropy     | 0.0109   |
| total_timesteps    | 196500   |
| value_loss         | 15.8     |
---------------------------------
9.0
9.0
15.92
20.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.968    |
| fps                | 461      |
| nupdates           | 39400    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 197000   |
| value_loss         | 5.16     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 39500    |
| policy_entropy     | 0.215    |
| total_timesteps    | 197500   |
| value_loss         | 341      |
---------------------------------
10.0
10.0
14.97
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 215      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 39600    |
| policy_entropy     | 0.289    |
| total_timesteps    | 198000   |
| value_loss         | 2.94e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.875    |
| fps                | 461      |
| nupdates           | 39700    |
| policy_entropy     | 0.114    |
| total_timesteps    | 198500   |
| value_loss         | 32       |
---------------------------------
29.0
29.0
16.09
10.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | -5.36    |
| fps                | 461      |
| nupdates           | 39800    |
| policy_entropy     | 0.1      |
| total_timesteps    | 199000   |
| value_loss         | 937      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | -1.37    |
| fps                | 461      |
| nupdates           | 39900    |
| policy_entropy     | 0.293    |
| total_timesteps    | 199500   |
| value_loss         | 148      |
---------------------------------
23.0
23.0
17.4
20.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 40000    |
| policy_entropy     | 0.673    |
| total_timesteps    | 200000   |
| value_loss         | 128      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | -1.24    |
| fps                | 461      |
| nupdates           | 40100    |
| policy_entropy     | 0.071    |
| total_timesteps    | 200500   |
| value_loss         | 440      |
---------------------------------
9.0
9.0
17.27
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 210      |
| explained_variance | -13.7    |
| fps                | 461      |
| nupdates           | 40200    |
| policy_entropy     | 0.472    |
| total_timesteps    | 201000   |
| value_loss         | 730      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 212      |
| explained_variance | 0.686    |
| fps                | 461      |
| nupdates           | 40300    |
| policy_entropy     | 0.034    |
| total_timesteps    | 201500   |
| value_loss         | 61.7     |
---------------------------------
10.0
10.0
15.69
10.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.867    |
| fps                | 461      |
| nupdates           | 40400    |
| policy_entropy     | 0.00575  |
| total_timesteps    | 202000   |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.773    |
| fps                | 461      |
| nupdates           | 40500    |
| policy_entropy     | 0.192    |
| total_timesteps    | 202500   |
| value_loss         | 230      |
---------------------------------
9.0
9.0
15.55
10.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | -483     |
| fps                | 461      |
| nupdates           | 40600    |
| policy_entropy     | 0.316    |
| total_timesteps    | 203000   |
| value_loss         | 1.13e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 207      |
| explained_variance | -0.222   |
| fps                | 461      |
| nupdates           | 40700    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 203500   |
| value_loss         | 798      |
---------------------------------
16.0
16.0
19.45
19.5
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 204      |
| explained_variance | -3.24    |
| fps                | 461      |
| nupdates           | 40800    |
| policy_entropy     | 0.0611   |
| total_timesteps    | 204000   |
| value_loss         | 356      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 208      |
| explained_variance | -1.56    |
| fps                | 461      |
| nupdates           | 40900    |
| policy_entropy     | 0.121    |
| total_timesteps    | 204500   |
| value_loss         | 179      |
---------------------------------
10.0
10.0
15.69
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.989    |
| fps                | 461      |
| nupdates           | 41000    |
| policy_entropy     | 0.0381   |
| total_timesteps    | 205000   |
| value_loss         | 3.46     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 214      |
| explained_variance | 0.788    |
| fps                | 461      |
| nupdates           | 41100    |
| policy_entropy     | 0.145    |
| total_timesteps    | 205500   |
| value_loss         | 204      |
---------------------------------
10.0
10.0
15.42
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 214      |
| explained_variance | -0.347   |
| fps                | 461      |
| nupdates           | 41200    |
| policy_entropy     | 0.305    |
| total_timesteps    | 206000   |
| value_loss         | 690      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.958    |
| fps                | 461      |
| nupdates           | 41300    |
| policy_entropy     | 0.0104   |
| total_timesteps    | 206500   |
| value_loss         | 4.13     |
---------------------------------
22.0
22.0
16.63
16.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.896    |
| fps                | 461      |
| nupdates           | 41400    |
| policy_entropy     | 0.0846   |
| total_timesteps    | 207000   |
| value_loss         | 227      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.876    |
| fps                | 461      |
| nupdates           | 41500    |
| policy_entropy     | 0.089    |
| total_timesteps    | 207500   |
| value_loss         | 19.5     |
---------------------------------
20.0
20.0
16.74
20.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.803    |
| fps                | 461      |
| nupdates           | 41600    |
| policy_entropy     | 0.00694  |
| total_timesteps    | 208000   |
| value_loss         | 22.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0.853    |
| fps                | 461      |
| nupdates           | 41700    |
| policy_entropy     | 0.0637   |
| total_timesteps    | 208500   |
| value_loss         | 81.9     |
---------------------------------
21.0
21.0
16.44
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.897    |
| fps                | 461      |
| nupdates           | 41800    |
| policy_entropy     | 0.0297   |
| total_timesteps    | 209000   |
| value_loss         | 11.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.801    |
| fps                | 461      |
| nupdates           | 41900    |
| policy_entropy     | 0.259    |
| total_timesteps    | 209500   |
| value_loss         | 42.8     |
---------------------------------
9.0
9.0
13.99
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.97     |
| fps                | 461      |
| nupdates           | 42000    |
| policy_entropy     | 0.00551  |
| total_timesteps    | 210000   |
| value_loss         | 7.3      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.885    |
| fps                | 461      |
| nupdates           | 42100    |
| policy_entropy     | 0.00481  |
| total_timesteps    | 210500   |
| value_loss         | 12.9     |
---------------------------------
9.0
9.0
14.96
15.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.243    |
| fps                | 461      |
| nupdates           | 42200    |
| policy_entropy     | 0.0219   |
| total_timesteps    | 211000   |
| value_loss         | 322      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 217      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 42300    |
| policy_entropy     | 0.262    |
| total_timesteps    | 211500   |
| value_loss         | 123      |
---------------------------------
11.0
11.0
16.67
11.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.99     |
| fps                | 461      |
| nupdates           | 42400    |
| policy_entropy     | 0.00874  |
| total_timesteps    | 212000   |
| value_loss         | 0.672    |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.861    |
| fps                | 461      |
| nupdates           | 42500    |
| policy_entropy     | 0.00528  |
| total_timesteps    | 212500   |
| value_loss         | 36       |
---------------------------------
10.0
10.0
15.74
12.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 213      |
| explained_variance | -2.21    |
| fps                | 461      |
| nupdates           | 42600    |
| policy_entropy     | 0.0478   |
| total_timesteps    | 213000   |
| value_loss         | 224      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | -0.948   |
| fps                | 461      |
| nupdates           | 42700    |
| policy_entropy     | 0.181    |
| total_timesteps    | 213500   |
| value_loss         | 51.7     |
---------------------------------
10.0
10.0
14.12
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.989    |
| fps                | 461      |
| nupdates           | 42800    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 214000   |
| value_loss         | 2.33     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0        |
| fps                | 461      |
| nupdates           | 42900    |
| policy_entropy     | 0.146    |
| total_timesteps    | 214500   |
| value_loss         | 101      |
---------------------------------
11.0
11.0
15.43
11.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 212      |
| explained_variance | 0.913    |
| fps                | 461      |
| nupdates           | 43000    |
| policy_entropy     | 0.00875  |
| total_timesteps    | 215000   |
| value_loss         | 209      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.898    |
| fps                | 461      |
| nupdates           | 43100    |
| policy_entropy     | 0.00955  |
| total_timesteps    | 215500   |
| value_loss         | 222      |
---------------------------------
11.0
11.0
16.39
10.5
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | 0.967    |
| fps                | 461      |
| nupdates           | 43200    |
| policy_entropy     | 0.0384   |
| total_timesteps    | 216000   |
| value_loss         | 7.19     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.895    |
| fps                | 461      |
| nupdates           | 43300    |
| policy_entropy     | 0.00987  |
| total_timesteps    | 216500   |
| value_loss         | 8.75     |
---------------------------------
10.0
10.0
16.25
10.5
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.866    |
| fps                | 461      |
| nupdates           | 43400    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 217000   |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 212      |
| explained_variance | -0.532   |
| fps                | 461      |
| nupdates           | 43500    |
| policy_entropy     | 0.0071   |
| total_timesteps    | 217500   |
| value_loss         | 186      |
---------------------------------
18.0
18.0
15.53
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 217      |
| explained_variance | -7.71    |
| fps                | 461      |
| nupdates           | 43600    |
| policy_entropy     | 0.0061   |
| total_timesteps    | 218000   |
| value_loss         | 1.45e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.453    |
| fps                | 461      |
| nupdates           | 43700    |
| policy_entropy     | 0.0458   |
| total_timesteps    | 218500   |
| value_loss         | 433      |
---------------------------------
19.0
19.0
16.85
19.5
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 211      |
| explained_variance | 0.689    |
| fps                | 461      |
| nupdates           | 43800    |
| policy_entropy     | 0.423    |
| total_timesteps    | 219000   |
| value_loss         | 177      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.957    |
| fps                | 461      |
| nupdates           | 43900    |
| policy_entropy     | 0.00551  |
| total_timesteps    | 219500   |
| value_loss         | 4.52     |
---------------------------------
20.0
20.0
15.98
20.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 215      |
| explained_variance | 0.772    |
| fps                | 461      |
| nupdates           | 44000    |
| policy_entropy     | 0.0305   |
| total_timesteps    | 220000   |
| value_loss         | 22       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 214      |
| explained_variance | -0.294   |
| fps                | 461      |
| nupdates           | 44100    |
| policy_entropy     | 0.497    |
| total_timesteps    | 220500   |
| value_loss         | 105      |
---------------------------------
22.0
22.0
15.97
10.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 213      |
| explained_variance | -3.03    |
| fps                | 461      |
| nupdates           | 44200    |
| policy_entropy     | 0.375    |
| total_timesteps    | 221000   |
| value_loss         | 322      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | -2.09    |
| fps                | 461      |
| nupdates           | 44300    |
| policy_entropy     | 0.0487   |
| total_timesteps    | 221500   |
| value_loss         | 215      |
---------------------------------
20.0
20.0
15.73
11.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.712    |
| fps                | 461      |
| nupdates           | 44400    |
| policy_entropy     | 0.0612   |
| total_timesteps    | 222000   |
| value_loss         | 38.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.89     |
| fps                | 461      |
| nupdates           | 44500    |
| policy_entropy     | 0.00622  |
| total_timesteps    | 222500   |
| value_loss         | 10.1     |
---------------------------------
20.0
20.0
16.52
15.5
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 215      |
| explained_variance | -40.3    |
| fps                | 461      |
| nupdates           | 44600    |
| policy_entropy     | 0.0433   |
| total_timesteps    | 223000   |
| value_loss         | 7.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | -2.14    |
| fps                | 461      |
| nupdates           | 44700    |
| policy_entropy     | 0.107    |
| total_timesteps    | 223500   |
| value_loss         | 444      |
---------------------------------
9.0
9.0
15.7
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.954    |
| fps                | 461      |
| nupdates           | 44800    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 224000   |
| value_loss         | 7.56     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0.807    |
| fps                | 460      |
| nupdates           | 44900    |
| policy_entropy     | 0.0342   |
| total_timesteps    | 224500   |
| value_loss         | 7.23     |
---------------------------------
9.0
9.0
16.73
12.0
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.884    |
| fps                | 460      |
| nupdates           | 45000    |
| policy_entropy     | 0.154    |
| total_timesteps    | 225000   |
| value_loss         | 17.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 216      |
| explained_variance | -0.00441 |
| fps                | 460      |
| nupdates           | 45100    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 225500   |
| value_loss         | 471      |
---------------------------------
11.0
11.0
15.02
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 218      |
| explained_variance | 0.952    |
| fps                | 460      |
| nupdates           | 45200    |
| policy_entropy     | 0.0529   |
| total_timesteps    | 226000   |
| value_loss         | 4.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.947    |
| fps                | 460      |
| nupdates           | 45300    |
| policy_entropy     | 0.00458  |
| total_timesteps    | 226500   |
| value_loss         | 7.35     |
---------------------------------
37.0
37.0
14.39
20.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | -2.7     |
| fps                | 460      |
| nupdates           | 45400    |
| policy_entropy     | 0.048    |
| total_timesteps    | 227000   |
| value_loss         | 325      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.847    |
| fps                | 460      |
| nupdates           | 45500    |
| policy_entropy     | 0.0335   |
| total_timesteps    | 227500   |
| value_loss         | 29.1     |
---------------------------------
10.0
10.0
14.03
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 221      |
| explained_variance | 0.941    |
| fps                | 460      |
| nupdates           | 45600    |
| policy_entropy     | 0.00818  |
| total_timesteps    | 228000   |
| value_loss         | 10.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.81     |
| fps                | 460      |
| nupdates           | 45700    |
| policy_entropy     | 0.16     |
| total_timesteps    | 228500   |
| value_loss         | 20.7     |
---------------------------------
10.0
10.0
14.84
15.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.454    |
| fps                | 460      |
| nupdates           | 45800    |
| policy_entropy     | 0.00559  |
| total_timesteps    | 229000   |
| value_loss         | 46.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 210      |
| explained_variance | -0.304   |
| fps                | 460      |
| nupdates           | 45900    |
| policy_entropy     | 0.00696  |
| total_timesteps    | 229500   |
| value_loss         | 1.72e+04 |
---------------------------------
20.0
20.0
18.4
15.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 207      |
| explained_variance | -2.76    |
| fps                | 460      |
| nupdates           | 46000    |
| policy_entropy     | 0.335    |
| total_timesteps    | 230000   |
| value_loss         | 610      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 206      |
| explained_variance | 0.924    |
| fps                | 460      |
| nupdates           | 46100    |
| policy_entropy     | 0.0148   |
| total_timesteps    | 230500   |
| value_loss         | 7.17     |
---------------------------------
10.0
10.0
17.96
10.0
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 205      |
| explained_variance | 0.735    |
| fps                | 460      |
| nupdates           | 46200    |
| policy_entropy     | 0.021    |
| total_timesteps    | 231000   |
| value_loss         | 7.85     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 214      |
| explained_variance | 0.139    |
| fps                | 460      |
| nupdates           | 46300    |
| policy_entropy     | 0.179    |
| total_timesteps    | 231500   |
| value_loss         | 20.3     |
---------------------------------
19.0
19.0
14.45
14.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.34     |
| fps                | 460      |
| nupdates           | 46400    |
| policy_entropy     | 0.214    |
| total_timesteps    | 232000   |
| value_loss         | 34.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.952    |
| fps                | 460      |
| nupdates           | 46500    |
| policy_entropy     | 0.0362   |
| total_timesteps    | 232500   |
| value_loss         | 4.8      |
---------------------------------
13.0
13.0
14.32
13.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.252    |
| fps                | 460      |
| nupdates           | 46600    |
| policy_entropy     | 0.0368   |
| total_timesteps    | 233000   |
| value_loss         | 40.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | -3.55    |
| fps                | 460      |
| nupdates           | 46700    |
| policy_entropy     | 0.424    |
| total_timesteps    | 233500   |
| value_loss         | 745      |
---------------------------------
9.0
9.0
14.38
11.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.913    |
| fps                | 460      |
| nupdates           | 46800    |
| policy_entropy     | 0.0218   |
| total_timesteps    | 234000   |
| value_loss         | 8.53     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | -1.1     |
| fps                | 460      |
| nupdates           | 46900    |
| policy_entropy     | 0.037    |
| total_timesteps    | 234500   |
| value_loss         | 61.9     |
---------------------------------
10.0
10.0
15.93
10.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 212      |
| explained_variance | -2.57    |
| fps                | 460      |
| nupdates           | 47000    |
| policy_entropy     | 0.0486   |
| total_timesteps    | 235000   |
| value_loss         | 1.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 208      |
| explained_variance | -1.23    |
| fps                | 460      |
| nupdates           | 47100    |
| policy_entropy     | 0.0555   |
| total_timesteps    | 235500   |
| value_loss         | 449      |
---------------------------------
11.0
11.0
16.82
11.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.868    |
| fps                | 460      |
| nupdates           | 47200    |
| policy_entropy     | 0.00424  |
| total_timesteps    | 236000   |
| value_loss         | 11.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | -1.38    |
| fps                | 460      |
| nupdates           | 47300    |
| policy_entropy     | 0.0383   |
| total_timesteps    | 236500   |
| value_loss         | 179      |
---------------------------------
19.0
19.0
15.47
14.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.831    |
| fps                | 460      |
| nupdates           | 47400    |
| policy_entropy     | 0.285    |
| total_timesteps    | 237000   |
| value_loss         | 4.77     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 218      |
| explained_variance | -0.436   |
| fps                | 460      |
| nupdates           | 47500    |
| policy_entropy     | 0.0392   |
| total_timesteps    | 237500   |
| value_loss         | 691      |
---------------------------------
11.0
11.0
16.11
10.5
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 216      |
| explained_variance | -0.626   |
| fps                | 460      |
| nupdates           | 47600    |
| policy_entropy     | 0.179    |
| total_timesteps    | 238000   |
| value_loss         | 167      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.0597   |
| fps                | 460      |
| nupdates           | 47700    |
| policy_entropy     | 0.0403   |
| total_timesteps    | 238500   |
| value_loss         | 443      |
---------------------------------
21.0
21.0
14.81
15.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.888    |
| fps                | 460      |
| nupdates           | 47800    |
| policy_entropy     | 0.0366   |
| total_timesteps    | 239000   |
| value_loss         | 16.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.972    |
| fps                | 459      |
| nupdates           | 47900    |
| policy_entropy     | 0.0093   |
| total_timesteps    | 239500   |
| value_loss         | 8.31     |
---------------------------------
13.0
13.0
14.5
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.706    |
| fps                | 459      |
| nupdates           | 48000    |
| policy_entropy     | 0.0364   |
| total_timesteps    | 240000   |
| value_loss         | 21       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.832    |
| fps                | 459      |
| nupdates           | 48100    |
| policy_entropy     | 0.209    |
| total_timesteps    | 240500   |
| value_loss         | 68.7     |
---------------------------------
10.0
10.0
14.14
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.896    |
| fps                | 459      |
| nupdates           | 48200    |
| policy_entropy     | 0.0254   |
| total_timesteps    | 241000   |
| value_loss         | 14.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.736    |
| fps                | 459      |
| nupdates           | 48300    |
| policy_entropy     | 0.0389   |
| total_timesteps    | 241500   |
| value_loss         | 43.6     |
---------------------------------
20.0
20.0
14.37
18.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | -0.265   |
| fps                | 459      |
| nupdates           | 48400    |
| policy_entropy     | 0.0467   |
| total_timesteps    | 242000   |
| value_loss         | 343      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 221      |
| explained_variance | 0.689    |
| fps                | 459      |
| nupdates           | 48500    |
| policy_entropy     | 0.197    |
| total_timesteps    | 242500   |
| value_loss         | 86.5     |
---------------------------------
11.0
11.0
15.49
11.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.31     |
| fps                | 459      |
| nupdates           | 48600    |
| policy_entropy     | 0.145    |
| total_timesteps    | 243000   |
| value_loss         | 194      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.977    |
| fps                | 459      |
| nupdates           | 48700    |
| policy_entropy     | 0.0225   |
| total_timesteps    | 243500   |
| value_loss         | 8.77     |
---------------------------------
22.0
22.0
15.81
15.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.93     |
| fps                | 459      |
| nupdates           | 48800    |
| policy_entropy     | 0.011    |
| total_timesteps    | 244000   |
| value_loss         | 5.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.68     |
| fps                | 459      |
| nupdates           | 48900    |
| policy_entropy     | 0.0322   |
| total_timesteps    | 244500   |
| value_loss         | 13.5     |
---------------------------------
11.0
11.0
15.38
10.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.983    |
| fps                | 459      |
| nupdates           | 49000    |
| policy_entropy     | 0.0314   |
| total_timesteps    | 245000   |
| value_loss         | 4.84     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.941    |
| fps                | 459      |
| nupdates           | 49100    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 245500   |
| value_loss         | 15.4     |
---------------------------------
10.0
10.0
15.68
15.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.92     |
| fps                | 459      |
| nupdates           | 49200    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 246000   |
| value_loss         | 18.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.99     |
| fps                | 459      |
| nupdates           | 49300    |
| policy_entropy     | 0.0326   |
| total_timesteps    | 246500   |
| value_loss         | 8.56     |
---------------------------------
10.0
10.0
14.95
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 220      |
| explained_variance | -0.0475  |
| fps                | 458      |
| nupdates           | 49400    |
| policy_entropy     | 0.251    |
| total_timesteps    | 247000   |
| value_loss         | 89.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.993    |
| fps                | 458      |
| nupdates           | 49500    |
| policy_entropy     | 0.0155   |
| total_timesteps    | 247500   |
| value_loss         | 2.02     |
---------------------------------
10.0
10.0
14.51
13.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.0863   |
| fps                | 458      |
| nupdates           | 49600    |
| policy_entropy     | 0.0363   |
| total_timesteps    | 248000   |
| value_loss         | 319      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.933    |
| fps                | 458      |
| nupdates           | 49700    |
| policy_entropy     | 0.0194   |
| total_timesteps    | 248500   |
| value_loss         | 39.4     |
---------------------------------
9.0
9.0
14.62
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.966    |
| fps                | 458      |
| nupdates           | 49800    |
| policy_entropy     | 0.0192   |
| total_timesteps    | 249000   |
| value_loss         | 4.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | -6.37    |
| fps                | 458      |
| nupdates           | 49900    |
| policy_entropy     | 0.717    |
| total_timesteps    | 249500   |
| value_loss         | 435      |
---------------------------------
21.0
21.0
15.01
12.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | -2.67    |
| fps                | 458      |
| nupdates           | 50000    |
| policy_entropy     | 0.0361   |
| total_timesteps    | 250000   |
| value_loss         | 158      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 215      |
| explained_variance | 0.864    |
| fps                | 458      |
| nupdates           | 50100    |
| policy_entropy     | 0.0122   |
| total_timesteps    | 250500   |
| value_loss         | 8.7      |
---------------------------------
10.0
10.0
14.29
10.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.989    |
| fps                | 458      |
| nupdates           | 50200    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 251000   |
| value_loss         | 3.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.545    |
| fps                | 458      |
| nupdates           | 50300    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 251500   |
| value_loss         | 343      |
---------------------------------
9.0
9.0
13.57
9.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 221      |
| explained_variance | -2.1     |
| fps                | 458      |
| nupdates           | 50400    |
| policy_entropy     | 0.0346   |
| total_timesteps    | 252000   |
| value_loss         | 272      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.955    |
| fps                | 458      |
| nupdates           | 50500    |
| policy_entropy     | 0.0404   |
| total_timesteps    | 252500   |
| value_loss         | 3.65     |
---------------------------------
9.0
9.0
14.96
15.5
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 219      |
| explained_variance | 0.978    |
| fps                | 458      |
| nupdates           | 50600    |
| policy_entropy     | 0.0125   |
| total_timesteps    | 253000   |
| value_loss         | 4.06     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 218      |
| explained_variance | -1.62    |
| fps                | 458      |
| nupdates           | 50700    |
| policy_entropy     | 0.0329   |
| total_timesteps    | 253500   |
| value_loss         | 371      |
---------------------------------
10.0
10.0
15.2
14.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.942    |
| fps                | 458      |
| nupdates           | 50800    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 254000   |
| value_loss         | 15.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.838    |
| fps                | 457      |
| nupdates           | 50900    |
| policy_entropy     | 0.0151   |
| total_timesteps    | 254500   |
| value_loss         | 31.3     |
---------------------------------
21.0
21.0
14.12
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 221      |
| explained_variance | 0.714    |
| fps                | 457      |
| nupdates           | 51000    |
| policy_entropy     | 0.0625   |
| total_timesteps    | 255000   |
| value_loss         | 55.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | -0.382   |
| fps                | 457      |
| nupdates           | 51100    |
| policy_entropy     | 0.0166   |
| total_timesteps    | 255500   |
| value_loss         | 133      |
---------------------------------
21.0
21.0
18.12
14.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 207      |
| explained_variance | -1.31    |
| fps                | 457      |
| nupdates           | 51200    |
| policy_entropy     | 0.0436   |
| total_timesteps    | 256000   |
| value_loss         | 1.3e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 18.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.323    |
| fps                | 457      |
| nupdates           | 51300    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 256500   |
| value_loss         | 92.8     |
---------------------------------
10.0
10.0
15.37
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0884  |
| fps                | 457      |
| nupdates           | 51400    |
| policy_entropy     | 0.415    |
| total_timesteps    | 257000   |
| value_loss         | 383      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.79     |
| fps                | 457      |
| nupdates           | 51500    |
| policy_entropy     | 0.111    |
| total_timesteps    | 257500   |
| value_loss         | 32.2     |
---------------------------------
9.0
9.0
13.75
10.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.954    |
| fps                | 457      |
| nupdates           | 51600    |
| policy_entropy     | 0.0213   |
| total_timesteps    | 258000   |
| value_loss         | 6.06     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.803    |
| fps                | 457      |
| nupdates           | 51700    |
| policy_entropy     | 0.17     |
| total_timesteps    | 258500   |
| value_loss         | 26       |
---------------------------------
20.0
20.0
13.91
18.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.361    |
| fps                | 457      |
| nupdates           | 51800    |
| policy_entropy     | 0.071    |
| total_timesteps    | 259000   |
| value_loss         | 37.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.915    |
| fps                | 457      |
| nupdates           | 51900    |
| policy_entropy     | 0.216    |
| total_timesteps    | 259500   |
| value_loss         | 7.45     |
---------------------------------
10.0
10.0
13.88
11.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.801    |
| fps                | 456      |
| nupdates           | 52000    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 260000   |
| value_loss         | 21.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.963    |
| fps                | 456      |
| nupdates           | 52100    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 260500   |
| value_loss         | 8.11     |
---------------------------------
11.0
11.0
14.72
11.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.988    |
| fps                | 456      |
| nupdates           | 52200    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 261000   |
| value_loss         | 0.974    |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.966    |
| fps                | 456      |
| nupdates           | 52300    |
| policy_entropy     | 0.00988  |
| total_timesteps    | 261500   |
| value_loss         | 15.1     |
---------------------------------
11.0
11.0
14.89
11.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.264    |
| fps                | 456      |
| nupdates           | 52400    |
| policy_entropy     | 0.00967  |
| total_timesteps    | 262000   |
| value_loss         | 375      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | -0.553   |
| fps                | 456      |
| nupdates           | 52500    |
| policy_entropy     | 0.142    |
| total_timesteps    | 262500   |
| value_loss         | 545      |
---------------------------------
9.0
9.0
14.58
9.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | -1.69    |
| fps                | 456      |
| nupdates           | 52600    |
| policy_entropy     | 0.0329   |
| total_timesteps    | 263000   |
| value_loss         | 266      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | -0.481   |
| fps                | 456      |
| nupdates           | 52700    |
| policy_entropy     | 0.00597  |
| total_timesteps    | 263500   |
| value_loss         | 188      |
---------------------------------
10.0
10.0
14.37
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.686    |
| fps                | 456      |
| nupdates           | 52800    |
| policy_entropy     | 0.207    |
| total_timesteps    | 264000   |
| value_loss         | 29.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 222      |
| explained_variance | -1.48    |
| fps                | 456      |
| nupdates           | 52900    |
| policy_entropy     | 0.0741   |
| total_timesteps    | 264500   |
| value_loss         | 73.3     |
---------------------------------
18.0
18.0
16.01
10.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 215      |
| explained_variance | -2.41    |
| fps                | 456      |
| nupdates           | 53000    |
| policy_entropy     | 0.272    |
| total_timesteps    | 265000   |
| value_loss         | 315      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 212      |
| explained_variance | 0.0341   |
| fps                | 455      |
| nupdates           | 53100    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 265500   |
| value_loss         | 604      |
---------------------------------
20.0
20.0
17.88
20.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 210      |
| explained_variance | 0.879    |
| fps                | 455      |
| nupdates           | 53200    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 266000   |
| value_loss         | 230      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.974    |
| fps                | 455      |
| nupdates           | 53300    |
| policy_entropy     | 0.0419   |
| total_timesteps    | 266500   |
| value_loss         | 6.15     |
---------------------------------
22.0
22.0
15.05
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.893    |
| fps                | 455      |
| nupdates           | 53400    |
| policy_entropy     | 0.195    |
| total_timesteps    | 267000   |
| value_loss         | 32.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.883    |
| fps                | 455      |
| nupdates           | 53500    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 267500   |
| value_loss         | 11.3     |
---------------------------------
11.0
11.0
14.32
11.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | -0.217   |
| fps                | 455      |
| nupdates           | 53600    |
| policy_entropy     | 0.232    |
| total_timesteps    | 268000   |
| value_loss         | 164      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | 0.93     |
| fps                | 455      |
| nupdates           | 53700    |
| policy_entropy     | 0.00874  |
| total_timesteps    | 268500   |
| value_loss         | 994      |
---------------------------------
11.0
11.0
15.01
10.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | 0.958    |
| fps                | 455      |
| nupdates           | 53800    |
| policy_entropy     | 0.011    |
| total_timesteps    | 269000   |
| value_loss         | 2.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 216      |
| explained_variance | -3.31    |
| fps                | 455      |
| nupdates           | 53900    |
| policy_entropy     | 0.0391   |
| total_timesteps    | 269500   |
| value_loss         | 428      |
---------------------------------
10.0
10.0
14.37
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.988    |
| fps                | 455      |
| nupdates           | 54000    |
| policy_entropy     | 0.00928  |
| total_timesteps    | 270000   |
| value_loss         | 10.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.105    |
| fps                | 455      |
| nupdates           | 54100    |
| policy_entropy     | 0.0256   |
| total_timesteps    | 270500   |
| value_loss         | 324      |
---------------------------------
9.0
9.0
14.28
10.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 219      |
| explained_variance | 0.933    |
| fps                | 454      |
| nupdates           | 54200    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 271000   |
| value_loss         | 6.09     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.965    |
| fps                | 454      |
| nupdates           | 54300    |
| policy_entropy     | 0.00444  |
| total_timesteps    | 271500   |
| value_loss         | 2.69     |
---------------------------------
9.0
9.0
14.68
20.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.514    |
| fps                | 454      |
| nupdates           | 54400    |
| policy_entropy     | 0.00668  |
| total_timesteps    | 272000   |
| value_loss         | 50.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.261    |
| fps                | 454      |
| nupdates           | 54500    |
| policy_entropy     | 0.237    |
| total_timesteps    | 272500   |
| value_loss         | 168      |
---------------------------------
22.0
22.0
15.44
10.5
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.587    |
| fps                | 454      |
| nupdates           | 54600    |
| policy_entropy     | 0.0627   |
| total_timesteps    | 273000   |
| value_loss         | 23.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.559    |
| fps                | 454      |
| nupdates           | 54700    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 273500   |
| value_loss         | 365      |
---------------------------------
21.0
21.0
13.93
11.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.788    |
| fps                | 454      |
| nupdates           | 54800    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 274000   |
| value_loss         | 114      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.994    |
| fps                | 454      |
| nupdates           | 54900    |
| policy_entropy     | 0.00509  |
| total_timesteps    | 274500   |
| value_loss         | 1.54     |
---------------------------------
9.0
9.0
13.84
10.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.574    |
| fps                | 454      |
| nupdates           | 55000    |
| policy_entropy     | 0.28     |
| total_timesteps    | 275000   |
| value_loss         | 26.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.992    |
| fps                | 454      |
| nupdates           | 55100    |
| policy_entropy     | 0.0983   |
| total_timesteps    | 275500   |
| value_loss         | 0.728    |
---------------------------------
10.0
10.0
14.15
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | -2.21    |
| fps                | 454      |
| nupdates           | 55200    |
| policy_entropy     | 0.0234   |
| total_timesteps    | 276000   |
| value_loss         | 447      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 220      |
| explained_variance | 0.563    |
| fps                | 454      |
| nupdates           | 55300    |
| policy_entropy     | 0.12     |
| total_timesteps    | 276500   |
| value_loss         | 20.7     |
---------------------------------
10.0
10.0
14.44
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.988    |
| fps                | 454      |
| nupdates           | 55400    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 277000   |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | -1.07    |
| fps                | 454      |
| nupdates           | 55500    |
| policy_entropy     | 0.25     |
| total_timesteps    | 277500   |
| value_loss         | 188      |
---------------------------------
9.0
9.0
14.05
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | 0.653    |
| fps                | 454      |
| nupdates           | 55600    |
| policy_entropy     | 0.219    |
| total_timesteps    | 278000   |
| value_loss         | 58.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.602    |
| fps                | 454      |
| nupdates           | 55700    |
| policy_entropy     | 0.251    |
| total_timesteps    | 278500   |
| value_loss         | 21       |
---------------------------------
10.0
10.0
15.18
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 219      |
| explained_variance | 0.983    |
| fps                | 453      |
| nupdates           | 55800    |
| policy_entropy     | 0.00859  |
| total_timesteps    | 279000   |
| value_loss         | 3.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.809    |
| fps                | 453      |
| nupdates           | 55900    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 279500   |
| value_loss         | 9.82     |
---------------------------------
10.0
10.0
14.42
11.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | -1.66    |
| fps                | 453      |
| nupdates           | 56000    |
| policy_entropy     | 0.0924   |
| total_timesteps    | 280000   |
| value_loss         | 213      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.976    |
| fps                | 453      |
| nupdates           | 56100    |
| policy_entropy     | 0.0709   |
| total_timesteps    | 280500   |
| value_loss         | 2.31     |
---------------------------------
19.0
19.0
14.81
12.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.889    |
| fps                | 453      |
| nupdates           | 56200    |
| policy_entropy     | 0.147    |
| total_timesteps    | 281000   |
| value_loss         | 35.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.966    |
| fps                | 453      |
| nupdates           | 56300    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 281500   |
| value_loss         | 7.39     |
---------------------------------
10.0
10.0
13.87
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | 0.938    |
| fps                | 453      |
| nupdates           | 56400    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 282000   |
| value_loss         | 7.01     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.976    |
| fps                | 453      |
| nupdates           | 56500    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 282500   |
| value_loss         | 6.02     |
---------------------------------
19.0
19.0
14.28
14.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.987    |
| fps                | 453      |
| nupdates           | 56600    |
| policy_entropy     | 0.00559  |
| total_timesteps    | 283000   |
| value_loss         | 578      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | -2.89    |
| fps                | 453      |
| nupdates           | 56700    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 283500   |
| value_loss         | 360      |
---------------------------------
20.0
20.0
13.86
14.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.982    |
| fps                | 453      |
| nupdates           | 56800    |
| policy_entropy     | 0.017    |
| total_timesteps    | 284000   |
| value_loss         | 3.91     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.917    |
| fps                | 453      |
| nupdates           | 56900    |
| policy_entropy     | 0.133    |
| total_timesteps    | 284500   |
| value_loss         | 2.38     |
---------------------------------
9.0
9.0
14.59
11.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 220      |
| explained_variance | 0.856    |
| fps                | 453      |
| nupdates           | 57000    |
| policy_entropy     | 0.0103   |
| total_timesteps    | 285000   |
| value_loss         | 9.93     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.899    |
| fps                | 453      |
| nupdates           | 57100    |
| policy_entropy     | 0.00479  |
| total_timesteps    | 285500   |
| value_loss         | 8.19     |
---------------------------------
10.0
10.0
13.45
10.0
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.822    |
| fps                | 453      |
| nupdates           | 57200    |
| policy_entropy     | 0.00875  |
| total_timesteps    | 286000   |
| value_loss         | 13       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.871    |
| fps                | 452      |
| nupdates           | 57300    |
| policy_entropy     | 0.00302  |
| total_timesteps    | 286500   |
| value_loss         | 12.7     |
---------------------------------
10.0
10.0
15.18
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | -0.809   |
| fps                | 452      |
| nupdates           | 57400    |
| policy_entropy     | 0.0215   |
| total_timesteps    | 287000   |
| value_loss         | 1.17e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 217      |
| explained_variance | 0.82     |
| fps                | 452      |
| nupdates           | 57500    |
| policy_entropy     | 0.00221  |
| total_timesteps    | 287500   |
| value_loss         | 18.5     |
---------------------------------
20.0
20.0
14.94
15.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.698    |
| fps                | 452      |
| nupdates           | 57600    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 288000   |
| value_loss         | 44.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | -3.26    |
| fps                | 452      |
| nupdates           | 57700    |
| policy_entropy     | 0.0229   |
| total_timesteps    | 288500   |
| value_loss         | 399      |
---------------------------------
11.0
11.0
14.34
11.0
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | -2.29    |
| fps                | 452      |
| nupdates           | 57800    |
| policy_entropy     | 0.0231   |
| total_timesteps    | 289000   |
| value_loss         | 159      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.896    |
| fps                | 452      |
| nupdates           | 57900    |
| policy_entropy     | 0.0524   |
| total_timesteps    | 289500   |
| value_loss         | 12.2     |
---------------------------------
11.0
11.0
14.19
15.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | 0.031    |
| fps                | 452      |
| nupdates           | 58000    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 290000   |
| value_loss         | 472      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.989    |
| fps                | 452      |
| nupdates           | 58100    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 290500   |
| value_loss         | 4.74     |
---------------------------------
19.0
19.0
13.96
19.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | 0.454    |
| fps                | 452      |
| nupdates           | 58200    |
| policy_entropy     | 0.137    |
| total_timesteps    | 291000   |
| value_loss         | 30       |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.962    |
| fps                | 452      |
| nupdates           | 58300    |
| policy_entropy     | 0.052    |
| total_timesteps    | 291500   |
| value_loss         | 16.7     |
---------------------------------
21.0
21.0
14.34
18.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.944    |
| fps                | 452      |
| nupdates           | 58400    |
| policy_entropy     | 0.00876  |
| total_timesteps    | 292000   |
| value_loss         | 5.41     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.804    |
| fps                | 452      |
| nupdates           | 58500    |
| policy_entropy     | 0.237    |
| total_timesteps    | 292500   |
| value_loss         | 33.5     |
---------------------------------
21.0
21.0
15.2
20.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 218      |
| explained_variance | -1.23    |
| fps                | 452      |
| nupdates           | 58600    |
| policy_entropy     | 0.0643   |
| total_timesteps    | 293000   |
| value_loss         | 825      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.933    |
| fps                | 452      |
| nupdates           | 58700    |
| policy_entropy     | 0.18     |
| total_timesteps    | 293500   |
| value_loss         | 2.61     |
---------------------------------
21.0
21.0
14.26
15.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | 0.949    |
| fps                | 452      |
| nupdates           | 58800    |
| policy_entropy     | 0.00603  |
| total_timesteps    | 294000   |
| value_loss         | 70.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 219      |
| explained_variance | 0.165    |
| fps                | 452      |
| nupdates           | 58900    |
| policy_entropy     | 0.00519  |
| total_timesteps    | 294500   |
| value_loss         | 381      |
---------------------------------
10.0
10.0
14.6
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.969    |
| fps                | 452      |
| nupdates           | 59000    |
| policy_entropy     | 0.00428  |
| total_timesteps    | 295000   |
| value_loss         | 706      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 217      |
| explained_variance | 0.99     |
| fps                | 451      |
| nupdates           | 59100    |
| policy_entropy     | 0.00286  |
| total_timesteps    | 295500   |
| value_loss         | 5        |
---------------------------------
9.0
9.0
13.91
15.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.247    |
| fps                | 451      |
| nupdates           | 59200    |
| policy_entropy     | 0.00548  |
| total_timesteps    | 296000   |
| value_loss         | 553      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | 0.966    |
| fps                | 451      |
| nupdates           | 59300    |
| policy_entropy     | 0.0107   |
| total_timesteps    | 296500   |
| value_loss         | 3.07     |
---------------------------------
10.0
10.0
14.49
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 221      |
| explained_variance | 0.505    |
| fps                | 451      |
| nupdates           | 59400    |
| policy_entropy     | 0.157    |
| total_timesteps    | 297000   |
| value_loss         | 11.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 220      |
| explained_variance | -1.97    |
| fps                | 451      |
| nupdates           | 59500    |
| policy_entropy     | 0.0261   |
| total_timesteps    | 297500   |
| value_loss         | 392      |
---------------------------------
9.0
9.0
13.82
14.5
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.927    |
| fps                | 451      |
| nupdates           | 59600    |
| policy_entropy     | 0.00895  |
| total_timesteps    | 298000   |
| value_loss         | 6.6      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 219      |
| explained_variance | -0.668   |
| fps                | 451      |
| nupdates           | 59700    |
| policy_entropy     | 0.0454   |
| total_timesteps    | 298500   |
| value_loss         | 574      |
---------------------------------
9.0
9.0
14.34
15.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 221      |
| explained_variance | -0.448   |
| fps                | 451      |
| nupdates           | 59800    |
| policy_entropy     | 0.0297   |
| total_timesteps    | 299000   |
| value_loss         | 265      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 222      |
| explained_variance | 0.959    |
| fps                | 451      |
| nupdates           | 59900    |
| policy_entropy     | 0.127    |
| total_timesteps    | 299500   |
| value_loss         | 7.75     |
---------------------------------
21.0
21.0
14.63
20.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.424    |
| fps                | 451      |
| nupdates           | 60000    |
| policy_entropy     | 0.276    |
| total_timesteps    | 300000   |
| value_loss         | 41.1     |
---------------------------------