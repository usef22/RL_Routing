WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002208D985780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002208D985780>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\common\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002208DC76550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002208DC76550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\a2c\a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\tensorflow\python\ops\clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\a2c\a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\tensorflow\python\training\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From C:\Users\usef2\anaconda3\envs\RL_drone-main\lib\site-packages\stable_baselines\a2c\a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.
___________________________________________________________________________________________________
{'Destination': 1, 'BW_Block': 4}
___________________________________________________________________________________________________
>>>>>>>>>>>>>>>>>>>>>> 9
7
[[2070 1607 1013 2529 1793  800  587]
 [2231 1565 1392 2300 2937 2516 1974]
 [1750 1201 1473 2535 3095 2391 4086]
 [2126  790 1108 1931 1612 1003 4398]
 [1939  536  670 1118 1283  822 3921]
 [2966 1512 1704 1811 1939 1667 4611]
 [3700 2665 2503 3366 2387 1378 2548]]
Wrapping the env in a DummyVecEnv.
---------------------------------
| explained_variance | 0.0226   |
| fps                | 13       |
| nupdates           | 1        |
| policy_entropy     | 1.1      |
| total_timesteps    | 5        |
| value_loss         | 92.2     |
---------------------------------
----------------------------------
| ep_len_mean        | 330       |
| ep_reward_mean     | -1.21e+03 |
| explained_variance | -0.0393   |
| fps                | 359       |
| nupdates           | 100       |
| policy_entropy     | 1.1       |
| total_timesteps    | 500       |
| value_loss         | 97        |
----------------------------------
251.0
251.0
290.5
290.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 290       |
| ep_reward_mean     | -1.03e+03 |
| explained_variance | 0.0424    |
| fps                | 411       |
| nupdates           | 200       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1000      |
| value_loss         | 127       |
----------------------------------
----------------------------------
| ep_len_mean        | 366       |
| ep_reward_mean     | -1.32e+03 |
| explained_variance | -0.0351   |
| fps                | 432       |
| nupdates           | 300       |
| policy_entropy     | 1.1       |
| total_timesteps    | 1500      |
| value_loss         | 102       |
----------------------------------
151.0
151.0
322.6
330.0
---------------------------------
| ep_len_mean        | 323      |
| ep_reward_mean     | -1.1e+03 |
| explained_variance | 0.0304   |
| fps                | 443      |
| nupdates           | 400      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2000     |
| value_loss         | 171      |
---------------------------------
---------------------------------
| ep_len_mean        | 352      |
| ep_reward_mean     | -1.2e+03 |
| explained_variance | -0.0615  |
| fps                | 453      |
| nupdates           | 500      |
| policy_entropy     | 1.1      |
| total_timesteps    | 2500     |
| value_loss         | 105      |
---------------------------------
204.0
204.0
320.55555555555554
330.0
----------------------------------
| ep_len_mean        | 321       |
| ep_reward_mean     | -1.05e+03 |
| explained_variance | 0.0556    |
| fps                | 459       |
| nupdates           | 600       |
| policy_entropy     | 1.09      |
| total_timesteps    | 3000      |
| value_loss         | 24.4      |
----------------------------------
----------------------------------
| ep_len_mean        | 314       |
| ep_reward_mean     | -1e+03    |
| explained_variance | -0.000895 |
| fps                | 461       |
| nupdates           | 700       |
| policy_entropy     | 1.09      |
| total_timesteps    | 3500      |
| value_loss         | 90        |
----------------------------------
68.0
68.0
319.1666666666667
309.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 319       |
| ep_reward_mean     | -1.01e+03 |
| explained_variance | 0.0698    |
| fps                | 461       |
| nupdates           | 800       |
| policy_entropy     | 1.07      |
| total_timesteps    | 4000      |
| value_loss         | 239       |
----------------------------------
---------------------------------
| ep_len_mean        | 309      |
| ep_reward_mean     | -965     |
| explained_variance | 1.19e-07 |
| fps                | 464      |
| nupdates           | 900      |
| policy_entropy     | 1.01     |
| total_timesteps    | 4500     |
| value_loss         | 154      |
---------------------------------
264.0
264.0
299.3125
236.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 299      |
| ep_reward_mean     | -927     |
| explained_variance | 0.0032   |
| fps                | 466      |
| nupdates           | 1000     |
| policy_entropy     | 1.07     |
| total_timesteps    | 5000     |
| value_loss         | 82.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 319      |
| ep_reward_mean     | -1e+03   |
| explained_variance | 0.000249 |
| fps                | 468      |
| nupdates           | 1100     |
| policy_entropy     | 1.05     |
| total_timesteps    | 5500     |
| value_loss         | 53.6     |
---------------------------------
59.0
59.0
298.25
231.5
---------------------------------
| ep_len_mean        | 298      |
| ep_reward_mean     | -928     |
| explained_variance | 3.96e-05 |
| fps                | 470      |
| nupdates           | 1200     |
| policy_entropy     | 1.06     |
| total_timesteps    | 6000     |
| value_loss         | 4.68     |
---------------------------------
---------------------------------
| ep_len_mean        | 283      |
| ep_reward_mean     | -866     |
| explained_variance | 0        |
| fps                | 472      |
| nupdates           | 1300     |
| policy_entropy     | 1.07     |
| total_timesteps    | 6500     |
| value_loss         | 140      |
---------------------------------
592.0
592.0
296.39130434782606
174.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 296       |
| ep_reward_mean     | -916      |
| explained_variance | -4.95e-05 |
| fps                | 473       |
| nupdates           | 1400      |
| policy_entropy     | 1.04      |
| total_timesteps    | 7000      |
| value_loss         | 144       |
----------------------------------
---------------------------------
| ep_len_mean        | 299      |
| ep_reward_mean     | -925     |
| explained_variance | -8.3e-05 |
| fps                | 474      |
| nupdates           | 1500     |
| policy_entropy     | 1.06     |
| total_timesteps    | 7500     |
| value_loss         | 86.7     |
---------------------------------
80.0
80.0
295.1111111111111
172.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 295      |
| ep_reward_mean     | -915     |
| explained_variance | 2.66e-05 |
| fps                | 475      |
| nupdates           | 1600     |
| policy_entropy     | 1.03     |
| total_timesteps    | 8000     |
| value_loss         | 61.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 255      |
| ep_reward_mean     | -751     |
| explained_variance | 0.00311  |
| fps                | 476      |
| nupdates           | 1700     |
| policy_entropy     | 0.95     |
| total_timesteps    | 8500     |
| value_loss         | 320      |
---------------------------------
371.0
371.0
249.69444444444446
74.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 250      |
| ep_reward_mean     | -733     |
| explained_variance | 0.00809  |
| fps                | 477      |
| nupdates           | 1800     |
| policy_entropy     | 0.881    |
| total_timesteps    | 9000     |
| value_loss         | 243      |
---------------------------------
----------------------------------
| ep_len_mean        | 230       |
| ep_reward_mean     | -651      |
| explained_variance | -7.27e-06 |
| fps                | 477       |
| nupdates           | 1900      |
| policy_entropy     | 0.962     |
| total_timesteps    | 9500      |
| value_loss         | 20.5      |
----------------------------------
77.0
77.0
191.6346153846154
38.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 192       |
| ep_reward_mean     | -497      |
| explained_variance | -0.000111 |
| fps                | 477       |
| nupdates           | 2000      |
| policy_entropy     | 0.921     |
| total_timesteps    | 10000     |
| value_loss         | 127       |
----------------------------------
----------------------------------
| ep_len_mean        | 183       |
| ep_reward_mean     | -458      |
| explained_variance | -1.31e-06 |
| fps                | 477       |
| nupdates           | 2100      |
| policy_entropy     | 0.884     |
| total_timesteps    | 10500     |
| value_loss         | 57.7      |
----------------------------------
63.0
63.0
182.83333333333334
62.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
----------------------------------
| ep_len_mean        | 183       |
| ep_reward_mean     | -453      |
| explained_variance | -0.000501 |
| fps                | 478       |
| nupdates           | 2200      |
| policy_entropy     | 0.919     |
| total_timesteps    | 11000     |
| value_loss         | 161       |
----------------------------------
----------------------------------
| ep_len_mean        | 164       |
| ep_reward_mean     | -375      |
| explained_variance | -0.000721 |
| fps                | 477       |
| nupdates           | 2300      |
| policy_entropy     | 0.697     |
| total_timesteps    | 11500     |
| value_loss         | 80.6      |
----------------------------------
118.0
118.0
151.74683544303798
36.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 152      |
| ep_reward_mean     | -325     |
| explained_variance | 0.0352   |
| fps                | 477      |
| nupdates           | 2400     |
| policy_entropy     | 0.613    |
| total_timesteps    | 12000    |
| value_loss         | 38.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 136      |
| ep_reward_mean     | -261     |
| explained_variance | -0.0236  |
| fps                | 477      |
| nupdates           | 2500     |
| policy_entropy     | 0.477    |
| total_timesteps    | 12500    |
| value_loss         | 5.74e+04 |
---------------------------------
67.0
67.0
126.1
42.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 126      |
| ep_reward_mean     | -218     |
| explained_variance | 1.19e-07 |
| fps                | 477      |
| nupdates           | 2600     |
| policy_entropy     | 0.117    |
| total_timesteps    | 13000    |
| value_loss         | 109      |
---------------------------------
---------------------------------
| ep_len_mean        | 119      |
| ep_reward_mean     | -186     |
| explained_variance | -0.0616  |
| fps                | 478      |
| nupdates           | 2700     |
| policy_entropy     | 0.427    |
| total_timesteps    | 13500    |
| value_loss         | 18.4     |
---------------------------------
18.0
18.0
97.01
63.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 97       |
| ep_reward_mean     | -99.2    |
| explained_variance | 0.00398  |
| fps                | 478      |
| nupdates           | 2800     |
| policy_entropy     | 0.678    |
| total_timesteps    | 14000    |
| value_loss         | 62.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 81.3     |
| ep_reward_mean     | -34      |
| explained_variance | 0        |
| fps                | 479      |
| nupdates           | 2900     |
| policy_entropy     | 0.49     |
| total_timesteps    | 14500    |
| value_loss         | 12.7     |
---------------------------------
57.0
57.0
64.21
34.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 64.2     |
| ep_reward_mean     | 40.1     |
| explained_variance | 0.00172  |
| fps                | 478      |
| nupdates           | 3000     |
| policy_entropy     | 0.811    |
| total_timesteps    | 15000    |
| value_loss         | 60.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 57.1     |
| ep_reward_mean     | 70.3     |
| explained_variance | 0        |
| fps                | 479      |
| nupdates           | 3100     |
| policy_entropy     | 0.273    |
| total_timesteps    | 15500    |
| value_loss         | 11.5     |
---------------------------------
15.0
15.0
59.68
24.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 59.7     |
| ep_reward_mean     | 67.3     |
| explained_variance | -0.00837 |
| fps                | 479      |
| nupdates           | 3200     |
| policy_entropy     | 0.932    |
| total_timesteps    | 16000    |
| value_loss         | 88.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 50.3     |
| ep_reward_mean     | 101      |
| explained_variance | 0.59     |
| fps                | 478      |
| nupdates           | 3300     |
| policy_entropy     | 0.402    |
| total_timesteps    | 16500    |
| value_loss         | 87.6     |
---------------------------------
10.0
10.0
47.29
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 47.3     |
| ep_reward_mean     | 112      |
| explained_variance | 0.00316  |
| fps                | 476      |
| nupdates           | 3400     |
| policy_entropy     | 0.386    |
| total_timesteps    | 17000    |
| value_loss         | 5.35e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 48.9     |
| ep_reward_mean     | 110      |
| explained_variance | -0.00186 |
| fps                | 473      |
| nupdates           | 3500     |
| policy_entropy     | 0.444    |
| total_timesteps    | 17500    |
| value_loss         | 21.5     |
---------------------------------
28.0
28.0
44.62
14.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 44.6     |
| ep_reward_mean     | 127      |
| explained_variance | 0.000897 |
| fps                | 471      |
| nupdates           | 3600     |
| policy_entropy     | 0.437    |
| total_timesteps    | 18000    |
| value_loss         | 9.02e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 43       |
| ep_reward_mean     | 132      |
| explained_variance | -0.115   |
| fps                | 460      |
| nupdates           | 3700     |
| policy_entropy     | 0.665    |
| total_timesteps    | 18500    |
| value_loss         | 78.5     |
---------------------------------
12.0
12.0
41.16
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 41.2     |
| ep_reward_mean     | 137      |
| explained_variance | 0        |
| fps                | 458      |
| nupdates           | 3800     |
| policy_entropy     | 0.386    |
| total_timesteps    | 19000    |
| value_loss         | 86.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 35.3     |
| ep_reward_mean     | 150      |
| explained_variance | 0.188    |
| fps                | 458      |
| nupdates           | 3900     |
| policy_entropy     | 0.244    |
| total_timesteps    | 19500    |
| value_loss         | 252      |
---------------------------------
11.0
11.0
35.36
20.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 35.4     |
| ep_reward_mean     | 148      |
| explained_variance | -0.0324  |
| fps                | 455      |
| nupdates           | 4000     |
| policy_entropy     | 0.415    |
| total_timesteps    | 20000    |
| value_loss         | 85.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 36.5     |
| ep_reward_mean     | 145      |
| explained_variance | -0.0595  |
| fps                | 454      |
| nupdates           | 4100     |
| policy_entropy     | 0.774    |
| total_timesteps    | 20500    |
| value_loss         | 7.91e+04 |
---------------------------------
83.0
83.0
35.42
30.5
---------------------------------
| ep_len_mean        | 35.4     |
| ep_reward_mean     | 146      |
| explained_variance | 0        |
| fps                | 450      |
| nupdates           | 4200     |
| policy_entropy     | 0.196    |
| total_timesteps    | 21000    |
| value_loss         | 6.19     |
---------------------------------
---------------------------------
| ep_len_mean        | 35.2     |
| ep_reward_mean     | 147      |
| explained_variance | -0.156   |
| fps                | 443      |
| nupdates           | 4300     |
| policy_entropy     | 0.232    |
| total_timesteps    | 21500    |
| value_loss         | 119      |
---------------------------------
119.0
119.0
32.73
20.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 32.7     |
| ep_reward_mean     | 154      |
| explained_variance | 0.00357  |
| fps                | 435      |
| nupdates           | 4400     |
| policy_entropy     | 0.737    |
| total_timesteps    | 22000    |
| value_loss         | 31       |
---------------------------------
---------------------------------
| ep_len_mean        | 33.5     |
| ep_reward_mean     | 154      |
| explained_variance | 0.154    |
| fps                | 425      |
| nupdates           | 4500     |
| policy_entropy     | 0.158    |
| total_timesteps    | 22500    |
| value_loss         | 208      |
---------------------------------
11.0
11.0
31.29
16.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 31.3     |
| ep_reward_mean     | 162      |
| explained_variance | 0.0551   |
| fps                | 412      |
| nupdates           | 4600     |
| policy_entropy     | 0.688    |
| total_timesteps    | 23000    |
| value_loss         | 1.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 26.8     |
| ep_reward_mean     | 172      |
| explained_variance | 0        |
| fps                | 410      |
| nupdates           | 4700     |
| policy_entropy     | 0.473    |
| total_timesteps    | 23500    |
| value_loss         | 76.6     |
---------------------------------
38.0
38.0
25.8
19.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 25.8     |
| ep_reward_mean     | 176      |
| explained_variance | 0.0336   |
| fps                | 406      |
| nupdates           | 4800     |
| policy_entropy     | 0.914    |
| total_timesteps    | 24000    |
| value_loss         | 87.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 24.1     |
| ep_reward_mean     | 180      |
| explained_variance | -0.149   |
| fps                | 405      |
| nupdates           | 4900     |
| policy_entropy     | 0.0971   |
| total_timesteps    | 24500    |
| value_loss         | 233      |
---------------------------------
10.0
10.0
23.68
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 23.7     |
| ep_reward_mean     | 183      |
| explained_variance | 0.00529  |
| fps                | 405      |
| nupdates           | 5000     |
| policy_entropy     | 0.663    |
| total_timesteps    | 25000    |
| value_loss         | 39.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.1     |
| ep_reward_mean     | 179      |
| explained_variance | 0.609    |
| fps                | 403      |
| nupdates           | 5100     |
| policy_entropy     | 0.187    |
| total_timesteps    | 25500    |
| value_loss         | 428      |
---------------------------------
30.0
30.0
25.21
24.0
---------------------------------
| ep_len_mean        | 25.2     |
| ep_reward_mean     | 182      |
| explained_variance | 0.761    |
| fps                | 402      |
| nupdates           | 5200     |
| policy_entropy     | 0.424    |
| total_timesteps    | 26000    |
| value_loss         | 55       |
---------------------------------
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 191      |
| explained_variance | 5.96e-08 |
| fps                | 400      |
| nupdates           | 5300     |
| policy_entropy     | 0.379    |
| total_timesteps    | 26500    |
| value_loss         | 3.86     |
---------------------------------
57.0
57.0
21.36
16.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 21.4     |
| ep_reward_mean     | 193      |
| explained_variance | 0.564    |
| fps                | 398      |
| nupdates           | 5400     |
| policy_entropy     | 0.114    |
| total_timesteps    | 27000    |
| value_loss         | 365      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 200      |
| explained_variance | 0.0508   |
| fps                | 398      |
| nupdates           | 5500     |
| policy_entropy     | 0.314    |
| total_timesteps    | 27500    |
| value_loss         | 134      |
---------------------------------
10.0
10.0
16.68
12.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 202      |
| explained_variance | -3.84    |
| fps                | 398      |
| nupdates           | 5600     |
| policy_entropy     | 0.22     |
| total_timesteps    | 28000    |
| value_loss         | 9.34e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 202      |
| explained_variance | 0        |
| fps                | 398      |
| nupdates           | 5700     |
| policy_entropy     | 0.386    |
| total_timesteps    | 28500    |
| value_loss         | 8.68     |
---------------------------------
22.0
22.0
15.5
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 205      |
| explained_variance | 0.673    |
| fps                | 399      |
| nupdates           | 5800     |
| policy_entropy     | 0.621    |
| total_timesteps    | 29000    |
| value_loss         | 57.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 205      |
| explained_variance | 0.38     |
| fps                | 399      |
| nupdates           | 5900     |
| policy_entropy     | 0.632    |
| total_timesteps    | 29500    |
| value_loss         | 8.33     |
---------------------------------
34.0
34.0
17.56
10.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 201      |
| explained_variance | -17.3    |
| fps                | 399      |
| nupdates           | 6000     |
| policy_entropy     | 0.301    |
| total_timesteps    | 30000    |
| value_loss         | 738      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 201      |
| explained_variance | 0.35     |
| fps                | 399      |
| nupdates           | 6100     |
| policy_entropy     | 0.115    |
| total_timesteps    | 30500    |
| value_loss         | 640      |
---------------------------------
8.0
8.0
20.1
23.5
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 197      |
| explained_variance | 0.37     |
| fps                | 399      |
| nupdates           | 6200     |
| policy_entropy     | 0.307    |
| total_timesteps    | 31000    |
| value_loss         | 99.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 194      |
| explained_variance | 0        |
| fps                | 400      |
| nupdates           | 6300     |
| policy_entropy     | 0.636    |
| total_timesteps    | 31500    |
| value_loss         | 93.3     |
---------------------------------
48.0
48.0
21.05
17.0
---------------------------------
| ep_len_mean        | 21.1     |
| ep_reward_mean     | 194      |
| explained_variance | 0.738    |
| fps                | 400      |
| nupdates           | 6400     |
| policy_entropy     | 0.348    |
| total_timesteps    | 32000    |
| value_loss         | 36.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 21.5     |
| ep_reward_mean     | 191      |
| explained_variance | -0.132   |
| fps                | 401      |
| nupdates           | 6500     |
| policy_entropy     | 0.16     |
| total_timesteps    | 32500    |
| value_loss         | 204      |
---------------------------------
9.0
9.0
21.27
11.0
---------------------------------
| ep_len_mean        | 21.3     |
| ep_reward_mean     | 189      |
| explained_variance | -1.13    |
| fps                | 401      |
| nupdates           | 6600     |
| policy_entropy     | 0.435    |
| total_timesteps    | 33000    |
| value_loss         | 31.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 22.1     |
| ep_reward_mean     | 188      |
| explained_variance | -0.0104  |
| fps                | 400      |
| nupdates           | 6700     |
| policy_entropy     | 0.417    |
| total_timesteps    | 33500    |
| value_loss         | 8.07     |
---------------------------------
10.0
10.0
20.52
10.0
----------------------------------
| ep_len_mean        | 20.5      |
| ep_reward_mean     | 191       |
| explained_variance | -1.19e-07 |
| fps                | 400       |
| nupdates           | 6800      |
| policy_entropy     | 0.493     |
| total_timesteps    | 34000     |
| value_loss         | 7.1       |
----------------------------------
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 199      |
| explained_variance | 0        |
| fps                | 401      |
| nupdates           | 6900     |
| policy_entropy     | 0.417    |
| total_timesteps    | 34500    |
| value_loss         | 18.4     |
---------------------------------
17.0
17.0
16.9
10.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 203      |
| explained_variance | -6.53    |
| fps                | 401      |
| nupdates           | 7000     |
| policy_entropy     | 0.214    |
| total_timesteps    | 35000    |
| value_loss         | 147      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 206      |
| explained_variance | -14.8    |
| fps                | 401      |
| nupdates           | 7100     |
| policy_entropy     | 0.428    |
| total_timesteps    | 35500    |
| value_loss         | 875      |
---------------------------------
9.0
9.0
17.96
11.0
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 197      |
| explained_variance | -3.57    |
| fps                | 400      |
| nupdates           | 7200     |
| policy_entropy     | 0.318    |
| total_timesteps    | 36000    |
| value_loss         | 1.44e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 196      |
| explained_variance | -13      |
| fps                | 399      |
| nupdates           | 7300     |
| policy_entropy     | 0.428    |
| total_timesteps    | 36500    |
| value_loss         | 162      |
---------------------------------
9.0
9.0
20.05
11.0
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 192      |
| explained_variance | 0.238    |
| fps                | 398      |
| nupdates           | 7400     |
| policy_entropy     | 0.0434   |
| total_timesteps    | 37000    |
| value_loss         | 183      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.6     |
| ep_reward_mean     | 193      |
| explained_variance | -1.28    |
| fps                | 396      |
| nupdates           | 7500     |
| policy_entropy     | 0.601    |
| total_timesteps    | 37500    |
| value_loss         | 251      |
---------------------------------
24.0
24.0
19.38
20.5
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 198      |
| explained_variance | -6.68    |
| fps                | 396      |
| nupdates           | 7600     |
| policy_entropy     | 0.496    |
| total_timesteps    | 38000    |
| value_loss         | 99.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.5     |
| ep_reward_mean     | 202      |
| explained_variance | 0.597    |
| fps                | 396      |
| nupdates           | 7700     |
| policy_entropy     | 0.0593   |
| total_timesteps    | 38500    |
| value_loss         | 85.1     |
---------------------------------
11.0
11.0
18.59
11.0
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 201      |
| explained_variance | 1.19e-07 |
| fps                | 397      |
| nupdates           | 7800     |
| policy_entropy     | 0.506    |
| total_timesteps    | 39000    |
| value_loss         | 41.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 200      |
| explained_variance | -2.46    |
| fps                | 396      |
| nupdates           | 7900     |
| policy_entropy     | 0.314    |
| total_timesteps    | 39500    |
| value_loss         | 223      |
---------------------------------
42.0
42.0
17.05
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 202      |
| explained_variance | -0.894   |
| fps                | 396      |
| nupdates           | 8000     |
| policy_entropy     | 0.29     |
| total_timesteps    | 40000    |
| value_loss         | 282      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 204      |
| explained_variance | 0.124    |
| fps                | 395      |
| nupdates           | 8100     |
| policy_entropy     | 0.474    |
| total_timesteps    | 40500    |
| value_loss         | 65       |
---------------------------------
44.0
44.0
17.35
13.5
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 202      |
| explained_variance | 0.547    |
| fps                | 394      |
| nupdates           | 8200     |
| policy_entropy     | 0.0749   |
| total_timesteps    | 41000    |
| value_loss         | 413      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 205      |
| explained_variance | -3.69    |
| fps                | 395      |
| nupdates           | 8300     |
| policy_entropy     | 0.361    |
| total_timesteps    | 41500    |
| value_loss         | 362      |
---------------------------------
11.0
11.0
18.53
10.5
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 201      |
| explained_variance | -0.525   |
| fps                | 395      |
| nupdates           | 8400     |
| policy_entropy     | 0.137    |
| total_timesteps    | 42000    |
| value_loss         | 376      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 200      |
| explained_variance | 0.315    |
| fps                | 394      |
| nupdates           | 8500     |
| policy_entropy     | 0.367    |
| total_timesteps    | 42500    |
| value_loss         | 1.53e+04 |
---------------------------------
35.0
35.0
17.33
12.5
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 203      |
| explained_variance | -0.119   |
| fps                | 394      |
| nupdates           | 8600     |
| policy_entropy     | 0.133    |
| total_timesteps    | 43000    |
| value_loss         | 3.09e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0.128    |
| fps                | 394      |
| nupdates           | 8700     |
| policy_entropy     | 0.605    |
| total_timesteps    | 43500    |
| value_loss         | 6.5e+03  |
---------------------------------
13.0
13.0
16.3
12.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.3     |
| ep_reward_mean     | 205      |
| explained_variance | 0.388    |
| fps                | 393      |
| nupdates           | 8800     |
| policy_entropy     | 0.276    |
| total_timesteps    | 44000    |
| value_loss         | 2e+03    |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 199      |
| explained_variance | -0.0403  |
| fps                | 393      |
| nupdates           | 8900     |
| policy_entropy     | 0.229    |
| total_timesteps    | 44500    |
| value_loss         | 489      |
---------------------------------
13.0
13.0
18.05
11.5
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 198      |
| explained_variance | -0.19    |
| fps                | 392      |
| nupdates           | 9000     |
| policy_entropy     | 0.569    |
| total_timesteps    | 45000    |
| value_loss         | 146      |
---------------------------------
---------------------------------
| ep_len_mean        | 19       |
| ep_reward_mean     | 196      |
| explained_variance | 0.927    |
| fps                | 392      |
| nupdates           | 9100     |
| policy_entropy     | 0.046    |
| total_timesteps    | 45500    |
| value_loss         | 14.1     |
---------------------------------
11.0
11.0
20.01
13.5
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 193      |
| explained_variance | 0.224    |
| fps                | 391      |
| nupdates           | 9200     |
| policy_entropy     | 0.0643   |
| total_timesteps    | 46000    |
| value_loss         | 8.11e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 200      |
| explained_variance | 0.646    |
| fps                | 389      |
| nupdates           | 9300     |
| policy_entropy     | 0.196    |
| total_timesteps    | 46500    |
| value_loss         | 103      |
---------------------------------
15.0
15.0
17.18
12.0
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 203      |
| explained_variance | -1.59    |
| fps                | 387      |
| nupdates           | 9400     |
| policy_entropy     | 0.296    |
| total_timesteps    | 47000    |
| value_loss         | 125      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 205      |
| explained_variance | 0        |
| fps                | 386      |
| nupdates           | 9500     |
| policy_entropy     | 0.42     |
| total_timesteps    | 47500    |
| value_loss         | 79.8     |
---------------------------------
9.0
9.0
17.29
10.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 205      |
| explained_variance | 0.644    |
| fps                | 386      |
| nupdates           | 9600     |
| policy_entropy     | 0.228    |
| total_timesteps    | 48000    |
| value_loss         | 66.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 200      |
| explained_variance | -0.57    |
| fps                | 385      |
| nupdates           | 9700     |
| policy_entropy     | 0.349    |
| total_timesteps    | 48500    |
| value_loss         | 97.7     |
---------------------------------
35.0
35.0
16.79
10.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | 0.623    |
| fps                | 384      |
| nupdates           | 9800     |
| policy_entropy     | 0.18     |
| total_timesteps    | 49000    |
| value_loss         | 31.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 205      |
| explained_variance | 0.41     |
| fps                | 384      |
| nupdates           | 9900     |
| policy_entropy     | 0.0395   |
| total_timesteps    | 49500    |
| value_loss         | 550      |
---------------------------------
23.0
23.0
17.74
22.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 204      |
| explained_variance | -3.52    |
| fps                | 384      |
| nupdates           | 10000    |
| policy_entropy     | 0.247    |
| total_timesteps    | 50000    |
| value_loss         | 682      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.3     |
| ep_reward_mean     | 202      |
| explained_variance | 0.282    |
| fps                | 385      |
| nupdates           | 10100    |
| policy_entropy     | 0.301    |
| total_timesteps    | 50500    |
| value_loss         | 169      |
---------------------------------
8.0
8.0
19.3
11.0
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 199      |
| explained_variance | 0.646    |
| fps                | 385      |
| nupdates           | 10200    |
| policy_entropy     | 0.173    |
| total_timesteps    | 51000    |
| value_loss         | 34.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 200      |
| explained_variance | -4.5     |
| fps                | 386      |
| nupdates           | 10300    |
| policy_entropy     | 0.211    |
| total_timesteps    | 51500    |
| value_loss         | 89.7     |
---------------------------------
22.0
22.0
18.0
10.5
---------------------------------
| ep_len_mean        | 18       |
| ep_reward_mean     | 204      |
| explained_variance | -0.45    |
| fps                | 386      |
| nupdates           | 10400    |
| policy_entropy     | 0.154    |
| total_timesteps    | 52000    |
| value_loss         | 9.5e+03  |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 205      |
| explained_variance | 0.45     |
| fps                | 387      |
| nupdates           | 10500    |
| policy_entropy     | 0.0552   |
| total_timesteps    | 52500    |
| value_loss         | 92.4     |
---------------------------------
38.0
38.0
17.9
10.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 204      |
| explained_variance | -2.47    |
| fps                | 387      |
| nupdates           | 10600    |
| policy_entropy     | 0.267    |
| total_timesteps    | 53000    |
| value_loss         | 402      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 206      |
| explained_variance | 0.817    |
| fps                | 387      |
| nupdates           | 10700    |
| policy_entropy     | 0.0362   |
| total_timesteps    | 53500    |
| value_loss         | 155      |
---------------------------------
8.0
8.0
16.97
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 206      |
| explained_variance | 0.462    |
| fps                | 388      |
| nupdates           | 10800    |
| policy_entropy     | 0.283    |
| total_timesteps    | 54000    |
| value_loss         | 278      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0666   |
| fps                | 388      |
| nupdates           | 10900    |
| policy_entropy     | 0.0988   |
| total_timesteps    | 54500    |
| value_loss         | 2.24e+03 |
---------------------------------
9.0
9.0
16.15
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 208      |
| explained_variance | -0.188   |
| fps                | 388      |
| nupdates           | 11000    |
| policy_entropy     | 0.0999   |
| total_timesteps    | 55000    |
| value_loss         | 2.23e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.122    |
| fps                | 389      |
| nupdates           | 11100    |
| policy_entropy     | 0.112    |
| total_timesteps    | 55500    |
| value_loss         | 819      |
---------------------------------
10.0
10.0
15.12
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 211      |
| explained_variance | 1.19e-07 |
| fps                | 388      |
| nupdates           | 11200    |
| policy_entropy     | 0.436    |
| total_timesteps    | 56000    |
| value_loss         | 88.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.23     |
| fps                | 388      |
| nupdates           | 11300    |
| policy_entropy     | 0.168    |
| total_timesteps    | 56500    |
| value_loss         | 1.64e+03 |
---------------------------------
9.0
9.0
15.69
10.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | -0.13    |
| fps                | 387      |
| nupdates           | 11400    |
| policy_entropy     | 0.219    |
| total_timesteps    | 57000    |
| value_loss         | 185      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 203      |
| explained_variance | -6.09    |
| fps                | 387      |
| nupdates           | 11500    |
| policy_entropy     | 0.0524   |
| total_timesteps    | 57500    |
| value_loss         | 1.92e+03 |
---------------------------------
21.0
21.0
17.75
20.5
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 203      |
| explained_variance | -0.654   |
| fps                | 385      |
| nupdates           | 11600    |
| policy_entropy     | 0.101    |
| total_timesteps    | 58000    |
| value_loss         | 1.19e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 203      |
| explained_variance | 0        |
| fps                | 384      |
| nupdates           | 11700    |
| policy_entropy     | 0.394    |
| total_timesteps    | 58500    |
| value_loss         | 233      |
---------------------------------
10.0
10.0
19.5
10.0
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 194      |
| explained_variance | 0.276    |
| fps                | 383      |
| nupdates           | 11800    |
| policy_entropy     | 0.296    |
| total_timesteps    | 59000    |
| value_loss         | 1.64e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 193      |
| explained_variance | -38.9    |
| fps                | 383      |
| nupdates           | 11900    |
| policy_entropy     | 0.147    |
| total_timesteps    | 59500    |
| value_loss         | 484      |
---------------------------------
10.0
10.0
18.68
10.0
---------------------------------
| ep_len_mean        | 18.7     |
| ep_reward_mean     | 195      |
| explained_variance | -9.45    |
| fps                | 382      |
| nupdates           | 12000    |
| policy_entropy     | 0.396    |
| total_timesteps    | 60000    |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.4     |
| ep_reward_mean     | 190      |
| explained_variance | 0.481    |
| fps                | 380      |
| nupdates           | 12100    |
| policy_entropy     | 0.266    |
| total_timesteps    | 60500    |
| value_loss         | 190      |
---------------------------------
55.0
55.0
19.78
10.5
---------------------------------
| ep_len_mean        | 19.8     |
| ep_reward_mean     | 195      |
| explained_variance | 0.484    |
| fps                | 379      |
| nupdates           | 12200    |
| policy_entropy     | 0.294    |
| total_timesteps    | 61000    |
| value_loss         | 164      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 200      |
| explained_variance | -0.232   |
| fps                | 379      |
| nupdates           | 12300    |
| policy_entropy     | 0.0466   |
| total_timesteps    | 61500    |
| value_loss         | 2.55e+04 |
---------------------------------
10.0
10.0
20.08
10.0
---------------------------------
| ep_len_mean        | 20.1     |
| ep_reward_mean     | 200      |
| explained_variance | -0.409   |
| fps                | 380      |
| nupdates           | 12400    |
| policy_entropy     | 0.0341   |
| total_timesteps    | 62000    |
| value_loss         | 204      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 204      |
| explained_variance | 0.622    |
| fps                | 380      |
| nupdates           | 12500    |
| policy_entropy     | 0.0527   |
| total_timesteps    | 62500    |
| value_loss         | 1.34e+03 |
---------------------------------
22.0
22.0
17.11
11.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 203      |
| explained_variance | 0.00565  |
| fps                | 380      |
| nupdates           | 12600    |
| policy_entropy     | 0.195    |
| total_timesteps    | 63000    |
| value_loss         | 332      |
---------------------------------
----------------------------------
| ep_len_mean        | 15.9      |
| ep_reward_mean     | 204       |
| explained_variance | -1.19e-07 |
| fps                | 381       |
| nupdates           | 12700     |
| policy_entropy     | 0.532     |
| total_timesteps    | 63500     |
| value_loss         | 115       |
----------------------------------
10.0
10.0
16.96
9.5
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 204      |
| explained_variance | 0.15     |
| fps                | 381      |
| nupdates           | 12800    |
| policy_entropy     | 0.0808   |
| total_timesteps    | 64000    |
| value_loss         | 1.64e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 202      |
| explained_variance | -1.33    |
| fps                | 380      |
| nupdates           | 12900    |
| policy_entropy     | 0.401    |
| total_timesteps    | 64500    |
| value_loss         | 91.4     |
---------------------------------
10.0
10.0
16.5
10.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 207      |
| explained_variance | -4.61    |
| fps                | 380      |
| nupdates           | 13000    |
| policy_entropy     | 0.572    |
| total_timesteps    | 65000    |
| value_loss         | 352      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 206      |
| explained_variance | 0.0107   |
| fps                | 380      |
| nupdates           | 13100    |
| policy_entropy     | 0.0195   |
| total_timesteps    | 65500    |
| value_loss         | 88.9     |
---------------------------------
25.0
25.0
17.27
17.0
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 205      |
| explained_variance | -0.21    |
| fps                | 380      |
| nupdates           | 13200    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 66000    |
| value_loss         | 127      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 203      |
| explained_variance | 0.338    |
| fps                | 380      |
| nupdates           | 13300    |
| policy_entropy     | 0.0725   |
| total_timesteps    | 66500    |
| value_loss         | 335      |
---------------------------------
8.0
8.0
16.8
10.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 205      |
| explained_variance | -0.0613  |
| fps                | 380      |
| nupdates           | 13400    |
| policy_entropy     | 0.231    |
| total_timesteps    | 67000    |
| value_loss         | 145      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 205      |
| explained_variance | 0.309    |
| fps                | 381      |
| nupdates           | 13500    |
| policy_entropy     | 0.473    |
| total_timesteps    | 67500    |
| value_loss         | 252      |
---------------------------------
10.0
10.0
16.02
11.5
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 209      |
| explained_variance | 0.536    |
| fps                | 381      |
| nupdates           | 13600    |
| policy_entropy     | 0.0189   |
| total_timesteps    | 68000    |
| value_loss         | 113      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.486    |
| fps                | 381      |
| nupdates           | 13700    |
| policy_entropy     | 0.053    |
| total_timesteps    | 68500    |
| value_loss         | 71.5     |
---------------------------------
10.0
10.0
16.01
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 213      |
| explained_variance | -0.0282  |
| fps                | 381      |
| nupdates           | 13800    |
| policy_entropy     | 0.0404   |
| total_timesteps    | 69000    |
| value_loss         | 1.26e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.0697   |
| fps                | 381      |
| nupdates           | 13900    |
| policy_entropy     | 0.0135   |
| total_timesteps    | 69500    |
| value_loss         | 87.9     |
---------------------------------
23.0
23.0
16.69
16.5
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.0219   |
| fps                | 380      |
| nupdates           | 14000    |
| policy_entropy     | 0.579    |
| total_timesteps    | 70000    |
| value_loss         | 88.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 207      |
| explained_variance | -1.81    |
| fps                | 380      |
| nupdates           | 14100    |
| policy_entropy     | 0.187    |
| total_timesteps    | 70500    |
| value_loss         | 144      |
---------------------------------
25.0
25.0
16.43
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 209      |
| explained_variance | -0.167   |
| fps                | 379      |
| nupdates           | 14200    |
| policy_entropy     | 0.37     |
| total_timesteps    | 71000    |
| value_loss         | 221      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 209      |
| explained_variance | -0.0102  |
| fps                | 379      |
| nupdates           | 14300    |
| policy_entropy     | 0.471    |
| total_timesteps    | 71500    |
| value_loss         | 25.4     |
---------------------------------
10.0
10.0
15.43
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 378      |
| nupdates           | 14400    |
| policy_entropy     | 0.124    |
| total_timesteps    | 72000    |
| value_loss         | 124      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.554    |
| fps                | 378      |
| nupdates           | 14500    |
| policy_entropy     | 0.0214   |
| total_timesteps    | 72500    |
| value_loss         | 756      |
---------------------------------
23.0
23.0
16.75
16.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | 0.153    |
| fps                | 378      |
| nupdates           | 14600    |
| policy_entropy     | 0.0598   |
| total_timesteps    | 73000    |
| value_loss         | 319      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 209      |
| explained_variance | -1.37    |
| fps                | 379      |
| nupdates           | 14700    |
| policy_entropy     | 0.187    |
| total_timesteps    | 73500    |
| value_loss         | 657      |
---------------------------------
20.0
20.0
18.15
15.0
---------------------------------
| ep_len_mean        | 18.1     |
| ep_reward_mean     | 203      |
| explained_variance | -1.99    |
| fps                | 379      |
| nupdates           | 14800    |
| policy_entropy     | 0.076    |
| total_timesteps    | 74000    |
| value_loss         | 9.78e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 206      |
| explained_variance | 0.169    |
| fps                | 379      |
| nupdates           | 14900    |
| policy_entropy     | 0.0188   |
| total_timesteps    | 74500    |
| value_loss         | 356      |
---------------------------------
28.0
28.0
17.67
11.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 204      |
| explained_variance | 0.202    |
| fps                | 379      |
| nupdates           | 15000    |
| policy_entropy     | 0.315    |
| total_timesteps    | 75000    |
| value_loss         | 402      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | 0.0102   |
| fps                | 379      |
| nupdates           | 15100    |
| policy_entropy     | 0.153    |
| total_timesteps    | 75500    |
| value_loss         | 575      |
---------------------------------
36.0
36.0
16.57
10.0
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 209      |
| explained_variance | -3.68    |
| fps                | 379      |
| nupdates           | 15200    |
| policy_entropy     | 0.407    |
| total_timesteps    | 76000    |
| value_loss         | 301      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | -0.894   |
| fps                | 378      |
| nupdates           | 15300    |
| policy_entropy     | 0.383    |
| total_timesteps    | 76500    |
| value_loss         | 336      |
---------------------------------
22.0
22.0
15.68
9.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 210      |
| explained_variance | -1.16    |
| fps                | 378      |
| nupdates           | 15400    |
| policy_entropy     | 0.0944   |
| total_timesteps    | 77000    |
| value_loss         | 688      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 212      |
| explained_variance | -0.715   |
| fps                | 378      |
| nupdates           | 15500    |
| policy_entropy     | 0.206    |
| total_timesteps    | 77500    |
| value_loss         | 590      |
---------------------------------
10.0
10.0
15.08
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.223    |
| fps                | 378      |
| nupdates           | 15600    |
| policy_entropy     | 0.297    |
| total_timesteps    | 78000    |
| value_loss         | 300      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.483    |
| fps                | 378      |
| nupdates           | 15700    |
| policy_entropy     | 0.0256   |
| total_timesteps    | 78500    |
| value_loss         | 306      |
---------------------------------
10.0
10.0
14.72
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 211      |
| explained_variance | -0.275   |
| fps                | 378      |
| nupdates           | 15800    |
| policy_entropy     | 0.356    |
| total_timesteps    | 79000    |
| value_loss         | 36.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 209      |
| explained_variance | -1.91    |
| fps                | 378      |
| nupdates           | 15900    |
| policy_entropy     | 0.231    |
| total_timesteps    | 79500    |
| value_loss         | 183      |
---------------------------------
44.0
44.0
15.87
16.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | -0.468   |
| fps                | 378      |
| nupdates           | 16000    |
| policy_entropy     | 0.024    |
| total_timesteps    | 80000    |
| value_loss         | 196      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0.135    |
| fps                | 378      |
| nupdates           | 16100    |
| policy_entropy     | 0.146    |
| total_timesteps    | 80500    |
| value_loss         | 525      |
---------------------------------
9.0
9.0
15.26
9.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 212      |
| explained_variance | -0.306   |
| fps                | 378      |
| nupdates           | 16200    |
| policy_entropy     | 0.139    |
| total_timesteps    | 81000    |
| value_loss         | 447      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0.184    |
| fps                | 378      |
| nupdates           | 16300    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 81500    |
| value_loss         | 368      |
---------------------------------
10.0
10.0
15.93
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 208      |
| explained_variance | 0.252    |
| fps                | 378      |
| nupdates           | 16400    |
| policy_entropy     | 0.006    |
| total_timesteps    | 82000    |
| value_loss         | 61.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0        |
| fps                | 379      |
| nupdates           | 16500    |
| policy_entropy     | 0.117    |
| total_timesteps    | 82500    |
| value_loss         | 150      |
---------------------------------
10.0
10.0
14.46
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 211      |
| explained_variance | -4.78    |
| fps                | 379      |
| nupdates           | 16600    |
| policy_entropy     | 0.0446   |
| total_timesteps    | 83000    |
| value_loss         | 822      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 210      |
| explained_variance | 0.0415   |
| fps                | 379      |
| nupdates           | 16700    |
| policy_entropy     | 0.48     |
| total_timesteps    | 83500    |
| value_loss         | 166      |
---------------------------------
8.0
8.0
15.08
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 210      |
| explained_variance | 0        |
| fps                | 379      |
| nupdates           | 16800    |
| policy_entropy     | 0.22     |
| total_timesteps    | 84000    |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0        |
| fps                | 379      |
| nupdates           | 16900    |
| policy_entropy     | 0.584    |
| total_timesteps    | 84500    |
| value_loss         | 143      |
---------------------------------
11.0
11.0
15.04
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 213      |
| explained_variance | -0.156   |
| fps                | 379      |
| nupdates           | 17000    |
| policy_entropy     | 0.218    |
| total_timesteps    | 85000    |
| value_loss         | 311      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | -0.687   |
| fps                | 379      |
| nupdates           | 17100    |
| policy_entropy     | 0.27     |
| total_timesteps    | 85500    |
| value_loss         | 166      |
---------------------------------
10.0
10.0
17.57
11.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 208      |
| explained_variance | -0.685   |
| fps                | 379      |
| nupdates           | 17200    |
| policy_entropy     | 0.0239   |
| total_timesteps    | 86000    |
| value_loss         | 206      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 208      |
| explained_variance | 0.686    |
| fps                | 379      |
| nupdates           | 17300    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 86500    |
| value_loss         | 136      |
---------------------------------
33.0
33.0
16.1
10.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 211      |
| explained_variance | 0.46     |
| fps                | 379      |
| nupdates           | 17400    |
| policy_entropy     | 0.0229   |
| total_timesteps    | 87000    |
| value_loss         | 64.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | -0.366   |
| fps                | 380      |
| nupdates           | 17500    |
| policy_entropy     | 0.742    |
| total_timesteps    | 87500    |
| value_loss         | 161      |
---------------------------------
14.0
14.0
21.63
17.0
----------------------------------
| ep_len_mean        | 21.6      |
| ep_reward_mean     | 187       |
| explained_variance | -4.55e+03 |
| fps                | 380       |
| nupdates           | 17600     |
| policy_entropy     | 0.737     |
| total_timesteps    | 88000     |
| value_loss         | 10.6      |
----------------------------------
---------------------------------
| ep_len_mean        | 23.4     |
| ep_reward_mean     | 183      |
| explained_variance | -108     |
| fps                | 380      |
| nupdates           | 17700    |
| policy_entropy     | 0.542    |
| total_timesteps    | 88500    |
| value_loss         | 0.00236  |
---------------------------------
9.0
9.0
27.53
17.0
---------------------------------
| ep_len_mean        | 27.5     |
| ep_reward_mean     | 174      |
| explained_variance | -55.5    |
| fps                | 380      |
| nupdates           | 17800    |
| policy_entropy     | 0.474    |
| total_timesteps    | 89000    |
| value_loss         | 2.8      |
---------------------------------
---------------------------------
| ep_len_mean        | 33.3     |
| ep_reward_mean     | 162      |
| explained_variance | 0.126    |
| fps                | 381      |
| nupdates           | 17900    |
| policy_entropy     | 0.217    |
| total_timesteps    | 89500    |
| value_loss         | 412      |
---------------------------------
241.0
241.0
35.97
10.5
---------------------------------
| ep_len_mean        | 36       |
| ep_reward_mean     | 155      |
| explained_variance | -0.00262 |
| fps                | 381      |
| nupdates           | 18000    |
| policy_entropy     | 0.742    |
| total_timesteps    | 90000    |
| value_loss         | 9.88     |
---------------------------------
---------------------------------
| ep_len_mean        | 37.6     |
| ep_reward_mean     | 150      |
| explained_variance | -0.00337 |
| fps                | 381      |
| nupdates           | 18100    |
| policy_entropy     | 0.687    |
| total_timesteps    | 90500    |
| value_loss         | 38.5     |
---------------------------------
835.0
835.0
45.8
11.0
---------------------------------
| ep_len_mean        | 45.8     |
| ep_reward_mean     | 126      |
| explained_variance | -43.8    |
| fps                | 381      |
| nupdates           | 18200    |
| policy_entropy     | 0.723    |
| total_timesteps    | 91000    |
| value_loss         | 0.0614   |
---------------------------------
---------------------------------
| ep_len_mean        | 45.8     |
| ep_reward_mean     | 126      |
| explained_variance | -9.11    |
| fps                | 382      |
| nupdates           | 18300    |
| policy_entropy     | 0.533    |
| total_timesteps    | 91500    |
| value_loss         | 0.0104   |
---------------------------------
12.0
12.0
55.0
99.5
---------------------------------
| ep_len_mean        | 55       |
| ep_reward_mean     | 107      |
| explained_variance | -0.0217  |
| fps                | 382      |
| nupdates           | 18400    |
| policy_entropy     | 0.589    |
| total_timesteps    | 92000    |
| value_loss         | 9.94     |
---------------------------------
---------------------------------
| ep_len_mean        | 58.1     |
| ep_reward_mean     | 96       |
| explained_variance | -0.0702  |
| fps                | 382      |
| nupdates           | 18500    |
| policy_entropy     | 0.27     |
| total_timesteps    | 92500    |
| value_loss         | 3.56e+04 |
---------------------------------
10.0
10.0
58.24
10.5
---------------------------------
| ep_len_mean        | 58.2     |
| ep_reward_mean     | 96.3     |
| explained_variance | -255     |
| fps                | 382      |
| nupdates           | 18600    |
| policy_entropy     | 0.599    |
| total_timesteps    | 93000    |
| value_loss         | 0.075    |
---------------------------------
----------------------------------
| ep_len_mean        | 58.2      |
| ep_reward_mean     | 96.3      |
| explained_variance | -4.11e-05 |
| fps                | 383       |
| nupdates           | 18700     |
| policy_entropy     | 0.596     |
| total_timesteps    | 93500     |
| value_loss         | 37.2      |
----------------------------------
10.0
10.0
58.24
10.5
---------------------------------
| ep_len_mean        | 58.2     |
| ep_reward_mean     | 96.3     |
| explained_variance | -5.33    |
| fps                | 383      |
| nupdates           | 18800    |
| policy_entropy     | 0.608    |
| total_timesteps    | 94000    |
| value_loss         | 0.000876 |
---------------------------------
---------------------------------
| ep_len_mean        | 58.2     |
| ep_reward_mean     | 96.3     |
| explained_variance | 0.000426 |
| fps                | 383      |
| nupdates           | 18900    |
| policy_entropy     | 0.639    |
| total_timesteps    | 94500    |
| value_loss         | 86.5     |
---------------------------------
12.0
12.0
81.68
11.5
----------------------------------
| ep_len_mean        | 81.7      |
| ep_reward_mean     | 25.8      |
| explained_variance | -4.82e+04 |
| fps                | 383       |
| nupdates           | 19000     |
| policy_entropy     | 0.493     |
| total_timesteps    | 95000     |
| value_loss         | 46.8      |
----------------------------------
----------------------------------
| ep_len_mean        | 81.7      |
| ep_reward_mean     | 25.8      |
| explained_variance | -1.65e+03 |
| fps                | 384       |
| nupdates           | 19100     |
| policy_entropy     | 0.594     |
| total_timesteps    | 95500     |
| value_loss         | 0.569     |
----------------------------------
12.0
12.0
81.68
11.5
---------------------------------
| ep_len_mean        | 81.7     |
| ep_reward_mean     | 25.8     |
| explained_variance | -79.4    |
| fps                | 384      |
| nupdates           | 19200    |
| policy_entropy     | 0.683    |
| total_timesteps    | 96000    |
| value_loss         | 0.0677   |
---------------------------------
----------------------------------
| ep_len_mean        | 94        |
| ep_reward_mean     | 1.7       |
| explained_variance | -1.15e+04 |
| fps                | 384       |
| nupdates           | 19300     |
| policy_entropy     | 0.761     |
| total_timesteps    | 96500     |
| value_loss         | 0.562     |
----------------------------------
10.0
10.0
93.97
15.5
---------------------------------
| ep_len_mean        | 94       |
| ep_reward_mean     | 1.7      |
| explained_variance | -0.986   |
| fps                | 384      |
| nupdates           | 19400    |
| policy_entropy     | 0.352    |
| total_timesteps    | 97000    |
| value_loss         | 11       |
---------------------------------
---------------------------------
| ep_len_mean        | 94       |
| ep_reward_mean     | 1.7      |
| explained_variance | -6.43    |
| fps                | 385      |
| nupdates           | 19500    |
| policy_entropy     | 0.458    |
| total_timesteps    | 97500    |
| value_loss         | 0.00807  |
---------------------------------
9.0
9.0
109.89
13.5
----------------------------------
| ep_len_mean        | 110       |
| ep_reward_mean     | -32.3     |
| explained_variance | -4.53e+04 |
| fps                | 385       |
| nupdates           | 19600     |
| policy_entropy     | 0.668     |
| total_timesteps    | 98000     |
| value_loss         | 9.82      |
----------------------------------
----------------------------------
| ep_len_mean        | 114       |
| ep_reward_mean     | -40.1     |
| explained_variance | -2.34e+03 |
| fps                | 385       |
| nupdates           | 19700     |
| policy_entropy     | 0.847     |
| total_timesteps    | 98500     |
| value_loss         | 0.00687   |
----------------------------------
303.0
303.0
116.81
22.5
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -45.9    |
| explained_variance | 0.00749  |
| fps                | 385      |
| nupdates           | 19800    |
| policy_entropy     | 0.755    |
| total_timesteps    | 99000    |
| value_loss         | 0.426    |
---------------------------------
----------------------------------
| ep_len_mean        | 117       |
| ep_reward_mean     | -45.9     |
| explained_variance | -9.19e-05 |
| fps                | 386       |
| nupdates           | 19900     |
| policy_entropy     | 0.21      |
| total_timesteps    | 99500     |
| value_loss         | 5.73      |
----------------------------------
303.0
303.0
116.81
22.5
----------------------------------
| ep_len_mean        | 117       |
| ep_reward_mean     | -45.9     |
| explained_variance | -0.000279 |
| fps                | 386       |
| nupdates           | 20000     |
| policy_entropy     | 0.0727    |
| total_timesteps    | 100000    |
| value_loss         | 0.795     |
----------------------------------
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -45.9    |
| explained_variance | -2.79    |
| fps                | 386      |
| nupdates           | 20100    |
| policy_entropy     | 0.0451   |
| total_timesteps    | 100500   |
| value_loss         | 0.00854  |
---------------------------------
303.0
303.0
116.81
22.5
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -45.9    |
| explained_variance | -23      |
| fps                | 386      |
| nupdates           | 20200    |
| policy_entropy     | 0.207    |
| total_timesteps    | 101000   |
| value_loss         | 0.000145 |
---------------------------------
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -45.9    |
| explained_variance | -4.35    |
| fps                | 387      |
| nupdates           | 20300    |
| policy_entropy     | 0.737    |
| total_timesteps    | 101500   |
| value_loss         | 0.00134  |
---------------------------------
303.0
303.0
116.81
22.5
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -45.9    |
| explained_variance | -0.00187 |
| fps                | 387      |
| nupdates           | 20400    |
| policy_entropy     | 0.582    |
| total_timesteps    | 102000   |
| value_loss         | 31.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -45.9    |
| explained_variance | -27.8    |
| fps                | 387      |
| nupdates           | 20500    |
| policy_entropy     | 0.382    |
| total_timesteps    | 102500   |
| value_loss         | 0.00254  |
---------------------------------
69.0
69.0
148.92
30.0
---------------------------------
| ep_len_mean        | 149      |
| ep_reward_mean     | -115     |
| explained_variance | -525     |
| fps                | 387      |
| nupdates           | 20600    |
| policy_entropy     | 0.771    |
| total_timesteps    | 103000   |
| value_loss         | 0.0252   |
---------------------------------
----------------------------------
| ep_len_mean        | 152       |
| ep_reward_mean     | -121      |
| explained_variance | -1.29e+03 |
| fps                | 388       |
| nupdates           | 20700     |
| policy_entropy     | 0.455     |
| total_timesteps    | 103500    |
| value_loss         | 0.44      |
----------------------------------
12.0
12.0
151.65
21.5
---------------------------------
| ep_len_mean        | 152      |
| ep_reward_mean     | -121     |
| explained_variance | -0.147   |
| fps                | 388      |
| nupdates           | 20800    |
| policy_entropy     | 0.765    |
| total_timesteps    | 104000   |
| value_loss         | 5.73     |
---------------------------------
----------------------------------
| ep_len_mean        | 164       |
| ep_reward_mean     | -144      |
| explained_variance | -0.000768 |
| fps                | 388       |
| nupdates           | 20900     |
| policy_entropy     | 0.762     |
| total_timesteps    | 104500    |
| value_loss         | 91.2      |
----------------------------------
11.0
11.0
166.54
13.5
---------------------------------
| ep_len_mean        | 167      |
| ep_reward_mean     | -154     |
| explained_variance | -8.78    |
| fps                | 388      |
| nupdates           | 21000    |
| policy_entropy     | 0.751    |
| total_timesteps    | 105000   |
| value_loss         | 0.326    |
---------------------------------
---------------------------------
| ep_len_mean        | 167      |
| ep_reward_mean     | -154     |
| explained_variance | -0.471   |
| fps                | 388      |
| nupdates           | 21100    |
| policy_entropy     | 0.76     |
| total_timesteps    | 105500   |
| value_loss         | 0.378    |
---------------------------------
12.0
12.0
174.11
12.0
---------------------------------
| ep_len_mean        | 174      |
| ep_reward_mean     | -180     |
| explained_variance | 0.159    |
| fps                | 389      |
| nupdates           | 21200    |
| policy_entropy     | 0.103    |
| total_timesteps    | 106000   |
| value_loss         | 0.935    |
---------------------------------
---------------------------------
| ep_len_mean        | 176      |
| ep_reward_mean     | -186     |
| explained_variance | -14.6    |
| fps                | 389      |
| nupdates           | 21300    |
| policy_entropy     | 0.762    |
| total_timesteps    | 106500   |
| value_loss         | 0.0357   |
---------------------------------
38.0
38.0
176.37
25.0
---------------------------------
| ep_len_mean        | 176      |
| ep_reward_mean     | -186     |
| explained_variance | -0.00548 |
| fps                | 389      |
| nupdates           | 21400    |
| policy_entropy     | 0.301    |
| total_timesteps    | 107000   |
| value_loss         | 48       |
---------------------------------
----------------------------------
| ep_len_mean        | 188       |
| ep_reward_mean     | -209      |
| explained_variance | -2.27e+04 |
| fps                | 389       |
| nupdates           | 21500     |
| policy_entropy     | 0.663     |
| total_timesteps    | 107500    |
| value_loss         | 0.000598  |
----------------------------------
12.0
12.0
181.91
12.0
---------------------------------
| ep_len_mean        | 182      |
| ep_reward_mean     | -197     |
| explained_variance | -0.0252  |
| fps                | 389      |
| nupdates           | 21600    |
| policy_entropy     | 0.228    |
| total_timesteps    | 108000   |
| value_loss         | 5.52     |
---------------------------------
---------------------------------
| ep_len_mean        | 186      |
| ep_reward_mean     | -210     |
| explained_variance | -2.01    |
| fps                | 390      |
| nupdates           | 21700    |
| policy_entropy     | 0.192    |
| total_timesteps    | 108500   |
| value_loss         | 0.192    |
---------------------------------
244.0
244.0
193.36
20.0
---------------------------------
| ep_len_mean        | 193      |
| ep_reward_mean     | -227     |
| explained_variance | 0.629    |
| fps                | 390      |
| nupdates           | 21800    |
| policy_entropy     | 0.0625   |
| total_timesteps    | 109000   |
| value_loss         | 67.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 177      |
| ep_reward_mean     | -186     |
| explained_variance | -70      |
| fps                | 390      |
| nupdates           | 21900    |
| policy_entropy     | 0.395    |
| total_timesteps    | 109500   |
| value_loss         | 58.9     |
---------------------------------
11.0
11.0
175.86
11.0
---------------------------------
| ep_len_mean        | 176      |
| ep_reward_mean     | -183     |
| explained_variance | -0.18    |
| fps                | 390      |
| nupdates           | 22000    |
| policy_entropy     | 0.137    |
| total_timesteps    | 110000   |
| value_loss         | 5.62     |
---------------------------------
---------------------------------
| ep_len_mean        | 181      |
| ep_reward_mean     | -198     |
| explained_variance | -1.93    |
| fps                | 390      |
| nupdates           | 22100    |
| policy_entropy     | 0.0733   |
| total_timesteps    | 110500   |
| value_loss         | 2.55     |
---------------------------------
504.0
504.0
180.7
13.5
---------------------------------
| ep_len_mean        | 181      |
| ep_reward_mean     | -198     |
| explained_variance | -11.1    |
| fps                | 390      |
| nupdates           | 22200    |
| policy_entropy     | 0.0639   |
| total_timesteps    | 111000   |
| value_loss         | 0.657    |
---------------------------------
---------------------------------
| ep_len_mean        | 165      |
| ep_reward_mean     | -142     |
| explained_variance | -12.2    |
| fps                | 391      |
| nupdates           | 22300    |
| policy_entropy     | 0.152    |
| total_timesteps    | 111500   |
| value_loss         | 0.356    |
---------------------------------
10.0
10.0
157.64
12.5
---------------------------------
| ep_len_mean        | 158      |
| ep_reward_mean     | -133     |
| explained_variance | 0.0736   |
| fps                | 391      |
| nupdates           | 22400    |
| policy_entropy     | 0.0712   |
| total_timesteps    | 112000   |
| value_loss         | 1.25     |
---------------------------------
---------------------------------
| ep_len_mean        | 161      |
| ep_reward_mean     | -141     |
| explained_variance | -253     |
| fps                | 391      |
| nupdates           | 22500    |
| policy_entropy     | 0.0747   |
| total_timesteps    | 112500   |
| value_loss         | 0.0332   |
---------------------------------
15.0
15.0
161.42
15.5
---------------------------------
| ep_len_mean        | 161      |
| ep_reward_mean     | -141     |
| explained_variance | -6.29    |
| fps                | 391      |
| nupdates           | 22600    |
| policy_entropy     | 0.17     |
| total_timesteps    | 113000   |
| value_loss         | 0.0011   |
---------------------------------
---------------------------------
| ep_len_mean        | 172      |
| ep_reward_mean     | -163     |
| explained_variance | 0.721    |
| fps                | 391      |
| nupdates           | 22700    |
| policy_entropy     | 0.204    |
| total_timesteps    | 113500   |
| value_loss         | 374      |
---------------------------------
54.0
54.0
114.81
12.0
---------------------------------
| ep_len_mean        | 115      |
| ep_reward_mean     | -33.7    |
| explained_variance | 0.0626   |
| fps                | 391      |
| nupdates           | 22800    |
| policy_entropy     | 0.0804   |
| total_timesteps    | 114000   |
| value_loss         | 293      |
---------------------------------
---------------------------------
| ep_len_mean        | 117      |
| ep_reward_mean     | -37      |
| explained_variance | -192     |
| fps                | 392      |
| nupdates           | 22900    |
| policy_entropy     | 0.313    |
| total_timesteps    | 114500   |
| value_loss         | 767      |
---------------------------------
133.0
133.0
105.38
69.0
---------------------------------
| ep_len_mean        | 105      |
| ep_reward_mean     | -15.9    |
| explained_variance | 0        |
| fps                | 392      |
| nupdates           | 23000    |
| policy_entropy     | 0.337    |
| total_timesteps    | 115000   |
| value_loss         | 0.0241   |
---------------------------------
---------------------------------
| ep_len_mean        | 78.5     |
| ep_reward_mean     | 55.9     |
| explained_variance | -367     |
| fps                | 392      |
| nupdates           | 23100    |
| policy_entropy     | 0.0809   |
| total_timesteps    | 115500   |
| value_loss         | 788      |
---------------------------------
25.0
25.0
66.05
16.5
---------------------------------
| ep_len_mean        | 66       |
| ep_reward_mean     | 89       |
| explained_variance | -0.676   |
| fps                | 392      |
| nupdates           | 23200    |
| policy_entropy     | 0.32     |
| total_timesteps    | 116000   |
| value_loss         | 1.54e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 54       |
| ep_reward_mean     | 119      |
| explained_variance | 0.243    |
| fps                | 392      |
| nupdates           | 23300    |
| policy_entropy     | 0.402    |
| total_timesteps    | 116500   |
| value_loss         | 1.57e+05 |
---------------------------------
22.0
22.0
38.64
18.5
---------------------------------
| ep_len_mean        | 38.6     |
| ep_reward_mean     | 155      |
| explained_variance | -11.9    |
| fps                | 392      |
| nupdates           | 23400    |
| policy_entropy     | 0.515    |
| total_timesteps    | 117000   |
| value_loss         | 43.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 32.7     |
| ep_reward_mean     | 171      |
| explained_variance | -9.51    |
| fps                | 393      |
| nupdates           | 23500    |
| policy_entropy     | 0.265    |
| total_timesteps    | 117500   |
| value_loss         | 315      |
---------------------------------
30.0
30.0
25.39
11.5
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 183      |
| explained_variance | -1.78    |
| fps                | 393      |
| nupdates           | 23600    |
| policy_entropy     | 0.198    |
| total_timesteps    | 118000   |
| value_loss         | 229      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.9     |
| ep_reward_mean     | 181      |
| explained_variance | -2.44    |
| fps                | 393      |
| nupdates           | 23700    |
| policy_entropy     | 0.578    |
| total_timesteps    | 118500   |
| value_loss         | 226      |
---------------------------------
13.0
13.0
23.92
13.0
---------------------------------
| ep_len_mean        | 23.9     |
| ep_reward_mean     | 182      |
| explained_variance | -8.5     |
| fps                | 393      |
| nupdates           | 23800    |
| policy_entropy     | 0.246    |
| total_timesteps    | 119000   |
| value_loss         | 522      |
---------------------------------
---------------------------------
| ep_len_mean        | 24.8     |
| ep_reward_mean     | 178      |
| explained_variance | 0.215    |
| fps                | 393      |
| nupdates           | 23900    |
| policy_entropy     | 0.832    |
| total_timesteps    | 119500   |
| value_loss         | 77.2     |
---------------------------------
70.0
70.0
23.61
9.5
---------------------------------
| ep_len_mean        | 23.6     |
| ep_reward_mean     | 182      |
| explained_variance | 0.786    |
| fps                | 394      |
| nupdates           | 24000    |
| policy_entropy     | 0.779    |
| total_timesteps    | 120000   |
| value_loss         | 251      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.5     |
| ep_reward_mean     | 191      |
| explained_variance | -2.36    |
| fps                | 394      |
| nupdates           | 24100    |
| policy_entropy     | 0.612    |
| total_timesteps    | 120500   |
| value_loss         | 141      |
---------------------------------
9.0
9.0
18.94
12.5
---------------------------------
| ep_len_mean        | 18.9     |
| ep_reward_mean     | 196      |
| explained_variance | -4.63    |
| fps                | 394      |
| nupdates           | 24200    |
| policy_entropy     | 0.296    |
| total_timesteps    | 121000   |
| value_loss         | 725      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 200      |
| explained_variance | -0.932   |
| fps                | 394      |
| nupdates           | 24300    |
| policy_entropy     | 0.266    |
| total_timesteps    | 121500   |
| value_loss         | 377      |
---------------------------------
9.0
9.0
18.56
9.5
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 197      |
| explained_variance | -2.55    |
| fps                | 394      |
| nupdates           | 24400    |
| policy_entropy     | 0.0514   |
| total_timesteps    | 122000   |
| value_loss         | 3.26e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 190      |
| explained_variance | 0        |
| fps                | 394      |
| nupdates           | 24500    |
| policy_entropy     | 0.272    |
| total_timesteps    | 122500   |
| value_loss         | 7.49     |
---------------------------------
10.0
10.0
26.93
25.5
---------------------------------
| ep_len_mean        | 26.9     |
| ep_reward_mean     | 172      |
| explained_variance | -0.0842  |
| fps                | 394      |
| nupdates           | 24600    |
| policy_entropy     | 0.102    |
| total_timesteps    | 123000   |
| value_loss         | 217      |
---------------------------------
----------------------------------
| ep_len_mean        | 28.2      |
| ep_reward_mean     | 168       |
| explained_variance | -1.19e+04 |
| fps                | 395       |
| nupdates           | 24700     |
| policy_entropy     | 0.731     |
| total_timesteps    | 123500    |
| value_loss         | 1.54      |
----------------------------------
10.0
10.0
32.16
16.5
---------------------------------
| ep_len_mean        | 32.2     |
| ep_reward_mean     | 159      |
| explained_variance | 0.0628   |
| fps                | 395      |
| nupdates           | 24800    |
| policy_entropy     | 0.0651   |
| total_timesteps    | 124000   |
| value_loss         | 220      |
---------------------------------
---------------------------------
| ep_len_mean        | 31.6     |
| ep_reward_mean     | 163      |
| explained_variance | -3.31    |
| fps                | 395      |
| nupdates           | 24900    |
| policy_entropy     | 0.702    |
| total_timesteps    | 124500   |
| value_loss         | 0.191    |
---------------------------------
51.0
51.0
35.34
11.0
---------------------------------
| ep_len_mean        | 35.3     |
| ep_reward_mean     | 155      |
| explained_variance | -0.73    |
| fps                | 395      |
| nupdates           | 25000    |
| policy_entropy     | 0.076    |
| total_timesteps    | 125000   |
| value_loss         | 878      |
---------------------------------
---------------------------------
| ep_len_mean        | 37.4     |
| ep_reward_mean     | 149      |
| explained_variance | -6.62    |
| fps                | 395      |
| nupdates           | 25100    |
| policy_entropy     | 0.875    |
| total_timesteps    | 125500   |
| value_loss         | 14.8     |
---------------------------------
13.0
13.0
40.77
13.0
---------------------------------
| ep_len_mean        | 40.8     |
| ep_reward_mean     | 143      |
| explained_variance | 0.29     |
| fps                | 395      |
| nupdates           | 25200    |
| policy_entropy     | 0.656    |
| total_timesteps    | 126000   |
| value_loss         | 0.022    |
---------------------------------
---------------------------------
| ep_len_mean        | 44.4     |
| ep_reward_mean     | 136      |
| explained_variance | -152     |
| fps                | 395      |
| nupdates           | 25300    |
| policy_entropy     | 0.638    |
| total_timesteps    | 126500   |
| value_loss         | 0.112    |
---------------------------------
22.0
22.0
48.9
23.5
----------------------------------
| ep_len_mean        | 48.9      |
| ep_reward_mean     | 127       |
| explained_variance | -1.83e+05 |
| fps                | 396       |
| nupdates           | 25400     |
| policy_entropy     | 0.602     |
| total_timesteps    | 127000    |
| value_loss         | 42.2      |
----------------------------------
---------------------------------
| ep_len_mean        | 48.1     |
| ep_reward_mean     | 135      |
| explained_variance | -0.393   |
| fps                | 396      |
| nupdates           | 25500    |
| policy_entropy     | 0.64     |
| total_timesteps    | 127500   |
| value_loss         | 87.5     |
---------------------------------
40.0
40.0
46.3
12.0
---------------------------------
| ep_len_mean        | 46.3     |
| ep_reward_mean     | 139      |
| explained_variance | -1.27    |
| fps                | 396      |
| nupdates           | 25600    |
| policy_entropy     | 0.511    |
| total_timesteps    | 128000   |
| value_loss         | 47.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 45.8     |
| ep_reward_mean     | 139      |
| explained_variance | -13.9    |
| fps                | 396      |
| nupdates           | 25700    |
| policy_entropy     | 0.316    |
| total_timesteps    | 128500   |
| value_loss         | 85.8     |
---------------------------------
12.0
12.0
49.86
11.0
---------------------------------
| ep_len_mean        | 49.9     |
| ep_reward_mean     | 130      |
| explained_variance | 0.574    |
| fps                | 396      |
| nupdates           | 25800    |
| policy_entropy     | 0.619    |
| total_timesteps    | 129000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| ep_len_mean        | 53.5     |
| ep_reward_mean     | 122      |
| explained_variance | -0.889   |
| fps                | 396      |
| nupdates           | 25900    |
| policy_entropy     | 0.0674   |
| total_timesteps    | 129500   |
| value_loss         | 677      |
---------------------------------
8.0
8.0
54.82
18.5
---------------------------------
| ep_len_mean        | 54.8     |
| ep_reward_mean     | 118      |
| explained_variance | -56.6    |
| fps                | 396      |
| nupdates           | 26000    |
| policy_entropy     | 0.472    |
| total_timesteps    | 130000   |
| value_loss         | 0.31     |
---------------------------------
---------------------------------
| ep_len_mean        | 54.8     |
| ep_reward_mean     | 118      |
| explained_variance | -0.867   |
| fps                | 397      |
| nupdates           | 26100    |
| policy_entropy     | 0.95     |
| total_timesteps    | 130500   |
| value_loss         | 12.5     |
---------------------------------
20.0
20.0
63.54
37.0
---------------------------------
| ep_len_mean        | 63.5     |
| ep_reward_mean     | 101      |
| explained_variance | -30.2    |
| fps                | 397      |
| nupdates           | 26200    |
| policy_entropy     | 0.623    |
| total_timesteps    | 131000   |
| value_loss         | 0.0321   |
---------------------------------
---------------------------------
| ep_len_mean        | 70.6     |
| ep_reward_mean     | 86.5     |
| explained_variance | -329     |
| fps                | 397      |
| nupdates           | 26300    |
| policy_entropy     | 0.664    |
| total_timesteps    | 131500   |
| value_loss         | 0.0462   |
---------------------------------
391.0
391.0
71.14
38.0
---------------------------------
| ep_len_mean        | 71.1     |
| ep_reward_mean     | 84.2     |
| explained_variance | -97.6    |
| fps                | 397      |
| nupdates           | 26400    |
| policy_entropy     | 0.627    |
| total_timesteps    | 132000   |
| value_loss         | 0.0402   |
---------------------------------
---------------------------------
| ep_len_mean        | 77       |
| ep_reward_mean     | 72       |
| explained_variance | -11.3    |
| fps                | 397      |
| nupdates           | 26500    |
| policy_entropy     | 0.797    |
| total_timesteps    | 132500   |
| value_loss         | 0.437    |
---------------------------------
9.0
9.0
80.49
18.0
---------------------------------
| ep_len_mean        | 80.5     |
| ep_reward_mean     | 67       |
| explained_variance | -776     |
| fps                | 397      |
| nupdates           | 26600    |
| policy_entropy     | 0.569    |
| total_timesteps    | 133000   |
| value_loss         | 1.47     |
---------------------------------
---------------------------------
| ep_len_mean        | 79.2     |
| ep_reward_mean     | 71.6     |
| explained_variance | 0.459    |
| fps                | 397      |
| nupdates           | 26700    |
| policy_entropy     | 0.0877   |
| total_timesteps    | 133500   |
| value_loss         | 31.8     |
---------------------------------
10.0
10.0
65.65
10.0
---------------------------------
| ep_len_mean        | 65.7     |
| ep_reward_mean     | 97.8     |
| explained_variance | 0.759    |
| fps                | 398      |
| nupdates           | 26800    |
| policy_entropy     | 0.289    |
| total_timesteps    | 134000   |
| value_loss         | 1.48     |
---------------------------------
---------------------------------
| ep_len_mean        | 67       |
| ep_reward_mean     | 95.8     |
| explained_variance | 0.18     |
| fps                | 398      |
| nupdates           | 26900    |
| policy_entropy     | 0.281    |
| total_timesteps    | 134500   |
| value_loss         | 226      |
---------------------------------
25.0
25.0
68.03
26.5
----------------------------------
| ep_len_mean        | 68        |
| ep_reward_mean     | 93.4      |
| explained_variance | -9.97e+03 |
| fps                | 398       |
| nupdates           | 27000     |
| policy_entropy     | 0.75      |
| total_timesteps    | 135000    |
| value_loss         | 1.18      |
----------------------------------
---------------------------------
| ep_len_mean        | 66.2     |
| ep_reward_mean     | 97.3     |
| explained_variance | -1.2e+03 |
| fps                | 398      |
| nupdates           | 27100    |
| policy_entropy     | 0.598    |
| total_timesteps    | 135500   |
| value_loss         | 2.18     |
---------------------------------
10.0
10.0
46.44
10.0
---------------------------------
| ep_len_mean        | 46.4     |
| ep_reward_mean     | 137      |
| explained_variance | -0.185   |
| fps                | 398      |
| nupdates           | 27200    |
| policy_entropy     | 0.376    |
| total_timesteps    | 136000   |
| value_loss         | 3.15e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 28.5     |
| ep_reward_mean     | 175      |
| explained_variance | -0.176   |
| fps                | 398      |
| nupdates           | 27300    |
| policy_entropy     | 0.194    |
| total_timesteps    | 136500   |
| value_loss         | 525      |
---------------------------------
24.0
24.0
27.62
15.5
---------------------------------
| ep_len_mean        | 27.6     |
| ep_reward_mean     | 176      |
| explained_variance | -0.261   |
| fps                | 398      |
| nupdates           | 27400    |
| policy_entropy     | 0.19     |
| total_timesteps    | 137000   |
| value_loss         | 6.59e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 22.1     |
| ep_reward_mean     | 187      |
| explained_variance | -9.95    |
| fps                | 398      |
| nupdates           | 27500    |
| policy_entropy     | 0.258    |
| total_timesteps    | 137500   |
| value_loss         | 177      |
---------------------------------
8.0
8.0
22.77
17.5
---------------------------------
| ep_len_mean        | 22.8     |
| ep_reward_mean     | 187      |
| explained_variance | -644     |
| fps                | 398      |
| nupdates           | 27600    |
| policy_entropy     | 0.319    |
| total_timesteps    | 138000   |
| value_loss         | 785      |
---------------------------------
---------------------------------
| ep_len_mean        | 23.1     |
| ep_reward_mean     | 186      |
| explained_variance | -41.7    |
| fps                | 399      |
| nupdates           | 27700    |
| policy_entropy     | 0.0942   |
| total_timesteps    | 138500   |
| value_loss         | 742      |
---------------------------------
9.0
9.0
24.31
11.5
---------------------------------
| ep_len_mean        | 24.3     |
| ep_reward_mean     | 183      |
| explained_variance | 0.463    |
| fps                | 399      |
| nupdates           | 27800    |
| policy_entropy     | 0.0353   |
| total_timesteps    | 139000   |
| value_loss         | 563      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.5     |
| ep_reward_mean     | 181      |
| explained_variance | -0.242   |
| fps                | 399      |
| nupdates           | 27900    |
| policy_entropy     | 0.0382   |
| total_timesteps    | 139500   |
| value_loss         | 610      |
---------------------------------
24.0
24.0
23.68
16.0
---------------------------------
| ep_len_mean        | 23.7     |
| ep_reward_mean     | 188      |
| explained_variance | 0.513    |
| fps                | 399      |
| nupdates           | 28000    |
| policy_entropy     | 0.45     |
| total_timesteps    | 140000   |
| value_loss         | 6.25     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 195      |
| explained_variance | -38.8    |
| fps                | 399      |
| nupdates           | 28100    |
| policy_entropy     | 0.3      |
| total_timesteps    | 140500   |
| value_loss         | 583      |
---------------------------------
9.0
9.0
20.04
10.5
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 198      |
| explained_variance | -4.96    |
| fps                | 399      |
| nupdates           | 28200    |
| policy_entropy     | 0.0801   |
| total_timesteps    | 141000   |
| value_loss         | 100      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 200      |
| explained_variance | 0.807    |
| fps                | 399      |
| nupdates           | 28300    |
| policy_entropy     | 0.0362   |
| total_timesteps    | 141500   |
| value_loss         | 292      |
---------------------------------
63.0
63.0
19.23
14.0
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 200      |
| explained_variance | -0.0537  |
| fps                | 399      |
| nupdates           | 28400    |
| policy_entropy     | 0.256    |
| total_timesteps    | 142000   |
| value_loss         | 2.34e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.7     |
| ep_reward_mean     | 200      |
| explained_variance | -1.89    |
| fps                | 399      |
| nupdates           | 28500    |
| policy_entropy     | 0.0131   |
| total_timesteps    | 142500   |
| value_loss         | 989      |
---------------------------------
9.0
9.0
20.2
9.5
---------------------------------
| ep_len_mean        | 20.2     |
| ep_reward_mean     | 197      |
| explained_variance | -7.44    |
| fps                | 399      |
| nupdates           | 28600    |
| policy_entropy     | 0.13     |
| total_timesteps    | 143000   |
| value_loss         | 1.95e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 199      |
| explained_variance | 0.569    |
| fps                | 399      |
| nupdates           | 28700    |
| policy_entropy     | 0.0213   |
| total_timesteps    | 143500   |
| value_loss         | 365      |
---------------------------------
15.0
15.0
19.34
11.0
---------------------------------
| ep_len_mean        | 19.3     |
| ep_reward_mean     | 198      |
| explained_variance | 0.219    |
| fps                | 399      |
| nupdates           | 28800    |
| policy_entropy     | 0.0226   |
| total_timesteps    | 144000   |
| value_loss         | 454      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 203      |
| explained_variance | -5.84    |
| fps                | 400      |
| nupdates           | 28900    |
| policy_entropy     | 0.28     |
| total_timesteps    | 144500   |
| value_loss         | 738      |
---------------------------------
11.0
11.0
17.65
12.5
---------------------------------
| ep_len_mean        | 17.6     |
| ep_reward_mean     | 206      |
| explained_variance | -0.745   |
| fps                | 400      |
| nupdates           | 29000    |
| policy_entropy     | 0.379    |
| total_timesteps    | 145000   |
| value_loss         | 168      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 208      |
| explained_variance | 0.536    |
| fps                | 400      |
| nupdates           | 29100    |
| policy_entropy     | 0.16     |
| total_timesteps    | 145500   |
| value_loss         | 281      |
---------------------------------
41.0
41.0
16.63
9.5
---------------------------------
| ep_len_mean        | 16.6     |
| ep_reward_mean     | 207      |
| explained_variance | -28.6    |
| fps                | 400      |
| nupdates           | 29200    |
| policy_entropy     | 0.125    |
| total_timesteps    | 146000   |
| value_loss         | 2.71e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 202      |
| explained_variance | 0        |
| fps                | 400      |
| nupdates           | 29300    |
| policy_entropy     | 0.355    |
| total_timesteps    | 146500   |
| value_loss         | 272      |
---------------------------------
30.0
30.0
20.01
16.5
---------------------------------
| ep_len_mean        | 20       |
| ep_reward_mean     | 195      |
| explained_variance | -0.186   |
| fps                | 400      |
| nupdates           | 29400    |
| policy_entropy     | 0.268    |
| total_timesteps    | 147000   |
| value_loss         | 5.98e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 21.1     |
| ep_reward_mean     | 191      |
| explained_variance | 0.796    |
| fps                | 400      |
| nupdates           | 29500    |
| policy_entropy     | 0.397    |
| total_timesteps    | 147500   |
| value_loss         | 106      |
---------------------------------
13.0
13.0
21.8
11.5
---------------------------------
| ep_len_mean        | 21.8     |
| ep_reward_mean     | 189      |
| explained_variance | -2.04    |
| fps                | 400      |
| nupdates           | 29600    |
| policy_entropy     | 0.145    |
| total_timesteps    | 148000   |
| value_loss         | 180      |
---------------------------------
---------------------------------
| ep_len_mean        | 20.3     |
| ep_reward_mean     | 193      |
| explained_variance | 0.534    |
| fps                | 400      |
| nupdates           | 29700    |
| policy_entropy     | 0.129    |
| total_timesteps    | 148500   |
| value_loss         | 206      |
---------------------------------
67.0
67.0
18.63
16.5
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 197      |
| explained_variance | -0.429   |
| fps                | 400      |
| nupdates           | 29800    |
| policy_entropy     | 0.663    |
| total_timesteps    | 149000   |
| value_loss         | 124      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 204      |
| explained_variance | -0.413   |
| fps                | 400      |
| nupdates           | 29900    |
| policy_entropy     | 0.0935   |
| total_timesteps    | 149500   |
| value_loss         | 1.22e+03 |
---------------------------------
9.0
9.0
16.76
9.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 206      |
| explained_variance | -0.819   |
| fps                | 400      |
| nupdates           | 30000    |
| policy_entropy     | 0.349    |
| total_timesteps    | 150000   |
| value_loss         | 114      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 210      |
| explained_variance | 0.673    |
| fps                | 401      |
| nupdates           | 30100    |
| policy_entropy     | 0.255    |
| total_timesteps    | 150500   |
| value_loss         | 790      |
---------------------------------
10.0
10.0
16.78
9.5
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.6      |
| fps                | 401      |
| nupdates           | 30200    |
| policy_entropy     | 0.0526   |
| total_timesteps    | 151000   |
| value_loss         | 79.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 210      |
| explained_variance | -0.0154  |
| fps                | 401      |
| nupdates           | 30300    |
| policy_entropy     | 0.331    |
| total_timesteps    | 151500   |
| value_loss         | 200      |
---------------------------------
35.0
35.0
14.61
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 211      |
| explained_variance | 0.877    |
| fps                | 401      |
| nupdates           | 30400    |
| policy_entropy     | 0.0381   |
| total_timesteps    | 152000   |
| value_loss         | 37.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 214      |
| explained_variance | 0.366    |
| fps                | 401      |
| nupdates           | 30500    |
| policy_entropy     | 0.0633   |
| total_timesteps    | 152500   |
| value_loss         | 43.8     |
---------------------------------
112.0
112.0
15.05
9.5
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 212      |
| explained_variance | -4.51    |
| fps                | 401      |
| nupdates           | 30600    |
| policy_entropy     | 0.538    |
| total_timesteps    | 153000   |
| value_loss         | 232      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 212      |
| explained_variance | -1.48    |
| fps                | 401      |
| nupdates           | 30700    |
| policy_entropy     | 0.169    |
| total_timesteps    | 153500   |
| value_loss         | 555      |
---------------------------------
22.0
22.0
15.62
16.0
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 211      |
| explained_variance | -6.67    |
| fps                | 401      |
| nupdates           | 30800    |
| policy_entropy     | 0.201    |
| total_timesteps    | 154000   |
| value_loss         | 346      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.574    |
| fps                | 401      |
| nupdates           | 30900    |
| policy_entropy     | 0.165    |
| total_timesteps    | 154500   |
| value_loss         | 179      |
---------------------------------
10.0
10.0
17.9
14.5
----------------------------------
| ep_len_mean        | 17.9      |
| ep_reward_mean     | 206       |
| explained_variance | -2.38e-07 |
| fps                | 401       |
| nupdates           | 31000     |
| policy_entropy     | 0.448     |
| total_timesteps    | 155000    |
| value_loss         | 392       |
----------------------------------
---------------------------------
| ep_len_mean        | 18.6     |
| ep_reward_mean     | 202      |
| explained_variance | -17.6    |
| fps                | 401      |
| nupdates           | 31100    |
| policy_entropy     | 0.167    |
| total_timesteps    | 155500   |
| value_loss         | 417      |
---------------------------------
34.0
34.0
16.85
10.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 204      |
| explained_variance | -0.44    |
| fps                | 401      |
| nupdates           | 31200    |
| policy_entropy     | 0.305    |
| total_timesteps    | 156000   |
| value_loss         | 115      |
---------------------------------
---------------------------------
| ep_len_mean        | 21.1     |
| ep_reward_mean     | 196      |
| explained_variance | -8.09    |
| fps                | 401      |
| nupdates           | 31300    |
| policy_entropy     | 0.167    |
| total_timesteps    | 156500   |
| value_loss         | 1.71e+03 |
---------------------------------
10.0
10.0
18.54
11.0
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 204      |
| explained_variance | -71.3    |
| fps                | 402      |
| nupdates           | 31400    |
| policy_entropy     | 0.201    |
| total_timesteps    | 157000   |
| value_loss         | 1.15e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 205      |
| explained_variance | -0.226   |
| fps                | 402      |
| nupdates           | 31500    |
| policy_entropy     | 0.181    |
| total_timesteps    | 157500   |
| value_loss         | 140      |
---------------------------------
10.0
10.0
14.44
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.77     |
| fps                | 402      |
| nupdates           | 31600    |
| policy_entropy     | 0.0182   |
| total_timesteps    | 158000   |
| value_loss         | 496      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.456    |
| fps                | 402      |
| nupdates           | 31700    |
| policy_entropy     | 0.0995   |
| total_timesteps    | 158500   |
| value_loss         | 39.1     |
---------------------------------
9.0
9.0
14.46
16.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.691    |
| fps                | 402      |
| nupdates           | 31800    |
| policy_entropy     | 0.0676   |
| total_timesteps    | 159000   |
| value_loss         | 118      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 210      |
| explained_variance | -1.61    |
| fps                | 402      |
| nupdates           | 31900    |
| policy_entropy     | 0.0502   |
| total_timesteps    | 159500   |
| value_loss         | 219      |
---------------------------------
10.0
10.0
17.69
15.5
---------------------------------
| ep_len_mean        | 17.7     |
| ep_reward_mean     | 203      |
| explained_variance | -3.75    |
| fps                | 402      |
| nupdates           | 32000    |
| policy_entropy     | 0.149    |
| total_timesteps    | 160000   |
| value_loss         | 381      |
---------------------------------
---------------------------------
| ep_len_mean        | 19.2     |
| ep_reward_mean     | 197      |
| explained_variance | -11.5    |
| fps                | 402      |
| nupdates           | 32100    |
| policy_entropy     | 0.441    |
| total_timesteps    | 160500   |
| value_loss         | 526      |
---------------------------------
20.0
20.0
19.58
20.0
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 195      |
| explained_variance | 0.537    |
| fps                | 402      |
| nupdates           | 32200    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 161000   |
| value_loss         | 390      |
---------------------------------
---------------------------------
| ep_len_mean        | 18.5     |
| ep_reward_mean     | 197      |
| explained_variance | -1.21    |
| fps                | 402      |
| nupdates           | 32300    |
| policy_entropy     | 0.0539   |
| total_timesteps    | 161500   |
| value_loss         | 450      |
---------------------------------
10.0
10.0
16.03
15.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 206      |
| explained_variance | -0.558   |
| fps                | 402      |
| nupdates           | 32400    |
| policy_entropy     | 0.0892   |
| total_timesteps    | 162000   |
| value_loss         | 681      |
---------------------------------
----------------------------------
| ep_len_mean        | 15.3      |
| ep_reward_mean     | 210       |
| explained_variance | -2.38e-07 |
| fps                | 402       |
| nupdates           | 32500     |
| policy_entropy     | 0.58      |
| total_timesteps    | 162500    |
| value_loss         | 97.2      |
----------------------------------
10.0
10.0
15.85
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.87     |
| fps                | 402      |
| nupdates           | 32600    |
| policy_entropy     | 0.396    |
| total_timesteps    | 163000   |
| value_loss         | 53       |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.789    |
| fps                | 402      |
| nupdates           | 32700    |
| policy_entropy     | 0.00842  |
| total_timesteps    | 163500   |
| value_loss         | 87.1     |
---------------------------------
10.0
10.0
14.47
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 212      |
| explained_variance | -0.00214 |
| fps                | 402      |
| nupdates           | 32800    |
| policy_entropy     | 0.185    |
| total_timesteps    | 164000   |
| value_loss         | 365      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 212      |
| explained_variance | -1.44    |
| fps                | 402      |
| nupdates           | 32900    |
| policy_entropy     | 0.137    |
| total_timesteps    | 164500   |
| value_loss         | 210      |
---------------------------------
10.0
10.0
14.52
15.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 213      |
| explained_variance | 0.845    |
| fps                | 403      |
| nupdates           | 33000    |
| policy_entropy     | 0.0231   |
| total_timesteps    | 165000   |
| value_loss         | 18.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 215      |
| explained_variance | 0.184    |
| fps                | 403      |
| nupdates           | 33100    |
| policy_entropy     | 0.531    |
| total_timesteps    | 165500   |
| value_loss         | 66.2     |
---------------------------------
9.0
9.0
12.87
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 12.9     |
| ep_reward_mean     | 217      |
| explained_variance | -0.412   |
| fps                | 403      |
| nupdates           | 33200    |
| policy_entropy     | 0.228    |
| total_timesteps    | 166000   |
| value_loss         | 147      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | -3.6     |
| fps                | 403      |
| nupdates           | 33300    |
| policy_entropy     | 0.0445   |
| total_timesteps    | 166500   |
| value_loss         | 76.4     |
---------------------------------
22.0
22.0
14.7
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 213      |
| explained_variance | -0.571   |
| fps                | 403      |
| nupdates           | 33400    |
| policy_entropy     | 0.138    |
| total_timesteps    | 167000   |
| value_loss         | 446      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.0242   |
| fps                | 403      |
| nupdates           | 33500    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 167500   |
| value_loss         | 315      |
---------------------------------
22.0
22.0
14.39
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 214      |
| explained_variance | -6.43    |
| fps                | 403      |
| nupdates           | 33600    |
| policy_entropy     | 0.104    |
| total_timesteps    | 168000   |
| value_loss         | 358      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.919    |
| fps                | 403      |
| nupdates           | 33700    |
| policy_entropy     | 0.0242   |
| total_timesteps    | 168500   |
| value_loss         | 6.46     |
---------------------------------
17.0
17.0
14.0
11.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 215      |
| explained_variance | -0.385   |
| fps                | 403      |
| nupdates           | 33800    |
| policy_entropy     | 0.421    |
| total_timesteps    | 169000   |
| value_loss         | 475      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 210      |
| explained_variance | 0.345    |
| fps                | 403      |
| nupdates           | 33900    |
| policy_entropy     | 0.323    |
| total_timesteps    | 169500   |
| value_loss         | 301      |
---------------------------------
9.0
9.0
16.83
24.0
---------------------------------
| ep_len_mean        | 16.8     |
| ep_reward_mean     | 209      |
| explained_variance | 0.47     |
| fps                | 403      |
| nupdates           | 34000    |
| policy_entropy     | 0.00795  |
| total_timesteps    | 170000   |
| value_loss         | 191      |
---------------------------------
---------------------------------
| ep_len_mean        | 17       |
| ep_reward_mean     | 206      |
| explained_variance | 0.751    |
| fps                | 403      |
| nupdates           | 34100    |
| policy_entropy     | 0.302    |
| total_timesteps    | 170500   |
| value_loss         | 188      |
---------------------------------
11.0
11.0
17.19
10.5
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 207      |
| explained_variance | -0.596   |
| fps                | 403      |
| nupdates           | 34200    |
| policy_entropy     | 0.0585   |
| total_timesteps    | 171000   |
| value_loss         | 39.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 17.3     |
| ep_reward_mean     | 207      |
| explained_variance | -1.52    |
| fps                | 403      |
| nupdates           | 34300    |
| policy_entropy     | 0.406    |
| total_timesteps    | 171500   |
| value_loss         | 366      |
---------------------------------
10.0
10.0
15.23
10.5
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 213      |
| explained_variance | 0.806    |
| fps                | 403      |
| nupdates           | 34400    |
| policy_entropy     | 0.0208   |
| total_timesteps    | 172000   |
| value_loss         | 15.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 215      |
| explained_variance | 5.96e-08 |
| fps                | 404      |
| nupdates           | 34500    |
| policy_entropy     | 0.147    |
| total_timesteps    | 172500   |
| value_loss         | 335      |
---------------------------------
10.0
10.0
13.95
10.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.415    |
| fps                | 403      |
| nupdates           | 34600    |
| policy_entropy     | 0.011    |
| total_timesteps    | 173000   |
| value_loss         | 90.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 212      |
| explained_variance | -2.84    |
| fps                | 403      |
| nupdates           | 34700    |
| policy_entropy     | 0.113    |
| total_timesteps    | 173500   |
| value_loss         | 268      |
---------------------------------
23.0
23.0
18.24
16.5
---------------------------------
| ep_len_mean        | 18.2     |
| ep_reward_mean     | 203      |
| explained_variance | -0.475   |
| fps                | 403      |
| nupdates           | 34800    |
| policy_entropy     | 0.0183   |
| total_timesteps    | 174000   |
| value_loss         | 2.2e+04  |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 206      |
| explained_variance | -18.3    |
| fps                | 404      |
| nupdates           | 34900    |
| policy_entropy     | 0.584    |
| total_timesteps    | 174500   |
| value_loss         | 786      |
---------------------------------
9.0
9.0
17.08
10.0
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 204      |
| explained_variance | 0.892    |
| fps                | 404      |
| nupdates           | 35000    |
| policy_entropy     | 0.0179   |
| total_timesteps    | 175000   |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.767    |
| fps                | 404      |
| nupdates           | 35100    |
| policy_entropy     | 0.216    |
| total_timesteps    | 175500   |
| value_loss         | 22.8     |
---------------------------------
11.0
11.0
13.87
10.5
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 214      |
| explained_variance | -2.05    |
| fps                | 404      |
| nupdates           | 35200    |
| policy_entropy     | 0.418    |
| total_timesteps    | 176000   |
| value_loss         | 310      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 212      |
| explained_variance | 0.657    |
| fps                | 404      |
| nupdates           | 35300    |
| policy_entropy     | 0.483    |
| total_timesteps    | 176500   |
| value_loss         | 37.8     |
---------------------------------
10.0
10.0
14.82
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 211      |
| explained_variance | 0.576    |
| fps                | 404      |
| nupdates           | 35400    |
| policy_entropy     | 0.0568   |
| total_timesteps    | 177000   |
| value_loss         | 81.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 214      |
| explained_variance | -1.36    |
| fps                | 404      |
| nupdates           | 35500    |
| policy_entropy     | 0.121    |
| total_timesteps    | 177500   |
| value_loss         | 129      |
---------------------------------
10.0
10.0
13.99
10.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 214      |
| explained_variance | -0.0543  |
| fps                | 404      |
| nupdates           | 35600    |
| policy_entropy     | 0.166    |
| total_timesteps    | 178000   |
| value_loss         | 365      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 213      |
| explained_variance | 0.532    |
| fps                | 404      |
| nupdates           | 35700    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 178500   |
| value_loss         | 69.9     |
---------------------------------
9.0
9.0
15.4
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 211      |
| explained_variance | -3.89    |
| fps                | 404      |
| nupdates           | 35800    |
| policy_entropy     | 0.0523   |
| total_timesteps    | 179000   |
| value_loss         | 130      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 210      |
| explained_variance | 0.493    |
| fps                | 404      |
| nupdates           | 35900    |
| policy_entropy     | 0.00898  |
| total_timesteps    | 179500   |
| value_loss         | 399      |
---------------------------------
29.0
29.0
15.52
16.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 209      |
| explained_variance | 0.95     |
| fps                | 404      |
| nupdates           | 36000    |
| policy_entropy     | 0.0265   |
| total_timesteps    | 180000   |
| value_loss         | 4.15     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 208      |
| explained_variance | -1.97    |
| fps                | 404      |
| nupdates           | 36100    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 180500   |
| value_loss         | 693      |
---------------------------------
23.0
23.0
13.93
10.0
----------------------------------
| ep_len_mean        | 13.9      |
| ep_reward_mean     | 210       |
| explained_variance | -1.19e-07 |
| fps                | 404       |
| nupdates           | 36200     |
| policy_entropy     | 0.187     |
| total_timesteps    | 181000    |
| value_loss         | 304       |
----------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 209      |
| explained_variance | -0.228   |
| fps                | 404      |
| nupdates           | 36300    |
| policy_entropy     | 0.0972   |
| total_timesteps    | 181500   |
| value_loss         | 199      |
---------------------------------
103.0
103.0
14.81
10.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 211      |
| explained_variance | -3.28    |
| fps                | 404      |
| nupdates           | 36400    |
| policy_entropy     | 0.309    |
| total_timesteps    | 182000   |
| value_loss         | 496      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 210      |
| explained_variance | -3.47    |
| fps                | 404      |
| nupdates           | 36500    |
| policy_entropy     | 0.0704   |
| total_timesteps    | 182500   |
| value_loss         | 629      |
---------------------------------
27.0
27.0
15.33
11.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.902    |
| fps                | 404      |
| nupdates           | 36600    |
| policy_entropy     | 0.0193   |
| total_timesteps    | 183000   |
| value_loss         | 59.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | -0.179   |
| fps                | 404      |
| nupdates           | 36700    |
| policy_entropy     | 0.0869   |
| total_timesteps    | 183500   |
| value_loss         | 348      |
---------------------------------
13.0
13.0
15.87
12.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.857    |
| fps                | 405      |
| nupdates           | 36800    |
| policy_entropy     | 0.021    |
| total_timesteps    | 184000   |
| value_loss         | 12.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 212      |
| explained_variance | 0.898    |
| fps                | 405      |
| nupdates           | 36900    |
| policy_entropy     | 0.0202   |
| total_timesteps    | 184500   |
| value_loss         | 8.6      |
---------------------------------
10.0
10.0
14.23
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | -0.345   |
| fps                | 405      |
| nupdates           | 37000    |
| policy_entropy     | 0.403    |
| total_timesteps    | 185000   |
| value_loss         | 323      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 213      |
| explained_variance | 0.548    |
| fps                | 405      |
| nupdates           | 37100    |
| policy_entropy     | 0.016    |
| total_timesteps    | 185500   |
| value_loss         | 229      |
---------------------------------
10.0
10.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 214      |
| explained_variance | 0        |
| fps                | 405      |
| nupdates           | 37200    |
| policy_entropy     | 0.525    |
| total_timesteps    | 186000   |
| value_loss         | 288      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 210      |
| explained_variance | -2.49    |
| fps                | 405      |
| nupdates           | 37300    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 186500   |
| value_loss         | 468      |
---------------------------------
9.0
9.0
16.25
9.0
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 211      |
| explained_variance | 0.815    |
| fps                | 405      |
| nupdates           | 37400    |
| policy_entropy     | 0.174    |
| total_timesteps    | 187000   |
| value_loss         | 39.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 210      |
| explained_variance | -1.26    |
| fps                | 405      |
| nupdates           | 37500    |
| policy_entropy     | 0.464    |
| total_timesteps    | 187500   |
| value_loss         | 447      |
---------------------------------
21.0
21.0
14.36
10.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.831    |
| fps                | 405      |
| nupdates           | 37600    |
| policy_entropy     | 0.011    |
| total_timesteps    | 188000   |
| value_loss         | 209      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 212      |
| explained_variance | -1.21    |
| fps                | 405      |
| nupdates           | 37700    |
| policy_entropy     | 0.107    |
| total_timesteps    | 188500   |
| value_loss         | 233      |
---------------------------------
20.0
20.0
15.12
10.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 214      |
| explained_variance | -2.42    |
| fps                | 405      |
| nupdates           | 37800    |
| policy_entropy     | 0.4      |
| total_timesteps    | 189000   |
| value_loss         | 377      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | -1.02    |
| fps                | 405      |
| nupdates           | 37900    |
| policy_entropy     | 0.492    |
| total_timesteps    | 189500   |
| value_loss         | 524      |
---------------------------------
19.0
19.0
14.73
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.966    |
| fps                | 405      |
| nupdates           | 38000    |
| policy_entropy     | 0.00712  |
| total_timesteps    | 190000   |
| value_loss         | 8.85     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 213      |
| explained_variance | -7.3     |
| fps                | 405      |
| nupdates           | 38100    |
| policy_entropy     | 0.482    |
| total_timesteps    | 190500   |
| value_loss         | 644      |
---------------------------------
20.0
20.0
15.88
10.5
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 213      |
| explained_variance | -0.262   |
| fps                | 405      |
| nupdates           | 38200    |
| policy_entropy     | 0.324    |
| total_timesteps    | 191000   |
| value_loss         | 328      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.692    |
| fps                | 405      |
| nupdates           | 38300    |
| policy_entropy     | 0.0392   |
| total_timesteps    | 191500   |
| value_loss         | 76.8     |
---------------------------------
10.0
10.0
14.23
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.921    |
| fps                | 405      |
| nupdates           | 38400    |
| policy_entropy     | 0.0236   |
| total_timesteps    | 192000   |
| value_loss         | 14.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 216      |
| explained_variance | -0.981   |
| fps                | 405      |
| nupdates           | 38500    |
| policy_entropy     | 0.482    |
| total_timesteps    | 192500   |
| value_loss         | 114      |
---------------------------------
10.0
10.0
14.53
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | -3.02    |
| fps                | 405      |
| nupdates           | 38600    |
| policy_entropy     | 0.0418   |
| total_timesteps    | 193000   |
| value_loss         | 2.58e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | 0.935    |
| fps                | 405      |
| nupdates           | 38700    |
| policy_entropy     | 0.0255   |
| total_timesteps    | 193500   |
| value_loss         | 6.15     |
---------------------------------
10.0
10.0
15.71
11.5
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.975    |
| fps                | 405      |
| nupdates           | 38800    |
| policy_entropy     | 0.0142   |
| total_timesteps    | 194000   |
| value_loss         | 6.94     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 211      |
| explained_variance | -0.857   |
| fps                | 405      |
| nupdates           | 38900    |
| policy_entropy     | 0.711    |
| total_timesteps    | 194500   |
| value_loss         | 54.5     |
---------------------------------
28.0
28.0
20.69
12.0
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 189      |
| explained_variance | -0.0373  |
| fps                | 405      |
| nupdates           | 39000    |
| policy_entropy     | 0.3      |
| total_timesteps    | 195000   |
| value_loss         | 1.07e+05 |
---------------------------------
---------------------------------
| ep_len_mean        | 22.4     |
| ep_reward_mean     | 182      |
| explained_variance | -0.0542  |
| fps                | 405      |
| nupdates           | 39100    |
| policy_entropy     | 0.36     |
| total_timesteps    | 195500   |
| value_loss         | 1.45e+05 |
---------------------------------
10.0
10.0
23.83
16.5
---------------------------------
| ep_len_mean        | 23.8     |
| ep_reward_mean     | 179      |
| explained_variance | 0        |
| fps                | 405      |
| nupdates           | 39200    |
| policy_entropy     | 0.0868   |
| total_timesteps    | 196000   |
| value_loss         | 27.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 27       |
| ep_reward_mean     | 166      |
| explained_variance | -13.2    |
| fps                | 405      |
| nupdates           | 39300    |
| policy_entropy     | 0.419    |
| total_timesteps    | 196500   |
| value_loss         | 5.17     |
---------------------------------
27.0
27.0
29.9
17.0
---------------------------------
| ep_len_mean        | 29.9     |
| ep_reward_mean     | 159      |
| explained_variance | 0.19     |
| fps                | 405      |
| nupdates           | 39400    |
| policy_entropy     | 0.00923  |
| total_timesteps    | 197000   |
| value_loss         | 212      |
---------------------------------
---------------------------------
| ep_len_mean        | 25.8     |
| ep_reward_mean     | 176      |
| explained_variance | 0.0967   |
| fps                | 405      |
| nupdates           | 39500    |
| policy_entropy     | 0.271    |
| total_timesteps    | 197500   |
| value_loss         | 3.05e+04 |
---------------------------------
26.0
26.0
24.53
10.0
----------------------------------
| ep_len_mean        | 24.5      |
| ep_reward_mean     | 182       |
| explained_variance | -1.19e-07 |
| fps                | 405       |
| nupdates           | 39600     |
| policy_entropy     | 0.133     |
| total_timesteps    | 198000    |
| value_loss         | 2.59      |
----------------------------------
---------------------------------
| ep_len_mean        | 22.9     |
| ep_reward_mean     | 187      |
| explained_variance | -0.0522  |
| fps                | 405      |
| nupdates           | 39700    |
| policy_entropy     | 0.11     |
| total_timesteps    | 198500   |
| value_loss         | 5.48e+04 |
---------------------------------
25.0
25.0
22.08
10.5
---------------------------------
| ep_len_mean        | 22.1     |
| ep_reward_mean     | 191      |
| explained_variance | 0.363    |
| fps                | 406      |
| nupdates           | 39800    |
| policy_entropy     | 0.00838  |
| total_timesteps    | 199000   |
| value_loss         | 1.55e+03 |
---------------------------------
---------------------------------
| ep_len_mean        | 22.1     |
| ep_reward_mean     | 191      |
| explained_variance | -0.0386  |
| fps                | 406      |
| nupdates           | 39900    |
| policy_entropy     | 0.02     |
| total_timesteps    | 199500   |
| value_loss         | 413      |
---------------------------------
9.0
9.0
20.74
10.0
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 194      |
| explained_variance | -2.19    |
| fps                | 406      |
| nupdates           | 40000    |
| policy_entropy     | 0.0459   |
| total_timesteps    | 200000   |
| value_loss         | 3.59e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 21.2     |
| ep_reward_mean     | 192      |
| explained_variance | -0.302   |
| fps                | 406      |
| nupdates           | 40100    |
| policy_entropy     | 0.264    |
| total_timesteps    | 200500   |
| value_loss         | 351      |
---------------------------------
9.0
9.0
19.62
10.0
---------------------------------
| ep_len_mean        | 19.6     |
| ep_reward_mean     | 192      |
| explained_variance | 0.263    |
| fps                | 406      |
| nupdates           | 40200    |
| policy_entropy     | 0.177    |
| total_timesteps    | 201000   |
| value_loss         | 4.57e+04 |
---------------------------------
----------------------------------
| ep_len_mean        | 19.8      |
| ep_reward_mean     | 191       |
| explained_variance | -1.19e-07 |
| fps                | 406       |
| nupdates           | 40300     |
| policy_entropy     | 0.219     |
| total_timesteps    | 201500    |
| value_loss         | 41.2      |
----------------------------------
58.0
58.0
23.02
15.0
---------------------------------
| ep_len_mean        | 23       |
| ep_reward_mean     | 180      |
| explained_variance | 0.618    |
| fps                | 406      |
| nupdates           | 40400    |
| policy_entropy     | 0.696    |
| total_timesteps    | 202000   |
| value_loss         | 505      |
---------------------------------
---------------------------------
| ep_len_mean        | 24.7     |
| ep_reward_mean     | 175      |
| explained_variance | -13.3    |
| fps                | 406      |
| nupdates           | 40500    |
| policy_entropy     | 0.00749  |
| total_timesteps    | 202500   |
| value_loss         | 2.84e+03 |
---------------------------------
36.0
36.0
23.92
11.5
---------------------------------
| ep_len_mean        | 23.9     |
| ep_reward_mean     | 179      |
| explained_variance | 0.000295 |
| fps                | 406      |
| nupdates           | 40600    |
| policy_entropy     | 0.0992   |
| total_timesteps    | 203000   |
| value_loss         | 6.47e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 22.7     |
| ep_reward_mean     | 185      |
| explained_variance | -25.8    |
| fps                | 406      |
| nupdates           | 40700    |
| policy_entropy     | 0.168    |
| total_timesteps    | 203500   |
| value_loss         | 209      |
---------------------------------
28.0
28.0
19.5
11.5
---------------------------------
| ep_len_mean        | 19.5     |
| ep_reward_mean     | 196      |
| explained_variance | -1.77    |
| fps                | 406      |
| nupdates           | 40800    |
| policy_entropy     | 0.332    |
| total_timesteps    | 204000   |
| value_loss         | 496      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.8     |
| ep_reward_mean     | 201      |
| explained_variance | 0.468    |
| fps                | 406      |
| nupdates           | 40900    |
| policy_entropy     | 0.00725  |
| total_timesteps    | 204500   |
| value_loss         | 57.2     |
---------------------------------
13.0
13.0
15.93
12.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 209      |
| explained_variance | -0.787   |
| fps                | 406      |
| nupdates           | 41000    |
| policy_entropy     | 0.162    |
| total_timesteps    | 205000   |
| value_loss         | 271      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 215      |
| explained_variance | 0.516    |
| fps                | 406      |
| nupdates           | 41100    |
| policy_entropy     | 0.0115   |
| total_timesteps    | 205500   |
| value_loss         | 62.9     |
---------------------------------
9.0
9.0
14.8
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.739    |
| fps                | 406      |
| nupdates           | 41200    |
| policy_entropy     | 0.0113   |
| total_timesteps    | 206000   |
| value_loss         | 46.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 213      |
| explained_variance | -5.21    |
| fps                | 406      |
| nupdates           | 41300    |
| policy_entropy     | 0.0446   |
| total_timesteps    | 206500   |
| value_loss         | 207      |
---------------------------------
10.0
10.0
16.1
11.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 212      |
| explained_variance | 0.912    |
| fps                | 406      |
| nupdates           | 41400    |
| policy_entropy     | 0.0491   |
| total_timesteps    | 207000   |
| value_loss         | 8.01     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 214      |
| explained_variance | 0.584    |
| fps                | 406      |
| nupdates           | 41500    |
| policy_entropy     | 0.0661   |
| total_timesteps    | 207500   |
| value_loss         | 110      |
---------------------------------
13.0
13.0
16.06
13.0
---------------------------------
| ep_len_mean        | 16.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.234    |
| fps                | 406      |
| nupdates           | 41600    |
| policy_entropy     | 0.00485  |
| total_timesteps    | 208000   |
| value_loss         | 518      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | 0.919    |
| fps                | 406      |
| nupdates           | 41700    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 208500   |
| value_loss         | 609      |
---------------------------------
9.0
9.0
15.6
20.5
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 214      |
| explained_variance | -4.85    |
| fps                | 407      |
| nupdates           | 41800    |
| policy_entropy     | 0.0826   |
| total_timesteps    | 209000   |
| value_loss         | 1e+03    |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 215      |
| explained_variance | -0.185   |
| fps                | 407      |
| nupdates           | 41900    |
| policy_entropy     | 0.0515   |
| total_timesteps    | 209500   |
| value_loss         | 303      |
---------------------------------
9.0
9.0
15.51
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.857    |
| fps                | 407      |
| nupdates           | 42000    |
| policy_entropy     | 0.153    |
| total_timesteps    | 210000   |
| value_loss         | 11.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 19.4     |
| ep_reward_mean     | 201      |
| explained_variance | -0.394   |
| fps                | 407      |
| nupdates           | 42100    |
| policy_entropy     | 0.121    |
| total_timesteps    | 210500   |
| value_loss         | 3.16e+04 |
---------------------------------
10.0
10.0
17.93
10.0
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 203      |
| explained_variance | -33.6    |
| fps                | 407      |
| nupdates           | 42200    |
| policy_entropy     | 0.245    |
| total_timesteps    | 211000   |
| value_loss         | 450      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.9     |
| ep_reward_mean     | 203      |
| explained_variance | -30.6    |
| fps                | 407      |
| nupdates           | 42300    |
| policy_entropy     | 0.0537   |
| total_timesteps    | 211500   |
| value_loss         | 2.07e+03 |
---------------------------------
9.0
9.0
14.52
10.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0.558    |
| fps                | 407      |
| nupdates           | 42400    |
| policy_entropy     | 0.249    |
| total_timesteps    | 212000   |
| value_loss         | 228      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 212      |
| explained_variance | -2.27    |
| fps                | 407      |
| nupdates           | 42500    |
| policy_entropy     | 0.376    |
| total_timesteps    | 212500   |
| value_loss         | 1.25e+03 |
---------------------------------
20.0
20.0
15.86
11.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.814    |
| fps                | 407      |
| nupdates           | 42600    |
| policy_entropy     | 0.0302   |
| total_timesteps    | 213000   |
| value_loss         | 130      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 213      |
| explained_variance | 0.617    |
| fps                | 407      |
| nupdates           | 42700    |
| policy_entropy     | 0.00533  |
| total_timesteps    | 213500   |
| value_loss         | 35.7     |
---------------------------------
9.0
9.0
13.83
11.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | -0.0195  |
| fps                | 407      |
| nupdates           | 42800    |
| policy_entropy     | 0.0221   |
| total_timesteps    | 214000   |
| value_loss         | 99.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 215      |
| explained_variance | -0.286   |
| fps                | 407      |
| nupdates           | 42900    |
| policy_entropy     | 0.36     |
| total_timesteps    | 214500   |
| value_loss         | 163      |
---------------------------------
10.0
10.0
14.51
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.598    |
| fps                | 407      |
| nupdates           | 43000    |
| policy_entropy     | 0.00667  |
| total_timesteps    | 215000   |
| value_loss         | 45.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.417    |
| fps                | 407      |
| nupdates           | 43100    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 215500   |
| value_loss         | 76.4     |
---------------------------------
22.0
22.0
14.37
19.5
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.923    |
| fps                | 407      |
| nupdates           | 43200    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 216000   |
| value_loss         | 402      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.529    |
| fps                | 407      |
| nupdates           | 43300    |
| policy_entropy     | 0.163    |
| total_timesteps    | 216500   |
| value_loss         | 29.6     |
---------------------------------
20.0
20.0
16.04
20.0
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 214      |
| explained_variance | 0.888    |
| fps                | 407      |
| nupdates           | 43400    |
| policy_entropy     | 0.163    |
| total_timesteps    | 217000   |
| value_loss         | 66.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 215      |
| explained_variance | 0.58     |
| fps                | 407      |
| nupdates           | 43500    |
| policy_entropy     | 0.0141   |
| total_timesteps    | 217500   |
| value_loss         | 33.1     |
---------------------------------
10.0
10.0
15.37
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.65     |
| fps                | 407      |
| nupdates           | 43600    |
| policy_entropy     | 0.0105   |
| total_timesteps    | 218000   |
| value_loss         | 37.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.944   |
| fps                | 407      |
| nupdates           | 43700    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 218500   |
| value_loss         | 273      |
---------------------------------
10.0
10.0
15.49
10.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.946    |
| fps                | 407      |
| nupdates           | 43800    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 219000   |
| value_loss         | 4.89     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.828    |
| fps                | 407      |
| nupdates           | 43900    |
| policy_entropy     | 0.00278  |
| total_timesteps    | 219500   |
| value_loss         | 39       |
---------------------------------
9.0
9.0
13.96
9.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 217      |
| explained_variance | 0.953    |
| fps                | 407      |
| nupdates           | 44000    |
| policy_entropy     | 0.00876  |
| total_timesteps    | 220000   |
| value_loss         | 4.36     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.393    |
| fps                | 407      |
| nupdates           | 44100    |
| policy_entropy     | 0.0197   |
| total_timesteps    | 220500   |
| value_loss         | 55.2     |
---------------------------------
11.0
11.0
13.67
11.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.37     |
| fps                | 407      |
| nupdates           | 44200    |
| policy_entropy     | 0.011    |
| total_timesteps    | 221000   |
| value_loss         | 292      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.893    |
| fps                | 407      |
| nupdates           | 44300    |
| policy_entropy     | 0.161    |
| total_timesteps    | 221500   |
| value_loss         | 14.8     |
---------------------------------
9.0
9.0
14.68
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 215      |
| explained_variance | -2.18    |
| fps                | 407      |
| nupdates           | 44400    |
| policy_entropy     | 0.316    |
| total_timesteps    | 222000   |
| value_loss         | 229      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.913    |
| fps                | 408      |
| nupdates           | 44500    |
| policy_entropy     | 0.00569  |
| total_timesteps    | 222500   |
| value_loss         | 9.63     |
---------------------------------
10.0
10.0
14.87
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.439    |
| fps                | 408      |
| nupdates           | 44600    |
| policy_entropy     | 0.00533  |
| total_timesteps    | 223000   |
| value_loss         | 399      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | -1.6     |
| fps                | 408      |
| nupdates           | 44700    |
| policy_entropy     | 0.0168   |
| total_timesteps    | 223500   |
| value_loss         | 46.1     |
---------------------------------
10.0
10.0
14.81
14.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.77     |
| fps                | 408      |
| nupdates           | 44800    |
| policy_entropy     | 0.125    |
| total_timesteps    | 224000   |
| value_loss         | 57.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.357    |
| fps                | 408      |
| nupdates           | 44900    |
| policy_entropy     | 0.0101   |
| total_timesteps    | 224500   |
| value_loss         | 66.1     |
---------------------------------
19.0
19.0
15.94
15.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.757    |
| fps                | 408      |
| nupdates           | 45000    |
| policy_entropy     | 0.25     |
| total_timesteps    | 225000   |
| value_loss         | 351      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.775    |
| fps                | 408      |
| nupdates           | 45100    |
| policy_entropy     | 0.00547  |
| total_timesteps    | 225500   |
| value_loss         | 576      |
---------------------------------
10.0
10.0
15.93
10.0
---------------------------------
| ep_len_mean        | 15.9     |
| ep_reward_mean     | 215      |
| explained_variance | 0.935    |
| fps                | 408      |
| nupdates           | 45200    |
| policy_entropy     | 0.0227   |
| total_timesteps    | 226000   |
| value_loss         | 5.16     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.6     |
| ep_reward_mean     | 213      |
| explained_variance | 0        |
| fps                | 408      |
| nupdates           | 45300    |
| policy_entropy     | 0.0527   |
| total_timesteps    | 226500   |
| value_loss         | 290      |
---------------------------------
17.0
17.0
20.66
11.0
---------------------------------
| ep_len_mean        | 20.7     |
| ep_reward_mean     | 193      |
| explained_variance | -1.37    |
| fps                | 408      |
| nupdates           | 45400    |
| policy_entropy     | 0.0116   |
| total_timesteps    | 227000   |
| value_loss         | 414      |
---------------------------------
---------------------------------
| ep_len_mean        | 21.4     |
| ep_reward_mean     | 190      |
| explained_variance | -0.577   |
| fps                | 408      |
| nupdates           | 45500    |
| policy_entropy     | 0.121    |
| total_timesteps    | 227500   |
| value_loss         | 890      |
---------------------------------
13.0
13.0
22.24
13.0
---------------------------------
| ep_len_mean        | 22.2     |
| ep_reward_mean     | 187      |
| explained_variance | -0.00167 |
| fps                | 408      |
| nupdates           | 45600    |
| policy_entropy     | 0.11     |
| total_timesteps    | 228000   |
| value_loss         | 5.86     |
---------------------------------
---------------------------------
| ep_len_mean        | 25.4     |
| ep_reward_mean     | 181      |
| explained_variance | -8.16    |
| fps                | 408      |
| nupdates           | 45700    |
| policy_entropy     | 0.0792   |
| total_timesteps    | 228500   |
| value_loss         | 1.21e+05 |
---------------------------------
22.0
22.0
26.54
21.0
---------------------------------
| ep_len_mean        | 26.5     |
| ep_reward_mean     | 179      |
| explained_variance | -1.3     |
| fps                | 408      |
| nupdates           | 45800    |
| policy_entropy     | 0.0353   |
| total_timesteps    | 229000   |
| value_loss         | 1.67e+04 |
---------------------------------
---------------------------------
| ep_len_mean        | 20.9     |
| ep_reward_mean     | 201      |
| explained_variance | 0        |
| fps                | 408      |
| nupdates           | 45900    |
| policy_entropy     | 0.263    |
| total_timesteps    | 229500   |
| value_loss         | 77.9     |
---------------------------------
22.0
22.0
18.38
23.0
---------------------------------
| ep_len_mean        | 18.4     |
| ep_reward_mean     | 207      |
| explained_variance | 0.67     |
| fps                | 408      |
| nupdates           | 46000    |
| policy_entropy     | 0.129    |
| total_timesteps    | 230000   |
| value_loss         | 217      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.7     |
| ep_reward_mean     | 211      |
| explained_variance | 0.968    |
| fps                | 408      |
| nupdates           | 46100    |
| policy_entropy     | 0.0156   |
| total_timesteps    | 230500   |
| value_loss         | 2.82     |
---------------------------------
20.0
20.0
15.83
12.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 213      |
| explained_variance | 0.677    |
| fps                | 408      |
| nupdates           | 46200    |
| policy_entropy     | 0.102    |
| total_timesteps    | 231000   |
| value_loss         | 62.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 215      |
| explained_variance | 0.626    |
| fps                | 408      |
| nupdates           | 46300    |
| policy_entropy     | 0.129    |
| total_timesteps    | 231500   |
| value_loss         | 27.7     |
---------------------------------
30.0
30.0
14.92
10.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 214      |
| explained_variance | 0.799    |
| fps                | 408      |
| nupdates           | 46400    |
| policy_entropy     | 0.0299   |
| total_timesteps    | 232000   |
| value_loss         | 72.8     |
---------------------------------
----------------------------------
| ep_len_mean        | 15.9      |
| ep_reward_mean     | 212       |
| explained_variance | -1.19e-07 |
| fps                | 408       |
| nupdates           | 46500     |
| policy_entropy     | 0.316     |
| total_timesteps    | 232500    |
| value_loss         | 112       |
----------------------------------
10.0
10.0
17.08
10.5
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 209      |
| explained_variance | 0.949    |
| fps                | 408      |
| nupdates           | 46600    |
| policy_entropy     | 0.00582  |
| total_timesteps    | 233000   |
| value_loss         | 4.13     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 211      |
| explained_variance | 0.706    |
| fps                | 408      |
| nupdates           | 46700    |
| policy_entropy     | 0.287    |
| total_timesteps    | 233500   |
| value_loss         | 77.8     |
---------------------------------
23.0
23.0
15.85
10.5
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.823    |
| fps                | 408      |
| nupdates           | 46800    |
| policy_entropy     | 0.00453  |
| total_timesteps    | 234000   |
| value_loss         | 22.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 216      |
| explained_variance | 0.876    |
| fps                | 408      |
| nupdates           | 46900    |
| policy_entropy     | 0.0076   |
| total_timesteps    | 234500   |
| value_loss         | 9.86     |
---------------------------------
11.0
11.0
13.73
10.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.536    |
| fps                | 408      |
| nupdates           | 47000    |
| policy_entropy     | 0.248    |
| total_timesteps    | 235000   |
| value_loss         | 38.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -1.69    |
| fps                | 408      |
| nupdates           | 47100    |
| policy_entropy     | 0.0806   |
| total_timesteps    | 235500   |
| value_loss         | 443      |
---------------------------------
10.0
10.0
14.91
10.0
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | -1.38    |
| fps                | 408      |
| nupdates           | 47200    |
| policy_entropy     | 0.481    |
| total_timesteps    | 236000   |
| value_loss         | 202      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 213      |
| explained_variance | -0.161   |
| fps                | 408      |
| nupdates           | 47300    |
| policy_entropy     | 0.00594  |
| total_timesteps    | 236500   |
| value_loss         | 592      |
---------------------------------
11.0
11.0
16.93
11.0
---------------------------------
| ep_len_mean        | 16.9     |
| ep_reward_mean     | 213      |
| explained_variance | 0.543    |
| fps                | 408      |
| nupdates           | 47400    |
| policy_entropy     | 0.221    |
| total_timesteps    | 237000   |
| value_loss         | 121      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.1     |
| ep_reward_mean     | 211      |
| explained_variance | -2.15    |
| fps                | 408      |
| nupdates           | 47500    |
| policy_entropy     | 0.213    |
| total_timesteps    | 237500   |
| value_loss         | 99.7     |
---------------------------------
21.0
21.0
15.31
15.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.594    |
| fps                | 408      |
| nupdates           | 47600    |
| policy_entropy     | 0.233    |
| total_timesteps    | 238000   |
| value_loss         | 90.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | -0.692   |
| fps                | 408      |
| nupdates           | 47700    |
| policy_entropy     | 0.177    |
| total_timesteps    | 238500   |
| value_loss         | 955      |
---------------------------------
11.0
11.0
15.49
11.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.601    |
| fps                | 408      |
| nupdates           | 47800    |
| policy_entropy     | 0.142    |
| total_timesteps    | 239000   |
| value_loss         | 169      |
---------------------------------
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 215      |
| explained_variance | 0.814    |
| fps                | 409      |
| nupdates           | 47900    |
| policy_entropy     | 0.373    |
| total_timesteps    | 239500   |
| value_loss         | 10.2     |
---------------------------------
11.0
11.0
16.53
11.0
---------------------------------
| ep_len_mean        | 16.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.0958   |
| fps                | 409      |
| nupdates           | 48000    |
| policy_entropy     | 0.544    |
| total_timesteps    | 240000   |
| value_loss         | 151      |
---------------------------------
---------------------------------
| ep_len_mean        | 17.2     |
| ep_reward_mean     | 215      |
| explained_variance | -1.15    |
| fps                | 409      |
| nupdates           | 48100    |
| policy_entropy     | 0.218    |
| total_timesteps    | 240500   |
| value_loss         | 542      |
---------------------------------
9.0
9.0
17.43
10.0
---------------------------------
| ep_len_mean        | 17.4     |
| ep_reward_mean     | 216      |
| explained_variance | 0.855    |
| fps                | 409      |
| nupdates           | 48200    |
| policy_entropy     | 0.00579  |
| total_timesteps    | 241000   |
| value_loss         | 12.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 217      |
| explained_variance | -0.268   |
| fps                | 409      |
| nupdates           | 48300    |
| policy_entropy     | 0.149    |
| total_timesteps    | 241500   |
| value_loss         | 144      |
---------------------------------
19.0
19.0
15.36
15.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.992    |
| fps                | 409      |
| nupdates           | 48400    |
| policy_entropy     | 0.012    |
| total_timesteps    | 242000   |
| value_loss         | 23.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.748    |
| fps                | 409      |
| nupdates           | 48500    |
| policy_entropy     | 0.00294  |
| total_timesteps    | 242500   |
| value_loss         | 21.6     |
---------------------------------
13.0
13.0
15.54
16.5
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.94     |
| fps                | 409      |
| nupdates           | 48600    |
| policy_entropy     | 0.0274   |
| total_timesteps    | 243000   |
| value_loss         | 5.37     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.597    |
| fps                | 409      |
| nupdates           | 48700    |
| policy_entropy     | 0.057    |
| total_timesteps    | 243500   |
| value_loss         | 16.3     |
---------------------------------
11.0
11.0
14.22
10.5
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.741    |
| fps                | 409      |
| nupdates           | 48800    |
| policy_entropy     | 0.0165   |
| total_timesteps    | 244000   |
| value_loss         | 35.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 216      |
| explained_variance | -2.46    |
| fps                | 409      |
| nupdates           | 48900    |
| policy_entropy     | 0.0911   |
| total_timesteps    | 244500   |
| value_loss         | 229      |
---------------------------------
9.0
9.0
14.14
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 216      |
| explained_variance | 0.913    |
| fps                | 409      |
| nupdates           | 49000    |
| policy_entropy     | 0.0376   |
| total_timesteps    | 245000   |
| value_loss         | 2.43     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.815    |
| fps                | 409      |
| nupdates           | 49100    |
| policy_entropy     | 0.0168   |
| total_timesteps    | 245500   |
| value_loss         | 15.7     |
---------------------------------
20.0
20.0
14.29
15.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | -2.55    |
| fps                | 409      |
| nupdates           | 49200    |
| policy_entropy     | 0.0896   |
| total_timesteps    | 246000   |
| value_loss         | 401      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.997    |
| fps                | 409      |
| nupdates           | 49300    |
| policy_entropy     | 0.00817  |
| total_timesteps    | 246500   |
| value_loss         | 0.64     |
---------------------------------
21.0
21.0
14.68
20.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.701    |
| fps                | 409      |
| nupdates           | 49400    |
| policy_entropy     | 0.129    |
| total_timesteps    | 247000   |
| value_loss         | 15.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.0948   |
| fps                | 409      |
| nupdates           | 49500    |
| policy_entropy     | 0.208    |
| total_timesteps    | 247500   |
| value_loss         | 135      |
---------------------------------
9.0
9.0
15.32
11.0
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 217      |
| explained_variance | -0.864   |
| fps                | 409      |
| nupdates           | 49600    |
| policy_entropy     | 0.133    |
| total_timesteps    | 248000   |
| value_loss         | 217      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.971    |
| fps                | 409      |
| nupdates           | 49700    |
| policy_entropy     | 0.0144   |
| total_timesteps    | 248500   |
| value_loss         | 1.78     |
---------------------------------
21.0
21.0
14.39
20.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.651    |
| fps                | 409      |
| nupdates           | 49800    |
| policy_entropy     | 0.00425  |
| total_timesteps    | 249000   |
| value_loss         | 25.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | -0.276   |
| fps                | 409      |
| nupdates           | 49900    |
| policy_entropy     | 0.0768   |
| total_timesteps    | 249500   |
| value_loss         | 153      |
---------------------------------
30.0
30.0
14.7
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 219      |
| explained_variance | -2.28    |
| fps                | 409      |
| nupdates           | 50000    |
| policy_entropy     | 0.101    |
| total_timesteps    | 250000   |
| value_loss         | 218      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 219      |
| explained_variance | 0.954    |
| fps                | 409      |
| nupdates           | 50100    |
| policy_entropy     | 0.00999  |
| total_timesteps    | 250500   |
| value_loss         | 4.85     |
---------------------------------
10.0
10.0
14.69
10.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | -8.88    |
| fps                | 409      |
| nupdates           | 50200    |
| policy_entropy     | 0.508    |
| total_timesteps    | 251000   |
| value_loss         | 659      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 215      |
| explained_variance | 0.161    |
| fps                | 409      |
| nupdates           | 50300    |
| policy_entropy     | 0.237    |
| total_timesteps    | 251500   |
| value_loss         | 531      |
---------------------------------
10.0
10.0
15.78
10.0
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 214      |
| explained_variance | 0.79     |
| fps                | 409      |
| nupdates           | 50400    |
| policy_entropy     | 0.0215   |
| total_timesteps    | 252000   |
| value_loss         | 85.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 16.2     |
| ep_reward_mean     | 214      |
| explained_variance | -3.66    |
| fps                | 409      |
| nupdates           | 50500    |
| policy_entropy     | 0.0519   |
| total_timesteps    | 252500   |
| value_loss         | 121      |
---------------------------------
10.0
10.0
15.5
10.0
---------------------------------
| ep_len_mean        | 15.5     |
| ep_reward_mean     | 216      |
| explained_variance | 0.929    |
| fps                | 409      |
| nupdates           | 50600    |
| policy_entropy     | 0.209    |
| total_timesteps    | 253000   |
| value_loss         | 4.58     |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | 0.995    |
| fps                | 409      |
| nupdates           | 50700    |
| policy_entropy     | 0.0512   |
| total_timesteps    | 253500   |
| value_loss         | 1.09     |
---------------------------------
21.0
21.0
14.81
11.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.259    |
| fps                | 409      |
| nupdates           | 50800    |
| policy_entropy     | 0.0852   |
| total_timesteps    | 254000   |
| value_loss         | 27.3     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 218      |
| explained_variance | 0.953    |
| fps                | 409      |
| nupdates           | 50900    |
| policy_entropy     | 0.00512  |
| total_timesteps    | 254500   |
| value_loss         | 9.5      |
---------------------------------
11.0
11.0
14.77
20.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 219      |
| explained_variance | -0.382   |
| fps                | 409      |
| nupdates           | 51000    |
| policy_entropy     | 0.0518   |
| total_timesteps    | 255000   |
| value_loss         | 45.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.923    |
| fps                | 409      |
| nupdates           | 51100    |
| policy_entropy     | 0.00633  |
| total_timesteps    | 255500   |
| value_loss         | 14       |
---------------------------------
103.0
103.0
14.92
10.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | -2.7     |
| fps                | 409      |
| nupdates           | 51200    |
| policy_entropy     | 0.183    |
| total_timesteps    | 256000   |
| value_loss         | 156      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.937    |
| fps                | 409      |
| nupdates           | 51300    |
| policy_entropy     | 0.00619  |
| total_timesteps    | 256500   |
| value_loss         | 11.1     |
---------------------------------
13.0
13.0
14.76
11.5
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 217      |
| explained_variance | 0.964    |
| fps                | 409      |
| nupdates           | 51400    |
| policy_entropy     | 0.0074   |
| total_timesteps    | 257000   |
| value_loss         | 5.65     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | 0.799    |
| fps                | 410      |
| nupdates           | 51500    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 257500   |
| value_loss         | 55.9     |
---------------------------------
9.0
9.0
15.29
10.5
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.356    |
| fps                | 410      |
| nupdates           | 51600    |
| policy_entropy     | 0.00426  |
| total_timesteps    | 258000   |
| value_loss         | 406      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 217      |
| explained_variance | 0.985    |
| fps                | 410      |
| nupdates           | 51700    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 258500   |
| value_loss         | 2.02     |
---------------------------------
37.0
37.0
14.91
12.5
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 218      |
| explained_variance | 0.595    |
| fps                | 410      |
| nupdates           | 51800    |
| policy_entropy     | 0.0163   |
| total_timesteps    | 259000   |
| value_loss         | 145      |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | -0.513   |
| fps                | 410      |
| nupdates           | 51900    |
| policy_entropy     | 0.279    |
| total_timesteps    | 259500   |
| value_loss         | 340      |
---------------------------------
21.0
21.0
13.84
11.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.261    |
| fps                | 410      |
| nupdates           | 52000    |
| policy_entropy     | 0.0204   |
| total_timesteps    | 260000   |
| value_loss         | 39.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 222      |
| explained_variance | 0.448    |
| fps                | 410      |
| nupdates           | 52100    |
| policy_entropy     | 0.00447  |
| total_timesteps    | 260500   |
| value_loss         | 424      |
---------------------------------
9.0
9.0
13.88
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 221      |
| explained_variance | 0.943    |
| fps                | 410      |
| nupdates           | 52200    |
| policy_entropy     | 0.00388  |
| total_timesteps    | 261000   |
| value_loss         | 10.8     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 221      |
| explained_variance | 0.451    |
| fps                | 410      |
| nupdates           | 52300    |
| policy_entropy     | 0.00383  |
| total_timesteps    | 261500   |
| value_loss         | 29.8     |
---------------------------------
20.0
20.0
13.75
11.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.962    |
| fps                | 410      |
| nupdates           | 52400    |
| policy_entropy     | 0.0558   |
| total_timesteps    | 262000   |
| value_loss         | 8.14     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 222      |
| explained_variance | 0.443    |
| fps                | 410      |
| nupdates           | 52500    |
| policy_entropy     | 0.0193   |
| total_timesteps    | 262500   |
| value_loss         | 299      |
---------------------------------
11.0
11.0
14.18
10.5
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 222      |
| explained_variance | 0.949    |
| fps                | 410      |
| nupdates           | 52600    |
| policy_entropy     | 0.0114   |
| total_timesteps    | 263000   |
| value_loss         | 8.12     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 220      |
| explained_variance | -0.186   |
| fps                | 410      |
| nupdates           | 52700    |
| policy_entropy     | 0.2      |
| total_timesteps    | 263500   |
| value_loss         | 198      |
---------------------------------
11.0
11.0
14.02
11.0
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 219      |
| explained_variance | -1.24    |
| fps                | 410      |
| nupdates           | 52800    |
| policy_entropy     | 0.232    |
| total_timesteps    | 264000   |
| value_loss         | 188      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.233    |
| fps                | 410      |
| nupdates           | 52900    |
| policy_entropy     | 0.12     |
| total_timesteps    | 264500   |
| value_loss         | 124      |
---------------------------------
10.0
10.0
14.72
15.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.975    |
| fps                | 410      |
| nupdates           | 53000    |
| policy_entropy     | 0.00397  |
| total_timesteps    | 265000   |
| value_loss         | 3.4      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.457    |
| fps                | 410      |
| nupdates           | 53100    |
| policy_entropy     | 0.143    |
| total_timesteps    | 265500   |
| value_loss         | 100      |
---------------------------------
30.0
30.0
15.07
15.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.142    |
| fps                | 410      |
| nupdates           | 53200    |
| policy_entropy     | 0.00651  |
| total_timesteps    | 266000   |
| value_loss         | 130      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 217      |
| explained_variance | 0.978    |
| fps                | 410      |
| nupdates           | 53300    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 266500   |
| value_loss         | 1.86     |
---------------------------------
19.0
19.0
14.54
11.0
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 218      |
| explained_variance | 0.962    |
| fps                | 410      |
| nupdates           | 53400    |
| policy_entropy     | 0.00838  |
| total_timesteps    | 267000   |
| value_loss         | 637      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | -0.72    |
| fps                | 410      |
| nupdates           | 53500    |
| policy_entropy     | 0.00813  |
| total_timesteps    | 267500   |
| value_loss         | 179      |
---------------------------------
11.0
11.0
13.34
10.0
Saving new best model to results\NovelGridworld-v0\NovelGridworld-v0_300000_STEP_30_200_best_model
---------------------------------
| ep_len_mean        | 13.3     |
| ep_reward_mean     | 222      |
| explained_variance | 0.834    |
| fps                | 410      |
| nupdates           | 53600    |
| policy_entropy     | 0.00365  |
| total_timesteps    | 268000   |
| value_loss         | 13.5     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.5     |
| ep_reward_mean     | 221      |
| explained_variance | -2.13    |
| fps                | 410      |
| nupdates           | 53700    |
| policy_entropy     | 0.0914   |
| total_timesteps    | 268500   |
| value_loss         | 761      |
---------------------------------
10.0
10.0
14.54
10.5
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 214      |
| explained_variance | 0        |
| fps                | 410      |
| nupdates           | 53800    |
| policy_entropy     | 0.259    |
| total_timesteps    | 269000   |
| value_loss         | 97       |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 212      |
| explained_variance | 0.481    |
| fps                | 410      |
| nupdates           | 53900    |
| policy_entropy     | 0.0906   |
| total_timesteps    | 269500   |
| value_loss         | 33.1     |
---------------------------------
9.0
9.0
16.45
10.0
---------------------------------
| ep_len_mean        | 16.4     |
| ep_reward_mean     | 211      |
| explained_variance | 0.923    |
| fps                | 410      |
| nupdates           | 54000    |
| policy_entropy     | 0.00379  |
| total_timesteps    | 270000   |
| value_loss         | 3.2      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.8     |
| ep_reward_mean     | 215      |
| explained_variance | 0.912    |
| fps                | 410      |
| nupdates           | 54100    |
| policy_entropy     | 0.0127   |
| total_timesteps    | 270500   |
| value_loss         | 11.3     |
---------------------------------
10.0
10.0
15.03
19.0
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 216      |
| explained_variance | 0.572    |
| fps                | 410      |
| nupdates           | 54200    |
| policy_entropy     | 0.189    |
| total_timesteps    | 271000   |
| value_loss         | 21.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | 0.767    |
| fps                | 410      |
| nupdates           | 54300    |
| policy_entropy     | 0.0241   |
| total_timesteps    | 271500   |
| value_loss         | 31.2     |
---------------------------------
11.0
11.0
14.2
10.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 217      |
| explained_variance | -0.47    |
| fps                | 410      |
| nupdates           | 54400    |
| policy_entropy     | 0.0505   |
| total_timesteps    | 272000   |
| value_loss         | 409      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 220      |
| explained_variance | 0.955    |
| fps                | 410      |
| nupdates           | 54500    |
| policy_entropy     | 0.00528  |
| total_timesteps    | 272500   |
| value_loss         | 19.1     |
---------------------------------
10.0
10.0
14.67
14.5
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.995    |
| fps                | 410      |
| nupdates           | 54600    |
| policy_entropy     | 0.0117   |
| total_timesteps    | 273000   |
| value_loss         | 11.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 222      |
| explained_variance | 0.62     |
| fps                | 410      |
| nupdates           | 54700    |
| policy_entropy     | 0.019    |
| total_timesteps    | 273500   |
| value_loss         | 11.6     |
---------------------------------
20.0
20.0
14.71
11.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 221      |
| explained_variance | 0.095    |
| fps                | 410      |
| nupdates           | 54800    |
| policy_entropy     | 0.024    |
| total_timesteps    | 274000   |
| value_loss         | 43.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.875    |
| fps                | 410      |
| nupdates           | 54900    |
| policy_entropy     | 0.00371  |
| total_timesteps    | 274500   |
| value_loss         | 42.4     |
---------------------------------
20.0
20.0
13.7
20.0
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 219      |
| explained_variance | 0.954    |
| fps                | 410      |
| nupdates           | 55000    |
| policy_entropy     | 0.00313  |
| total_timesteps    | 275000   |
| value_loss         | 9.28     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 219      |
| explained_variance | 0.638    |
| fps                | 410      |
| nupdates           | 55100    |
| policy_entropy     | 0.13     |
| total_timesteps    | 275500   |
| value_loss         | 76.5     |
---------------------------------
10.0
10.0
14.09
11.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.917    |
| fps                | 410      |
| nupdates           | 55200    |
| policy_entropy     | 0.00754  |
| total_timesteps    | 276000   |
| value_loss         | 7.97     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 221      |
| explained_variance | -2.01    |
| fps                | 410      |
| nupdates           | 55300    |
| policy_entropy     | 0.145    |
| total_timesteps    | 276500   |
| value_loss         | 187      |
---------------------------------
28.0
28.0
15.1
19.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.193    |
| fps                | 410      |
| nupdates           | 55400    |
| policy_entropy     | 0.00768  |
| total_timesteps    | 277000   |
| value_loss         | 379      |
---------------------------------
---------------------------------
| ep_len_mean        | 16       |
| ep_reward_mean     | 217      |
| explained_variance | -0.573   |
| fps                | 410      |
| nupdates           | 55500    |
| policy_entropy     | 0.00934  |
| total_timesteps    | 277500   |
| value_loss         | 182      |
---------------------------------
11.0
11.0
15.7
11.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 217      |
| explained_variance | -0.153   |
| fps                | 410      |
| nupdates           | 55600    |
| policy_entropy     | 0.146    |
| total_timesteps    | 278000   |
| value_loss         | 81.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 220      |
| explained_variance | 0.813    |
| fps                | 410      |
| nupdates           | 55700    |
| policy_entropy     | 0.00726  |
| total_timesteps    | 278500   |
| value_loss         | 33.1     |
---------------------------------
11.0
11.0
13.83
15.0
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.0513   |
| fps                | 410      |
| nupdates           | 55800    |
| policy_entropy     | 0.0515   |
| total_timesteps    | 279000   |
| value_loss         | 232      |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | 0.966    |
| fps                | 411      |
| nupdates           | 55900    |
| policy_entropy     | 0.0118   |
| total_timesteps    | 279500   |
| value_loss         | 3.88     |
---------------------------------
20.0
20.0
14.85
20.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 216      |
| explained_variance | 0.234    |
| fps                | 411      |
| nupdates           | 56000    |
| policy_entropy     | 0.00745  |
| total_timesteps    | 280000   |
| value_loss         | 83       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 216      |
| explained_variance | 0.992    |
| fps                | 411      |
| nupdates           | 56100    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 280500   |
| value_loss         | 1.05     |
---------------------------------
10.0
10.0
15.12
15.0
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.98     |
| fps                | 411      |
| nupdates           | 56200    |
| policy_entropy     | 0.00924  |
| total_timesteps    | 281000   |
| value_loss         | 2.94     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 217      |
| explained_variance | -1.27    |
| fps                | 411      |
| nupdates           | 56300    |
| policy_entropy     | 0.0533   |
| total_timesteps    | 281500   |
| value_loss         | 404      |
---------------------------------
13.0
13.0
15.22
21.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.674    |
| fps                | 411      |
| nupdates           | 56400    |
| policy_entropy     | 0.121    |
| total_timesteps    | 282000   |
| value_loss         | 255      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | -1.77    |
| fps                | 411      |
| nupdates           | 56500    |
| policy_entropy     | 0.05     |
| total_timesteps    | 282500   |
| value_loss         | 186      |
---------------------------------
10.0
10.0
14.67
10.0
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 216      |
| explained_variance | 0.949    |
| fps                | 411      |
| nupdates           | 56600    |
| policy_entropy     | 0.0217   |
| total_timesteps    | 283000   |
| value_loss         | 8.21     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 217      |
| explained_variance | -0.666   |
| fps                | 411      |
| nupdates           | 56700    |
| policy_entropy     | 0.127    |
| total_timesteps    | 283500   |
| value_loss         | 459      |
---------------------------------
9.0
9.0
15.39
10.0
---------------------------------
| ep_len_mean        | 15.4     |
| ep_reward_mean     | 214      |
| explained_variance | 0.188    |
| fps                | 411      |
| nupdates           | 56800    |
| policy_entropy     | 0.006    |
| total_timesteps    | 284000   |
| value_loss         | 299      |
---------------------------------
---------------------------------
| ep_len_mean        | 15       |
| ep_reward_mean     | 214      |
| explained_variance | 0.922    |
| fps                | 411      |
| nupdates           | 56900    |
| policy_entropy     | 0.00989  |
| total_timesteps    | 284500   |
| value_loss         | 9.85     |
---------------------------------
20.0
20.0
15.65
22.0
---------------------------------
| ep_len_mean        | 15.7     |
| ep_reward_mean     | 214      |
| explained_variance | 0.635    |
| fps                | 411      |
| nupdates           | 57000    |
| policy_entropy     | 0.113    |
| total_timesteps    | 285000   |
| value_loss         | 28.7     |
---------------------------------
---------------------------------
| ep_len_mean        | 15.1     |
| ep_reward_mean     | 216      |
| explained_variance | -1.08    |
| fps                | 411      |
| nupdates           | 57100    |
| policy_entropy     | 0.00492  |
| total_timesteps    | 285500   |
| value_loss         | 184      |
---------------------------------
9.0
9.0
15.24
10.0
---------------------------------
| ep_len_mean        | 15.2     |
| ep_reward_mean     | 216      |
| explained_variance | 0.952    |
| fps                | 411      |
| nupdates           | 57200    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 286000   |
| value_loss         | 5.93     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.7     |
| ep_reward_mean     | 220      |
| explained_variance | 0.129    |
| fps                | 411      |
| nupdates           | 57300    |
| policy_entropy     | 0.171    |
| total_timesteps    | 286500   |
| value_loss         | 127      |
---------------------------------
10.0
10.0
13.11
15.0
---------------------------------
| ep_len_mean        | 13.1     |
| ep_reward_mean     | 221      |
| explained_variance | -0.191   |
| fps                | 411      |
| nupdates           | 57400    |
| policy_entropy     | 0.0484   |
| total_timesteps    | 287000   |
| value_loss         | 56.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 13       |
| ep_reward_mean     | 221      |
| explained_variance | 0.91     |
| fps                | 411      |
| nupdates           | 57500    |
| policy_entropy     | 0.00436  |
| total_timesteps    | 287500   |
| value_loss         | 7.22     |
---------------------------------
11.0
11.0
13.36
14.5
---------------------------------
| ep_len_mean        | 13.4     |
| ep_reward_mean     | 221      |
| explained_variance | 0.69     |
| fps                | 411      |
| nupdates           | 57600    |
| policy_entropy     | 0.328    |
| total_timesteps    | 288000   |
| value_loss         | 17.6     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.8     |
| ep_reward_mean     | 221      |
| explained_variance | -1.55    |
| fps                | 411      |
| nupdates           | 57700    |
| policy_entropy     | 0.143    |
| total_timesteps    | 288500   |
| value_loss         | 233      |
---------------------------------
10.0
10.0
13.88
11.0
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 219      |
| explained_variance | -1.76    |
| fps                | 411      |
| nupdates           | 57800    |
| policy_entropy     | 0.0075   |
| total_timesteps    | 289000   |
| value_loss         | 61.9     |
---------------------------------
---------------------------------
| ep_len_mean        | 13.9     |
| ep_reward_mean     | 217      |
| explained_variance | -1.6     |
| fps                | 411      |
| nupdates           | 57900    |
| policy_entropy     | 0.0444   |
| total_timesteps    | 289500   |
| value_loss         | 304      |
---------------------------------
21.0
21.0
14.07
10.0
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | -0.219   |
| fps                | 411      |
| nupdates           | 58000    |
| policy_entropy     | 0.162    |
| total_timesteps    | 290000   |
| value_loss         | 28.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.992    |
| fps                | 411      |
| nupdates           | 58100    |
| policy_entropy     | 0.0205   |
| total_timesteps    | 290500   |
| value_loss         | 9.81     |
---------------------------------
31.0
31.0
14.02
10.5
---------------------------------
| ep_len_mean        | 14       |
| ep_reward_mean     | 218      |
| explained_variance | -0.204   |
| fps                | 411      |
| nupdates           | 58200    |
| policy_entropy     | 0.0197   |
| total_timesteps    | 291000   |
| value_loss         | 104      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.685    |
| fps                | 411      |
| nupdates           | 58300    |
| policy_entropy     | 0.0215   |
| total_timesteps    | 291500   |
| value_loss         | 20.9     |
---------------------------------
9.0
9.0
14.82
10.0
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 218      |
| explained_variance | 0.716    |
| fps                | 411      |
| nupdates           | 58400    |
| policy_entropy     | 0.065    |
| total_timesteps    | 292000   |
| value_loss         | 43.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 218      |
| explained_variance | 0.23     |
| fps                | 411      |
| nupdates           | 58500    |
| policy_entropy     | 0.359    |
| total_timesteps    | 292500   |
| value_loss         | 341      |
---------------------------------
10.0
10.0
14.22
20.0
---------------------------------
| ep_len_mean        | 14.2     |
| ep_reward_mean     | 218      |
| explained_variance | 0.943    |
| fps                | 411      |
| nupdates           | 58600    |
| policy_entropy     | 0.0338   |
| total_timesteps    | 293000   |
| value_loss         | 2.06     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.5     |
| ep_reward_mean     | 219      |
| explained_variance | 0.967    |
| fps                | 411      |
| nupdates           | 58700    |
| policy_entropy     | 0.0247   |
| total_timesteps    | 293500   |
| value_loss         | 3.21     |
---------------------------------
10.0
10.0
14.62
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | -1.58    |
| fps                | 411      |
| nupdates           | 58800    |
| policy_entropy     | 0.332    |
| total_timesteps    | 294000   |
| value_loss         | 544      |
---------------------------------
---------------------------------
| ep_len_mean        | 14.8     |
| ep_reward_mean     | 221      |
| explained_variance | 0.379    |
| fps                | 411      |
| nupdates           | 58900    |
| policy_entropy     | 0.0138   |
| total_timesteps    | 294500   |
| value_loss         | 20.2     |
---------------------------------
10.0
10.0
14.6
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 221      |
| explained_variance | 0.587    |
| fps                | 411      |
| nupdates           | 59000    |
| policy_entropy     | 0.00513  |
| total_timesteps    | 295000   |
| value_loss         | 47.1     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 220      |
| explained_variance | 0.968    |
| fps                | 411      |
| nupdates           | 59100    |
| policy_entropy     | 0.0619   |
| total_timesteps    | 295500   |
| value_loss         | 2.69     |
---------------------------------
10.0
10.0
14.29
14.5
---------------------------------
| ep_len_mean        | 14.3     |
| ep_reward_mean     | 218      |
| explained_variance | 0.681    |
| fps                | 411      |
| nupdates           | 59200    |
| policy_entropy     | 0.0936   |
| total_timesteps    | 296000   |
| value_loss         | 37.2     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.7     |
| ep_reward_mean     | 217      |
| explained_variance | 0.961    |
| fps                | 411      |
| nupdates           | 59300    |
| policy_entropy     | 0.00965  |
| total_timesteps    | 296500   |
| value_loss         | 4.58     |
---------------------------------
11.0
11.0
14.14
10.5
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 218      |
| explained_variance | 0.909    |
| fps                | 411      |
| nupdates           | 59400    |
| policy_entropy     | 0.0132   |
| total_timesteps    | 297000   |
| value_loss         | 25.4     |
---------------------------------
---------------------------------
| ep_len_mean        | 14.1     |
| ep_reward_mean     | 220      |
| explained_variance | -0.596   |
| fps                | 411      |
| nupdates           | 59500    |
| policy_entropy     | 0.0247   |
| total_timesteps    | 297500   |
| value_loss         | 286      |
---------------------------------
14.0
14.0
14.6
10.0
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 218      |
| explained_variance | 0.301    |
| fps                | 411      |
| nupdates           | 59600    |
| policy_entropy     | 0.0287   |
| total_timesteps    | 298000   |
| value_loss         | 267      |
---------------------------------
---------------------------------
| ep_len_mean        | 15.3     |
| ep_reward_mean     | 216      |
| explained_variance | 0.569    |
| fps                | 411      |
| nupdates           | 59700    |
| policy_entropy     | 0.00601  |
| total_timesteps    | 298500   |
| value_loss         | 89.6     |
---------------------------------
19.0
19.0
14.61
10.5
---------------------------------
| ep_len_mean        | 14.6     |
| ep_reward_mean     | 216      |
| explained_variance | 0.78     |
| fps                | 411      |
| nupdates           | 59800    |
| policy_entropy     | 0.00304  |
| total_timesteps    | 299000   |
| value_loss         | 27       |
---------------------------------
---------------------------------
| ep_len_mean        | 14.9     |
| ep_reward_mean     | 217      |
| explained_variance | -0.39    |
| fps                | 411      |
| nupdates           | 59900    |
| policy_entropy     | 0.0242   |
| total_timesteps    | 299500   |
| value_loss         | 283      |
---------------------------------
9.0
9.0
14.4
15.0
---------------------------------
| ep_len_mean        | 14.4     |
| ep_reward_mean     | 217      |
| explained_variance | 0.828    |
| fps                | 411      |
| nupdates           | 60000    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 300000   |
| value_loss         | 45.6     |
---------------------------------